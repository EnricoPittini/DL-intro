{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558285f4",
   "metadata": {},
   "source": [
    "# GAN : Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56bcbfaa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e65a30b",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e55a1",
   "metadata": {},
   "source": [
    "Let's briefly see how GAN works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f10b2b",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cd346753",
   "metadata": {},
   "source": [
    "We implement the **generator** $P(X|z)$ as a NN. It takes in input a latent vector $z$ (i.e. random seed/noise) and it generates an image $\\hat{X}$. We remind that the prior distribution $P(z)$ is known (gaussian $N(0,1))$: so, we know how to sample a latent encoding $z$.\n",
    "\n",
    "We couple the generator with another NN: the **discriminator**. It's a classic classifier NN. It takes in input an instance (either real instance $X$ or generated by the generator $\\hat{X}$) and it classifies it either as real or fake. It is a binary classifier NN. Labels $1/0$: $1$ for \"real\", $0$ for fake. The output of the discriminator is the probability of being real.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b971c",
   "metadata": {},
   "source": [
    "Intuitively, the training works in the following way. The two NNs are trained in an alterning way: when one is trained, the other is freezed.\n",
    "1. The generator is freezed. The discriminator is trained.\n",
    "2. The discriminator is freezed. The generator is trained.\n",
    "3. The generator is freezed. The discriminator is trained.\n",
    "\n",
    "...\n",
    "\n",
    "The two NNS have dual and opposite objectives. The aim of the discriminator is to discriminate the generated images from the real ones, while the aim of the generator is to fool the discriminator. The training is like a Min-Max game: two opponents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6393d1",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81187bb1",
   "metadata": {},
   "source": [
    "Loss $V(D,G)$: it depends on both the discriminator $D$ and the generator $G$.\n",
    "\n",
    "The loss has two components: component which measures the goodness of the discriminator in detecting the real images and component which measures the goodness of the discriminator in detecting the fake images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac91e7f",
   "metadata": {},
   "source": [
    "**Goodness of the discriminator in detecting the real images**\n",
    "\n",
    "Suppose we have a real image $X$. $D(X)$ is the output of the discriminator: probability of beign \"real\" (i.e. $1$).\n",
    "\n",
    "We compute $log(D(X))$: the bigger it is, the better is the discriminator in detecting that $X$ is real.\n",
    "\n",
    "Let $P_{data}$ the portion of the training set containing the real images. The mean $E_{X \\in P_{data}}(logD(X))$ is the measure of the goodness of the discriminator in detecting the real images. Average of $log(D(X))$ across all real images $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad1e5e",
   "metadata": {},
   "source": [
    "**Goodness of the discriminator in detecting fake images**\n",
    "\n",
    "Suppose that we have a latent encoding $z$. We generate a fake image using the generator $\\hat{X} = G(z)$. $D(G(z))$ is the output of the discriminator on that fake image: probability of being real. We consider $log(1-D(G(z)))$: the bigger is that value, and the better is the discriminator in detecting that this image is fake.\n",
    "\n",
    "Let $P_z$ be the set of generated latent encodings $z$ for the training. The mean $E_{z \\in P_z}(log(1-D(G(z))))$ is the measure of the goodnes of the generator in detecting the fake images. Average of $log(1-D(G(z)))$ across all the latent encodings $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ea459",
   "metadata": {},
   "source": [
    "**Loss function**\n",
    "\n",
    "The loss function is the sum of these two components. $V(D,G)=E_{X \\in P_{data}}(logD(X)) + E_{z \\in P_z}(log(1-D(G(z))))$\n",
    "\n",
    "- The discriminator $D$ wants to maximize this loss\n",
    "- The generator $G$ wants to minimize this loss. Actually, it does not want to minimize the full loss $V(D,G)$, but only $E_{z \\in P_z}(log(1-D(G(z))))$, because $G$ does not impact the other component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deecd07",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451291ab",
   "metadata": {},
   "source": [
    "In an alterning way, we train and the generator, while the other NN is freezed.\n",
    "- While we train the discriminator, the generator is freezed.\n",
    "- While we train the generator, the discriminator is freezed.\n",
    "\n",
    "Min-Max alterning game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6032a",
   "metadata": {},
   "source": [
    "**Algorithm**\n",
    "\n",
    "In each training step\n",
    "1. Training step for the discriminator. We freeze the generator.\n",
    "    - Take a batch of $m$ real images $X^{(i)}$.\n",
    "    - Take a batch of $m$ latent encodings $z^{(i)}$. (Sampled from N(0,1)).\n",
    "    - Compute the loss $1/m * \\sum_{i=1}^m(logD(X^{(i)})) + log(1-D(G(z^{(i)}))))$\n",
    "    - Update the weigths of the discriminator by performing gradient ascent (maximization), backpropagating this loss.\n",
    "2. Training step for the generator. We freeze the discriminator.\n",
    "    - Take a batch of $m$ latent encodings $z^{(i)}$. (Sampled from N(0,1)).\n",
    "    - Compute the loss $\\sum_{i=1}^m(log(1-D(G(z^{(i)}))))$\n",
    "    - Update the weigths of the generator by performing gradient descent (minimization), backpropagating this loss."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1d8e6dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994c1eeb",
   "metadata": {},
   "source": [
    "## GAN MNIST DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794f9ce",
   "metadata": {},
   "source": [
    "Let's implement the GAN model on the MNIST dataset. In particular, we use Conv layers: both the discriminator and the generator are Conv NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9865ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945ba0b",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f3175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04db4d",
   "metadata": {},
   "source": [
    "Normalization. This time we don't normalize into $[0,1]$, but into $[-1,1]$ (arbitrary choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34c604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - 127.5) / 127.5  # Normalize the values into [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf528852",
   "metadata": {},
   "source": [
    "Adding the channels dimension. Beacuse we use Conv NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fb529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bc6d74",
   "metadata": {},
   "source": [
    "### Latent dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474da08f",
   "metadata": {},
   "source": [
    "We fix the size of the random seed/latent encoding $z$ to $100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c911bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2c9fd",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77420b8",
   "metadata": {},
   "source": [
    "We define it as a Conv NN. It takes in input a latent encoding $z$ and it generates an images $X$.\n",
    "\n",
    "So, it starts from a flat input of dimension $100$, and it generates a structured output of dimensions $28x28x1$.\n",
    "\n",
    "For doing so, we follow this pattern.\n",
    "1. Input $z$: dimension $100$.\n",
    "2. Dense layer, producing $7*7*256=12544$ values.\n",
    "\n",
    "Now, we want to increase the spatial dimensions. For doing so, we use Transposed Conv layers.\n",
    "\n",
    "3. Reshaping from flat dimension $12544$ to dimensions $7, 7, 256$. \n",
    "3. Transposed Conv layer, with output dimensions $7, 7, 128$.\n",
    "4. Transposed Conv layer, with output dimensions $14, 14, 64$.\n",
    "5. Transposed Conv layer, with output dimensions $28, 28, 1$. The output is the generated image $\\hat{X}$. THe activation function is **arctan**, beacuse we want to generate values in the range $[-1,1]$.\n",
    "\n",
    "In addition, we use also the **leaky relu** activation function and the Batch normalization, in all the layers except the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1aa26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f010143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: latent encoding z\n",
    "zin = Input(shape=(latent_dim,))\n",
    "\n",
    "# Dense layer\n",
    "z = Dense(units=7*7*256, use_bias=False)(zin)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "\n",
    "# Reshaping\n",
    "z = Reshape((7,7,256))(z)\n",
    "\n",
    "# Transposed Conv layer\n",
    "z = Conv2DTranspose(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "\n",
    "# Transposed Conv layer\n",
    "z = Conv2DTranspose(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU()(z)\n",
    "\n",
    "# Last layer: transposed Conv layer. It returns the generated image x_hat\n",
    "x_hat = Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, \n",
    "                        activation='tanh')(z)\n",
    "\n",
    "generator = Model(inputs=zin, outputs=x_hat, name='Generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b31e867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12544)             1254400   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12544)            50176     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e3584e",
   "metadata": {},
   "source": [
    "We may try to generate an image now. SInce the generator is not trained yet, it generates a completely randomic image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0304b723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21ca356e4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random seed z\n",
    "latent_encoding = tf.random.normal([1, latent_dim])\n",
    "\n",
    "# Generate an image\n",
    "x_hat = generator(latent_encoding, training=False)\n",
    "\n",
    "plt.imshow(x_hat[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38afd0",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc09d7",
   "metadata": {},
   "source": [
    "We define it as a Conv NN. It is a classic Conv NN for classification.\n",
    "- Conv part: Conv layers. Gradual decreasing of the spatial dimensions, and increasing of the channels dimension.\n",
    "- Flattening\n",
    "- Dense part: Dense layer. Features exploitation. Only one dense layer, which is the output layer. It has one single output, which is the probability of being in the class $1$ (probability of being a real image). **sigmoid** activation function.\n",
    "\n",
    "In addition, we use **leaky relu** activation function and DropOut in the Conv layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfabc640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57bcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUT. Image x (either real or fake)\n",
    "xin = Input(shape=(28, 28, 1))\n",
    "\n",
    "### CONV PART\n",
    "x = Conv2D(filters=64, kernel_size=(5,5), strides=(2,2), padding='same')(xin)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=(5,5), strides=(2,2), padding='same')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "out = Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(inputs=xin, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "90bb2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_40 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6c8fd",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eaf397",
   "metadata": {},
   "source": [
    "Let's define the loss function.\n",
    "\n",
    "Actually, we define two loss functions: one for the discriminator, and one for the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c088e",
   "metadata": {},
   "source": [
    "**Loss function for the discriminator**\n",
    "\n",
    "This function takes in input two vectors.\n",
    "- `real_images_predictions` Vector of the outputs of the discriminator on the batch of real images. For each real image in the given batch, this vector contains a value, which is the prediction made by the discriminator: it is the probability of being a real image.\n",
    "- `fake_images_predictions` Vector of the outputs of the discriminator on the batch of fake images. For each fake image in the given batch, this vector contains a value, which is the prediction made by the discriminator: it is the probability of being a real image.\n",
    "\n",
    "Given these two quantities, we want to compute the loss on the real images and the loss on the fake images. LEt $m$ be the number of real/fake images in a batch (Same number of fake and real images in a batch). \n",
    "\n",
    "We do this in a slightly different way with respect to what we have seen before.\n",
    "\n",
    "- Loss on the real images. It can be computed as the binary crossentropy between a vector with length $m$ of all $1$ and the vector `real_images_predictions`. More precisely, we compute the binary crossentropy between each value in `real_images_predictions` and $1$, and then we compute the mean.\n",
    "- Loss on the fake images. It can be computed as the binary crossentropy between a vector with length $m$ of all $0$ and the vector `fake_images_predictions`. More precisely, we compute the binary crossentropy between each value in `fake_images_predictions` and $0$, and then we compute the mean.\n",
    "\n",
    "The actual loss of the discriminator is the sum between the loss on the real imaes and the loss on the fake images.\n",
    "\n",
    "The aim of the discriminator is to minimize this loss (contrary from what we have seen before). The binary crossentropy is a distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae54bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "binary_crossentropy = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d99766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss_function(real_images_predictions, fake_images_predictions):\n",
    "    # Loss on the real images\n",
    "    vector_all_ones = tf.ones_like(real_images_predictions)\n",
    "    real_images_loss = binary_crossentropy(vector_all_ones, real_images_predictions)\n",
    "    \n",
    "    # Loss on the fake images\n",
    "    vector_all_zeros = tf.zeros_like(fake_images_predictions)\n",
    "    fake_images_loss = binary_crossentropy(vector_all_zeros, fake_images_predictions)\n",
    "    \n",
    "    # Whole loss\n",
    "    total_loss = real_images_loss + fake_images_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3b3fc",
   "metadata": {},
   "source": [
    "**Loss function for the generator**\n",
    "\n",
    "This function takes in input only the `fake_images_predictions` (i.e. vector of the outputs of the discriminator on the batch of fake images). \n",
    "\n",
    "Given these two quantities, we want to compute the loss on the fake images. Only the loss on the fake images. \n",
    "\n",
    "We compute the loss on the fake images as the binary crossentropy between a vector with length $m$ of all $1$ and the vector `fake_images_predictions`. More precisely, we compute the binary crossentropy between each value in `fake_images_predictions` and $1$, and then we compute the mean.\n",
    "\n",
    "We take values $1$ and not $0$ beacuse in this way the aim of the generator is to minimize this loss. It is an error measure of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1dc217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_function(fake_images_predictions):\n",
    "    vector_all_ones = tf.ones_like(fake_images_predictions)\n",
    "    fake_images_loss = binary_crossentropy(vector_all_ones, fake_images_predictions)\n",
    "    return fake_images_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3ad07",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4574104",
   "metadata": {},
   "source": [
    "Finally, let's implement the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING THE WEIGTHS\n",
    "#generator.load_weights('generator.h5')\n",
    "#discriminator.load_weights('discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42638cfb",
   "metadata": {},
   "source": [
    "**Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e005e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe3bd9",
   "metadata": {},
   "source": [
    "**Training step**\n",
    "\n",
    "Function which performs a training step, both for the discriminator and the generator.\n",
    "\n",
    "It takes in input a batch of real images $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8931f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`: this annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(batch_real_images):\n",
    "    # Batch of latent encodings z\n",
    "    batch_latent_encodings = tf.random.normal([BATCH_SIZE, latent_dim])\n",
    "\n",
    "    # Computing the discriminator and the generator losses\n",
    "    with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n",
    "      # Generating the batch of fake images, given the batch of latent encodings\n",
    "      batch_generated_images = generator(batch_latent_encodings, training=True)\n",
    "\n",
    "      # Predictions of the discriminator on the real images\n",
    "      real_images_predictions = discriminator(batch_real_images, training=True)\n",
    "      # Predictions of the discriminator on the fake images\n",
    "      fake_images_predictions = discriminator(batch_generated_images, training=True)\n",
    "    \n",
    "      # Loss of the generator\n",
    "      generator_loss = generator_loss_function(fake_images_predictions)\n",
    "      # Loss of the discriminator\n",
    "      discriminator_loss = discriminator_loss_function(real_images_predictions, fake_images_predictions)\n",
    "\n",
    "    # Computing the gradients of the generator loss, with respect to all the weigths of the generator\n",
    "    gradients_of_generator = generator_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    # Computing the gradients of the discriminator loss, with respect to all the weigths of the discriminator\n",
    "    gradients_of_discriminator = discriminator_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "\n",
    "    # Apply the backpropagation of the gradients on the weigths. Update of the weigths. On both NNs\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    # Return the losses of the generator and of the discriminator on this current batch\n",
    "    return generator_loss, discriminator_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30ffbc",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "Now that we have defined the training step function, we can perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4d0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c24f31",
   "metadata": {},
   "source": [
    "Defining the number of epochs and the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac593a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a6179",
   "metadata": {},
   "source": [
    "Dividing the training set into batches. Basically, the returned object is an iterable structure, which is iterable over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eef61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86658c9e",
   "metadata": {},
   "source": [
    "Training procedure. WARNING: Almost $7$ hours of training (wuthout GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7393e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.677014946937561, Discriminator loss: 1.3491767644882202\n",
      "\tGenerator loss: 0.6640063524246216, Discriminator loss: 1.3335912227630615\n",
      "\tGenerator loss: 0.6468921899795532, Discriminator loss: 1.314003825187683\n",
      "\tGenerator loss: 0.6265604496002197, Discriminator loss: 1.2930049896240234\n",
      "\tGenerator loss: 0.6088463664054871, Discriminator loss: 1.2671630382537842\n",
      "\tGenerator loss: 0.5898944139480591, Discriminator loss: 1.249624252319336\n",
      "\tGenerator loss: 0.5759036540985107, Discriminator loss: 1.2245311737060547\n",
      "\tGenerator loss: 0.5651317834854126, Discriminator loss: 1.2006793022155762\n",
      "\tGenerator loss: 0.5563564300537109, Discriminator loss: 1.18065345287323\n",
      "\tGenerator loss: 0.5480780601501465, Discriminator loss: 1.1635420322418213\n",
      "\tGenerator loss: 0.5419126749038696, Discriminator loss: 1.1451250314712524\n",
      "\tGenerator loss: 0.5381556153297424, Discriminator loss: 1.1261706352233887\n",
      "\tGenerator loss: 0.5339550971984863, Discriminator loss: 1.1082963943481445\n",
      "\tGenerator loss: 0.5312150716781616, Discriminator loss: 1.0967962741851807\n",
      "\tGenerator loss: 0.526075005531311, Discriminator loss: 1.0932749509811401\n",
      "\tGenerator loss: 0.5221314430236816, Discriminator loss: 1.0820896625518799\n",
      "\tGenerator loss: 0.5215418338775635, Discriminator loss: 1.072279691696167\n",
      "\tGenerator loss: 0.518343448638916, Discriminator loss: 1.0691566467285156\n",
      "\tGenerator loss: 0.5131357908248901, Discriminator loss: 1.0736311674118042\n",
      "\tGenerator loss: 0.5101492404937744, Discriminator loss: 1.0709116458892822\n",
      "\tGenerator loss: 0.5051742792129517, Discriminator loss: 1.0744506120681763\n",
      "\tGenerator loss: 0.5012017488479614, Discriminator loss: 1.0760433673858643\n",
      "\tGenerator loss: 0.4977179765701294, Discriminator loss: 1.0777524709701538\n",
      "\tGenerator loss: 0.4927836060523987, Discriminator loss: 1.0870298147201538\n",
      "\tGenerator loss: 0.4897524118423462, Discriminator loss: 1.092146396636963\n",
      "\tGenerator loss: 0.49015316367149353, Discriminator loss: 1.0930280685424805\n",
      "\tGenerator loss: 0.48861163854599, Discriminator loss: 1.097223162651062\n",
      "\tGenerator loss: 0.49116867780685425, Discriminator loss: 1.0994869470596313\n",
      "\tGenerator loss: 0.4940181374549866, Discriminator loss: 1.099029302597046\n",
      "\tGenerator loss: 0.4962354302406311, Discriminator loss: 1.1024852991104126\n",
      "\tGenerator loss: 0.49483388662338257, Discriminator loss: 1.1156511306762695\n",
      "\tGenerator loss: 0.494716614484787, Discriminator loss: 1.1262016296386719\n",
      "\tGenerator loss: 0.49357008934020996, Discriminator loss: 1.1350330114364624\n",
      "\tGenerator loss: 0.4918997585773468, Discriminator loss: 1.1532604694366455\n",
      "\tGenerator loss: 0.48654770851135254, Discriminator loss: 1.1712939739227295\n",
      "\tGenerator loss: 0.48131847381591797, Discriminator loss: 1.194513201713562\n",
      "\tGenerator loss: 0.4791317284107208, Discriminator loss: 1.2102000713348389\n",
      "\tGenerator loss: 0.47218096256256104, Discriminator loss: 1.2411245107650757\n",
      "\tGenerator loss: 0.46584901213645935, Discriminator loss: 1.2669720649719238\n",
      "\tGenerator loss: 0.4594430923461914, Discriminator loss: 1.2949053049087524\n",
      "\tGenerator loss: 0.45538920164108276, Discriminator loss: 1.3251103162765503\n",
      "\tGenerator loss: 0.44781914353370667, Discriminator loss: 1.352646827697754\n",
      "\tGenerator loss: 0.44320058822631836, Discriminator loss: 1.37825608253479\n",
      "\tGenerator loss: 0.4374423325061798, Discriminator loss: 1.4034401178359985\n",
      "\tGenerator loss: 0.43512922525405884, Discriminator loss: 1.4250147342681885\n",
      "\tGenerator loss: 0.43180036544799805, Discriminator loss: 1.445181131362915\n",
      "\tGenerator loss: 0.42947226762771606, Discriminator loss: 1.4621386528015137\n",
      "\tGenerator loss: 0.4268079400062561, Discriminator loss: 1.4810518026351929\n",
      "\tGenerator loss: 0.42352962493896484, Discriminator loss: 1.499709129333496\n",
      "\tGenerator loss: 0.41799426078796387, Discriminator loss: 1.5187764167785645\n",
      "\tGenerator loss: 0.41711512207984924, Discriminator loss: 1.535933494567871\n",
      "\tGenerator loss: 0.4204632639884949, Discriminator loss: 1.5372061729431152\n",
      "\tGenerator loss: 0.4264846444129944, Discriminator loss: 1.5284457206726074\n",
      "\tGenerator loss: 0.43858063220977783, Discriminator loss: 1.501067876815796\n",
      "\tGenerator loss: 0.45503753423690796, Discriminator loss: 1.476542353630066\n",
      "\tGenerator loss: 0.4704486131668091, Discriminator loss: 1.46317720413208\n",
      "\tGenerator loss: 0.48789694905281067, Discriminator loss: 1.4227272272109985\n",
      "\tGenerator loss: 0.5040587782859802, Discriminator loss: 1.4057652950286865\n",
      "\tGenerator loss: 0.5256047248840332, Discriminator loss: 1.3477132320404053\n",
      "\tGenerator loss: 0.545054018497467, Discriminator loss: 1.2998707294464111\n",
      "\tGenerator loss: 0.5679237842559814, Discriminator loss: 1.2570297718048096\n",
      "\tGenerator loss: 0.5904947519302368, Discriminator loss: 1.217686414718628\n",
      "\tGenerator loss: 0.6144013404846191, Discriminator loss: 1.1795405149459839\n",
      "\tGenerator loss: 0.6364305019378662, Discriminator loss: 1.1432660818099976\n",
      "\tGenerator loss: 0.6549749970436096, Discriminator loss: 1.1069332361221313\n",
      "\tGenerator loss: 0.6753219366073608, Discriminator loss: 1.07379150390625\n",
      "\tGenerator loss: 0.6930563449859619, Discriminator loss: 1.041357398033142\n",
      "\tGenerator loss: 0.7074885964393616, Discriminator loss: 1.0171183347702026\n",
      "\tGenerator loss: 0.7215288877487183, Discriminator loss: 0.9861729741096497\n",
      "\tGenerator loss: 0.7346538305282593, Discriminator loss: 0.9565632343292236\n",
      "\tGenerator loss: 0.7439607977867126, Discriminator loss: 0.9343673586845398\n",
      "\tGenerator loss: 0.7551780939102173, Discriminator loss: 0.9108640551567078\n",
      "\tGenerator loss: 0.765551745891571, Discriminator loss: 0.8982929587364197\n",
      "\tGenerator loss: 0.7814096212387085, Discriminator loss: 0.8721283078193665\n",
      "\tGenerator loss: 0.7935471534729004, Discriminator loss: 0.8503447771072388\n",
      "\tGenerator loss: 0.8045445084571838, Discriminator loss: 0.8458724617958069\n",
      "\tGenerator loss: 0.8200218677520752, Discriminator loss: 0.8291912078857422\n",
      "\tGenerator loss: 0.8310441970825195, Discriminator loss: 0.8266499042510986\n",
      "\tGenerator loss: 0.8433007597923279, Discriminator loss: 0.8166512846946716\n",
      "\tGenerator loss: 0.8484503030776978, Discriminator loss: 0.7947179079055786\n",
      "\tGenerator loss: 0.8420243263244629, Discriminator loss: 0.7934478521347046\n",
      "\tGenerator loss: 0.8349900245666504, Discriminator loss: 0.7926062941551208\n",
      "\tGenerator loss: 0.818585216999054, Discriminator loss: 0.8018779754638672\n",
      "\tGenerator loss: 0.8008637428283691, Discriminator loss: 0.8252067565917969\n",
      "\tGenerator loss: 0.7849093079566956, Discriminator loss: 0.8313256502151489\n",
      "\tGenerator loss: 0.7674943208694458, Discriminator loss: 0.8654626607894897\n",
      "\tGenerator loss: 0.7517098188400269, Discriminator loss: 0.8990772366523743\n",
      "\tGenerator loss: 0.7434651851654053, Discriminator loss: 0.8973891735076904\n",
      "\tGenerator loss: 0.7387081384658813, Discriminator loss: 0.9147617220878601\n",
      "\tGenerator loss: 0.7322012186050415, Discriminator loss: 0.9333776235580444\n",
      "\tGenerator loss: 0.7294993996620178, Discriminator loss: 0.9477353096008301\n",
      "\tGenerator loss: 0.7236915826797485, Discriminator loss: 0.9713975191116333\n",
      "\tGenerator loss: 0.7153168320655823, Discriminator loss: 0.9919970631599426\n",
      "\tGenerator loss: 0.7055885791778564, Discriminator loss: 1.011527180671692\n",
      "\tGenerator loss: 0.695815920829773, Discriminator loss: 1.030137062072754\n",
      "\tGenerator loss: 0.6985478401184082, Discriminator loss: 1.057427167892456\n",
      "\tGenerator loss: 0.7153921723365784, Discriminator loss: 1.0512521266937256\n",
      "\tGenerator loss: 0.7362147569656372, Discriminator loss: 1.047304630279541\n",
      "\tGenerator loss: 0.7639209032058716, Discriminator loss: 1.0519496202468872\n",
      "\tGenerator loss: 0.7871507406234741, Discriminator loss: 1.0347853899002075\n",
      "\tGenerator loss: 0.8074345588684082, Discriminator loss: 1.0196013450622559\n",
      "\tGenerator loss: 0.8233388066291809, Discriminator loss: 1.0079858303070068\n",
      "\tGenerator loss: 0.8353860378265381, Discriminator loss: 0.9816077947616577\n",
      "\tGenerator loss: 0.8414266109466553, Discriminator loss: 0.9778467416763306\n",
      "\tGenerator loss: 0.8416492938995361, Discriminator loss: 0.9564987421035767\n",
      "\tGenerator loss: 0.8465139865875244, Discriminator loss: 0.9413361549377441\n",
      "\tGenerator loss: 0.8428983092308044, Discriminator loss: 0.9439663887023926\n",
      "\tGenerator loss: 0.846198558807373, Discriminator loss: 0.9302071928977966\n",
      "\tGenerator loss: 0.8435160517692566, Discriminator loss: 0.9167098999023438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8356623649597168, Discriminator loss: 0.8873085975646973\n",
      "\tGenerator loss: 0.8268160223960876, Discriminator loss: 0.8807362914085388\n",
      "\tGenerator loss: 0.8104394674301147, Discriminator loss: 0.8834721446037292\n",
      "\tGenerator loss: 0.7932038903236389, Discriminator loss: 0.8859573602676392\n",
      "\tGenerator loss: 0.7600727081298828, Discriminator loss: 0.9150193929672241\n",
      "\tGenerator loss: 0.7217538356781006, Discriminator loss: 0.9491752982139587\n",
      "\tGenerator loss: 0.6859130859375, Discriminator loss: 0.9815077781677246\n",
      "\tGenerator loss: 0.64190274477005, Discriminator loss: 1.0373821258544922\n",
      "\tGenerator loss: 0.5947540998458862, Discriminator loss: 1.1163198947906494\n",
      "\tGenerator loss: 0.5588991641998291, Discriminator loss: 1.1707277297973633\n",
      "\tGenerator loss: 0.554194986820221, Discriminator loss: 1.1863200664520264\n",
      "\tGenerator loss: 0.5774621963500977, Discriminator loss: 1.1645102500915527\n",
      "\tGenerator loss: 0.6195647120475769, Discriminator loss: 1.1485581398010254\n",
      "\tGenerator loss: 0.6763483285903931, Discriminator loss: 1.108064889907837\n",
      "\tGenerator loss: 0.7387029528617859, Discriminator loss: 1.0834394693374634\n",
      "\tGenerator loss: 0.796345591545105, Discriminator loss: 1.05109441280365\n",
      "\tGenerator loss: 0.839586615562439, Discriminator loss: 0.9987298846244812\n",
      "\tGenerator loss: 0.8683921098709106, Discriminator loss: 0.9695771336555481\n",
      "\tGenerator loss: 0.8827292919158936, Discriminator loss: 0.9598278999328613\n",
      "\tGenerator loss: 0.8974943161010742, Discriminator loss: 0.9343941807746887\n",
      "\tGenerator loss: 0.8942046165466309, Discriminator loss: 0.9177778959274292\n",
      "\tGenerator loss: 0.8861660361289978, Discriminator loss: 0.9149402976036072\n",
      "\tGenerator loss: 0.8809205293655396, Discriminator loss: 0.8821595311164856\n",
      "\tGenerator loss: 0.8879315853118896, Discriminator loss: 0.8460583686828613\n",
      "\tGenerator loss: 0.9043716192245483, Discriminator loss: 0.8236633539199829\n",
      "\tGenerator loss: 0.9244856834411621, Discriminator loss: 0.7987260222434998\n",
      "\tGenerator loss: 0.9557966589927673, Discriminator loss: 0.7790838479995728\n",
      "\tGenerator loss: 0.982455849647522, Discriminator loss: 0.7532252073287964\n",
      "\tGenerator loss: 1.0092103481292725, Discriminator loss: 0.7308347225189209\n",
      "\tGenerator loss: 1.0366899967193604, Discriminator loss: 0.7244903445243835\n",
      "\tGenerator loss: 1.0581579208374023, Discriminator loss: 0.7200092673301697\n",
      "\tGenerator loss: 1.0736000537872314, Discriminator loss: 0.7154524326324463\n",
      "\tGenerator loss: 1.0961668491363525, Discriminator loss: 0.7222585678100586\n",
      "\tGenerator loss: 1.1058882474899292, Discriminator loss: 0.7041600346565247\n",
      "\tGenerator loss: 1.127856731414795, Discriminator loss: 0.6781221628189087\n",
      "\tGenerator loss: 1.1593499183654785, Discriminator loss: 0.65547776222229\n",
      "\tGenerator loss: 1.187449336051941, Discriminator loss: 0.6381474733352661\n",
      "\tGenerator loss: 1.219292402267456, Discriminator loss: 0.6319665908813477\n",
      "\tGenerator loss: 1.2563807964324951, Discriminator loss: 0.6333891153335571\n",
      "\tGenerator loss: 1.273633360862732, Discriminator loss: 0.6196275949478149\n",
      "\tGenerator loss: 1.2862683534622192, Discriminator loss: 0.6128756999969482\n",
      "\tGenerator loss: 1.2911293506622314, Discriminator loss: 0.6032305359840393\n",
      "\tGenerator loss: 1.2898845672607422, Discriminator loss: 0.59995436668396\n",
      "\tGenerator loss: 1.2737234830856323, Discriminator loss: 0.5988283157348633\n",
      "\tGenerator loss: 1.2681996822357178, Discriminator loss: 0.6001578569412231\n",
      "\tGenerator loss: 1.2557504177093506, Discriminator loss: 0.597637414932251\n",
      "\tGenerator loss: 1.2356541156768799, Discriminator loss: 0.6169580817222595\n",
      "\tGenerator loss: 1.2165876626968384, Discriminator loss: 0.6232259273529053\n",
      "\tGenerator loss: 1.1957603693008423, Discriminator loss: 0.6471246480941772\n",
      "\tGenerator loss: 1.1872732639312744, Discriminator loss: 0.6745694875717163\n",
      "\tGenerator loss: 1.1696407794952393, Discriminator loss: 0.6848350763320923\n",
      "\tGenerator loss: 1.1623197793960571, Discriminator loss: 0.6877099275588989\n",
      "\tGenerator loss: 1.146470069885254, Discriminator loss: 0.7461764216423035\n",
      "\tGenerator loss: 1.1441251039505005, Discriminator loss: 0.7502899169921875\n",
      "\tGenerator loss: 1.1393182277679443, Discriminator loss: 0.7560129165649414\n",
      "\tGenerator loss: 1.1420818567276, Discriminator loss: 0.7751903533935547\n",
      "\tGenerator loss: 1.1635477542877197, Discriminator loss: 0.8225438594818115\n",
      "\tGenerator loss: 1.1848113536834717, Discriminator loss: 0.8588119745254517\n",
      "\tGenerator loss: 1.1882095336914062, Discriminator loss: 0.8732122182846069\n",
      "\tGenerator loss: 1.1977007389068604, Discriminator loss: 0.8893038034439087\n",
      "\tGenerator loss: 1.2268410921096802, Discriminator loss: 0.9137115478515625\n",
      "\tGenerator loss: 1.233529806137085, Discriminator loss: 0.9237186908721924\n",
      "\tGenerator loss: 1.237608551979065, Discriminator loss: 0.9377468824386597\n",
      "\tGenerator loss: 1.2522965669631958, Discriminator loss: 0.9921100735664368\n",
      "\tGenerator loss: 1.2520244121551514, Discriminator loss: 1.0232676267623901\n",
      "\tGenerator loss: 1.2408530712127686, Discriminator loss: 1.0395708084106445\n",
      "\tGenerator loss: 1.2207649946212769, Discriminator loss: 1.064152717590332\n",
      "\tGenerator loss: 1.181960105895996, Discriminator loss: 1.1335430145263672\n",
      "\tGenerator loss: 1.1333566904067993, Discriminator loss: 1.1608941555023193\n",
      "\tGenerator loss: 1.0684162378311157, Discriminator loss: 1.1627917289733887\n",
      "\tGenerator loss: 1.0066559314727783, Discriminator loss: 1.1621570587158203\n",
      "\tGenerator loss: 0.9290847778320312, Discriminator loss: 1.1840240955352783\n",
      "\tGenerator loss: 0.8607587218284607, Discriminator loss: 1.240079402923584\n",
      "\tGenerator loss: 0.804446816444397, Discriminator loss: 1.2777659893035889\n",
      "\tGenerator loss: 0.7653447985649109, Discriminator loss: 1.2987425327301025\n",
      "\tGenerator loss: 0.7746826410293579, Discriminator loss: 1.223940372467041\n",
      "\tGenerator loss: 0.7985689640045166, Discriminator loss: 1.2314473390579224\n",
      "\tGenerator loss: 0.8392469882965088, Discriminator loss: 1.2196884155273438\n",
      "\tGenerator loss: 0.8821231126785278, Discriminator loss: 1.1475757360458374\n",
      "\tGenerator loss: 0.9181104898452759, Discriminator loss: 1.114269733428955\n",
      "\tGenerator loss: 0.9531071782112122, Discriminator loss: 1.0698257684707642\n",
      "\tGenerator loss: 0.9792996644973755, Discriminator loss: 1.0153471231460571\n",
      "\tGenerator loss: 0.9946019053459167, Discriminator loss: 0.9486314058303833\n",
      "\tGenerator loss: 0.992723822593689, Discriminator loss: 0.9311124086380005\n",
      "\tGenerator loss: 0.9934316873550415, Discriminator loss: 0.920574426651001\n",
      "\tGenerator loss: 0.9854182004928589, Discriminator loss: 0.8899587392807007\n",
      "\tGenerator loss: 0.9864877462387085, Discriminator loss: 0.847808837890625\n",
      "\tGenerator loss: 0.9813787937164307, Discriminator loss: 0.8463805913925171\n",
      "\tGenerator loss: 0.9852915406227112, Discriminator loss: 0.8550899624824524\n",
      "\tGenerator loss: 0.98470139503479, Discriminator loss: 0.8493075370788574\n",
      "\tGenerator loss: 0.9891979694366455, Discriminator loss: 0.8523862361907959\n",
      "\tGenerator loss: 0.9899701476097107, Discriminator loss: 0.8961172699928284\n",
      "\tGenerator loss: 0.9796035289764404, Discriminator loss: 0.9291050434112549\n",
      "\tGenerator loss: 0.9518409967422485, Discriminator loss: 0.9272006750106812\n",
      "\tGenerator loss: 0.926034688949585, Discriminator loss: 0.9575680494308472\n",
      "\tGenerator loss: 0.8960009217262268, Discriminator loss: 0.9826793074607849\n",
      "\tGenerator loss: 0.8616688847541809, Discriminator loss: 1.0150736570358276\n",
      "\tGenerator loss: 0.850908637046814, Discriminator loss: 1.0349345207214355\n",
      "\tGenerator loss: 0.8416857123374939, Discriminator loss: 1.068791151046753\n",
      "\tGenerator loss: 0.8357210159301758, Discriminator loss: 1.0907135009765625\n",
      "\tGenerator loss: 0.8469202518463135, Discriminator loss: 1.092052936553955\n",
      "\tGenerator loss: 0.865898609161377, Discriminator loss: 1.092726469039917\n",
      "\tGenerator loss: 0.88068026304245, Discriminator loss: 1.0816762447357178\n",
      "\tGenerator loss: 0.8817795515060425, Discriminator loss: 1.0784938335418701\n",
      "\tGenerator loss: 0.8868860006332397, Discriminator loss: 1.0549218654632568\n",
      "\tGenerator loss: 0.8988511562347412, Discriminator loss: 1.056713342666626\n",
      "\tGenerator loss: 0.9224423170089722, Discriminator loss: 1.0221455097198486\n",
      "\tGenerator loss: 0.9545770883560181, Discriminator loss: 0.9700398445129395\n",
      "\tGenerator loss: 0.9870389699935913, Discriminator loss: 0.984068751335144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0135056972503662, Discriminator loss: 0.9311379194259644\n",
      "\tGenerator loss: 1.048398494720459, Discriminator loss: 0.9036275148391724\n",
      "\tGenerator loss: 1.073205828666687, Discriminator loss: 0.8679684996604919\n",
      "\tGenerator loss: 1.1067806482315063, Discriminator loss: 0.8742936849594116\n",
      "\tGenerator loss: 1.1202383041381836, Discriminator loss: 0.8321177959442139\n",
      "\tGenerator loss: 1.1375101804733276, Discriminator loss: 0.8158541917800903\n",
      "\tGenerator loss: 1.1445298194885254, Discriminator loss: 0.8198376893997192\n",
      "\tGenerator loss: 1.1581015586853027, Discriminator loss: 0.7929383516311646\n",
      "\tGenerator loss: 1.1718456745147705, Discriminator loss: 0.812767744064331\n",
      "\tGenerator loss: 1.1871968507766724, Discriminator loss: 0.8246344923973083\n",
      "\tGenerator loss: 1.197548270225525, Discriminator loss: 0.8312159776687622\n",
      "\tGenerator loss: 1.2084250450134277, Discriminator loss: 0.80975341796875\n",
      "\tGenerator loss: 1.2229561805725098, Discriminator loss: 0.823052704334259\n",
      "\tGenerator loss: 1.2347825765609741, Discriminator loss: 0.8329709768295288\n",
      "\tGenerator loss: 1.240680456161499, Discriminator loss: 0.866085410118103\n",
      "\tGenerator loss: 1.248810887336731, Discriminator loss: 0.8438743352890015\n",
      "\tGenerator loss: 1.246370553970337, Discriminator loss: 0.8806016445159912\n",
      "Time for epoch 1 is 479.0894966125488 sec\n",
      "\tGenerator loss: 1.2202640771865845, Discriminator loss: 0.8759073615074158\n",
      "\tGenerator loss: 1.187633991241455, Discriminator loss: 0.8766986131668091\n",
      "\tGenerator loss: 1.1486339569091797, Discriminator loss: 0.8760899901390076\n",
      "\tGenerator loss: 1.1164112091064453, Discriminator loss: 0.8890056610107422\n",
      "\tGenerator loss: 1.1024521589279175, Discriminator loss: 0.8834351301193237\n",
      "\tGenerator loss: 1.0727810859680176, Discriminator loss: 0.8970323801040649\n",
      "\tGenerator loss: 1.0640920400619507, Discriminator loss: 0.9112370610237122\n",
      "\tGenerator loss: 1.043951392173767, Discriminator loss: 0.9225600957870483\n",
      "\tGenerator loss: 1.0316859483718872, Discriminator loss: 0.9285846948623657\n",
      "\tGenerator loss: 1.0300593376159668, Discriminator loss: 0.9413872957229614\n",
      "\tGenerator loss: 1.029997706413269, Discriminator loss: 0.9741436839103699\n",
      "\tGenerator loss: 1.0391170978546143, Discriminator loss: 0.9680464863777161\n",
      "\tGenerator loss: 1.0371267795562744, Discriminator loss: 0.9352831840515137\n",
      "\tGenerator loss: 1.0417938232421875, Discriminator loss: 0.9448065757751465\n",
      "\tGenerator loss: 1.0329012870788574, Discriminator loss: 0.9547450542449951\n",
      "\tGenerator loss: 1.0179929733276367, Discriminator loss: 0.919559121131897\n",
      "\tGenerator loss: 1.0186583995819092, Discriminator loss: 0.9183627367019653\n",
      "\tGenerator loss: 1.0491418838500977, Discriminator loss: 0.9085707068443298\n",
      "\tGenerator loss: 1.06646728515625, Discriminator loss: 0.9165969491004944\n",
      "\tGenerator loss: 1.0613514184951782, Discriminator loss: 0.8961839079856873\n",
      "\tGenerator loss: 1.0636308193206787, Discriminator loss: 0.883208155632019\n",
      "\tGenerator loss: 1.0744444131851196, Discriminator loss: 0.8607923984527588\n",
      "\tGenerator loss: 1.0869152545928955, Discriminator loss: 0.8891600370407104\n",
      "\tGenerator loss: 1.0932917594909668, Discriminator loss: 0.8934544324874878\n",
      "\tGenerator loss: 1.1127510070800781, Discriminator loss: 0.8839004039764404\n",
      "\tGenerator loss: 1.0894831418991089, Discriminator loss: 0.9625632166862488\n",
      "\tGenerator loss: 1.0655773878097534, Discriminator loss: 1.0698165893554688\n",
      "\tGenerator loss: 0.997061550617218, Discriminator loss: 1.1233105659484863\n",
      "\tGenerator loss: 0.8980453014373779, Discriminator loss: 1.2893257141113281\n",
      "\tGenerator loss: 0.7792073488235474, Discriminator loss: 1.3590238094329834\n",
      "\tGenerator loss: 0.670576810836792, Discriminator loss: 1.431394100189209\n",
      "\tGenerator loss: 0.6114500761032104, Discriminator loss: 1.5050828456878662\n",
      "\tGenerator loss: 0.5856059789657593, Discriminator loss: 1.6059906482696533\n",
      "\tGenerator loss: 0.5703645348548889, Discriminator loss: 1.6097726821899414\n",
      "\tGenerator loss: 0.5949671268463135, Discriminator loss: 1.7512779235839844\n",
      "\tGenerator loss: 0.602044403553009, Discriminator loss: 1.9104068279266357\n",
      "\tGenerator loss: 0.5941938161849976, Discriminator loss: 2.0070996284484863\n",
      "\tGenerator loss: 0.5378598570823669, Discriminator loss: 2.108414888381958\n",
      "\tGenerator loss: 0.4826054871082306, Discriminator loss: 2.129152774810791\n",
      "\tGenerator loss: 0.4187861680984497, Discriminator loss: 2.173175811767578\n",
      "\tGenerator loss: 0.3724749684333801, Discriminator loss: 2.123621940612793\n",
      "\tGenerator loss: 0.36333179473876953, Discriminator loss: 2.1694960594177246\n",
      "\tGenerator loss: 0.3696472644805908, Discriminator loss: 2.116912603378296\n",
      "\tGenerator loss: 0.402549147605896, Discriminator loss: 2.0537490844726562\n",
      "\tGenerator loss: 0.4384075105190277, Discriminator loss: 2.0387027263641357\n",
      "\tGenerator loss: 0.4852403402328491, Discriminator loss: 2.0050928592681885\n",
      "\tGenerator loss: 0.5266020894050598, Discriminator loss: 1.9046778678894043\n",
      "\tGenerator loss: 0.5400586128234863, Discriminator loss: 1.840537428855896\n",
      "\tGenerator loss: 0.5468388199806213, Discriminator loss: 1.7815687656402588\n",
      "\tGenerator loss: 0.5504264831542969, Discriminator loss: 1.7023602724075317\n",
      "\tGenerator loss: 0.5480757355690002, Discriminator loss: 1.635644555091858\n",
      "\tGenerator loss: 0.5521414279937744, Discriminator loss: 1.562910795211792\n",
      "\tGenerator loss: 0.5707513093948364, Discriminator loss: 1.4670063257217407\n",
      "\tGenerator loss: 0.6049797534942627, Discriminator loss: 1.3898837566375732\n",
      "\tGenerator loss: 0.6526236534118652, Discriminator loss: 1.3424948453903198\n",
      "\tGenerator loss: 0.7187514305114746, Discriminator loss: 1.3102567195892334\n",
      "\tGenerator loss: 0.7674479484558105, Discriminator loss: 1.228498935699463\n",
      "\tGenerator loss: 0.8201490640640259, Discriminator loss: 1.2367782592773438\n",
      "\tGenerator loss: 0.8537991046905518, Discriminator loss: 1.1185503005981445\n",
      "\tGenerator loss: 0.8732013702392578, Discriminator loss: 1.047074794769287\n",
      "\tGenerator loss: 0.8941002488136292, Discriminator loss: 0.9944982528686523\n",
      "\tGenerator loss: 0.9234066009521484, Discriminator loss: 0.9614579081535339\n",
      "\tGenerator loss: 0.9522700905799866, Discriminator loss: 0.9367650747299194\n",
      "\tGenerator loss: 0.9872698783874512, Discriminator loss: 0.9128459692001343\n",
      "\tGenerator loss: 1.0183066129684448, Discriminator loss: 0.8786515593528748\n",
      "\tGenerator loss: 1.0501081943511963, Discriminator loss: 0.8742613792419434\n",
      "\tGenerator loss: 1.08491051197052, Discriminator loss: 0.871254563331604\n",
      "\tGenerator loss: 1.110546350479126, Discriminator loss: 0.8824753165245056\n",
      "\tGenerator loss: 1.1166905164718628, Discriminator loss: 0.8612271547317505\n",
      "\tGenerator loss: 1.1089270114898682, Discriminator loss: 0.8535171151161194\n",
      "\tGenerator loss: 1.1085166931152344, Discriminator loss: 0.8680177927017212\n",
      "\tGenerator loss: 1.0941433906555176, Discriminator loss: 0.899960994720459\n",
      "\tGenerator loss: 1.0773894786834717, Discriminator loss: 0.9421291351318359\n",
      "\tGenerator loss: 1.0614514350891113, Discriminator loss: 0.9674611687660217\n",
      "\tGenerator loss: 1.0535128116607666, Discriminator loss: 0.9873781204223633\n",
      "\tGenerator loss: 1.0442681312561035, Discriminator loss: 1.1260005235671997\n",
      "\tGenerator loss: 1.0281705856323242, Discriminator loss: 1.2321858406066895\n",
      "\tGenerator loss: 0.9966675043106079, Discriminator loss: 1.290992259979248\n",
      "\tGenerator loss: 0.9298014640808105, Discriminator loss: 1.357458472251892\n",
      "\tGenerator loss: 0.8578295707702637, Discriminator loss: 1.337256908416748\n",
      "\tGenerator loss: 0.8107060194015503, Discriminator loss: 1.3748517036437988\n",
      "\tGenerator loss: 0.7887104749679565, Discriminator loss: 1.4026877880096436\n",
      "\tGenerator loss: 0.7584338188171387, Discriminator loss: 1.4164469242095947\n",
      "\tGenerator loss: 0.7363389134407043, Discriminator loss: 1.4839316606521606\n",
      "\tGenerator loss: 0.7323921918869019, Discriminator loss: 1.4560375213623047\n",
      "\tGenerator loss: 0.7416300177574158, Discriminator loss: 1.6841181516647339\n",
      "\tGenerator loss: 0.7142990827560425, Discriminator loss: 1.7123520374298096\n",
      "\tGenerator loss: 0.7019537687301636, Discriminator loss: 1.6789331436157227\n",
      "\tGenerator loss: 0.6774032115936279, Discriminator loss: 1.8180283308029175\n",
      "\tGenerator loss: 0.6372637748718262, Discriminator loss: 1.8614022731781006\n",
      "\tGenerator loss: 0.6068101525306702, Discriminator loss: 1.8624927997589111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.6016803979873657, Discriminator loss: 1.810575246810913\n",
      "\tGenerator loss: 0.6043212413787842, Discriminator loss: 1.7193875312805176\n",
      "\tGenerator loss: 0.6223354935646057, Discriminator loss: 1.6757571697235107\n",
      "\tGenerator loss: 0.6422561407089233, Discriminator loss: 1.6433918476104736\n",
      "\tGenerator loss: 0.663886547088623, Discriminator loss: 1.6537152528762817\n",
      "\tGenerator loss: 0.688138484954834, Discriminator loss: 1.6713504791259766\n",
      "\tGenerator loss: 0.6828300952911377, Discriminator loss: 1.6065186262130737\n",
      "\tGenerator loss: 0.6726703643798828, Discriminator loss: 1.6144039630889893\n",
      "\tGenerator loss: 0.6591351628303528, Discriminator loss: 1.6221981048583984\n",
      "\tGenerator loss: 0.6533228158950806, Discriminator loss: 1.5577694177627563\n",
      "\tGenerator loss: 0.6654956340789795, Discriminator loss: 1.5308432579040527\n",
      "\tGenerator loss: 0.6708642840385437, Discriminator loss: 1.504365086555481\n",
      "\tGenerator loss: 0.6925392150878906, Discriminator loss: 1.479421854019165\n",
      "\tGenerator loss: 0.7091174125671387, Discriminator loss: 1.4765551090240479\n",
      "\tGenerator loss: 0.7338697910308838, Discriminator loss: 1.4356026649475098\n",
      "\tGenerator loss: 0.7600929737091064, Discriminator loss: 1.431573748588562\n",
      "\tGenerator loss: 0.7815603017807007, Discriminator loss: 1.3805875778198242\n",
      "\tGenerator loss: 0.8033159971237183, Discriminator loss: 1.3326640129089355\n",
      "\tGenerator loss: 0.8100177049636841, Discriminator loss: 1.2942516803741455\n",
      "\tGenerator loss: 0.8058993816375732, Discriminator loss: 1.2778489589691162\n",
      "\tGenerator loss: 0.8211907148361206, Discriminator loss: 1.2560230493545532\n",
      "\tGenerator loss: 0.831768810749054, Discriminator loss: 1.2210785150527954\n",
      "\tGenerator loss: 0.8568400144577026, Discriminator loss: 1.1742115020751953\n",
      "\tGenerator loss: 0.8667899370193481, Discriminator loss: 1.1369155645370483\n",
      "\tGenerator loss: 0.877719521522522, Discriminator loss: 1.092942714691162\n",
      "\tGenerator loss: 0.8980792760848999, Discriminator loss: 1.0930391550064087\n",
      "\tGenerator loss: 0.9198969602584839, Discriminator loss: 1.1012502908706665\n",
      "\tGenerator loss: 0.9410372972488403, Discriminator loss: 1.0437148809432983\n",
      "\tGenerator loss: 0.9535894393920898, Discriminator loss: 1.0387698411941528\n",
      "\tGenerator loss: 0.9765039682388306, Discriminator loss: 1.0022282600402832\n",
      "\tGenerator loss: 0.9745177030563354, Discriminator loss: 0.9945616722106934\n",
      "\tGenerator loss: 0.9964634776115417, Discriminator loss: 0.9988812804222107\n",
      "\tGenerator loss: 1.0197869539260864, Discriminator loss: 1.0016491413116455\n",
      "\tGenerator loss: 1.025994062423706, Discriminator loss: 0.9900681972503662\n",
      "\tGenerator loss: 1.0357513427734375, Discriminator loss: 0.9651381373405457\n",
      "\tGenerator loss: 1.0532174110412598, Discriminator loss: 0.9501559734344482\n",
      "\tGenerator loss: 1.076857328414917, Discriminator loss: 0.9239157438278198\n",
      "\tGenerator loss: 1.0902822017669678, Discriminator loss: 0.9048664569854736\n",
      "\tGenerator loss: 1.1071813106536865, Discriminator loss: 0.9079039096832275\n",
      "\tGenerator loss: 1.1350514888763428, Discriminator loss: 0.9205052256584167\n",
      "\tGenerator loss: 1.1540800333023071, Discriminator loss: 0.8998367786407471\n",
      "\tGenerator loss: 1.1740491390228271, Discriminator loss: 0.8788459897041321\n",
      "\tGenerator loss: 1.1998422145843506, Discriminator loss: 0.9014025926589966\n",
      "\tGenerator loss: 1.2200262546539307, Discriminator loss: 0.8805749416351318\n",
      "\tGenerator loss: 1.2425014972686768, Discriminator loss: 0.8820237517356873\n",
      "\tGenerator loss: 1.2655562162399292, Discriminator loss: 0.886299729347229\n",
      "\tGenerator loss: 1.2871887683868408, Discriminator loss: 0.9128755331039429\n",
      "\tGenerator loss: 1.3076595067977905, Discriminator loss: 0.910981297492981\n",
      "\tGenerator loss: 1.297424554824829, Discriminator loss: 0.9103531837463379\n",
      "\tGenerator loss: 1.2891640663146973, Discriminator loss: 0.9772565960884094\n",
      "\tGenerator loss: 1.2548985481262207, Discriminator loss: 0.9411386251449585\n",
      "\tGenerator loss: 1.2446693181991577, Discriminator loss: 0.9363896250724792\n",
      "\tGenerator loss: 1.246156930923462, Discriminator loss: 0.8762596845626831\n",
      "\tGenerator loss: 1.2629672288894653, Discriminator loss: 0.8926584124565125\n",
      "\tGenerator loss: 1.2779366970062256, Discriminator loss: 0.9120469093322754\n",
      "\tGenerator loss: 1.3273241519927979, Discriminator loss: 0.9720931053161621\n",
      "\tGenerator loss: 1.3403913974761963, Discriminator loss: 0.9837466478347778\n",
      "\tGenerator loss: 1.3389205932617188, Discriminator loss: 0.9948508739471436\n",
      "\tGenerator loss: 1.348235845565796, Discriminator loss: 1.0274224281311035\n",
      "\tGenerator loss: 1.3424233198165894, Discriminator loss: 1.0329346656799316\n",
      "\tGenerator loss: 1.3219542503356934, Discriminator loss: 1.0233659744262695\n",
      "\tGenerator loss: 1.2759733200073242, Discriminator loss: 1.0336533784866333\n",
      "\tGenerator loss: 1.256962537765503, Discriminator loss: 1.034196376800537\n",
      "\tGenerator loss: 1.2282289266586304, Discriminator loss: 1.0304346084594727\n",
      "\tGenerator loss: 1.2210066318511963, Discriminator loss: 1.1285202503204346\n",
      "\tGenerator loss: 1.154386043548584, Discriminator loss: 1.1019196510314941\n",
      "\tGenerator loss: 1.1284949779510498, Discriminator loss: 1.1109163761138916\n",
      "\tGenerator loss: 1.0893152952194214, Discriminator loss: 1.1264300346374512\n",
      "\tGenerator loss: 1.0496461391448975, Discriminator loss: 1.141817331314087\n",
      "\tGenerator loss: 1.0030286312103271, Discriminator loss: 1.1536762714385986\n",
      "\tGenerator loss: 0.9635552167892456, Discriminator loss: 1.215029239654541\n",
      "\tGenerator loss: 0.9056320786476135, Discriminator loss: 1.2709181308746338\n",
      "\tGenerator loss: 0.8481886386871338, Discriminator loss: 1.3059966564178467\n",
      "\tGenerator loss: 0.8082399368286133, Discriminator loss: 1.2277560234069824\n",
      "\tGenerator loss: 0.7684799432754517, Discriminator loss: 1.2850162982940674\n",
      "\tGenerator loss: 0.7541038393974304, Discriminator loss: 1.2715051174163818\n",
      "\tGenerator loss: 0.7521956562995911, Discriminator loss: 1.2763279676437378\n",
      "\tGenerator loss: 0.7790963649749756, Discriminator loss: 1.2845499515533447\n",
      "\tGenerator loss: 0.8083982467651367, Discriminator loss: 1.2752467393875122\n",
      "\tGenerator loss: 0.8274825811386108, Discriminator loss: 1.2864038944244385\n",
      "\tGenerator loss: 0.8449128866195679, Discriminator loss: 1.3323476314544678\n",
      "\tGenerator loss: 0.8612221479415894, Discriminator loss: 1.3753629922866821\n",
      "\tGenerator loss: 0.8353092670440674, Discriminator loss: 1.3789904117584229\n",
      "\tGenerator loss: 0.8025550246238708, Discriminator loss: 1.370184302330017\n",
      "\tGenerator loss: 0.7784932851791382, Discriminator loss: 1.3314850330352783\n",
      "\tGenerator loss: 0.7497357726097107, Discriminator loss: 1.3229888677597046\n",
      "\tGenerator loss: 0.7289648056030273, Discriminator loss: 1.3373322486877441\n",
      "\tGenerator loss: 0.7341119050979614, Discriminator loss: 1.3203954696655273\n",
      "\tGenerator loss: 0.7288579344749451, Discriminator loss: 1.3367772102355957\n",
      "\tGenerator loss: 0.733034610748291, Discriminator loss: 1.3250021934509277\n",
      "\tGenerator loss: 0.7356129884719849, Discriminator loss: 1.2952244281768799\n",
      "\tGenerator loss: 0.7499125003814697, Discriminator loss: 1.2356218099594116\n",
      "\tGenerator loss: 0.7872207164764404, Discriminator loss: 1.2106666564941406\n",
      "\tGenerator loss: 0.8229228258132935, Discriminator loss: 1.1977556943893433\n",
      "\tGenerator loss: 0.8601948022842407, Discriminator loss: 1.1641433238983154\n",
      "\tGenerator loss: 0.8910759091377258, Discriminator loss: 1.1217975616455078\n",
      "\tGenerator loss: 0.9149760603904724, Discriminator loss: 1.1004480123519897\n",
      "\tGenerator loss: 0.9241268634796143, Discriminator loss: 1.0785613059997559\n",
      "\tGenerator loss: 0.9308264255523682, Discriminator loss: 1.0556517839431763\n",
      "\tGenerator loss: 0.9250844717025757, Discriminator loss: 1.0285917520523071\n",
      "\tGenerator loss: 0.9174618721008301, Discriminator loss: 1.0384712219238281\n",
      "\tGenerator loss: 0.9018025398254395, Discriminator loss: 1.0130940675735474\n",
      "\tGenerator loss: 0.903907060623169, Discriminator loss: 1.0051298141479492\n",
      "\tGenerator loss: 0.906790018081665, Discriminator loss: 0.9903545379638672\n",
      "\tGenerator loss: 0.9149847030639648, Discriminator loss: 0.9895232915878296\n",
      "\tGenerator loss: 0.9151163697242737, Discriminator loss: 0.9771102666854858\n",
      "\tGenerator loss: 0.9234284162521362, Discriminator loss: 0.9799102544784546\n",
      "\tGenerator loss: 0.9364283084869385, Discriminator loss: 1.0178658962249756\n",
      "\tGenerator loss: 0.950933039188385, Discriminator loss: 1.0094983577728271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.942896842956543, Discriminator loss: 1.055619239807129\n",
      "\tGenerator loss: 0.9387094378471375, Discriminator loss: 1.056734323501587\n",
      "\tGenerator loss: 0.9057839512825012, Discriminator loss: 1.0676087141036987\n",
      "\tGenerator loss: 0.8934520483016968, Discriminator loss: 1.084644079208374\n",
      "\tGenerator loss: 0.8974895477294922, Discriminator loss: 1.1133596897125244\n",
      "\tGenerator loss: 0.9105442762374878, Discriminator loss: 1.1183615922927856\n",
      "\tGenerator loss: 0.8957905769348145, Discriminator loss: 1.1656854152679443\n",
      "\tGenerator loss: 0.8851075172424316, Discriminator loss: 1.202043890953064\n",
      "\tGenerator loss: 0.8886441588401794, Discriminator loss: 1.2060766220092773\n",
      "\tGenerator loss: 0.896240234375, Discriminator loss: 1.2186610698699951\n",
      "\tGenerator loss: 0.8795801401138306, Discriminator loss: 1.2105273008346558\n",
      "\tGenerator loss: 0.8777086138725281, Discriminator loss: 1.2588413953781128\n",
      "\tGenerator loss: 0.827521562576294, Discriminator loss: 1.369821548461914\n",
      "\tGenerator loss: 0.8175833225250244, Discriminator loss: 1.418108582496643\n",
      "\tGenerator loss: 0.7662670016288757, Discriminator loss: 1.4493235349655151\n",
      "\tGenerator loss: 0.7386935949325562, Discriminator loss: 1.4602024555206299\n",
      "\tGenerator loss: 0.7057530283927917, Discriminator loss: 1.477374792098999\n",
      "\tGenerator loss: 0.7018039226531982, Discriminator loss: 1.5780593156814575\n",
      "\tGenerator loss: 0.6738227009773254, Discriminator loss: 1.550276517868042\n",
      "\tGenerator loss: 0.6753847599029541, Discriminator loss: 1.529833197593689\n",
      "\tGenerator loss: 0.6813082695007324, Discriminator loss: 1.4999027252197266\n",
      "\tGenerator loss: 0.7019068598747253, Discriminator loss: 1.5172326564788818\n",
      "\tGenerator loss: 0.7025777697563171, Discriminator loss: 1.4909627437591553\n",
      "\tGenerator loss: 0.7087832689285278, Discriminator loss: 1.4769231081008911\n",
      "\tGenerator loss: 0.7394554615020752, Discriminator loss: 1.4767751693725586\n",
      "\tGenerator loss: 0.7388497591018677, Discriminator loss: 1.4102849960327148\n",
      "\tGenerator loss: 0.7325204014778137, Discriminator loss: 1.4372212886810303\n",
      "\tGenerator loss: 0.727157473564148, Discriminator loss: 1.4373070001602173\n",
      "\tGenerator loss: 0.7222893238067627, Discriminator loss: 1.4368640184402466\n",
      "\tGenerator loss: 0.7262488007545471, Discriminator loss: 1.3728394508361816\n",
      "\tGenerator loss: 0.7242757081985474, Discriminator loss: 1.3658831119537354\n",
      "\tGenerator loss: 0.7544009685516357, Discriminator loss: 1.3845185041427612\n",
      "\tGenerator loss: 0.7747400403022766, Discriminator loss: 1.4383602142333984\n",
      "\tGenerator loss: 0.7736351490020752, Discriminator loss: 1.4010953903198242\n",
      "\tGenerator loss: 0.7761409282684326, Discriminator loss: 1.330045461654663\n",
      "Time for epoch 2 is 501.36102294921875 sec\n",
      "\tGenerator loss: 0.7743337750434875, Discriminator loss: 1.285938024520874\n",
      "\tGenerator loss: 0.7812787294387817, Discriminator loss: 1.2403221130371094\n",
      "\tGenerator loss: 0.7943433523178101, Discriminator loss: 1.2279400825500488\n",
      "\tGenerator loss: 0.7988807559013367, Discriminator loss: 1.2287213802337646\n",
      "\tGenerator loss: 0.8142507672309875, Discriminator loss: 1.2114850282669067\n",
      "\tGenerator loss: 0.8332699537277222, Discriminator loss: 1.2123384475708008\n",
      "\tGenerator loss: 0.8206542730331421, Discriminator loss: 1.2132296562194824\n",
      "\tGenerator loss: 0.8294839262962341, Discriminator loss: 1.2078466415405273\n",
      "\tGenerator loss: 0.8074898719787598, Discriminator loss: 1.222968339920044\n",
      "\tGenerator loss: 0.8232777714729309, Discriminator loss: 1.2411655187606812\n",
      "\tGenerator loss: 0.8310747146606445, Discriminator loss: 1.2416605949401855\n",
      "\tGenerator loss: 0.8206275105476379, Discriminator loss: 1.2343151569366455\n",
      "\tGenerator loss: 0.8318651914596558, Discriminator loss: 1.2326396703720093\n",
      "\tGenerator loss: 0.8442103266716003, Discriminator loss: 1.27913498878479\n",
      "\tGenerator loss: 0.8475041389465332, Discriminator loss: 1.3029292821884155\n",
      "\tGenerator loss: 0.833232045173645, Discriminator loss: 1.2891106605529785\n",
      "\tGenerator loss: 0.8282411694526672, Discriminator loss: 1.2890130281448364\n",
      "\tGenerator loss: 0.8242710828781128, Discriminator loss: 1.293188214302063\n",
      "\tGenerator loss: 0.8249650001525879, Discriminator loss: 1.3057456016540527\n",
      "\tGenerator loss: 0.8083836436271667, Discriminator loss: 1.3121862411499023\n",
      "\tGenerator loss: 0.8242640495300293, Discriminator loss: 1.2664943933486938\n",
      "\tGenerator loss: 0.8326261043548584, Discriminator loss: 1.2630901336669922\n",
      "\tGenerator loss: 0.8660740852355957, Discriminator loss: 1.261399507522583\n",
      "\tGenerator loss: 0.8957571387290955, Discriminator loss: 1.2192424535751343\n",
      "\tGenerator loss: 0.9238908290863037, Discriminator loss: 1.1810898780822754\n",
      "\tGenerator loss: 0.9345049262046814, Discriminator loss: 1.2186912298202515\n",
      "\tGenerator loss: 0.9348993301391602, Discriminator loss: 1.2518819570541382\n",
      "\tGenerator loss: 0.9233542084693909, Discriminator loss: 1.2614398002624512\n",
      "\tGenerator loss: 0.8796412944793701, Discriminator loss: 1.3224848508834839\n",
      "\tGenerator loss: 0.8425633311271667, Discriminator loss: 1.2948901653289795\n",
      "\tGenerator loss: 0.8086104393005371, Discriminator loss: 1.2939938306808472\n",
      "\tGenerator loss: 0.777391791343689, Discriminator loss: 1.262082815170288\n",
      "\tGenerator loss: 0.765733540058136, Discriminator loss: 1.259178876876831\n",
      "\tGenerator loss: 0.778878927230835, Discriminator loss: 1.2281959056854248\n",
      "\tGenerator loss: 0.8014847040176392, Discriminator loss: 1.25180983543396\n",
      "\tGenerator loss: 0.8390251398086548, Discriminator loss: 1.2706310749053955\n",
      "\tGenerator loss: 0.8778083324432373, Discriminator loss: 1.309678077697754\n",
      "\tGenerator loss: 0.8968035578727722, Discriminator loss: 1.3279868364334106\n",
      "\tGenerator loss: 0.8926255702972412, Discriminator loss: 1.3156731128692627\n",
      "\tGenerator loss: 0.8662149906158447, Discriminator loss: 1.3074767589569092\n",
      "\tGenerator loss: 0.8099119663238525, Discriminator loss: 1.2911195755004883\n",
      "\tGenerator loss: 0.7831341624259949, Discriminator loss: 1.3059314489364624\n",
      "\tGenerator loss: 0.7617079019546509, Discriminator loss: 1.2822436094284058\n",
      "\tGenerator loss: 0.7573156952857971, Discriminator loss: 1.2798330783843994\n",
      "\tGenerator loss: 0.7517062425613403, Discriminator loss: 1.3074145317077637\n",
      "\tGenerator loss: 0.7666875123977661, Discriminator loss: 1.3324687480926514\n",
      "\tGenerator loss: 0.7834327816963196, Discriminator loss: 1.3119558095932007\n",
      "\tGenerator loss: 0.7961927652359009, Discriminator loss: 1.3381383419036865\n",
      "\tGenerator loss: 0.8094754219055176, Discriminator loss: 1.3560394048690796\n",
      "\tGenerator loss: 0.7942655086517334, Discriminator loss: 1.3958220481872559\n",
      "\tGenerator loss: 0.7724646329879761, Discriminator loss: 1.4215412139892578\n",
      "\tGenerator loss: 0.7381315231323242, Discriminator loss: 1.4367156028747559\n",
      "\tGenerator loss: 0.7071200609207153, Discriminator loss: 1.4276996850967407\n",
      "\tGenerator loss: 0.7030887603759766, Discriminator loss: 1.4631726741790771\n",
      "\tGenerator loss: 0.6943874359130859, Discriminator loss: 1.5137181282043457\n",
      "\tGenerator loss: 0.6849945783615112, Discriminator loss: 1.5072617530822754\n",
      "\tGenerator loss: 0.6803372502326965, Discriminator loss: 1.5427266359329224\n",
      "\tGenerator loss: 0.6715442538261414, Discriminator loss: 1.623589038848877\n",
      "\tGenerator loss: 0.6735555529594421, Discriminator loss: 1.5514287948608398\n",
      "\tGenerator loss: 0.6633212566375732, Discriminator loss: 1.5369220972061157\n",
      "\tGenerator loss: 0.6646884679794312, Discriminator loss: 1.5386888980865479\n",
      "\tGenerator loss: 0.6733549237251282, Discriminator loss: 1.5339467525482178\n",
      "\tGenerator loss: 0.6765459775924683, Discriminator loss: 1.4893854856491089\n",
      "\tGenerator loss: 0.6971242427825928, Discriminator loss: 1.4671623706817627\n",
      "\tGenerator loss: 0.7053978443145752, Discriminator loss: 1.4613256454467773\n",
      "\tGenerator loss: 0.7189966440200806, Discriminator loss: 1.5081098079681396\n",
      "\tGenerator loss: 0.7189163565635681, Discriminator loss: 1.519137978553772\n",
      "\tGenerator loss: 0.7205387353897095, Discriminator loss: 1.502291202545166\n",
      "\tGenerator loss: 0.696587085723877, Discriminator loss: 1.5305505990982056\n",
      "\tGenerator loss: 0.6826025247573853, Discriminator loss: 1.5111920833587646\n",
      "\tGenerator loss: 0.6694422960281372, Discriminator loss: 1.5006434917449951\n",
      "\tGenerator loss: 0.661219596862793, Discriminator loss: 1.4886605739593506\n",
      "\tGenerator loss: 0.6600484848022461, Discriminator loss: 1.4889607429504395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.6622704267501831, Discriminator loss: 1.490743637084961\n",
      "\tGenerator loss: 0.6809537410736084, Discriminator loss: 1.4948177337646484\n",
      "\tGenerator loss: 0.6846166849136353, Discriminator loss: 1.5002155303955078\n",
      "\tGenerator loss: 0.7018546462059021, Discriminator loss: 1.4743050336837769\n",
      "\tGenerator loss: 0.70699143409729, Discriminator loss: 1.5161702632904053\n",
      "\tGenerator loss: 0.7241873145103455, Discriminator loss: 1.5471094846725464\n",
      "\tGenerator loss: 0.716523289680481, Discriminator loss: 1.5036842823028564\n",
      "\tGenerator loss: 0.6991778612136841, Discriminator loss: 1.4886986017227173\n",
      "\tGenerator loss: 0.6789780855178833, Discriminator loss: 1.5186527967453003\n",
      "\tGenerator loss: 0.6640815734863281, Discriminator loss: 1.502873420715332\n",
      "\tGenerator loss: 0.6584054231643677, Discriminator loss: 1.482750415802002\n",
      "\tGenerator loss: 0.6551603078842163, Discriminator loss: 1.469228982925415\n",
      "\tGenerator loss: 0.6631933450698853, Discriminator loss: 1.465010643005371\n",
      "\tGenerator loss: 0.6798382997512817, Discriminator loss: 1.528167724609375\n",
      "\tGenerator loss: 0.6939554214477539, Discriminator loss: 1.4990456104278564\n",
      "\tGenerator loss: 0.7007541656494141, Discriminator loss: 1.5107827186584473\n",
      "\tGenerator loss: 0.7003437280654907, Discriminator loss: 1.5055181980133057\n",
      "\tGenerator loss: 0.6970710754394531, Discriminator loss: 1.4810247421264648\n",
      "\tGenerator loss: 0.6992262005805969, Discriminator loss: 1.467390537261963\n",
      "\tGenerator loss: 0.6966018676757812, Discriminator loss: 1.4494898319244385\n",
      "\tGenerator loss: 0.6898048520088196, Discriminator loss: 1.4306832551956177\n",
      "\tGenerator loss: 0.6938698291778564, Discriminator loss: 1.438976764678955\n",
      "\tGenerator loss: 0.7050867080688477, Discriminator loss: 1.4488693475723267\n",
      "\tGenerator loss: 0.7138981819152832, Discriminator loss: 1.4589155912399292\n",
      "\tGenerator loss: 0.7127578258514404, Discriminator loss: 1.4341564178466797\n",
      "\tGenerator loss: 0.718059778213501, Discriminator loss: 1.4090358018875122\n",
      "\tGenerator loss: 0.7233397960662842, Discriminator loss: 1.3804621696472168\n",
      "\tGenerator loss: 0.7274379730224609, Discriminator loss: 1.3685932159423828\n",
      "\tGenerator loss: 0.7402677536010742, Discriminator loss: 1.3777250051498413\n",
      "\tGenerator loss: 0.7482025623321533, Discriminator loss: 1.3585007190704346\n",
      "\tGenerator loss: 0.7505840063095093, Discriminator loss: 1.360851764678955\n",
      "\tGenerator loss: 0.7571713924407959, Discriminator loss: 1.352135181427002\n",
      "\tGenerator loss: 0.7571744918823242, Discriminator loss: 1.342499852180481\n",
      "\tGenerator loss: 0.7592802047729492, Discriminator loss: 1.3459908962249756\n",
      "\tGenerator loss: 0.76292884349823, Discriminator loss: 1.3215796947479248\n",
      "\tGenerator loss: 0.7712185978889465, Discriminator loss: 1.3009330034255981\n",
      "\tGenerator loss: 0.7794798016548157, Discriminator loss: 1.300061821937561\n",
      "\tGenerator loss: 0.7934999465942383, Discriminator loss: 1.311406135559082\n",
      "\tGenerator loss: 0.7944163084030151, Discriminator loss: 1.3276797533035278\n",
      "\tGenerator loss: 0.7930792570114136, Discriminator loss: 1.312741994857788\n",
      "\tGenerator loss: 0.7944907546043396, Discriminator loss: 1.283121109008789\n",
      "\tGenerator loss: 0.7945351004600525, Discriminator loss: 1.272303819656372\n",
      "\tGenerator loss: 0.7943778038024902, Discriminator loss: 1.2343640327453613\n",
      "\tGenerator loss: 0.8025053143501282, Discriminator loss: 1.2403998374938965\n",
      "\tGenerator loss: 0.8036609888076782, Discriminator loss: 1.2611908912658691\n",
      "\tGenerator loss: 0.8156896829605103, Discriminator loss: 1.2229115962982178\n",
      "\tGenerator loss: 0.8296851515769958, Discriminator loss: 1.205047845840454\n",
      "\tGenerator loss: 0.8335031270980835, Discriminator loss: 1.1971489191055298\n",
      "\tGenerator loss: 0.8424221277236938, Discriminator loss: 1.1830027103424072\n",
      "\tGenerator loss: 0.8411962389945984, Discriminator loss: 1.1925039291381836\n",
      "\tGenerator loss: 0.8538454174995422, Discriminator loss: 1.1797549724578857\n",
      "\tGenerator loss: 0.8553546667098999, Discriminator loss: 1.1634913682937622\n",
      "\tGenerator loss: 0.8589770793914795, Discriminator loss: 1.1588163375854492\n",
      "\tGenerator loss: 0.858644425868988, Discriminator loss: 1.192034125328064\n",
      "\tGenerator loss: 0.8619771003723145, Discriminator loss: 1.1360102891921997\n",
      "\tGenerator loss: 0.8669394850730896, Discriminator loss: 1.106313705444336\n",
      "\tGenerator loss: 0.8745388388633728, Discriminator loss: 1.1095554828643799\n",
      "\tGenerator loss: 0.8864002227783203, Discriminator loss: 1.1040834188461304\n",
      "\tGenerator loss: 0.896355152130127, Discriminator loss: 1.0889391899108887\n",
      "\tGenerator loss: 0.9103611707687378, Discriminator loss: 1.0758748054504395\n",
      "\tGenerator loss: 0.9291806221008301, Discriminator loss: 1.0804760456085205\n",
      "\tGenerator loss: 0.9323765635490417, Discriminator loss: 1.0753130912780762\n",
      "\tGenerator loss: 0.9406802654266357, Discriminator loss: 1.0868146419525146\n",
      "\tGenerator loss: 0.9266313314437866, Discriminator loss: 1.1089531183242798\n",
      "\tGenerator loss: 0.9161610007286072, Discriminator loss: 1.1305129528045654\n",
      "\tGenerator loss: 0.912307620048523, Discriminator loss: 1.1278454065322876\n",
      "\tGenerator loss: 0.9053547978401184, Discriminator loss: 1.111417531967163\n",
      "\tGenerator loss: 0.9003506302833557, Discriminator loss: 1.146549940109253\n",
      "\tGenerator loss: 0.8903719186782837, Discriminator loss: 1.1258506774902344\n",
      "\tGenerator loss: 0.8868007659912109, Discriminator loss: 1.1215686798095703\n",
      "\tGenerator loss: 0.8954840302467346, Discriminator loss: 1.0946497917175293\n",
      "\tGenerator loss: 0.9078189134597778, Discriminator loss: 1.1057584285736084\n",
      "\tGenerator loss: 0.9223582744598389, Discriminator loss: 1.137927770614624\n",
      "\tGenerator loss: 0.949066698551178, Discriminator loss: 1.1674822568893433\n",
      "\tGenerator loss: 0.9646193981170654, Discriminator loss: 1.1781831979751587\n",
      "\tGenerator loss: 0.9592914581298828, Discriminator loss: 1.1735095977783203\n",
      "\tGenerator loss: 0.9465621709823608, Discriminator loss: 1.1986738443374634\n",
      "\tGenerator loss: 0.9198148250579834, Discriminator loss: 1.2162630558013916\n",
      "\tGenerator loss: 0.9215894937515259, Discriminator loss: 1.1888941526412964\n",
      "\tGenerator loss: 0.9105857014656067, Discriminator loss: 1.176173210144043\n",
      "\tGenerator loss: 0.9062124490737915, Discriminator loss: 1.197748064994812\n",
      "\tGenerator loss: 0.8974449634552002, Discriminator loss: 1.1989967823028564\n",
      "\tGenerator loss: 0.9020682573318481, Discriminator loss: 1.231953740119934\n",
      "\tGenerator loss: 0.9093426465988159, Discriminator loss: 1.2247791290283203\n",
      "\tGenerator loss: 0.9179694056510925, Discriminator loss: 1.2379586696624756\n",
      "\tGenerator loss: 0.9354749917984009, Discriminator loss: 1.2405697107315063\n",
      "\tGenerator loss: 0.9204257130622864, Discriminator loss: 1.2634038925170898\n",
      "\tGenerator loss: 0.9181926250457764, Discriminator loss: 1.244333028793335\n",
      "\tGenerator loss: 0.913281261920929, Discriminator loss: 1.2862839698791504\n",
      "\tGenerator loss: 0.9131686091423035, Discriminator loss: 1.2899775505065918\n",
      "\tGenerator loss: 0.884809136390686, Discriminator loss: 1.2879266738891602\n",
      "\tGenerator loss: 0.8628267049789429, Discriminator loss: 1.247293472290039\n",
      "\tGenerator loss: 0.8526180982589722, Discriminator loss: 1.262015700340271\n",
      "\tGenerator loss: 0.8649637699127197, Discriminator loss: 1.229637622833252\n",
      "\tGenerator loss: 0.8882530927658081, Discriminator loss: 1.2125837802886963\n",
      "\tGenerator loss: 0.9239027500152588, Discriminator loss: 1.2089323997497559\n",
      "\tGenerator loss: 0.9499712586402893, Discriminator loss: 1.190321445465088\n",
      "\tGenerator loss: 0.9647140502929688, Discriminator loss: 1.192330241203308\n",
      "\tGenerator loss: 0.9671904444694519, Discriminator loss: 1.2108852863311768\n",
      "\tGenerator loss: 0.9545893669128418, Discriminator loss: 1.2343838214874268\n",
      "\tGenerator loss: 0.933929443359375, Discriminator loss: 1.2419953346252441\n",
      "\tGenerator loss: 0.9141680002212524, Discriminator loss: 1.2219101190567017\n",
      "\tGenerator loss: 0.9027035236358643, Discriminator loss: 1.1967699527740479\n",
      "\tGenerator loss: 0.8807013034820557, Discriminator loss: 1.2161206007003784\n",
      "\tGenerator loss: 0.8765385150909424, Discriminator loss: 1.2294435501098633\n",
      "\tGenerator loss: 0.8832355737686157, Discriminator loss: 1.2253248691558838\n",
      "\tGenerator loss: 0.89255690574646, Discriminator loss: 1.241039752960205\n",
      "\tGenerator loss: 0.8951341509819031, Discriminator loss: 1.2348638772964478\n",
      "\tGenerator loss: 0.8906394243240356, Discriminator loss: 1.2184064388275146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.877434492111206, Discriminator loss: 1.1989812850952148\n",
      "\tGenerator loss: 0.8930690288543701, Discriminator loss: 1.184753656387329\n",
      "\tGenerator loss: 0.9029707312583923, Discriminator loss: 1.2026995420455933\n",
      "\tGenerator loss: 0.9171042442321777, Discriminator loss: 1.2014963626861572\n",
      "\tGenerator loss: 0.9232112169265747, Discriminator loss: 1.1795005798339844\n",
      "\tGenerator loss: 0.9116063714027405, Discriminator loss: 1.1635938882827759\n",
      "\tGenerator loss: 0.9044092297554016, Discriminator loss: 1.1598033905029297\n",
      "\tGenerator loss: 0.9095369577407837, Discriminator loss: 1.1568242311477661\n",
      "\tGenerator loss: 0.9154852032661438, Discriminator loss: 1.146012544631958\n",
      "\tGenerator loss: 0.9221941232681274, Discriminator loss: 1.1950175762176514\n",
      "\tGenerator loss: 0.8948005437850952, Discriminator loss: 1.1883653402328491\n",
      "\tGenerator loss: 0.8735350370407104, Discriminator loss: 1.198608636856079\n",
      "\tGenerator loss: 0.8570879697799683, Discriminator loss: 1.2103402614593506\n",
      "\tGenerator loss: 0.8502004146575928, Discriminator loss: 1.2062019109725952\n",
      "\tGenerator loss: 0.8488266468048096, Discriminator loss: 1.199623942375183\n",
      "\tGenerator loss: 0.8394798040390015, Discriminator loss: 1.21529221534729\n",
      "\tGenerator loss: 0.8368158340454102, Discriminator loss: 1.1938837766647339\n",
      "\tGenerator loss: 0.8538219928741455, Discriminator loss: 1.1639924049377441\n",
      "\tGenerator loss: 0.8597491979598999, Discriminator loss: 1.1693530082702637\n",
      "\tGenerator loss: 0.8718819618225098, Discriminator loss: 1.1806033849716187\n",
      "\tGenerator loss: 0.8855748176574707, Discriminator loss: 1.191319227218628\n",
      "\tGenerator loss: 0.8858660459518433, Discriminator loss: 1.217137098312378\n",
      "\tGenerator loss: 0.8711601495742798, Discriminator loss: 1.2078726291656494\n",
      "\tGenerator loss: 0.8303566575050354, Discriminator loss: 1.1920108795166016\n",
      "\tGenerator loss: 0.8085908889770508, Discriminator loss: 1.1935244798660278\n",
      "\tGenerator loss: 0.8136327862739563, Discriminator loss: 1.1692479848861694\n",
      "\tGenerator loss: 0.8117656707763672, Discriminator loss: 1.1951980590820312\n",
      "\tGenerator loss: 0.8314969539642334, Discriminator loss: 1.2244770526885986\n",
      "\tGenerator loss: 0.841066837310791, Discriminator loss: 1.2220957279205322\n",
      "\tGenerator loss: 0.8515108227729797, Discriminator loss: 1.2245891094207764\n",
      "\tGenerator loss: 0.837995171546936, Discriminator loss: 1.2297916412353516\n",
      "\tGenerator loss: 0.8128309845924377, Discriminator loss: 1.2244619131088257\n",
      "\tGenerator loss: 0.7918739318847656, Discriminator loss: 1.2377943992614746\n",
      "\tGenerator loss: 0.7946180105209351, Discriminator loss: 1.2259786128997803\n",
      "\tGenerator loss: 0.7888278961181641, Discriminator loss: 1.2278003692626953\n",
      "\tGenerator loss: 0.8018744587898254, Discriminator loss: 1.2182509899139404\n",
      "\tGenerator loss: 0.8148393034934998, Discriminator loss: 1.2140982151031494\n",
      "\tGenerator loss: 0.8389012217521667, Discriminator loss: 1.2405208349227905\n",
      "\tGenerator loss: 0.8422025442123413, Discriminator loss: 1.2673943042755127\n",
      "\tGenerator loss: 0.8256908655166626, Discriminator loss: 1.2780115604400635\n",
      "\tGenerator loss: 0.7938801050186157, Discriminator loss: 1.2749537229537964\n",
      "\tGenerator loss: 0.7654078006744385, Discriminator loss: 1.261444330215454\n",
      "\tGenerator loss: 0.7456482648849487, Discriminator loss: 1.2424794435501099\n",
      "\tGenerator loss: 0.7564481496810913, Discriminator loss: 1.2532992362976074\n",
      "\tGenerator loss: 0.7678075432777405, Discriminator loss: 1.280510663986206\n",
      "\tGenerator loss: 0.7976535558700562, Discriminator loss: 1.236446499824524\n",
      "\tGenerator loss: 0.8180049657821655, Discriminator loss: 1.2176105976104736\n",
      "\tGenerator loss: 0.8239185810089111, Discriminator loss: 1.221402645111084\n",
      "\tGenerator loss: 0.8324061632156372, Discriminator loss: 1.1711349487304688\n",
      "\tGenerator loss: 0.8396165370941162, Discriminator loss: 1.160075068473816\n",
      "\tGenerator loss: 0.8383985161781311, Discriminator loss: 1.171008586883545\n",
      "\tGenerator loss: 0.8547834157943726, Discriminator loss: 1.1363544464111328\n",
      "\tGenerator loss: 0.862648606300354, Discriminator loss: 1.1709232330322266\n",
      "Time for epoch 3 is 486.3495993614197 sec\n",
      "\tGenerator loss: 0.879713773727417, Discriminator loss: 1.1490576267242432\n",
      "\tGenerator loss: 0.8704367280006409, Discriminator loss: 1.1374642848968506\n",
      "\tGenerator loss: 0.8669465780258179, Discriminator loss: 1.120283603668213\n",
      "\tGenerator loss: 0.8549451231956482, Discriminator loss: 1.121142864227295\n",
      "\tGenerator loss: 0.8297970294952393, Discriminator loss: 1.1415711641311646\n",
      "\tGenerator loss: 0.8305160999298096, Discriminator loss: 1.1352171897888184\n",
      "\tGenerator loss: 0.8511022329330444, Discriminator loss: 1.1140810251235962\n",
      "\tGenerator loss: 0.8738288879394531, Discriminator loss: 1.109459400177002\n",
      "\tGenerator loss: 0.8881336450576782, Discriminator loss: 1.0993359088897705\n",
      "\tGenerator loss: 0.9007257223129272, Discriminator loss: 1.0824594497680664\n",
      "\tGenerator loss: 0.9022732973098755, Discriminator loss: 1.0811355113983154\n",
      "\tGenerator loss: 0.9023427963256836, Discriminator loss: 1.0801113843917847\n",
      "\tGenerator loss: 0.8984076976776123, Discriminator loss: 1.0706813335418701\n",
      "\tGenerator loss: 0.8956775069236755, Discriminator loss: 1.0657846927642822\n",
      "\tGenerator loss: 0.8812922239303589, Discriminator loss: 1.0797898769378662\n",
      "\tGenerator loss: 0.8834128379821777, Discriminator loss: 1.0495272874832153\n",
      "\tGenerator loss: 0.8838318586349487, Discriminator loss: 1.054037094116211\n",
      "\tGenerator loss: 0.8981308937072754, Discriminator loss: 1.0669399499893188\n",
      "\tGenerator loss: 0.9101489186286926, Discriminator loss: 1.0979410409927368\n",
      "\tGenerator loss: 0.9183070659637451, Discriminator loss: 1.0967762470245361\n",
      "\tGenerator loss: 0.9051044583320618, Discriminator loss: 1.0890291929244995\n",
      "\tGenerator loss: 0.8880727887153625, Discriminator loss: 1.1091668605804443\n",
      "\tGenerator loss: 0.866201639175415, Discriminator loss: 1.1211378574371338\n",
      "\tGenerator loss: 0.8594695329666138, Discriminator loss: 1.1442283391952515\n",
      "\tGenerator loss: 0.8393311500549316, Discriminator loss: 1.16969633102417\n",
      "\tGenerator loss: 0.8284003138542175, Discriminator loss: 1.1747021675109863\n",
      "\tGenerator loss: 0.8358198404312134, Discriminator loss: 1.1975442171096802\n",
      "\tGenerator loss: 0.8252852559089661, Discriminator loss: 1.208446741104126\n",
      "\tGenerator loss: 0.8049793839454651, Discriminator loss: 1.230196237564087\n",
      "\tGenerator loss: 0.7713860273361206, Discriminator loss: 1.243671178817749\n",
      "\tGenerator loss: 0.7500424981117249, Discriminator loss: 1.2687312364578247\n",
      "\tGenerator loss: 0.7454053163528442, Discriminator loss: 1.3004281520843506\n",
      "\tGenerator loss: 0.7475395202636719, Discriminator loss: 1.3127408027648926\n",
      "\tGenerator loss: 0.7641699314117432, Discriminator loss: 1.387133240699768\n",
      "\tGenerator loss: 0.7750602960586548, Discriminator loss: 1.3860034942626953\n",
      "\tGenerator loss: 0.748695969581604, Discriminator loss: 1.3944340944290161\n",
      "\tGenerator loss: 0.7255274057388306, Discriminator loss: 1.4231128692626953\n",
      "\tGenerator loss: 0.690045952796936, Discriminator loss: 1.4642608165740967\n",
      "\tGenerator loss: 0.6719083189964294, Discriminator loss: 1.4377585649490356\n",
      "\tGenerator loss: 0.6545178890228271, Discriminator loss: 1.4909229278564453\n",
      "\tGenerator loss: 0.6643625497817993, Discriminator loss: 1.5451767444610596\n",
      "\tGenerator loss: 0.682801365852356, Discriminator loss: 1.5198415517807007\n",
      "\tGenerator loss: 0.7045148611068726, Discriminator loss: 1.5318303108215332\n",
      "\tGenerator loss: 0.7169485688209534, Discriminator loss: 1.511653184890747\n",
      "\tGenerator loss: 0.7127951979637146, Discriminator loss: 1.499748945236206\n",
      "\tGenerator loss: 0.6866178512573242, Discriminator loss: 1.5136590003967285\n",
      "\tGenerator loss: 0.6663722991943359, Discriminator loss: 1.4948585033416748\n",
      "\tGenerator loss: 0.6517282724380493, Discriminator loss: 1.5062520503997803\n",
      "\tGenerator loss: 0.6619647145271301, Discriminator loss: 1.49812650680542\n",
      "\tGenerator loss: 0.6916468143463135, Discriminator loss: 1.4779562950134277\n",
      "\tGenerator loss: 0.7338404655456543, Discriminator loss: 1.4717278480529785\n",
      "\tGenerator loss: 0.7659326791763306, Discriminator loss: 1.4450311660766602\n",
      "\tGenerator loss: 0.7812563180923462, Discriminator loss: 1.4039204120635986\n",
      "\tGenerator loss: 0.780471920967102, Discriminator loss: 1.3813661336898804\n",
      "\tGenerator loss: 0.7550473809242249, Discriminator loss: 1.3699495792388916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.7547041177749634, Discriminator loss: 1.377813696861267\n",
      "\tGenerator loss: 0.7621762156486511, Discriminator loss: 1.3311200141906738\n",
      "\tGenerator loss: 0.7982672452926636, Discriminator loss: 1.3383045196533203\n",
      "\tGenerator loss: 0.825653076171875, Discriminator loss: 1.2722046375274658\n",
      "\tGenerator loss: 0.8571401238441467, Discriminator loss: 1.2256191968917847\n",
      "\tGenerator loss: 0.8910418748855591, Discriminator loss: 1.197685956954956\n",
      "\tGenerator loss: 0.9071065783500671, Discriminator loss: 1.174328327178955\n",
      "\tGenerator loss: 0.926025390625, Discriminator loss: 1.1518661975860596\n",
      "\tGenerator loss: 0.9438762664794922, Discriminator loss: 1.1069879531860352\n",
      "\tGenerator loss: 0.9491037130355835, Discriminator loss: 1.0752923488616943\n",
      "\tGenerator loss: 0.9560716152191162, Discriminator loss: 1.082604169845581\n",
      "\tGenerator loss: 0.9921523332595825, Discriminator loss: 1.0696650743484497\n",
      "\tGenerator loss: 1.0227422714233398, Discriminator loss: 1.060502290725708\n",
      "\tGenerator loss: 1.0292550325393677, Discriminator loss: 1.0505825281143188\n",
      "\tGenerator loss: 1.0207066535949707, Discriminator loss: 1.0164906978607178\n",
      "\tGenerator loss: 1.023501992225647, Discriminator loss: 0.9881715774536133\n",
      "\tGenerator loss: 1.0119540691375732, Discriminator loss: 0.9975217580795288\n",
      "\tGenerator loss: 1.0305150747299194, Discriminator loss: 0.9792749881744385\n",
      "\tGenerator loss: 1.068779706954956, Discriminator loss: 0.9731128215789795\n",
      "\tGenerator loss: 1.1104562282562256, Discriminator loss: 0.9602092504501343\n",
      "\tGenerator loss: 1.1244202852249146, Discriminator loss: 0.9544148445129395\n",
      "\tGenerator loss: 1.0826787948608398, Discriminator loss: 0.9634356498718262\n",
      "\tGenerator loss: 1.0650303363800049, Discriminator loss: 0.9661780595779419\n",
      "\tGenerator loss: 1.0501060485839844, Discriminator loss: 0.989353358745575\n",
      "\tGenerator loss: 1.025618076324463, Discriminator loss: 0.9947388172149658\n",
      "\tGenerator loss: 1.028111457824707, Discriminator loss: 0.9645026326179504\n",
      "\tGenerator loss: 1.0137972831726074, Discriminator loss: 0.9915429353713989\n",
      "\tGenerator loss: 1.0219542980194092, Discriminator loss: 1.0017485618591309\n",
      "\tGenerator loss: 1.019167184829712, Discriminator loss: 1.0057358741760254\n",
      "\tGenerator loss: 1.009847640991211, Discriminator loss: 1.0166646242141724\n",
      "\tGenerator loss: 0.9867595434188843, Discriminator loss: 1.018212914466858\n",
      "\tGenerator loss: 0.9920891523361206, Discriminator loss: 1.0528590679168701\n",
      "\tGenerator loss: 0.9641132354736328, Discriminator loss: 1.071953535079956\n",
      "\tGenerator loss: 0.9353513717651367, Discriminator loss: 1.0841093063354492\n",
      "\tGenerator loss: 0.9210692644119263, Discriminator loss: 1.0922107696533203\n",
      "\tGenerator loss: 0.9076259136199951, Discriminator loss: 1.1068239212036133\n",
      "\tGenerator loss: 0.9039268493652344, Discriminator loss: 1.1154870986938477\n",
      "\tGenerator loss: 0.8983935117721558, Discriminator loss: 1.1339737176895142\n",
      "\tGenerator loss: 0.8828339576721191, Discriminator loss: 1.1398773193359375\n",
      "\tGenerator loss: 0.8781636953353882, Discriminator loss: 1.147843360900879\n",
      "\tGenerator loss: 0.8711189031600952, Discriminator loss: 1.1799708604812622\n",
      "\tGenerator loss: 0.8605388402938843, Discriminator loss: 1.186035394668579\n",
      "\tGenerator loss: 0.8378342390060425, Discriminator loss: 1.2270793914794922\n",
      "\tGenerator loss: 0.8044416904449463, Discriminator loss: 1.2302663326263428\n",
      "\tGenerator loss: 0.7799482941627502, Discriminator loss: 1.2171788215637207\n",
      "\tGenerator loss: 0.7864859104156494, Discriminator loss: 1.24435293674469\n",
      "\tGenerator loss: 0.784511148929596, Discriminator loss: 1.2905316352844238\n",
      "\tGenerator loss: 0.7799695730209351, Discriminator loss: 1.2816722393035889\n",
      "\tGenerator loss: 0.7689028978347778, Discriminator loss: 1.3158761262893677\n",
      "\tGenerator loss: 0.748308539390564, Discriminator loss: 1.3168714046478271\n",
      "\tGenerator loss: 0.7086277604103088, Discriminator loss: 1.3470631837844849\n",
      "\tGenerator loss: 0.7139624357223511, Discriminator loss: 1.3754949569702148\n",
      "\tGenerator loss: 0.7318459749221802, Discriminator loss: 1.376378059387207\n",
      "\tGenerator loss: 0.7274332046508789, Discriminator loss: 1.404231309890747\n",
      "\tGenerator loss: 0.7181627750396729, Discriminator loss: 1.3790802955627441\n",
      "\tGenerator loss: 0.7148324251174927, Discriminator loss: 1.3765225410461426\n",
      "\tGenerator loss: 0.6922690272331238, Discriminator loss: 1.4139158725738525\n",
      "\tGenerator loss: 0.7053952217102051, Discriminator loss: 1.4002196788787842\n",
      "\tGenerator loss: 0.7141226530075073, Discriminator loss: 1.410681128501892\n",
      "\tGenerator loss: 0.7174004316329956, Discriminator loss: 1.4280164241790771\n",
      "\tGenerator loss: 0.7045108675956726, Discriminator loss: 1.4134184122085571\n",
      "\tGenerator loss: 0.6702637672424316, Discriminator loss: 1.4564697742462158\n",
      "\tGenerator loss: 0.6543635725975037, Discriminator loss: 1.472335934638977\n",
      "\tGenerator loss: 0.6356117129325867, Discriminator loss: 1.4731806516647339\n",
      "\tGenerator loss: 0.6380046606063843, Discriminator loss: 1.4666098356246948\n",
      "\tGenerator loss: 0.6583335995674133, Discriminator loss: 1.4328562021255493\n",
      "\tGenerator loss: 0.6763026714324951, Discriminator loss: 1.4421448707580566\n",
      "\tGenerator loss: 0.6817561388015747, Discriminator loss: 1.4579490423202515\n",
      "\tGenerator loss: 0.6842144727706909, Discriminator loss: 1.4636530876159668\n",
      "\tGenerator loss: 0.6743384599685669, Discriminator loss: 1.4331817626953125\n",
      "\tGenerator loss: 0.6645764708518982, Discriminator loss: 1.4299697875976562\n",
      "\tGenerator loss: 0.6659101843833923, Discriminator loss: 1.4648076295852661\n",
      "\tGenerator loss: 0.6756646633148193, Discriminator loss: 1.4257316589355469\n",
      "\tGenerator loss: 0.7045816779136658, Discriminator loss: 1.3796629905700684\n",
      "\tGenerator loss: 0.728941798210144, Discriminator loss: 1.3794496059417725\n",
      "\tGenerator loss: 0.7497822046279907, Discriminator loss: 1.36884605884552\n",
      "\tGenerator loss: 0.7542928457260132, Discriminator loss: 1.3346154689788818\n",
      "\tGenerator loss: 0.7448938488960266, Discriminator loss: 1.322675108909607\n",
      "\tGenerator loss: 0.7516974806785583, Discriminator loss: 1.2999546527862549\n",
      "\tGenerator loss: 0.7565120458602905, Discriminator loss: 1.3063011169433594\n",
      "\tGenerator loss: 0.7628971934318542, Discriminator loss: 1.3168699741363525\n",
      "\tGenerator loss: 0.7776767015457153, Discriminator loss: 1.292478084564209\n",
      "\tGenerator loss: 0.8012157678604126, Discriminator loss: 1.2626006603240967\n",
      "\tGenerator loss: 0.8222692012786865, Discriminator loss: 1.25832998752594\n",
      "\tGenerator loss: 0.8299438953399658, Discriminator loss: 1.2313625812530518\n",
      "\tGenerator loss: 0.8269679546356201, Discriminator loss: 1.2157893180847168\n",
      "\tGenerator loss: 0.8307085633277893, Discriminator loss: 1.2543702125549316\n",
      "\tGenerator loss: 0.8267509937286377, Discriminator loss: 1.2232747077941895\n",
      "\tGenerator loss: 0.8430601358413696, Discriminator loss: 1.2236443758010864\n",
      "\tGenerator loss: 0.8552234768867493, Discriminator loss: 1.1944808959960938\n",
      "\tGenerator loss: 0.8998895883560181, Discriminator loss: 1.1847842931747437\n",
      "\tGenerator loss: 0.9097681045532227, Discriminator loss: 1.1446651220321655\n",
      "\tGenerator loss: 0.9222924709320068, Discriminator loss: 1.1311681270599365\n",
      "\tGenerator loss: 0.9176048040390015, Discriminator loss: 1.096985101699829\n",
      "\tGenerator loss: 0.9356330633163452, Discriminator loss: 1.0909500122070312\n",
      "\tGenerator loss: 0.9303486943244934, Discriminator loss: 1.0820069313049316\n",
      "\tGenerator loss: 0.9567703604698181, Discriminator loss: 1.0312811136245728\n",
      "\tGenerator loss: 0.9668070077896118, Discriminator loss: 1.0290164947509766\n",
      "\tGenerator loss: 1.0014324188232422, Discriminator loss: 1.0344566106796265\n",
      "\tGenerator loss: 1.0032793283462524, Discriminator loss: 1.0257329940795898\n",
      "\tGenerator loss: 0.9973118901252747, Discriminator loss: 1.020885705947876\n",
      "\tGenerator loss: 0.9707022905349731, Discriminator loss: 0.9937855005264282\n",
      "\tGenerator loss: 0.9768751263618469, Discriminator loss: 0.9980607628822327\n",
      "\tGenerator loss: 1.0002026557922363, Discriminator loss: 1.022152066230774\n",
      "\tGenerator loss: 1.0470945835113525, Discriminator loss: 0.9565824270248413\n",
      "\tGenerator loss: 1.069547414779663, Discriminator loss: 0.9381526708602905\n",
      "\tGenerator loss: 1.0832123756408691, Discriminator loss: 0.9917266964912415\n",
      "\tGenerator loss: 1.0581769943237305, Discriminator loss: 0.9773650169372559\n",
      "\tGenerator loss: 1.019775629043579, Discriminator loss: 0.968497633934021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9969120025634766, Discriminator loss: 0.946040153503418\n",
      "\tGenerator loss: 1.029171347618103, Discriminator loss: 0.9423625469207764\n",
      "\tGenerator loss: 1.079850673675537, Discriminator loss: 0.9554774761199951\n",
      "\tGenerator loss: 1.1176707744598389, Discriminator loss: 0.9443415403366089\n",
      "\tGenerator loss: 1.108144760131836, Discriminator loss: 0.9338454604148865\n",
      "\tGenerator loss: 1.0864282846450806, Discriminator loss: 0.940626859664917\n",
      "\tGenerator loss: 1.0618326663970947, Discriminator loss: 0.9343342185020447\n",
      "\tGenerator loss: 1.043615698814392, Discriminator loss: 0.9499454498291016\n",
      "\tGenerator loss: 1.0558147430419922, Discriminator loss: 0.9824125170707703\n",
      "\tGenerator loss: 1.063225507736206, Discriminator loss: 0.9783670902252197\n",
      "\tGenerator loss: 1.0484004020690918, Discriminator loss: 0.9731554985046387\n",
      "\tGenerator loss: 1.0459203720092773, Discriminator loss: 0.9941914081573486\n",
      "\tGenerator loss: 1.0015395879745483, Discriminator loss: 1.0216000080108643\n",
      "\tGenerator loss: 1.0110869407653809, Discriminator loss: 1.0649614334106445\n",
      "\tGenerator loss: 0.9965024590492249, Discriminator loss: 1.0843327045440674\n",
      "\tGenerator loss: 0.9391096234321594, Discriminator loss: 1.1462318897247314\n",
      "\tGenerator loss: 0.8849508762359619, Discriminator loss: 1.16722571849823\n",
      "\tGenerator loss: 0.8651984930038452, Discriminator loss: 1.180314064025879\n",
      "\tGenerator loss: 0.873026967048645, Discriminator loss: 1.1690542697906494\n",
      "\tGenerator loss: 0.9096677303314209, Discriminator loss: 1.2171019315719604\n",
      "\tGenerator loss: 0.9203975200653076, Discriminator loss: 1.2699999809265137\n",
      "\tGenerator loss: 0.8868225812911987, Discriminator loss: 1.2902483940124512\n",
      "\tGenerator loss: 0.8136093616485596, Discriminator loss: 1.2887704372406006\n",
      "\tGenerator loss: 0.786896288394928, Discriminator loss: 1.3068822622299194\n",
      "\tGenerator loss: 0.7964037656784058, Discriminator loss: 1.3409086465835571\n",
      "\tGenerator loss: 0.8371316194534302, Discriminator loss: 1.3767534494400024\n",
      "\tGenerator loss: 0.8611879944801331, Discriminator loss: 1.3817414045333862\n",
      "\tGenerator loss: 0.8438119888305664, Discriminator loss: 1.4870758056640625\n",
      "\tGenerator loss: 0.7395988702774048, Discriminator loss: 1.506733775138855\n",
      "\tGenerator loss: 0.6491351127624512, Discriminator loss: 1.5507071018218994\n",
      "\tGenerator loss: 0.6289618015289307, Discriminator loss: 1.5550428628921509\n",
      "\tGenerator loss: 0.6639357805252075, Discriminator loss: 1.572145700454712\n",
      "\tGenerator loss: 0.7452032566070557, Discriminator loss: 1.6292297840118408\n",
      "\tGenerator loss: 0.7678471803665161, Discriminator loss: 1.6464736461639404\n",
      "\tGenerator loss: 0.7172621488571167, Discriminator loss: 1.5983814001083374\n",
      "\tGenerator loss: 0.6489182710647583, Discriminator loss: 1.5819511413574219\n",
      "\tGenerator loss: 0.6406077146530151, Discriminator loss: 1.557645559310913\n",
      "\tGenerator loss: 0.6772619485855103, Discriminator loss: 1.5494171380996704\n",
      "\tGenerator loss: 0.7148758172988892, Discriminator loss: 1.6156110763549805\n",
      "\tGenerator loss: 0.7408033609390259, Discriminator loss: 1.663769245147705\n",
      "\tGenerator loss: 0.6967116594314575, Discriminator loss: 1.6322556734085083\n",
      "\tGenerator loss: 0.6433649063110352, Discriminator loss: 1.5885744094848633\n",
      "\tGenerator loss: 0.6196128726005554, Discriminator loss: 1.5672478675842285\n",
      "\tGenerator loss: 0.6461857557296753, Discriminator loss: 1.5224709510803223\n",
      "\tGenerator loss: 0.6948622465133667, Discriminator loss: 1.5221394300460815\n",
      "\tGenerator loss: 0.764127790927887, Discriminator loss: 1.5220756530761719\n",
      "\tGenerator loss: 0.7860040664672852, Discriminator loss: 1.4931960105895996\n",
      "\tGenerator loss: 0.7459630966186523, Discriminator loss: 1.4745919704437256\n",
      "\tGenerator loss: 0.6865805983543396, Discriminator loss: 1.4443769454956055\n",
      "\tGenerator loss: 0.6775153279304504, Discriminator loss: 1.3869761228561401\n",
      "\tGenerator loss: 0.7109791040420532, Discriminator loss: 1.3705472946166992\n",
      "\tGenerator loss: 0.7734137177467346, Discriminator loss: 1.3351467847824097\n",
      "\tGenerator loss: 0.8272228240966797, Discriminator loss: 1.2917215824127197\n",
      "\tGenerator loss: 0.8503929376602173, Discriminator loss: 1.245773196220398\n",
      "\tGenerator loss: 0.8833540081977844, Discriminator loss: 1.212403655052185\n",
      "\tGenerator loss: 0.8741185665130615, Discriminator loss: 1.2200849056243896\n",
      "\tGenerator loss: 0.8618360757827759, Discriminator loss: 1.1939771175384521\n",
      "\tGenerator loss: 0.836017906665802, Discriminator loss: 1.1788175106048584\n",
      "\tGenerator loss: 0.8190109729766846, Discriminator loss: 1.1541736125946045\n",
      "\tGenerator loss: 0.8201578855514526, Discriminator loss: 1.137404441833496\n",
      "\tGenerator loss: 0.8503899574279785, Discriminator loss: 1.098862886428833\n",
      "\tGenerator loss: 0.9007829427719116, Discriminator loss: 1.091693639755249\n",
      "\tGenerator loss: 0.9392223358154297, Discriminator loss: 1.105302095413208\n",
      "\tGenerator loss: 0.9660621881484985, Discriminator loss: 1.080467939376831\n",
      "\tGenerator loss: 0.9415246844291687, Discriminator loss: 1.0783424377441406\n",
      "\tGenerator loss: 0.9129527807235718, Discriminator loss: 1.0471352338790894\n",
      "\tGenerator loss: 0.8956937789916992, Discriminator loss: 1.024989366531372\n",
      "\tGenerator loss: 0.9139498472213745, Discriminator loss: 1.0250325202941895\n",
      "\tGenerator loss: 0.9542297720909119, Discriminator loss: 1.0328781604766846\n",
      "\tGenerator loss: 1.0057909488677979, Discriminator loss: 1.0244905948638916\n",
      "\tGenerator loss: 1.04762864112854, Discriminator loss: 1.0335187911987305\n",
      "Time for epoch 4 is 480.7973771095276 sec\n",
      "\tGenerator loss: 1.033003330230713, Discriminator loss: 1.0298614501953125\n",
      "\tGenerator loss: 0.9850301742553711, Discriminator loss: 1.0065381526947021\n",
      "\tGenerator loss: 0.9296592473983765, Discriminator loss: 1.021892786026001\n",
      "\tGenerator loss: 0.9004900455474854, Discriminator loss: 1.0249894857406616\n",
      "\tGenerator loss: 0.9371005296707153, Discriminator loss: 1.0270650386810303\n",
      "\tGenerator loss: 0.9738480448722839, Discriminator loss: 1.046283483505249\n",
      "\tGenerator loss: 1.0068806409835815, Discriminator loss: 1.0283162593841553\n",
      "\tGenerator loss: 1.0275936126708984, Discriminator loss: 1.0531659126281738\n",
      "\tGenerator loss: 1.029237151145935, Discriminator loss: 1.048454999923706\n",
      "\tGenerator loss: 1.010939359664917, Discriminator loss: 1.0278041362762451\n",
      "\tGenerator loss: 0.9609843492507935, Discriminator loss: 1.0527920722961426\n",
      "\tGenerator loss: 0.9350979328155518, Discriminator loss: 1.0740903615951538\n",
      "\tGenerator loss: 0.9492525458335876, Discriminator loss: 1.04457426071167\n",
      "\tGenerator loss: 0.9710532426834106, Discriminator loss: 1.039680004119873\n",
      "\tGenerator loss: 1.0230813026428223, Discriminator loss: 1.043125867843628\n",
      "\tGenerator loss: 1.040844440460205, Discriminator loss: 1.0523402690887451\n",
      "\tGenerator loss: 0.9989595413208008, Discriminator loss: 1.0659364461898804\n",
      "\tGenerator loss: 0.9885624647140503, Discriminator loss: 1.0577118396759033\n",
      "\tGenerator loss: 0.9901528358459473, Discriminator loss: 1.087388038635254\n",
      "\tGenerator loss: 0.9875761270523071, Discriminator loss: 1.0857603549957275\n",
      "\tGenerator loss: 1.005857229232788, Discriminator loss: 1.0751214027404785\n",
      "\tGenerator loss: 1.025033950805664, Discriminator loss: 1.0851994752883911\n",
      "\tGenerator loss: 1.029723048210144, Discriminator loss: 1.045863151550293\n",
      "\tGenerator loss: 1.0338400602340698, Discriminator loss: 1.0837209224700928\n",
      "\tGenerator loss: 1.0513513088226318, Discriminator loss: 1.0805981159210205\n",
      "\tGenerator loss: 1.0393664836883545, Discriminator loss: 1.0512661933898926\n",
      "\tGenerator loss: 1.0417442321777344, Discriminator loss: 1.017808198928833\n",
      "\tGenerator loss: 1.0211063623428345, Discriminator loss: 1.020050287246704\n",
      "\tGenerator loss: 1.048509955406189, Discriminator loss: 1.0098621845245361\n",
      "\tGenerator loss: 1.0608875751495361, Discriminator loss: 1.0261303186416626\n",
      "\tGenerator loss: 1.055579423904419, Discriminator loss: 1.004718542098999\n",
      "\tGenerator loss: 1.0627014636993408, Discriminator loss: 1.003782868385315\n",
      "\tGenerator loss: 1.0700032711029053, Discriminator loss: 0.9693028926849365\n",
      "\tGenerator loss: 1.0990252494812012, Discriminator loss: 1.003003716468811\n",
      "\tGenerator loss: 1.1167080402374268, Discriminator loss: 1.0041899681091309\n",
      "\tGenerator loss: 1.0891518592834473, Discriminator loss: 0.983680248260498\n",
      "\tGenerator loss: 1.0522642135620117, Discriminator loss: 0.9847277402877808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0707097053527832, Discriminator loss: 1.002000093460083\n",
      "\tGenerator loss: 1.0696412324905396, Discriminator loss: 0.9931507706642151\n",
      "\tGenerator loss: 1.0794239044189453, Discriminator loss: 0.9901703596115112\n",
      "\tGenerator loss: 1.0778459310531616, Discriminator loss: 1.0069301128387451\n",
      "\tGenerator loss: 1.0949726104736328, Discriminator loss: 1.0055160522460938\n",
      "\tGenerator loss: 1.0895044803619385, Discriminator loss: 1.0288126468658447\n",
      "\tGenerator loss: 1.0577629804611206, Discriminator loss: 1.0284514427185059\n",
      "\tGenerator loss: 1.0391201972961426, Discriminator loss: 1.0543498992919922\n",
      "\tGenerator loss: 1.0304404497146606, Discriminator loss: 1.0409774780273438\n",
      "\tGenerator loss: 1.0008764266967773, Discriminator loss: 1.0549261569976807\n",
      "\tGenerator loss: 0.999146580696106, Discriminator loss: 1.0616767406463623\n",
      "\tGenerator loss: 1.0255441665649414, Discriminator loss: 1.059326171875\n",
      "\tGenerator loss: 1.0517762899398804, Discriminator loss: 1.096429705619812\n",
      "\tGenerator loss: 1.069671630859375, Discriminator loss: 1.1271125078201294\n",
      "\tGenerator loss: 1.0396764278411865, Discriminator loss: 1.1204262971878052\n",
      "\tGenerator loss: 0.9918283820152283, Discriminator loss: 1.116250991821289\n",
      "\tGenerator loss: 0.9585849046707153, Discriminator loss: 1.1932373046875\n",
      "\tGenerator loss: 0.9492043256759644, Discriminator loss: 1.1979669332504272\n",
      "\tGenerator loss: 0.9494820237159729, Discriminator loss: 1.1831588745117188\n",
      "\tGenerator loss: 0.9671022891998291, Discriminator loss: 1.2573966979980469\n",
      "\tGenerator loss: 0.967055082321167, Discriminator loss: 1.3518178462982178\n",
      "\tGenerator loss: 0.9238232374191284, Discriminator loss: 1.3126237392425537\n",
      "\tGenerator loss: 0.8697662353515625, Discriminator loss: 1.318037748336792\n",
      "\tGenerator loss: 0.8349505066871643, Discriminator loss: 1.3668041229248047\n",
      "\tGenerator loss: 0.817468523979187, Discriminator loss: 1.414778232574463\n",
      "\tGenerator loss: 0.8147487640380859, Discriminator loss: 1.3579171895980835\n",
      "\tGenerator loss: 0.874297559261322, Discriminator loss: 1.3294655084609985\n",
      "\tGenerator loss: 0.9119699001312256, Discriminator loss: 1.3533668518066406\n",
      "\tGenerator loss: 0.9299221038818359, Discriminator loss: 1.4332704544067383\n",
      "\tGenerator loss: 0.8667536377906799, Discriminator loss: 1.4439738988876343\n",
      "\tGenerator loss: 0.7851946353912354, Discriminator loss: 1.4233887195587158\n",
      "\tGenerator loss: 0.7596200704574585, Discriminator loss: 1.4916744232177734\n",
      "\tGenerator loss: 0.7360684275627136, Discriminator loss: 1.4652440547943115\n",
      "\tGenerator loss: 0.7514430284500122, Discriminator loss: 1.4006669521331787\n",
      "\tGenerator loss: 0.8036820888519287, Discriminator loss: 1.3531818389892578\n",
      "\tGenerator loss: 0.8723449110984802, Discriminator loss: 1.3615764379501343\n",
      "\tGenerator loss: 0.8748427629470825, Discriminator loss: 1.3542718887329102\n",
      "\tGenerator loss: 0.8684619069099426, Discriminator loss: 1.346225380897522\n",
      "\tGenerator loss: 0.8109031915664673, Discriminator loss: 1.2857632637023926\n",
      "\tGenerator loss: 0.8020718693733215, Discriminator loss: 1.2226591110229492\n",
      "\tGenerator loss: 0.8239626884460449, Discriminator loss: 1.2156412601470947\n",
      "\tGenerator loss: 0.885140597820282, Discriminator loss: 1.2339085340499878\n",
      "\tGenerator loss: 0.9256531000137329, Discriminator loss: 1.2312642335891724\n",
      "\tGenerator loss: 0.9329686164855957, Discriminator loss: 1.1980559825897217\n",
      "\tGenerator loss: 0.9117113351821899, Discriminator loss: 1.1754826307296753\n",
      "\tGenerator loss: 0.8586193919181824, Discriminator loss: 1.1874945163726807\n",
      "\tGenerator loss: 0.8324037790298462, Discriminator loss: 1.1910972595214844\n",
      "\tGenerator loss: 0.8461596965789795, Discriminator loss: 1.149127721786499\n",
      "\tGenerator loss: 0.8997412323951721, Discriminator loss: 1.0838322639465332\n",
      "\tGenerator loss: 0.9827032089233398, Discriminator loss: 1.1479518413543701\n",
      "\tGenerator loss: 1.038987398147583, Discriminator loss: 1.092616319656372\n",
      "\tGenerator loss: 1.0399534702301025, Discriminator loss: 1.0788205862045288\n",
      "\tGenerator loss: 0.986241340637207, Discriminator loss: 1.0567219257354736\n",
      "\tGenerator loss: 0.9504669904708862, Discriminator loss: 1.038123369216919\n",
      "\tGenerator loss: 0.9660254716873169, Discriminator loss: 1.0304605960845947\n",
      "\tGenerator loss: 1.0354903936386108, Discriminator loss: 1.0370392799377441\n",
      "\tGenerator loss: 1.085289478302002, Discriminator loss: 1.0217106342315674\n",
      "\tGenerator loss: 1.1127511262893677, Discriminator loss: 0.9817218780517578\n",
      "\tGenerator loss: 1.140303134918213, Discriminator loss: 0.9884929656982422\n",
      "\tGenerator loss: 1.1454367637634277, Discriminator loss: 0.9623203277587891\n",
      "\tGenerator loss: 1.143218755722046, Discriminator loss: 0.9281954765319824\n",
      "\tGenerator loss: 1.1397818326950073, Discriminator loss: 0.949661374092102\n",
      "\tGenerator loss: 1.1791889667510986, Discriminator loss: 0.9077982306480408\n",
      "\tGenerator loss: 1.198188304901123, Discriminator loss: 0.8994095325469971\n",
      "\tGenerator loss: 1.2579201459884644, Discriminator loss: 0.8942575454711914\n",
      "\tGenerator loss: 1.3028569221496582, Discriminator loss: 0.858583390712738\n",
      "\tGenerator loss: 1.2976863384246826, Discriminator loss: 0.864897608757019\n",
      "\tGenerator loss: 1.3112729787826538, Discriminator loss: 0.8533942699432373\n",
      "\tGenerator loss: 1.2905995845794678, Discriminator loss: 0.8475283980369568\n",
      "\tGenerator loss: 1.2556730508804321, Discriminator loss: 0.892376184463501\n",
      "\tGenerator loss: 1.2401843070983887, Discriminator loss: 0.8524932265281677\n",
      "\tGenerator loss: 1.2795300483703613, Discriminator loss: 0.828791618347168\n",
      "\tGenerator loss: 1.3191909790039062, Discriminator loss: 0.8618392944335938\n",
      "\tGenerator loss: 1.2957284450531006, Discriminator loss: 0.9173486232757568\n",
      "\tGenerator loss: 1.2380833625793457, Discriminator loss: 0.9572311639785767\n",
      "\tGenerator loss: 1.1439824104309082, Discriminator loss: 0.9489026069641113\n",
      "\tGenerator loss: 1.0764628648757935, Discriminator loss: 0.9449176788330078\n",
      "\tGenerator loss: 1.0704500675201416, Discriminator loss: 1.008564829826355\n",
      "\tGenerator loss: 1.0731143951416016, Discriminator loss: 0.9627724289894104\n",
      "\tGenerator loss: 1.1007708311080933, Discriminator loss: 0.9473299980163574\n",
      "\tGenerator loss: 1.1400237083435059, Discriminator loss: 1.005014419555664\n",
      "\tGenerator loss: 1.1201484203338623, Discriminator loss: 1.004875898361206\n",
      "\tGenerator loss: 1.0812222957611084, Discriminator loss: 1.0351650714874268\n",
      "\tGenerator loss: 1.011347770690918, Discriminator loss: 1.0659806728363037\n",
      "\tGenerator loss: 0.9387882947921753, Discriminator loss: 1.1066789627075195\n",
      "\tGenerator loss: 0.8898013830184937, Discriminator loss: 1.1657955646514893\n",
      "\tGenerator loss: 0.8888933658599854, Discriminator loss: 1.195231318473816\n",
      "\tGenerator loss: 0.9184176921844482, Discriminator loss: 1.2405914068222046\n",
      "\tGenerator loss: 0.9373617768287659, Discriminator loss: 1.3439239263534546\n",
      "\tGenerator loss: 0.8765661120414734, Discriminator loss: 1.5182693004608154\n",
      "\tGenerator loss: 0.7812374830245972, Discriminator loss: 1.4595950841903687\n",
      "\tGenerator loss: 0.7230939865112305, Discriminator loss: 1.4791607856750488\n",
      "\tGenerator loss: 0.7554106712341309, Discriminator loss: 1.5715548992156982\n",
      "\tGenerator loss: 0.8117887377738953, Discriminator loss: 1.5291794538497925\n",
      "\tGenerator loss: 0.8423306941986084, Discriminator loss: 1.5153603553771973\n",
      "\tGenerator loss: 0.8210561275482178, Discriminator loss: 1.5852372646331787\n",
      "\tGenerator loss: 0.7658364176750183, Discriminator loss: 1.6115338802337646\n",
      "\tGenerator loss: 0.6929622888565063, Discriminator loss: 1.671164631843567\n",
      "\tGenerator loss: 0.6789779663085938, Discriminator loss: 1.703320026397705\n",
      "\tGenerator loss: 0.6903222799301147, Discriminator loss: 1.7574517726898193\n",
      "\tGenerator loss: 0.7264140844345093, Discriminator loss: 1.7199037075042725\n",
      "\tGenerator loss: 0.7488624453544617, Discriminator loss: 1.7305644750595093\n",
      "\tGenerator loss: 0.7469038963317871, Discriminator loss: 1.6399098634719849\n",
      "\tGenerator loss: 0.7638797163963318, Discriminator loss: 1.5708179473876953\n",
      "\tGenerator loss: 0.7929060459136963, Discriminator loss: 1.606972575187683\n",
      "\tGenerator loss: 0.8010616302490234, Discriminator loss: 1.528684139251709\n",
      "\tGenerator loss: 0.8191590905189514, Discriminator loss: 1.5331615209579468\n",
      "\tGenerator loss: 0.8463393449783325, Discriminator loss: 1.457156777381897\n",
      "\tGenerator loss: 0.8919573426246643, Discriminator loss: 1.4849046468734741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9158260226249695, Discriminator loss: 1.392625331878662\n",
      "\tGenerator loss: 0.9180769920349121, Discriminator loss: 1.319166660308838\n",
      "\tGenerator loss: 0.922029972076416, Discriminator loss: 1.2435541152954102\n",
      "\tGenerator loss: 0.9652502536773682, Discriminator loss: 1.195763349533081\n",
      "\tGenerator loss: 1.0063300132751465, Discriminator loss: 1.1666481494903564\n",
      "\tGenerator loss: 1.0663279294967651, Discriminator loss: 1.0650172233581543\n",
      "\tGenerator loss: 1.0856094360351562, Discriminator loss: 1.047997236251831\n",
      "\tGenerator loss: 1.1149415969848633, Discriminator loss: 1.047324538230896\n",
      "\tGenerator loss: 1.1431366205215454, Discriminator loss: 1.022352933883667\n",
      "\tGenerator loss: 1.1278445720672607, Discriminator loss: 1.017566442489624\n",
      "\tGenerator loss: 1.1120924949645996, Discriminator loss: 0.9563238620758057\n",
      "\tGenerator loss: 1.0972461700439453, Discriminator loss: 0.9343971014022827\n",
      "\tGenerator loss: 1.1455718278884888, Discriminator loss: 0.9343708753585815\n",
      "\tGenerator loss: 1.1951322555541992, Discriminator loss: 0.9082130193710327\n",
      "\tGenerator loss: 1.2438428401947021, Discriminator loss: 0.8785879015922546\n",
      "\tGenerator loss: 1.275357961654663, Discriminator loss: 0.92533278465271\n",
      "\tGenerator loss: 1.2405478954315186, Discriminator loss: 0.9411637783050537\n",
      "\tGenerator loss: 1.179875373840332, Discriminator loss: 0.9515630006790161\n",
      "\tGenerator loss: 1.1032674312591553, Discriminator loss: 0.9076359868049622\n",
      "\tGenerator loss: 1.0806560516357422, Discriminator loss: 0.9290403127670288\n",
      "\tGenerator loss: 1.1200737953186035, Discriminator loss: 0.9163590669631958\n",
      "\tGenerator loss: 1.2146904468536377, Discriminator loss: 0.887664258480072\n",
      "\tGenerator loss: 1.273094892501831, Discriminator loss: 0.9026328325271606\n",
      "\tGenerator loss: 1.3234881162643433, Discriminator loss: 0.89192795753479\n",
      "\tGenerator loss: 1.3045988082885742, Discriminator loss: 0.9205564260482788\n",
      "\tGenerator loss: 1.2547794580459595, Discriminator loss: 1.0107685327529907\n",
      "\tGenerator loss: 1.1413464546203613, Discriminator loss: 1.0653626918792725\n",
      "\tGenerator loss: 1.030186414718628, Discriminator loss: 1.1084039211273193\n",
      "\tGenerator loss: 0.9328622221946716, Discriminator loss: 1.134569764137268\n",
      "\tGenerator loss: 0.9292523860931396, Discriminator loss: 1.1461286544799805\n",
      "\tGenerator loss: 0.9648442268371582, Discriminator loss: 1.1565008163452148\n",
      "\tGenerator loss: 1.0500861406326294, Discriminator loss: 1.2439473867416382\n",
      "\tGenerator loss: 1.0529630184173584, Discriminator loss: 1.2935049533843994\n",
      "\tGenerator loss: 1.0460541248321533, Discriminator loss: 1.3995611667633057\n",
      "\tGenerator loss: 0.9435893893241882, Discriminator loss: 1.405977725982666\n",
      "\tGenerator loss: 0.8739347457885742, Discriminator loss: 1.3695435523986816\n",
      "\tGenerator loss: 0.7697721123695374, Discriminator loss: 1.3474338054656982\n",
      "\tGenerator loss: 0.7555719614028931, Discriminator loss: 1.3647563457489014\n",
      "\tGenerator loss: 0.8451814651489258, Discriminator loss: 1.4600614309310913\n",
      "\tGenerator loss: 0.9077998399734497, Discriminator loss: 1.418029546737671\n",
      "\tGenerator loss: 0.937971830368042, Discriminator loss: 1.4023029804229736\n",
      "\tGenerator loss: 0.9622747898101807, Discriminator loss: 1.4051564931869507\n",
      "\tGenerator loss: 0.9654322862625122, Discriminator loss: 1.3503113985061646\n",
      "\tGenerator loss: 0.9347871541976929, Discriminator loss: 1.380950927734375\n",
      "\tGenerator loss: 0.8838750123977661, Discriminator loss: 1.3889806270599365\n",
      "\tGenerator loss: 0.8290362358093262, Discriminator loss: 1.593727469444275\n",
      "\tGenerator loss: 0.7850475907325745, Discriminator loss: 1.5378992557525635\n",
      "\tGenerator loss: 0.7413667440414429, Discriminator loss: 1.571424961090088\n",
      "\tGenerator loss: 0.6994102597236633, Discriminator loss: 1.5990216732025146\n",
      "\tGenerator loss: 0.6768337488174438, Discriminator loss: 1.6404435634613037\n",
      "\tGenerator loss: 0.6921197175979614, Discriminator loss: 1.5916967391967773\n",
      "\tGenerator loss: 0.6941986083984375, Discriminator loss: 1.6222333908081055\n",
      "\tGenerator loss: 0.7137513160705566, Discriminator loss: 1.5465426445007324\n",
      "\tGenerator loss: 0.7680971622467041, Discriminator loss: 1.4810770750045776\n",
      "\tGenerator loss: 0.780598521232605, Discriminator loss: 1.4919686317443848\n",
      "\tGenerator loss: 0.7900046110153198, Discriminator loss: 1.5329060554504395\n",
      "\tGenerator loss: 0.7945876717567444, Discriminator loss: 1.5534183979034424\n",
      "\tGenerator loss: 0.7456430196762085, Discriminator loss: 1.6530307531356812\n",
      "\tGenerator loss: 0.6993182897567749, Discriminator loss: 1.6116119623184204\n",
      "\tGenerator loss: 0.6402101516723633, Discriminator loss: 1.5803560018539429\n",
      "\tGenerator loss: 0.6096905469894409, Discriminator loss: 1.557307481765747\n",
      "\tGenerator loss: 0.6190747022628784, Discriminator loss: 1.4913750886917114\n",
      "\tGenerator loss: 0.6786842346191406, Discriminator loss: 1.4939274787902832\n",
      "\tGenerator loss: 0.7388629913330078, Discriminator loss: 1.497087836265564\n",
      "\tGenerator loss: 0.7767216563224792, Discriminator loss: 1.46701979637146\n",
      "\tGenerator loss: 0.7672747373580933, Discriminator loss: 1.4504597187042236\n",
      "\tGenerator loss: 0.7767015099525452, Discriminator loss: 1.3810346126556396\n",
      "\tGenerator loss: 0.7729623317718506, Discriminator loss: 1.3185651302337646\n",
      "\tGenerator loss: 0.7621921300888062, Discriminator loss: 1.3231219053268433\n",
      "\tGenerator loss: 0.7622875571250916, Discriminator loss: 1.2794501781463623\n",
      "\tGenerator loss: 0.7884823083877563, Discriminator loss: 1.2234997749328613\n",
      "\tGenerator loss: 0.8173476457595825, Discriminator loss: 1.1838462352752686\n",
      "\tGenerator loss: 0.8639404773712158, Discriminator loss: 1.1164586544036865\n",
      "\tGenerator loss: 0.9065278768539429, Discriminator loss: 1.1056263446807861\n",
      "\tGenerator loss: 0.9642123579978943, Discriminator loss: 1.0901408195495605\n",
      "\tGenerator loss: 1.0152180194854736, Discriminator loss: 1.0915135145187378\n",
      "\tGenerator loss: 1.0273847579956055, Discriminator loss: 1.042850375175476\n",
      "\tGenerator loss: 1.0335619449615479, Discriminator loss: 0.9760875105857849\n",
      "\tGenerator loss: 1.0311473608016968, Discriminator loss: 0.9366210699081421\n",
      "\tGenerator loss: 1.0736589431762695, Discriminator loss: 0.8935650587081909\n",
      "\tGenerator loss: 1.090078353881836, Discriminator loss: 0.8767710328102112\n",
      "\tGenerator loss: 1.1425118446350098, Discriminator loss: 0.8124691247940063\n",
      "\tGenerator loss: 1.2120249271392822, Discriminator loss: 0.7805706262588501\n",
      "\tGenerator loss: 1.2689878940582275, Discriminator loss: 0.7390835285186768\n",
      "\tGenerator loss: 1.3415918350219727, Discriminator loss: 0.7320363521575928\n",
      "\tGenerator loss: 1.4146323204040527, Discriminator loss: 0.7833067774772644\n",
      "\tGenerator loss: 1.3989886045455933, Discriminator loss: 0.8788645267486572\n",
      "\tGenerator loss: 1.376652717590332, Discriminator loss: 0.8140872120857239\n",
      "\tGenerator loss: 1.30912446975708, Discriminator loss: 0.7311855554580688\n",
      "Time for epoch 5 is 472.59821820259094 sec\n",
      "\tGenerator loss: 1.2832212448120117, Discriminator loss: 0.7151126861572266\n",
      "\tGenerator loss: 1.2839512825012207, Discriminator loss: 0.735842227935791\n",
      "\tGenerator loss: 1.2420120239257812, Discriminator loss: 0.7650452256202698\n",
      "\tGenerator loss: 1.2426902055740356, Discriminator loss: 0.7698477506637573\n",
      "\tGenerator loss: 1.2556202411651611, Discriminator loss: 0.8633549809455872\n",
      "\tGenerator loss: 1.2563517093658447, Discriminator loss: 0.9570399522781372\n",
      "\tGenerator loss: 1.2102985382080078, Discriminator loss: 0.873953104019165\n",
      "\tGenerator loss: 1.131655216217041, Discriminator loss: 1.0045843124389648\n",
      "\tGenerator loss: 1.110350489616394, Discriminator loss: 0.9866018891334534\n",
      "\tGenerator loss: 1.0826456546783447, Discriminator loss: 0.9752817153930664\n",
      "\tGenerator loss: 1.0490784645080566, Discriminator loss: 1.019018530845642\n",
      "\tGenerator loss: 1.0432554483413696, Discriminator loss: 1.0297598838806152\n",
      "\tGenerator loss: 1.0528318881988525, Discriminator loss: 1.0262582302093506\n",
      "\tGenerator loss: 1.0470304489135742, Discriminator loss: 1.0707831382751465\n",
      "\tGenerator loss: 1.0551577806472778, Discriminator loss: 1.1226208209991455\n",
      "\tGenerator loss: 1.0092971324920654, Discriminator loss: 1.153355598449707\n",
      "\tGenerator loss: 0.9971063733100891, Discriminator loss: 1.1872906684875488\n",
      "\tGenerator loss: 0.9064780473709106, Discriminator loss: 1.2952214479446411\n",
      "\tGenerator loss: 0.8634669780731201, Discriminator loss: 1.4831955432891846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8118747472763062, Discriminator loss: 1.4572370052337646\n",
      "\tGenerator loss: 0.7819026112556458, Discriminator loss: 1.499894380569458\n",
      "\tGenerator loss: 0.777733325958252, Discriminator loss: 1.5597336292266846\n",
      "\tGenerator loss: 0.7714951038360596, Discriminator loss: 1.5245254039764404\n",
      "\tGenerator loss: 0.7973625659942627, Discriminator loss: 1.7509465217590332\n",
      "\tGenerator loss: 0.8009719848632812, Discriminator loss: 1.8142900466918945\n",
      "\tGenerator loss: 0.7943308353424072, Discriminator loss: 1.6470452547073364\n",
      "\tGenerator loss: 0.7616103291511536, Discriminator loss: 1.5539851188659668\n",
      "\tGenerator loss: 0.7266122102737427, Discriminator loss: 1.5621695518493652\n",
      "\tGenerator loss: 0.7346344590187073, Discriminator loss: 1.492301106452942\n",
      "\tGenerator loss: 0.7620963454246521, Discriminator loss: 1.4873199462890625\n",
      "\tGenerator loss: 0.804162859916687, Discriminator loss: 1.5775115489959717\n",
      "\tGenerator loss: 0.8103228807449341, Discriminator loss: 1.6614861488342285\n",
      "\tGenerator loss: 0.7851734161376953, Discriminator loss: 1.5848312377929688\n",
      "\tGenerator loss: 0.7497059106826782, Discriminator loss: 1.9045634269714355\n",
      "\tGenerator loss: 0.6879350543022156, Discriminator loss: 1.727642297744751\n",
      "\tGenerator loss: 0.6739379167556763, Discriminator loss: 1.6022175550460815\n",
      "\tGenerator loss: 0.6900426149368286, Discriminator loss: 1.5484013557434082\n",
      "\tGenerator loss: 0.744731068611145, Discriminator loss: 1.566283941268921\n",
      "\tGenerator loss: 0.8065292835235596, Discriminator loss: 1.4462480545043945\n",
      "\tGenerator loss: 0.8574346899986267, Discriminator loss: 1.5059949159622192\n",
      "\tGenerator loss: 0.8788716793060303, Discriminator loss: 1.597651481628418\n",
      "\tGenerator loss: 0.8645483255386353, Discriminator loss: 1.4184389114379883\n",
      "\tGenerator loss: 0.8333641290664673, Discriminator loss: 1.3982501029968262\n",
      "\tGenerator loss: 0.7987443208694458, Discriminator loss: 1.3565783500671387\n",
      "\tGenerator loss: 0.7900755405426025, Discriminator loss: 1.3310397863388062\n",
      "\tGenerator loss: 0.8325631618499756, Discriminator loss: 1.291560173034668\n",
      "\tGenerator loss: 0.8801649808883667, Discriminator loss: 1.2735884189605713\n",
      "\tGenerator loss: 0.9146707057952881, Discriminator loss: 1.2317365407943726\n",
      "\tGenerator loss: 0.9493012428283691, Discriminator loss: 1.1851661205291748\n",
      "\tGenerator loss: 0.9634761214256287, Discriminator loss: 1.1331850290298462\n",
      "\tGenerator loss: 0.970513641834259, Discriminator loss: 1.1676325798034668\n",
      "\tGenerator loss: 0.9677447080612183, Discriminator loss: 1.1464767456054688\n",
      "\tGenerator loss: 0.9676508903503418, Discriminator loss: 1.092383623123169\n",
      "\tGenerator loss: 0.9771221876144409, Discriminator loss: 1.0723645687103271\n",
      "\tGenerator loss: 0.9993861317634583, Discriminator loss: 1.057708740234375\n",
      "\tGenerator loss: 1.0515687465667725, Discriminator loss: 1.0756893157958984\n",
      "\tGenerator loss: 1.0768110752105713, Discriminator loss: 1.0592687129974365\n",
      "\tGenerator loss: 1.0811212062835693, Discriminator loss: 1.081028699874878\n",
      "\tGenerator loss: 1.058740258216858, Discriminator loss: 1.037501335144043\n",
      "\tGenerator loss: 1.00272798538208, Discriminator loss: 1.0292134284973145\n",
      "\tGenerator loss: 0.994253396987915, Discriminator loss: 1.0007567405700684\n",
      "\tGenerator loss: 1.012164831161499, Discriminator loss: 0.9545570611953735\n",
      "\tGenerator loss: 1.0739991664886475, Discriminator loss: 0.9772113561630249\n",
      "\tGenerator loss: 1.1313616037368774, Discriminator loss: 0.9922643303871155\n",
      "\tGenerator loss: 1.1588425636291504, Discriminator loss: 0.9935282468795776\n",
      "\tGenerator loss: 1.1527130603790283, Discriminator loss: 0.9842712879180908\n",
      "\tGenerator loss: 1.1037893295288086, Discriminator loss: 1.0046954154968262\n",
      "\tGenerator loss: 1.067021131515503, Discriminator loss: 0.952837347984314\n",
      "\tGenerator loss: 1.0267741680145264, Discriminator loss: 0.9773679375648499\n",
      "\tGenerator loss: 1.0345442295074463, Discriminator loss: 1.024290919303894\n",
      "\tGenerator loss: 1.0327513217926025, Discriminator loss: 1.010316014289856\n",
      "\tGenerator loss: 1.0700652599334717, Discriminator loss: 1.0167834758758545\n",
      "\tGenerator loss: 1.0846208333969116, Discriminator loss: 1.020711898803711\n",
      "\tGenerator loss: 1.1283848285675049, Discriminator loss: 1.0063401460647583\n",
      "\tGenerator loss: 1.136630892753601, Discriminator loss: 1.0131525993347168\n",
      "\tGenerator loss: 1.0893547534942627, Discriminator loss: 1.0027087926864624\n",
      "\tGenerator loss: 1.0745117664337158, Discriminator loss: 1.006669044494629\n",
      "\tGenerator loss: 1.095613718032837, Discriminator loss: 0.9963082671165466\n",
      "\tGenerator loss: 1.1038060188293457, Discriminator loss: 1.0305911302566528\n",
      "\tGenerator loss: 1.104600191116333, Discriminator loss: 1.0533759593963623\n",
      "\tGenerator loss: 1.0884664058685303, Discriminator loss: 1.0364534854888916\n",
      "\tGenerator loss: 1.0897023677825928, Discriminator loss: 1.0681610107421875\n",
      "\tGenerator loss: 1.0560373067855835, Discriminator loss: 1.1162021160125732\n",
      "\tGenerator loss: 1.0058579444885254, Discriminator loss: 1.1417427062988281\n",
      "\tGenerator loss: 0.9782434701919556, Discriminator loss: 1.1804553270339966\n",
      "\tGenerator loss: 0.9579811692237854, Discriminator loss: 1.13893461227417\n",
      "\tGenerator loss: 0.9451645612716675, Discriminator loss: 1.2300984859466553\n",
      "\tGenerator loss: 0.9719782471656799, Discriminator loss: 1.2396141290664673\n",
      "\tGenerator loss: 0.9793790578842163, Discriminator loss: 1.1858294010162354\n",
      "\tGenerator loss: 0.967573881149292, Discriminator loss: 1.2093608379364014\n",
      "\tGenerator loss: 0.970602810382843, Discriminator loss: 1.2432832717895508\n",
      "\tGenerator loss: 0.9633523225784302, Discriminator loss: 1.2968552112579346\n",
      "\tGenerator loss: 0.932378888130188, Discriminator loss: 1.3556766510009766\n",
      "\tGenerator loss: 0.9008336663246155, Discriminator loss: 1.368428111076355\n",
      "\tGenerator loss: 0.8576616048812866, Discriminator loss: 1.4041564464569092\n",
      "\tGenerator loss: 0.812371015548706, Discriminator loss: 1.4080239534378052\n",
      "\tGenerator loss: 0.7787619829177856, Discriminator loss: 1.4149978160858154\n",
      "\tGenerator loss: 0.7812433242797852, Discriminator loss: 1.4943687915802002\n",
      "\tGenerator loss: 0.7814334630966187, Discriminator loss: 1.4704760313034058\n",
      "\tGenerator loss: 0.7862216830253601, Discriminator loss: 1.4444761276245117\n",
      "\tGenerator loss: 0.7854068279266357, Discriminator loss: 1.5041168928146362\n",
      "\tGenerator loss: 0.7999162673950195, Discriminator loss: 1.5971920490264893\n",
      "\tGenerator loss: 0.7784378528594971, Discriminator loss: 1.5568292140960693\n",
      "\tGenerator loss: 0.7250885963439941, Discriminator loss: 1.6448321342468262\n",
      "\tGenerator loss: 0.6748117208480835, Discriminator loss: 1.579168677330017\n",
      "\tGenerator loss: 0.6441026926040649, Discriminator loss: 1.5520086288452148\n",
      "\tGenerator loss: 0.6430395841598511, Discriminator loss: 1.5281994342803955\n",
      "\tGenerator loss: 0.6830910444259644, Discriminator loss: 1.5781173706054688\n",
      "\tGenerator loss: 0.7545419335365295, Discriminator loss: 1.6594538688659668\n",
      "\tGenerator loss: 0.7828084230422974, Discriminator loss: 1.569547176361084\n",
      "\tGenerator loss: 0.7770534753799438, Discriminator loss: 1.523226022720337\n",
      "\tGenerator loss: 0.7557987570762634, Discriminator loss: 1.5043607950210571\n",
      "\tGenerator loss: 0.7399436235427856, Discriminator loss: 1.4907379150390625\n",
      "\tGenerator loss: 0.7069668173789978, Discriminator loss: 1.5566215515136719\n",
      "\tGenerator loss: 0.6978462934494019, Discriminator loss: 1.5324101448059082\n",
      "\tGenerator loss: 0.7002232670783997, Discriminator loss: 1.5248918533325195\n",
      "\tGenerator loss: 0.699127197265625, Discriminator loss: 1.5847315788269043\n",
      "\tGenerator loss: 0.6838686466217041, Discriminator loss: 1.5916118621826172\n",
      "\tGenerator loss: 0.6496120691299438, Discriminator loss: 1.5520399808883667\n",
      "\tGenerator loss: 0.648131787776947, Discriminator loss: 1.5600064992904663\n",
      "\tGenerator loss: 0.6633083820343018, Discriminator loss: 1.5357656478881836\n",
      "\tGenerator loss: 0.665685772895813, Discriminator loss: 1.5530561208724976\n",
      "\tGenerator loss: 0.6653918623924255, Discriminator loss: 1.5426709651947021\n",
      "\tGenerator loss: 0.6876204013824463, Discriminator loss: 1.5558216571807861\n",
      "\tGenerator loss: 0.6837207674980164, Discriminator loss: 1.5115214586257935\n",
      "\tGenerator loss: 0.6760565042495728, Discriminator loss: 1.471139907836914\n",
      "\tGenerator loss: 0.6973366737365723, Discriminator loss: 1.428208351135254\n",
      "\tGenerator loss: 0.7201849818229675, Discriminator loss: 1.4431006908416748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.754352331161499, Discriminator loss: 1.3984335660934448\n",
      "\tGenerator loss: 0.7709906697273254, Discriminator loss: 1.3769276142120361\n",
      "\tGenerator loss: 0.7675744295120239, Discriminator loss: 1.4022842645645142\n",
      "\tGenerator loss: 0.7651084065437317, Discriminator loss: 1.3858855962753296\n",
      "\tGenerator loss: 0.7681403160095215, Discriminator loss: 1.3522828817367554\n",
      "\tGenerator loss: 0.7546730637550354, Discriminator loss: 1.3382093906402588\n",
      "\tGenerator loss: 0.7712211608886719, Discriminator loss: 1.3122639656066895\n",
      "\tGenerator loss: 0.7864055037498474, Discriminator loss: 1.3121634721755981\n",
      "\tGenerator loss: 0.8135713338851929, Discriminator loss: 1.3001058101654053\n",
      "\tGenerator loss: 0.8281370997428894, Discriminator loss: 1.2833071947097778\n",
      "\tGenerator loss: 0.8576874732971191, Discriminator loss: 1.2866735458374023\n",
      "\tGenerator loss: 0.8599191308021545, Discriminator loss: 1.2424513101577759\n",
      "\tGenerator loss: 0.8322125673294067, Discriminator loss: 1.2479785680770874\n",
      "\tGenerator loss: 0.823940634727478, Discriminator loss: 1.2826361656188965\n",
      "\tGenerator loss: 0.8178660273551941, Discriminator loss: 1.2830199003219604\n",
      "\tGenerator loss: 0.8335181474685669, Discriminator loss: 1.299628496170044\n",
      "\tGenerator loss: 0.842760443687439, Discriminator loss: 1.285599708557129\n",
      "\tGenerator loss: 0.8529633283615112, Discriminator loss: 1.3154098987579346\n",
      "\tGenerator loss: 0.8550699949264526, Discriminator loss: 1.2684178352355957\n",
      "\tGenerator loss: 0.8604889512062073, Discriminator loss: 1.2875187397003174\n",
      "\tGenerator loss: 0.8494812250137329, Discriminator loss: 1.2729454040527344\n",
      "\tGenerator loss: 0.8416062593460083, Discriminator loss: 1.292146921157837\n",
      "\tGenerator loss: 0.8321720361709595, Discriminator loss: 1.284610390663147\n",
      "\tGenerator loss: 0.8195237517356873, Discriminator loss: 1.287656307220459\n",
      "\tGenerator loss: 0.8288416862487793, Discriminator loss: 1.3105933666229248\n",
      "\tGenerator loss: 0.8317832946777344, Discriminator loss: 1.3683265447616577\n",
      "\tGenerator loss: 0.8363575339317322, Discriminator loss: 1.4282498359680176\n",
      "\tGenerator loss: 0.8076304197311401, Discriminator loss: 1.3887418508529663\n",
      "\tGenerator loss: 0.7788165211677551, Discriminator loss: 1.385426640510559\n",
      "\tGenerator loss: 0.7641980648040771, Discriminator loss: 1.4064714908599854\n",
      "\tGenerator loss: 0.7619619369506836, Discriminator loss: 1.4488909244537354\n",
      "\tGenerator loss: 0.7614248991012573, Discriminator loss: 1.3836978673934937\n",
      "\tGenerator loss: 0.7657256126403809, Discriminator loss: 1.3685834407806396\n",
      "\tGenerator loss: 0.7983840703964233, Discriminator loss: 1.4429854154586792\n",
      "\tGenerator loss: 0.8095934391021729, Discriminator loss: 1.4467968940734863\n",
      "\tGenerator loss: 0.7920405268669128, Discriminator loss: 1.4591050148010254\n",
      "\tGenerator loss: 0.7692921161651611, Discriminator loss: 1.551668643951416\n",
      "\tGenerator loss: 0.7215741872787476, Discriminator loss: 1.5260233879089355\n",
      "\tGenerator loss: 0.6876949667930603, Discriminator loss: 1.587058424949646\n",
      "\tGenerator loss: 0.6760363578796387, Discriminator loss: 1.565021276473999\n",
      "\tGenerator loss: 0.6925109624862671, Discriminator loss: 1.5497941970825195\n",
      "\tGenerator loss: 0.7098619341850281, Discriminator loss: 1.559108853340149\n",
      "\tGenerator loss: 0.7421948909759521, Discriminator loss: 1.5519435405731201\n",
      "\tGenerator loss: 0.7390483617782593, Discriminator loss: 1.525557279586792\n",
      "\tGenerator loss: 0.7249456644058228, Discriminator loss: 1.5583233833312988\n",
      "\tGenerator loss: 0.6913121938705444, Discriminator loss: 1.5714898109436035\n",
      "\tGenerator loss: 0.6777217984199524, Discriminator loss: 1.549208402633667\n",
      "\tGenerator loss: 0.6892405152320862, Discriminator loss: 1.596426010131836\n",
      "\tGenerator loss: 0.6847519874572754, Discriminator loss: 1.5863308906555176\n",
      "\tGenerator loss: 0.6728837490081787, Discriminator loss: 1.5851000547409058\n",
      "\tGenerator loss: 0.697406530380249, Discriminator loss: 1.6090834140777588\n",
      "\tGenerator loss: 0.7041476964950562, Discriminator loss: 1.5956169366836548\n",
      "\tGenerator loss: 0.6982346177101135, Discriminator loss: 1.601810336112976\n",
      "\tGenerator loss: 0.6918340921401978, Discriminator loss: 1.5813610553741455\n",
      "\tGenerator loss: 0.671188235282898, Discriminator loss: 1.6068446636199951\n",
      "\tGenerator loss: 0.6812536716461182, Discriminator loss: 1.5717281103134155\n",
      "\tGenerator loss: 0.6936026811599731, Discriminator loss: 1.552565574645996\n",
      "\tGenerator loss: 0.6977564692497253, Discriminator loss: 1.5897040367126465\n",
      "\tGenerator loss: 0.7073372602462769, Discriminator loss: 1.6041675806045532\n",
      "\tGenerator loss: 0.723545491695404, Discriminator loss: 1.5953340530395508\n",
      "\tGenerator loss: 0.7094321250915527, Discriminator loss: 1.6273200511932373\n",
      "\tGenerator loss: 0.70924973487854, Discriminator loss: 1.5806320905685425\n",
      "\tGenerator loss: 0.7070886492729187, Discriminator loss: 1.5687053203582764\n",
      "\tGenerator loss: 0.708575963973999, Discriminator loss: 1.5430245399475098\n",
      "\tGenerator loss: 0.7068293690681458, Discriminator loss: 1.5070267915725708\n",
      "\tGenerator loss: 0.7212712168693542, Discriminator loss: 1.5146172046661377\n",
      "\tGenerator loss: 0.7342137098312378, Discriminator loss: 1.4675230979919434\n",
      "\tGenerator loss: 0.7557920813560486, Discriminator loss: 1.4257967472076416\n",
      "\tGenerator loss: 0.7725959420204163, Discriminator loss: 1.4050137996673584\n",
      "\tGenerator loss: 0.77757728099823, Discriminator loss: 1.3990055322647095\n",
      "\tGenerator loss: 0.7909566760063171, Discriminator loss: 1.4096791744232178\n",
      "\tGenerator loss: 0.7879835367202759, Discriminator loss: 1.3914637565612793\n",
      "\tGenerator loss: 0.7909079790115356, Discriminator loss: 1.3759005069732666\n",
      "\tGenerator loss: 0.793293297290802, Discriminator loss: 1.337324619293213\n",
      "\tGenerator loss: 0.8003208041191101, Discriminator loss: 1.3175760507583618\n",
      "\tGenerator loss: 0.8126448392868042, Discriminator loss: 1.322962999343872\n",
      "\tGenerator loss: 0.8155470490455627, Discriminator loss: 1.2959246635437012\n",
      "\tGenerator loss: 0.8246747255325317, Discriminator loss: 1.251621961593628\n",
      "\tGenerator loss: 0.8469962477684021, Discriminator loss: 1.2571989297866821\n",
      "\tGenerator loss: 0.8571188449859619, Discriminator loss: 1.2479866743087769\n",
      "\tGenerator loss: 0.863513708114624, Discriminator loss: 1.2396721839904785\n",
      "\tGenerator loss: 0.8739186525344849, Discriminator loss: 1.236380934715271\n",
      "\tGenerator loss: 0.86126708984375, Discriminator loss: 1.233473300933838\n",
      "\tGenerator loss: 0.8514852523803711, Discriminator loss: 1.2327371835708618\n",
      "\tGenerator loss: 0.8593708872795105, Discriminator loss: 1.193734884262085\n",
      "\tGenerator loss: 0.8661133646965027, Discriminator loss: 1.178433895111084\n",
      "\tGenerator loss: 0.8835828304290771, Discriminator loss: 1.1958129405975342\n",
      "\tGenerator loss: 0.8976992964744568, Discriminator loss: 1.177709937095642\n",
      "\tGenerator loss: 0.9093908071517944, Discriminator loss: 1.1689475774765015\n",
      "\tGenerator loss: 0.9177193641662598, Discriminator loss: 1.1316697597503662\n",
      "\tGenerator loss: 0.9412801265716553, Discriminator loss: 1.1041524410247803\n",
      "\tGenerator loss: 0.9472306370735168, Discriminator loss: 1.1364214420318604\n",
      "\tGenerator loss: 0.9553672075271606, Discriminator loss: 1.1883766651153564\n",
      "\tGenerator loss: 0.932511568069458, Discriminator loss: 1.1776151657104492\n",
      "\tGenerator loss: 0.9188398122787476, Discriminator loss: 1.179738163948059\n",
      "\tGenerator loss: 0.8776767253875732, Discriminator loss: 1.1819971799850464\n",
      "\tGenerator loss: 0.8661497235298157, Discriminator loss: 1.157335877418518\n",
      "\tGenerator loss: 0.8521801233291626, Discriminator loss: 1.192917823791504\n",
      "\tGenerator loss: 0.8554462790489197, Discriminator loss: 1.1981651782989502\n",
      "\tGenerator loss: 0.8721188306808472, Discriminator loss: 1.1832177639007568\n",
      "\tGenerator loss: 0.8839440941810608, Discriminator loss: 1.165380597114563\n",
      "\tGenerator loss: 0.9034879207611084, Discriminator loss: 1.187720775604248\n",
      "\tGenerator loss: 0.8939229249954224, Discriminator loss: 1.1624417304992676\n",
      "\tGenerator loss: 0.9000660181045532, Discriminator loss: 1.1034955978393555\n",
      "\tGenerator loss: 0.9171307682991028, Discriminator loss: 1.0743616819381714\n",
      "\tGenerator loss: 0.9402836561203003, Discriminator loss: 1.0990862846374512\n",
      "\tGenerator loss: 0.9747443795204163, Discriminator loss: 1.2763824462890625\n",
      "Time for epoch 6 is 472.41011691093445 sec\n",
      "\tGenerator loss: 0.9611483812332153, Discriminator loss: 1.235878348350525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9140382409095764, Discriminator loss: 1.2338085174560547\n",
      "\tGenerator loss: 0.8549801111221313, Discriminator loss: 1.2361793518066406\n",
      "\tGenerator loss: 0.8047940731048584, Discriminator loss: 1.2314385175704956\n",
      "\tGenerator loss: 0.7765827178955078, Discriminator loss: 1.2371093034744263\n",
      "\tGenerator loss: 0.7793700098991394, Discriminator loss: 1.2172253131866455\n",
      "\tGenerator loss: 0.8162798881530762, Discriminator loss: 1.2245937585830688\n",
      "\tGenerator loss: 0.8602534532546997, Discriminator loss: 1.2078135013580322\n",
      "\tGenerator loss: 0.9111059904098511, Discriminator loss: 1.1812615394592285\n",
      "\tGenerator loss: 0.9353583455085754, Discriminator loss: 1.2321016788482666\n",
      "\tGenerator loss: 0.9489254951477051, Discriminator loss: 1.2368216514587402\n",
      "\tGenerator loss: 0.916584312915802, Discriminator loss: 1.2590279579162598\n",
      "\tGenerator loss: 0.8704097270965576, Discriminator loss: 1.2890125513076782\n",
      "\tGenerator loss: 0.810163140296936, Discriminator loss: 1.2942917346954346\n",
      "\tGenerator loss: 0.7498265504837036, Discriminator loss: 1.2968882322311401\n",
      "\tGenerator loss: 0.7291895747184753, Discriminator loss: 1.2705737352371216\n",
      "\tGenerator loss: 0.721504807472229, Discriminator loss: 1.2782416343688965\n",
      "\tGenerator loss: 0.7499080300331116, Discriminator loss: 1.270888328552246\n",
      "\tGenerator loss: 0.7947057485580444, Discriminator loss: 1.25612473487854\n",
      "\tGenerator loss: 0.8435261249542236, Discriminator loss: 1.260446548461914\n",
      "\tGenerator loss: 0.8910940289497375, Discriminator loss: 1.2617610692977905\n",
      "\tGenerator loss: 0.9082881212234497, Discriminator loss: 1.2480034828186035\n",
      "\tGenerator loss: 0.9090554714202881, Discriminator loss: 1.247767686843872\n",
      "\tGenerator loss: 0.8758517503738403, Discriminator loss: 1.2151522636413574\n",
      "\tGenerator loss: 0.8466672897338867, Discriminator loss: 1.1914081573486328\n",
      "\tGenerator loss: 0.8066390752792358, Discriminator loss: 1.2323946952819824\n",
      "\tGenerator loss: 0.7939221858978271, Discriminator loss: 1.2944515943527222\n",
      "\tGenerator loss: 0.77605801820755, Discriminator loss: 1.2900680303573608\n",
      "\tGenerator loss: 0.7660156488418579, Discriminator loss: 1.3540723323822021\n",
      "\tGenerator loss: 0.7401806116104126, Discriminator loss: 1.3444442749023438\n",
      "\tGenerator loss: 0.7188546061515808, Discriminator loss: 1.3181527853012085\n",
      "\tGenerator loss: 0.7179394364356995, Discriminator loss: 1.2794933319091797\n",
      "\tGenerator loss: 0.7322685718536377, Discriminator loss: 1.2504438161849976\n",
      "\tGenerator loss: 0.752550482749939, Discriminator loss: 1.20542311668396\n",
      "\tGenerator loss: 0.8069419264793396, Discriminator loss: 1.2239463329315186\n",
      "\tGenerator loss: 0.8585679531097412, Discriminator loss: 1.22624933719635\n",
      "\tGenerator loss: 0.8738366365432739, Discriminator loss: 1.2372207641601562\n",
      "\tGenerator loss: 0.8799159526824951, Discriminator loss: 1.2222747802734375\n",
      "\tGenerator loss: 0.8719717264175415, Discriminator loss: 1.1979055404663086\n",
      "\tGenerator loss: 0.8504671454429626, Discriminator loss: 1.1731218099594116\n",
      "\tGenerator loss: 0.8235937356948853, Discriminator loss: 1.1666879653930664\n",
      "\tGenerator loss: 0.7927634119987488, Discriminator loss: 1.1739752292633057\n",
      "\tGenerator loss: 0.799829363822937, Discriminator loss: 1.1522685289382935\n",
      "\tGenerator loss: 0.818372368812561, Discriminator loss: 1.135589599609375\n",
      "\tGenerator loss: 0.8583623170852661, Discriminator loss: 1.1210455894470215\n",
      "\tGenerator loss: 0.8958086967468262, Discriminator loss: 1.1237064599990845\n",
      "\tGenerator loss: 0.9314517974853516, Discriminator loss: 1.0886728763580322\n",
      "\tGenerator loss: 0.9281599521636963, Discriminator loss: 1.0938405990600586\n",
      "\tGenerator loss: 0.9321143627166748, Discriminator loss: 1.101880431175232\n",
      "\tGenerator loss: 0.9382603764533997, Discriminator loss: 1.070338487625122\n",
      "\tGenerator loss: 0.9242291450500488, Discriminator loss: 1.0992845296859741\n",
      "\tGenerator loss: 0.9088738560676575, Discriminator loss: 1.112290859222412\n",
      "\tGenerator loss: 0.8999156355857849, Discriminator loss: 1.0985591411590576\n",
      "\tGenerator loss: 0.9165256023406982, Discriminator loss: 1.0770132541656494\n",
      "\tGenerator loss: 0.9289308786392212, Discriminator loss: 1.0622076988220215\n",
      "\tGenerator loss: 0.9330737590789795, Discriminator loss: 1.0931923389434814\n",
      "\tGenerator loss: 0.9633562564849854, Discriminator loss: 1.059394121170044\n",
      "\tGenerator loss: 0.978427529335022, Discriminator loss: 1.0768009424209595\n",
      "\tGenerator loss: 0.9814425706863403, Discriminator loss: 1.0300753116607666\n",
      "\tGenerator loss: 0.9761707782745361, Discriminator loss: 1.0211427211761475\n",
      "\tGenerator loss: 0.9825339317321777, Discriminator loss: 1.012878656387329\n",
      "\tGenerator loss: 0.9948514103889465, Discriminator loss: 1.0273218154907227\n",
      "\tGenerator loss: 1.0005991458892822, Discriminator loss: 1.0570435523986816\n",
      "\tGenerator loss: 0.9981377720832825, Discriminator loss: 1.0660377740859985\n",
      "\tGenerator loss: 0.9882024526596069, Discriminator loss: 1.0448963642120361\n",
      "\tGenerator loss: 0.9870691299438477, Discriminator loss: 1.0496923923492432\n",
      "\tGenerator loss: 0.967456579208374, Discriminator loss: 1.0633134841918945\n",
      "\tGenerator loss: 0.9508676528930664, Discriminator loss: 1.1113080978393555\n",
      "\tGenerator loss: 0.9399864673614502, Discriminator loss: 1.1180620193481445\n",
      "\tGenerator loss: 0.9328550100326538, Discriminator loss: 1.085561752319336\n",
      "\tGenerator loss: 0.942762017250061, Discriminator loss: 1.0740808248519897\n",
      "\tGenerator loss: 0.9361344575881958, Discriminator loss: 1.0945188999176025\n",
      "\tGenerator loss: 0.9488213658332825, Discriminator loss: 1.1125423908233643\n",
      "\tGenerator loss: 0.9428235292434692, Discriminator loss: 1.1136858463287354\n",
      "\tGenerator loss: 0.9537602663040161, Discriminator loss: 1.1175593137741089\n",
      "\tGenerator loss: 0.9518665671348572, Discriminator loss: 1.2782011032104492\n",
      "\tGenerator loss: 0.9116023778915405, Discriminator loss: 1.3760199546813965\n",
      "\tGenerator loss: 0.8588200807571411, Discriminator loss: 1.4082536697387695\n",
      "\tGenerator loss: 0.80596923828125, Discriminator loss: 1.4196314811706543\n",
      "\tGenerator loss: 0.7652409076690674, Discriminator loss: 1.380403995513916\n",
      "\tGenerator loss: 0.7499390840530396, Discriminator loss: 1.4322272539138794\n",
      "\tGenerator loss: 0.7649644613265991, Discriminator loss: 1.4352573156356812\n",
      "\tGenerator loss: 0.7850329279899597, Discriminator loss: 1.3947038650512695\n",
      "\tGenerator loss: 0.8025338649749756, Discriminator loss: 1.4426206350326538\n",
      "\tGenerator loss: 0.8202483654022217, Discriminator loss: 1.3947103023529053\n",
      "\tGenerator loss: 0.8370916247367859, Discriminator loss: 1.5666327476501465\n",
      "\tGenerator loss: 0.815338671207428, Discriminator loss: 1.5266070365905762\n",
      "\tGenerator loss: 0.7871876358985901, Discriminator loss: 1.4879958629608154\n",
      "\tGenerator loss: 0.7537596225738525, Discriminator loss: 1.6416876316070557\n",
      "\tGenerator loss: 0.7214642763137817, Discriminator loss: 1.6713037490844727\n",
      "\tGenerator loss: 0.6810024976730347, Discriminator loss: 1.6682484149932861\n",
      "\tGenerator loss: 0.6676589846611023, Discriminator loss: 1.6303881406784058\n",
      "\tGenerator loss: 0.6760841608047485, Discriminator loss: 1.5488312244415283\n",
      "\tGenerator loss: 0.6989578008651733, Discriminator loss: 1.5243723392486572\n",
      "\tGenerator loss: 0.7488808631896973, Discriminator loss: 1.5231527090072632\n",
      "\tGenerator loss: 0.7907226085662842, Discriminator loss: 1.5258612632751465\n",
      "\tGenerator loss: 0.812774658203125, Discriminator loss: 1.5586575269699097\n",
      "\tGenerator loss: 0.7947749495506287, Discriminator loss: 1.5051393508911133\n",
      "\tGenerator loss: 0.7810397148132324, Discriminator loss: 1.5155041217803955\n",
      "\tGenerator loss: 0.7587026357650757, Discriminator loss: 1.5376720428466797\n",
      "\tGenerator loss: 0.7380512952804565, Discriminator loss: 1.4915461540222168\n",
      "\tGenerator loss: 0.7265031337738037, Discriminator loss: 1.473605751991272\n",
      "\tGenerator loss: 0.7388172149658203, Discriminator loss: 1.4270923137664795\n",
      "\tGenerator loss: 0.7679059505462646, Discriminator loss: 1.392485499382019\n",
      "\tGenerator loss: 0.8001978397369385, Discriminator loss: 1.3956859111785889\n",
      "\tGenerator loss: 0.8406593799591064, Discriminator loss: 1.3896594047546387\n",
      "\tGenerator loss: 0.8476741909980774, Discriminator loss: 1.4401218891143799\n",
      "\tGenerator loss: 0.8452666997909546, Discriminator loss: 1.3852283954620361\n",
      "\tGenerator loss: 0.8269863128662109, Discriminator loss: 1.3406418561935425\n",
      "\tGenerator loss: 0.808994472026825, Discriminator loss: 1.3294835090637207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8040077686309814, Discriminator loss: 1.3454821109771729\n",
      "\tGenerator loss: 0.8230663537979126, Discriminator loss: 1.3273801803588867\n",
      "\tGenerator loss: 0.8392254114151001, Discriminator loss: 1.2927494049072266\n",
      "\tGenerator loss: 0.8492395877838135, Discriminator loss: 1.2881708145141602\n",
      "\tGenerator loss: 0.8700364232063293, Discriminator loss: 1.2994132041931152\n",
      "\tGenerator loss: 0.8914663195610046, Discriminator loss: 1.2523280382156372\n",
      "\tGenerator loss: 0.9075417518615723, Discriminator loss: 1.228266954421997\n",
      "\tGenerator loss: 0.90137779712677, Discriminator loss: 1.2408525943756104\n",
      "\tGenerator loss: 0.8749467134475708, Discriminator loss: 1.2032415866851807\n",
      "\tGenerator loss: 0.8668309450149536, Discriminator loss: 1.1878817081451416\n",
      "\tGenerator loss: 0.8553748726844788, Discriminator loss: 1.1834408044815063\n",
      "\tGenerator loss: 0.8642048239707947, Discriminator loss: 1.1814565658569336\n",
      "\tGenerator loss: 0.8869638442993164, Discriminator loss: 1.1858210563659668\n",
      "\tGenerator loss: 0.9031379818916321, Discriminator loss: 1.1914726495742798\n",
      "\tGenerator loss: 0.9165941476821899, Discriminator loss: 1.1624164581298828\n",
      "\tGenerator loss: 0.9362133741378784, Discriminator loss: 1.1828575134277344\n",
      "\tGenerator loss: 0.9323733448982239, Discriminator loss: 1.1966965198516846\n",
      "\tGenerator loss: 0.9163676500320435, Discriminator loss: 1.1882660388946533\n",
      "\tGenerator loss: 0.8939456939697266, Discriminator loss: 1.1591917276382446\n",
      "\tGenerator loss: 0.8933389186859131, Discriminator loss: 1.1671123504638672\n",
      "\tGenerator loss: 0.895857036113739, Discriminator loss: 1.1585665941238403\n",
      "\tGenerator loss: 0.8970410823822021, Discriminator loss: 1.1837644577026367\n",
      "\tGenerator loss: 0.897365152835846, Discriminator loss: 1.1673483848571777\n",
      "\tGenerator loss: 0.9056315422058105, Discriminator loss: 1.1830031871795654\n",
      "\tGenerator loss: 0.9217236042022705, Discriminator loss: 1.1459534168243408\n",
      "\tGenerator loss: 0.9204659461975098, Discriminator loss: 1.188223958015442\n",
      "\tGenerator loss: 0.9408001899719238, Discriminator loss: 1.18375563621521\n",
      "\tGenerator loss: 0.9314858913421631, Discriminator loss: 1.2262773513793945\n",
      "\tGenerator loss: 0.9043387174606323, Discriminator loss: 1.2354788780212402\n",
      "\tGenerator loss: 0.8798009157180786, Discriminator loss: 1.2310051918029785\n",
      "\tGenerator loss: 0.8596242666244507, Discriminator loss: 1.2868916988372803\n",
      "\tGenerator loss: 0.8323264122009277, Discriminator loss: 1.2368714809417725\n",
      "\tGenerator loss: 0.8030592203140259, Discriminator loss: 1.2399089336395264\n",
      "\tGenerator loss: 0.8062381744384766, Discriminator loss: 1.2036694288253784\n",
      "\tGenerator loss: 0.8322573900222778, Discriminator loss: 1.2200336456298828\n",
      "\tGenerator loss: 0.8843754529953003, Discriminator loss: 1.2460925579071045\n",
      "\tGenerator loss: 0.927627444267273, Discriminator loss: 1.3053991794586182\n",
      "\tGenerator loss: 0.9329476952552795, Discriminator loss: 1.3163702487945557\n",
      "\tGenerator loss: 0.914806604385376, Discriminator loss: 1.3058490753173828\n",
      "\tGenerator loss: 0.8546501398086548, Discriminator loss: 1.3323506116867065\n",
      "\tGenerator loss: 0.8177772760391235, Discriminator loss: 1.3280022144317627\n",
      "\tGenerator loss: 0.7856307625770569, Discriminator loss: 1.3077982664108276\n",
      "\tGenerator loss: 0.750495433807373, Discriminator loss: 1.3040201663970947\n",
      "\tGenerator loss: 0.7396308183670044, Discriminator loss: 1.3125104904174805\n",
      "\tGenerator loss: 0.7613186836242676, Discriminator loss: 1.2948524951934814\n",
      "\tGenerator loss: 0.8072766065597534, Discriminator loss: 1.3826699256896973\n",
      "\tGenerator loss: 0.8332903385162354, Discriminator loss: 1.373387336730957\n",
      "\tGenerator loss: 0.839836597442627, Discriminator loss: 1.364927887916565\n",
      "\tGenerator loss: 0.8271430730819702, Discriminator loss: 1.3783762454986572\n",
      "\tGenerator loss: 0.8036818504333496, Discriminator loss: 1.368330955505371\n",
      "\tGenerator loss: 0.7562406659126282, Discriminator loss: 1.3775346279144287\n",
      "\tGenerator loss: 0.7289236783981323, Discriminator loss: 1.417081356048584\n",
      "\tGenerator loss: 0.7191244959831238, Discriminator loss: 1.4400322437286377\n",
      "\tGenerator loss: 0.7073806524276733, Discriminator loss: 1.4249101877212524\n",
      "\tGenerator loss: 0.7000994682312012, Discriminator loss: 1.3744702339172363\n",
      "\tGenerator loss: 0.7152941226959229, Discriminator loss: 1.3826205730438232\n",
      "\tGenerator loss: 0.7328187227249146, Discriminator loss: 1.3509106636047363\n",
      "\tGenerator loss: 0.7670100927352905, Discriminator loss: 1.3429580926895142\n",
      "\tGenerator loss: 0.7843090295791626, Discriminator loss: 1.3331849575042725\n",
      "\tGenerator loss: 0.814631998538971, Discriminator loss: 1.3160643577575684\n",
      "\tGenerator loss: 0.8315625190734863, Discriminator loss: 1.3114163875579834\n",
      "\tGenerator loss: 0.8142924308776855, Discriminator loss: 1.345966100692749\n",
      "\tGenerator loss: 0.7973854541778564, Discriminator loss: 1.3844020366668701\n",
      "\tGenerator loss: 0.7666356563568115, Discriminator loss: 1.4000625610351562\n",
      "\tGenerator loss: 0.7414041757583618, Discriminator loss: 1.3518970012664795\n",
      "\tGenerator loss: 0.7214589715003967, Discriminator loss: 1.3419853448867798\n",
      "\tGenerator loss: 0.7061787843704224, Discriminator loss: 1.3407645225524902\n",
      "\tGenerator loss: 0.7207853198051453, Discriminator loss: 1.374158501625061\n",
      "\tGenerator loss: 0.7607611417770386, Discriminator loss: 1.3450024127960205\n",
      "\tGenerator loss: 0.7777442336082458, Discriminator loss: 1.4045677185058594\n",
      "\tGenerator loss: 0.7863492965698242, Discriminator loss: 1.3839598894119263\n",
      "\tGenerator loss: 0.7765212059020996, Discriminator loss: 1.3747947216033936\n",
      "\tGenerator loss: 0.780846357345581, Discriminator loss: 1.323427677154541\n",
      "\tGenerator loss: 0.7764006853103638, Discriminator loss: 1.333848237991333\n",
      "\tGenerator loss: 0.7754188776016235, Discriminator loss: 1.335237741470337\n",
      "\tGenerator loss: 0.7799381017684937, Discriminator loss: 1.363659381866455\n",
      "\tGenerator loss: 0.7901885509490967, Discriminator loss: 1.3529934883117676\n",
      "\tGenerator loss: 0.7840237021446228, Discriminator loss: 1.332551121711731\n",
      "\tGenerator loss: 0.7939409017562866, Discriminator loss: 1.3249869346618652\n",
      "\tGenerator loss: 0.8137216567993164, Discriminator loss: 1.347612977027893\n",
      "\tGenerator loss: 0.822742760181427, Discriminator loss: 1.3402283191680908\n",
      "\tGenerator loss: 0.8315743207931519, Discriminator loss: 1.3800952434539795\n",
      "\tGenerator loss: 0.8231038451194763, Discriminator loss: 1.383881688117981\n",
      "\tGenerator loss: 0.8151497840881348, Discriminator loss: 1.3939411640167236\n",
      "\tGenerator loss: 0.7794791460037231, Discriminator loss: 1.383938193321228\n",
      "\tGenerator loss: 0.7440073490142822, Discriminator loss: 1.3422386646270752\n",
      "\tGenerator loss: 0.729655921459198, Discriminator loss: 1.352030634880066\n",
      "\tGenerator loss: 0.7440541982650757, Discriminator loss: 1.360029697418213\n",
      "\tGenerator loss: 0.789188802242279, Discriminator loss: 1.2900218963623047\n",
      "\tGenerator loss: 0.8382399678230286, Discriminator loss: 1.2933839559555054\n",
      "\tGenerator loss: 0.8663421869277954, Discriminator loss: 1.3394994735717773\n",
      "\tGenerator loss: 0.874075174331665, Discriminator loss: 1.3328790664672852\n",
      "\tGenerator loss: 0.8652501702308655, Discriminator loss: 1.329648494720459\n",
      "\tGenerator loss: 0.8560810089111328, Discriminator loss: 1.3376480340957642\n",
      "\tGenerator loss: 0.8295433521270752, Discriminator loss: 1.320575475692749\n",
      "\tGenerator loss: 0.7794451713562012, Discriminator loss: 1.3231110572814941\n",
      "\tGenerator loss: 0.7735840678215027, Discriminator loss: 1.3012455701828003\n",
      "\tGenerator loss: 0.7863197326660156, Discriminator loss: 1.3240931034088135\n",
      "\tGenerator loss: 0.7948916554450989, Discriminator loss: 1.2996678352355957\n",
      "\tGenerator loss: 0.846189022064209, Discriminator loss: 1.2729599475860596\n",
      "\tGenerator loss: 0.8784394264221191, Discriminator loss: 1.295719861984253\n",
      "\tGenerator loss: 0.9008491635322571, Discriminator loss: 1.2748464345932007\n",
      "\tGenerator loss: 0.8928621411323547, Discriminator loss: 1.2423405647277832\n",
      "\tGenerator loss: 0.8929563164710999, Discriminator loss: 1.227476716041565\n",
      "\tGenerator loss: 0.8750432729721069, Discriminator loss: 1.2693302631378174\n",
      "\tGenerator loss: 0.8697095513343811, Discriminator loss: 1.2526301145553589\n",
      "\tGenerator loss: 0.8620535135269165, Discriminator loss: 1.2298600673675537\n",
      "\tGenerator loss: 0.8638373017311096, Discriminator loss: 1.289656400680542\n",
      "\tGenerator loss: 0.8656076192855835, Discriminator loss: 1.260152816772461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8653624057769775, Discriminator loss: 1.2515921592712402\n",
      "\tGenerator loss: 0.8673442006111145, Discriminator loss: 1.2323851585388184\n",
      "\tGenerator loss: 0.8800280094146729, Discriminator loss: 1.2319315671920776\n",
      "\tGenerator loss: 0.9003196358680725, Discriminator loss: 1.1993868350982666\n",
      "\tGenerator loss: 0.9066655039787292, Discriminator loss: 1.223349928855896\n",
      "\tGenerator loss: 0.9179619550704956, Discriminator loss: 1.2357274293899536\n",
      "\tGenerator loss: 0.8943773508071899, Discriminator loss: 1.2033884525299072\n",
      "\tGenerator loss: 0.885482907295227, Discriminator loss: 1.1775058507919312\n",
      "\tGenerator loss: 0.8809019327163696, Discriminator loss: 1.197385311126709\n",
      "\tGenerator loss: 0.8725976943969727, Discriminator loss: 1.1745994091033936\n",
      "\tGenerator loss: 0.867359459400177, Discriminator loss: 1.148427963256836\n",
      "\tGenerator loss: 0.8891268968582153, Discriminator loss: 1.175220012664795\n",
      "\tGenerator loss: 0.900825023651123, Discriminator loss: 1.2574557065963745\n",
      "\tGenerator loss: 0.8894246816635132, Discriminator loss: 1.3283694982528687\n",
      "\tGenerator loss: 0.8672468662261963, Discriminator loss: 1.3108242750167847\n",
      "\tGenerator loss: 0.8526833653450012, Discriminator loss: 1.2640104293823242\n",
      "Time for epoch 7 is 473.74947571754456 sec\n",
      "\tGenerator loss: 0.8211266994476318, Discriminator loss: 1.2525612115859985\n",
      "\tGenerator loss: 0.8055092096328735, Discriminator loss: 1.233717441558838\n",
      "\tGenerator loss: 0.8128888607025146, Discriminator loss: 1.2360427379608154\n",
      "\tGenerator loss: 0.8259328603744507, Discriminator loss: 1.2609145641326904\n",
      "\tGenerator loss: 0.8447120189666748, Discriminator loss: 1.3304063081741333\n",
      "\tGenerator loss: 0.8667883276939392, Discriminator loss: 1.3628926277160645\n",
      "\tGenerator loss: 0.8531181216239929, Discriminator loss: 1.3020920753479004\n",
      "\tGenerator loss: 0.8217244744300842, Discriminator loss: 1.3508427143096924\n",
      "\tGenerator loss: 0.8012995719909668, Discriminator loss: 1.3364650011062622\n",
      "\tGenerator loss: 0.7957165837287903, Discriminator loss: 1.334841012954712\n",
      "\tGenerator loss: 0.7950626611709595, Discriminator loss: 1.3476555347442627\n",
      "\tGenerator loss: 0.8113659024238586, Discriminator loss: 1.3430534601211548\n",
      "\tGenerator loss: 0.8195780515670776, Discriminator loss: 1.3096871376037598\n",
      "\tGenerator loss: 0.8396771550178528, Discriminator loss: 1.3175207376480103\n",
      "\tGenerator loss: 0.8370887637138367, Discriminator loss: 1.368114709854126\n",
      "\tGenerator loss: 0.8270927667617798, Discriminator loss: 1.339290738105774\n",
      "\tGenerator loss: 0.8083698153495789, Discriminator loss: 1.3584163188934326\n",
      "\tGenerator loss: 0.7947832345962524, Discriminator loss: 1.3796931505203247\n",
      "\tGenerator loss: 0.7892348170280457, Discriminator loss: 1.431652307510376\n",
      "\tGenerator loss: 0.7754338979721069, Discriminator loss: 1.4067649841308594\n",
      "\tGenerator loss: 0.7784822583198547, Discriminator loss: 1.4234637022018433\n",
      "\tGenerator loss: 0.7697880268096924, Discriminator loss: 1.470978021621704\n",
      "\tGenerator loss: 0.7937275171279907, Discriminator loss: 1.4317113161087036\n",
      "\tGenerator loss: 0.7979243397712708, Discriminator loss: 1.4774248600006104\n",
      "\tGenerator loss: 0.8035914897918701, Discriminator loss: 1.4778790473937988\n",
      "\tGenerator loss: 0.8029628992080688, Discriminator loss: 1.4168388843536377\n",
      "\tGenerator loss: 0.8028619289398193, Discriminator loss: 1.3870376348495483\n",
      "\tGenerator loss: 0.7984200119972229, Discriminator loss: 1.3800718784332275\n",
      "\tGenerator loss: 0.8068195581436157, Discriminator loss: 1.3895108699798584\n",
      "\tGenerator loss: 0.8029370307922363, Discriminator loss: 1.346491813659668\n",
      "\tGenerator loss: 0.801816463470459, Discriminator loss: 1.382690668106079\n",
      "\tGenerator loss: 0.8103646636009216, Discriminator loss: 1.3992509841918945\n",
      "\tGenerator loss: 0.8111439943313599, Discriminator loss: 1.3886038064956665\n",
      "\tGenerator loss: 0.8006465435028076, Discriminator loss: 1.43263840675354\n",
      "\tGenerator loss: 0.799666702747345, Discriminator loss: 1.416467547416687\n",
      "\tGenerator loss: 0.7980079650878906, Discriminator loss: 1.3770359754562378\n",
      "\tGenerator loss: 0.8045142889022827, Discriminator loss: 1.3812041282653809\n",
      "\tGenerator loss: 0.811884343624115, Discriminator loss: 1.3508038520812988\n",
      "\tGenerator loss: 0.833059549331665, Discriminator loss: 1.3069820404052734\n",
      "\tGenerator loss: 0.8429960012435913, Discriminator loss: 1.3364858627319336\n",
      "\tGenerator loss: 0.8547407388687134, Discriminator loss: 1.3211103677749634\n",
      "\tGenerator loss: 0.8736639618873596, Discriminator loss: 1.324688196182251\n",
      "\tGenerator loss: 0.8864418268203735, Discriminator loss: 1.2974350452423096\n",
      "\tGenerator loss: 0.8788427710533142, Discriminator loss: 1.2820390462875366\n",
      "\tGenerator loss: 0.8796955347061157, Discriminator loss: 1.2757349014282227\n",
      "\tGenerator loss: 0.8539036512374878, Discriminator loss: 1.286797046661377\n",
      "\tGenerator loss: 0.8365585803985596, Discriminator loss: 1.2833702564239502\n",
      "\tGenerator loss: 0.8472185134887695, Discriminator loss: 1.2638375759124756\n",
      "\tGenerator loss: 0.869099497795105, Discriminator loss: 1.2485629320144653\n",
      "\tGenerator loss: 0.8926747441291809, Discriminator loss: 1.2425665855407715\n",
      "\tGenerator loss: 0.922146201133728, Discriminator loss: 1.2496554851531982\n",
      "\tGenerator loss: 0.9232808947563171, Discriminator loss: 1.2374763488769531\n",
      "\tGenerator loss: 0.9340879917144775, Discriminator loss: 1.1965097188949585\n",
      "\tGenerator loss: 0.9373724460601807, Discriminator loss: 1.2481639385223389\n",
      "\tGenerator loss: 0.9209961891174316, Discriminator loss: 1.234257698059082\n",
      "\tGenerator loss: 0.9067155718803406, Discriminator loss: 1.2160683870315552\n",
      "\tGenerator loss: 0.8914694786071777, Discriminator loss: 1.2608060836791992\n",
      "\tGenerator loss: 0.8825815320014954, Discriminator loss: 1.2755496501922607\n",
      "\tGenerator loss: 0.8663750886917114, Discriminator loss: 1.2755053043365479\n",
      "\tGenerator loss: 0.8603702187538147, Discriminator loss: 1.2886048555374146\n",
      "\tGenerator loss: 0.8587380051612854, Discriminator loss: 1.2942132949829102\n",
      "\tGenerator loss: 0.8392119407653809, Discriminator loss: 1.2902796268463135\n",
      "\tGenerator loss: 0.8432896733283997, Discriminator loss: 1.283567190170288\n",
      "\tGenerator loss: 0.8575724363327026, Discriminator loss: 1.2756383419036865\n",
      "\tGenerator loss: 0.8669477701187134, Discriminator loss: 1.2864693403244019\n",
      "\tGenerator loss: 0.8889737129211426, Discriminator loss: 1.3426837921142578\n",
      "\tGenerator loss: 0.8865758180618286, Discriminator loss: 1.3597663640975952\n",
      "\tGenerator loss: 0.8645621538162231, Discriminator loss: 1.323339581489563\n",
      "\tGenerator loss: 0.8237068057060242, Discriminator loss: 1.4247876405715942\n",
      "\tGenerator loss: 0.785166323184967, Discriminator loss: 1.465360403060913\n",
      "\tGenerator loss: 0.7483581304550171, Discriminator loss: 1.4444184303283691\n",
      "\tGenerator loss: 0.7287164330482483, Discriminator loss: 1.4403321743011475\n",
      "\tGenerator loss: 0.7257449626922607, Discriminator loss: 1.4294785261154175\n",
      "\tGenerator loss: 0.7502275705337524, Discriminator loss: 1.4603594541549683\n",
      "\tGenerator loss: 0.7521795630455017, Discriminator loss: 1.4948432445526123\n",
      "\tGenerator loss: 0.758596658706665, Discriminator loss: 1.4412646293640137\n",
      "\tGenerator loss: 0.7644830942153931, Discriminator loss: 1.4364604949951172\n",
      "\tGenerator loss: 0.796536922454834, Discriminator loss: 1.4136202335357666\n",
      "\tGenerator loss: 0.8085375428199768, Discriminator loss: 1.4692869186401367\n",
      "\tGenerator loss: 0.811012327671051, Discriminator loss: 1.518975019454956\n",
      "\tGenerator loss: 0.7903071045875549, Discriminator loss: 1.4843705892562866\n",
      "\tGenerator loss: 0.7473243474960327, Discriminator loss: 1.5427327156066895\n",
      "\tGenerator loss: 0.7123326659202576, Discriminator loss: 1.582133173942566\n",
      "\tGenerator loss: 0.6684865951538086, Discriminator loss: 1.5768837928771973\n",
      "\tGenerator loss: 0.6257731914520264, Discriminator loss: 1.6299468278884888\n",
      "\tGenerator loss: 0.5974416732788086, Discriminator loss: 1.561892032623291\n",
      "\tGenerator loss: 0.605144739151001, Discriminator loss: 1.5762258768081665\n",
      "\tGenerator loss: 0.6197738647460938, Discriminator loss: 1.59921395778656\n",
      "\tGenerator loss: 0.6536142826080322, Discriminator loss: 1.5632984638214111\n",
      "\tGenerator loss: 0.6822984218597412, Discriminator loss: 1.5488476753234863\n",
      "\tGenerator loss: 0.7120965719223022, Discriminator loss: 1.5341649055480957\n",
      "\tGenerator loss: 0.7329138517379761, Discriminator loss: 1.5236228704452515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.72389155626297, Discriminator loss: 1.539768934249878\n",
      "\tGenerator loss: 0.7026088833808899, Discriminator loss: 1.521295428276062\n",
      "\tGenerator loss: 0.6874236464500427, Discriminator loss: 1.4829277992248535\n",
      "\tGenerator loss: 0.6684894561767578, Discriminator loss: 1.4614354372024536\n",
      "\tGenerator loss: 0.6451018452644348, Discriminator loss: 1.4498382806777954\n",
      "\tGenerator loss: 0.6248617172241211, Discriminator loss: 1.459573745727539\n",
      "\tGenerator loss: 0.628948986530304, Discriminator loss: 1.4121623039245605\n",
      "\tGenerator loss: 0.6635867953300476, Discriminator loss: 1.344988465309143\n",
      "\tGenerator loss: 0.6975324749946594, Discriminator loss: 1.3373758792877197\n",
      "\tGenerator loss: 0.7466565370559692, Discriminator loss: 1.3153492212295532\n",
      "\tGenerator loss: 0.7705954313278198, Discriminator loss: 1.2757089138031006\n",
      "\tGenerator loss: 0.7900683283805847, Discriminator loss: 1.26619291305542\n",
      "\tGenerator loss: 0.8163151741027832, Discriminator loss: 1.2217899560928345\n",
      "\tGenerator loss: 0.8286341428756714, Discriminator loss: 1.1809831857681274\n",
      "\tGenerator loss: 0.839850902557373, Discriminator loss: 1.1641614437103271\n",
      "\tGenerator loss: 0.8316268920898438, Discriminator loss: 1.143744707107544\n",
      "\tGenerator loss: 0.8419274687767029, Discriminator loss: 1.1106107234954834\n",
      "\tGenerator loss: 0.8496023416519165, Discriminator loss: 1.0904896259307861\n",
      "\tGenerator loss: 0.8589223623275757, Discriminator loss: 1.0904395580291748\n",
      "\tGenerator loss: 0.883888304233551, Discriminator loss: 1.0689265727996826\n",
      "\tGenerator loss: 0.9149690866470337, Discriminator loss: 1.0187764167785645\n",
      "\tGenerator loss: 0.9448224306106567, Discriminator loss: 0.9765710234642029\n",
      "\tGenerator loss: 0.9765100479125977, Discriminator loss: 1.0075607299804688\n",
      "\tGenerator loss: 1.0111792087554932, Discriminator loss: 0.9565879106521606\n",
      "\tGenerator loss: 1.0336871147155762, Discriminator loss: 0.931388258934021\n",
      "\tGenerator loss: 1.0607109069824219, Discriminator loss: 0.8983193635940552\n",
      "\tGenerator loss: 1.0819103717803955, Discriminator loss: 0.89003986120224\n",
      "\tGenerator loss: 1.071254014968872, Discriminator loss: 0.8823646306991577\n",
      "\tGenerator loss: 1.0843292474746704, Discriminator loss: 0.8678821325302124\n",
      "\tGenerator loss: 1.0786926746368408, Discriminator loss: 0.8661510944366455\n",
      "\tGenerator loss: 1.0794661045074463, Discriminator loss: 0.8671563863754272\n",
      "\tGenerator loss: 1.100999116897583, Discriminator loss: 0.8437496423721313\n",
      "\tGenerator loss: 1.1252830028533936, Discriminator loss: 0.8425518870353699\n",
      "\tGenerator loss: 1.116787075996399, Discriminator loss: 0.8872381448745728\n",
      "\tGenerator loss: 1.1027777194976807, Discriminator loss: 0.9906027317047119\n",
      "\tGenerator loss: 1.0810322761535645, Discriminator loss: 0.9405934810638428\n",
      "\tGenerator loss: 1.0751988887786865, Discriminator loss: 0.9373627305030823\n",
      "\tGenerator loss: 1.040377140045166, Discriminator loss: 0.9534257650375366\n",
      "\tGenerator loss: 1.0265635251998901, Discriminator loss: 0.9212040901184082\n",
      "\tGenerator loss: 1.0058513879776, Discriminator loss: 0.950469970703125\n",
      "\tGenerator loss: 1.0315277576446533, Discriminator loss: 0.9808904528617859\n",
      "\tGenerator loss: 1.0312888622283936, Discriminator loss: 0.9799209833145142\n",
      "\tGenerator loss: 1.0510464906692505, Discriminator loss: 1.0105361938476562\n",
      "\tGenerator loss: 1.0604960918426514, Discriminator loss: 1.020880937576294\n",
      "\tGenerator loss: 1.0531532764434814, Discriminator loss: 1.0514791011810303\n",
      "\tGenerator loss: 1.0295541286468506, Discriminator loss: 1.0324821472167969\n",
      "\tGenerator loss: 1.0019521713256836, Discriminator loss: 1.076462745666504\n",
      "\tGenerator loss: 0.9592892527580261, Discriminator loss: 1.109356164932251\n",
      "\tGenerator loss: 0.9415320158004761, Discriminator loss: 1.0866641998291016\n",
      "\tGenerator loss: 0.9327990412712097, Discriminator loss: 1.257893443107605\n",
      "\tGenerator loss: 0.9282454252243042, Discriminator loss: 1.2621631622314453\n",
      "\tGenerator loss: 0.8925492763519287, Discriminator loss: 1.4509490728378296\n",
      "\tGenerator loss: 0.8566064834594727, Discriminator loss: 1.4437555074691772\n",
      "\tGenerator loss: 0.8224372863769531, Discriminator loss: 1.5438857078552246\n",
      "\tGenerator loss: 0.7965641617774963, Discriminator loss: 1.4246881008148193\n",
      "\tGenerator loss: 0.7810474634170532, Discriminator loss: 1.4235118627548218\n",
      "\tGenerator loss: 0.7735071182250977, Discriminator loss: 1.3823589086532593\n",
      "\tGenerator loss: 0.7724762558937073, Discriminator loss: 1.3839993476867676\n",
      "\tGenerator loss: 0.7957547307014465, Discriminator loss: 1.406982183456421\n",
      "\tGenerator loss: 0.8139179944992065, Discriminator loss: 1.4271845817565918\n",
      "\tGenerator loss: 0.8349502682685852, Discriminator loss: 1.4684715270996094\n",
      "\tGenerator loss: 0.8330053091049194, Discriminator loss: 1.5667445659637451\n",
      "\tGenerator loss: 0.8107459545135498, Discriminator loss: 1.642067313194275\n",
      "\tGenerator loss: 0.7623216509819031, Discriminator loss: 1.518617868423462\n",
      "\tGenerator loss: 0.7274307012557983, Discriminator loss: 1.5457425117492676\n",
      "\tGenerator loss: 0.6958515644073486, Discriminator loss: 1.5295658111572266\n",
      "\tGenerator loss: 0.6719191074371338, Discriminator loss: 1.5948433876037598\n",
      "\tGenerator loss: 0.6824405193328857, Discriminator loss: 1.5341860055923462\n",
      "\tGenerator loss: 0.706519365310669, Discriminator loss: 1.5245704650878906\n",
      "\tGenerator loss: 0.734268069267273, Discriminator loss: 1.5357637405395508\n",
      "\tGenerator loss: 0.761688232421875, Discriminator loss: 1.5264134407043457\n",
      "\tGenerator loss: 0.7756397128105164, Discriminator loss: 1.5572636127471924\n",
      "\tGenerator loss: 0.7846717834472656, Discriminator loss: 1.6244738101959229\n",
      "\tGenerator loss: 0.7635022401809692, Discriminator loss: 1.6080825328826904\n",
      "\tGenerator loss: 0.7274250984191895, Discriminator loss: 1.6241123676300049\n",
      "\tGenerator loss: 0.6969454884529114, Discriminator loss: 1.6060326099395752\n",
      "\tGenerator loss: 0.663892388343811, Discriminator loss: 1.567307472229004\n",
      "\tGenerator loss: 0.6532522439956665, Discriminator loss: 1.5311532020568848\n",
      "\tGenerator loss: 0.6626202464103699, Discriminator loss: 1.5214720964431763\n",
      "\tGenerator loss: 0.6847801208496094, Discriminator loss: 1.4806482791900635\n",
      "\tGenerator loss: 0.7330683469772339, Discriminator loss: 1.4203046560287476\n",
      "\tGenerator loss: 0.7758619785308838, Discriminator loss: 1.422471523284912\n",
      "\tGenerator loss: 0.8166368007659912, Discriminator loss: 1.395567536354065\n",
      "\tGenerator loss: 0.838322639465332, Discriminator loss: 1.4161434173583984\n",
      "\tGenerator loss: 0.8466233015060425, Discriminator loss: 1.387676477432251\n",
      "\tGenerator loss: 0.8289260864257812, Discriminator loss: 1.362571358680725\n",
      "\tGenerator loss: 0.7996827363967896, Discriminator loss: 1.3627777099609375\n",
      "\tGenerator loss: 0.7843116521835327, Discriminator loss: 1.3452496528625488\n",
      "\tGenerator loss: 0.7587230801582336, Discriminator loss: 1.3262218236923218\n",
      "\tGenerator loss: 0.7392349243164062, Discriminator loss: 1.3357670307159424\n",
      "\tGenerator loss: 0.743977427482605, Discriminator loss: 1.3236298561096191\n",
      "\tGenerator loss: 0.7654169797897339, Discriminator loss: 1.3110730648040771\n",
      "\tGenerator loss: 0.8097870349884033, Discriminator loss: 1.2911607027053833\n",
      "\tGenerator loss: 0.8349701762199402, Discriminator loss: 1.302044153213501\n",
      "\tGenerator loss: 0.8683868646621704, Discriminator loss: 1.3043034076690674\n",
      "\tGenerator loss: 0.8886310458183289, Discriminator loss: 1.2742321491241455\n",
      "\tGenerator loss: 0.8910131454467773, Discriminator loss: 1.2796218395233154\n",
      "\tGenerator loss: 0.8841290473937988, Discriminator loss: 1.2544915676116943\n",
      "\tGenerator loss: 0.8661037087440491, Discriminator loss: 1.2190617322921753\n",
      "\tGenerator loss: 0.8509232997894287, Discriminator loss: 1.232008695602417\n",
      "\tGenerator loss: 0.8319017887115479, Discriminator loss: 1.2142341136932373\n",
      "\tGenerator loss: 0.8293812274932861, Discriminator loss: 1.1979540586471558\n",
      "\tGenerator loss: 0.8385099172592163, Discriminator loss: 1.1882965564727783\n",
      "\tGenerator loss: 0.8527284264564514, Discriminator loss: 1.1850006580352783\n",
      "\tGenerator loss: 0.8768459558486938, Discriminator loss: 1.1777786016464233\n",
      "\tGenerator loss: 0.8928504586219788, Discriminator loss: 1.1941123008728027\n",
      "\tGenerator loss: 0.9086565971374512, Discriminator loss: 1.1661381721496582\n",
      "\tGenerator loss: 0.9090965390205383, Discriminator loss: 1.147327184677124\n",
      "\tGenerator loss: 0.8975793123245239, Discriminator loss: 1.1363575458526611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.906159520149231, Discriminator loss: 1.122969150543213\n",
      "\tGenerator loss: 0.9021798968315125, Discriminator loss: 1.1637599468231201\n",
      "\tGenerator loss: 0.9102804660797119, Discriminator loss: 1.1968210935592651\n",
      "\tGenerator loss: 0.8967474699020386, Discriminator loss: 1.1921323537826538\n",
      "\tGenerator loss: 0.87447589635849, Discriminator loss: 1.1880440711975098\n",
      "\tGenerator loss: 0.8572087287902832, Discriminator loss: 1.2021808624267578\n",
      "\tGenerator loss: 0.8430820107460022, Discriminator loss: 1.201775312423706\n",
      "\tGenerator loss: 0.8346492052078247, Discriminator loss: 1.209221601486206\n",
      "\tGenerator loss: 0.8387852311134338, Discriminator loss: 1.2346010208129883\n",
      "\tGenerator loss: 0.8513097167015076, Discriminator loss: 1.2410768270492554\n",
      "\tGenerator loss: 0.8475847244262695, Discriminator loss: 1.2784016132354736\n",
      "\tGenerator loss: 0.8463354706764221, Discriminator loss: 1.2728970050811768\n",
      "\tGenerator loss: 0.8356528878211975, Discriminator loss: 1.2764830589294434\n",
      "\tGenerator loss: 0.8250856399536133, Discriminator loss: 1.3110623359680176\n",
      "\tGenerator loss: 0.8253738880157471, Discriminator loss: 1.2989680767059326\n",
      "\tGenerator loss: 0.8130767345428467, Discriminator loss: 1.3277952671051025\n",
      "\tGenerator loss: 0.8008681535720825, Discriminator loss: 1.3164258003234863\n",
      "\tGenerator loss: 0.7782902121543884, Discriminator loss: 1.340678095817566\n",
      "\tGenerator loss: 0.7849395275115967, Discriminator loss: 1.3923578262329102\n",
      "\tGenerator loss: 0.7814744710922241, Discriminator loss: 1.4427927732467651\n",
      "\tGenerator loss: 0.7513236999511719, Discriminator loss: 1.4426424503326416\n",
      "\tGenerator loss: 0.730262815952301, Discriminator loss: 1.4630191326141357\n",
      "\tGenerator loss: 0.7072964906692505, Discriminator loss: 1.4737720489501953\n",
      "\tGenerator loss: 0.6715185046195984, Discriminator loss: 1.453313946723938\n",
      "\tGenerator loss: 0.6704519987106323, Discriminator loss: 1.4910809993743896\n",
      "\tGenerator loss: 0.6768739819526672, Discriminator loss: 1.5221540927886963\n",
      "\tGenerator loss: 0.6756881475448608, Discriminator loss: 1.4740643501281738\n",
      "\tGenerator loss: 0.6868016719818115, Discriminator loss: 1.4775841236114502\n",
      "\tGenerator loss: 0.6835778951644897, Discriminator loss: 1.5060031414031982\n",
      "\tGenerator loss: 0.6896651387214661, Discriminator loss: 1.4449117183685303\n",
      "\tGenerator loss: 0.7063867449760437, Discriminator loss: 1.391824722290039\n",
      "\tGenerator loss: 0.7207971811294556, Discriminator loss: 1.3678369522094727\n",
      "\tGenerator loss: 0.7411960959434509, Discriminator loss: 1.3607608079910278\n",
      "\tGenerator loss: 0.7665115594863892, Discriminator loss: 1.4627940654754639\n",
      "Time for epoch 8 is 475.6960666179657 sec\n",
      "\tGenerator loss: 0.7673621773719788, Discriminator loss: 1.420055627822876\n",
      "\tGenerator loss: 0.7612664699554443, Discriminator loss: 1.3941770792007446\n",
      "\tGenerator loss: 0.7489243745803833, Discriminator loss: 1.378720760345459\n",
      "\tGenerator loss: 0.734974205493927, Discriminator loss: 1.3432573080062866\n",
      "\tGenerator loss: 0.7247968316078186, Discriminator loss: 1.3544371128082275\n",
      "\tGenerator loss: 0.7319591045379639, Discriminator loss: 1.3105871677398682\n",
      "\tGenerator loss: 0.7367247343063354, Discriminator loss: 1.2924253940582275\n",
      "\tGenerator loss: 0.758149266242981, Discriminator loss: 1.2722084522247314\n",
      "\tGenerator loss: 0.7948190569877625, Discriminator loss: 1.226872444152832\n",
      "\tGenerator loss: 0.8260594606399536, Discriminator loss: 1.2265830039978027\n",
      "\tGenerator loss: 0.8729013204574585, Discriminator loss: 1.1970406770706177\n",
      "\tGenerator loss: 0.9128575325012207, Discriminator loss: 1.1814618110656738\n",
      "\tGenerator loss: 0.9214550852775574, Discriminator loss: 1.1680727005004883\n",
      "\tGenerator loss: 0.908158540725708, Discriminator loss: 1.1502593755722046\n",
      "\tGenerator loss: 0.8923563957214355, Discriminator loss: 1.1652779579162598\n",
      "\tGenerator loss: 0.8720077872276306, Discriminator loss: 1.132935643196106\n",
      "\tGenerator loss: 0.8876386880874634, Discriminator loss: 1.1106815338134766\n",
      "\tGenerator loss: 0.8962290287017822, Discriminator loss: 1.1015413999557495\n",
      "\tGenerator loss: 0.9303233623504639, Discriminator loss: 1.1192781925201416\n",
      "\tGenerator loss: 0.9490973949432373, Discriminator loss: 1.0873050689697266\n",
      "\tGenerator loss: 0.95809006690979, Discriminator loss: 1.075150728225708\n",
      "\tGenerator loss: 0.979619026184082, Discriminator loss: 1.0610883235931396\n",
      "\tGenerator loss: 0.993132472038269, Discriminator loss: 1.0555230379104614\n",
      "\tGenerator loss: 0.9997522234916687, Discriminator loss: 1.0918240547180176\n",
      "\tGenerator loss: 1.0056830644607544, Discriminator loss: 1.0609122514724731\n",
      "\tGenerator loss: 1.0110235214233398, Discriminator loss: 1.0443298816680908\n",
      "\tGenerator loss: 1.0085434913635254, Discriminator loss: 1.0370328426361084\n",
      "\tGenerator loss: 0.9937203526496887, Discriminator loss: 1.0411806106567383\n",
      "\tGenerator loss: 0.9811545610427856, Discriminator loss: 1.0546759366989136\n",
      "\tGenerator loss: 0.9791650772094727, Discriminator loss: 1.0366017818450928\n",
      "\tGenerator loss: 0.9765527248382568, Discriminator loss: 1.0704548358917236\n",
      "\tGenerator loss: 0.9557077288627625, Discriminator loss: 1.1090770959854126\n",
      "\tGenerator loss: 0.9553329348564148, Discriminator loss: 1.089734435081482\n",
      "\tGenerator loss: 0.9607642889022827, Discriminator loss: 1.134331226348877\n",
      "\tGenerator loss: 0.9548289775848389, Discriminator loss: 1.1237461566925049\n",
      "\tGenerator loss: 0.9675908088684082, Discriminator loss: 1.1025199890136719\n",
      "\tGenerator loss: 0.965458333492279, Discriminator loss: 1.118260383605957\n",
      "\tGenerator loss: 0.9697445631027222, Discriminator loss: 1.1163218021392822\n",
      "\tGenerator loss: 0.968536376953125, Discriminator loss: 1.1026442050933838\n",
      "\tGenerator loss: 0.9617673754692078, Discriminator loss: 1.1472721099853516\n",
      "\tGenerator loss: 0.94939124584198, Discriminator loss: 1.1915279626846313\n",
      "\tGenerator loss: 0.9403561353683472, Discriminator loss: 1.1638717651367188\n",
      "\tGenerator loss: 0.9270102977752686, Discriminator loss: 1.1538221836090088\n",
      "\tGenerator loss: 0.9193730354309082, Discriminator loss: 1.1639190912246704\n",
      "\tGenerator loss: 0.9221622943878174, Discriminator loss: 1.1425795555114746\n",
      "\tGenerator loss: 0.9287146329879761, Discriminator loss: 1.1528685092926025\n",
      "\tGenerator loss: 0.9169808626174927, Discriminator loss: 1.1537823677062988\n",
      "\tGenerator loss: 0.9114397168159485, Discriminator loss: 1.1801435947418213\n",
      "\tGenerator loss: 0.9207859039306641, Discriminator loss: 1.2225439548492432\n",
      "\tGenerator loss: 0.9163550138473511, Discriminator loss: 1.2200615406036377\n",
      "\tGenerator loss: 0.9151418209075928, Discriminator loss: 1.2236661911010742\n",
      "\tGenerator loss: 0.89647376537323, Discriminator loss: 1.2543447017669678\n",
      "\tGenerator loss: 0.8812704682350159, Discriminator loss: 1.2471559047698975\n",
      "\tGenerator loss: 0.887347400188446, Discriminator loss: 1.2256629467010498\n",
      "\tGenerator loss: 0.8784189224243164, Discriminator loss: 1.2534527778625488\n",
      "\tGenerator loss: 0.8803346157073975, Discriminator loss: 1.2809934616088867\n",
      "\tGenerator loss: 0.8613752722740173, Discriminator loss: 1.261562705039978\n",
      "\tGenerator loss: 0.8525080680847168, Discriminator loss: 1.2924528121948242\n",
      "\tGenerator loss: 0.8352322578430176, Discriminator loss: 1.2438056468963623\n",
      "\tGenerator loss: 0.8418657779693604, Discriminator loss: 1.2126654386520386\n",
      "\tGenerator loss: 0.8734702467918396, Discriminator loss: 1.2101914882659912\n",
      "\tGenerator loss: 0.8871887922286987, Discriminator loss: 1.2410507202148438\n",
      "\tGenerator loss: 0.8858018517494202, Discriminator loss: 1.2277534008026123\n",
      "\tGenerator loss: 0.8955514430999756, Discriminator loss: 1.1962826251983643\n",
      "\tGenerator loss: 0.8924221992492676, Discriminator loss: 1.1823735237121582\n",
      "\tGenerator loss: 0.9040088057518005, Discriminator loss: 1.2205917835235596\n",
      "\tGenerator loss: 0.8919939994812012, Discriminator loss: 1.2241547107696533\n",
      "\tGenerator loss: 0.8718270659446716, Discriminator loss: 1.2426997423171997\n",
      "\tGenerator loss: 0.8393557071685791, Discriminator loss: 1.294887661933899\n",
      "\tGenerator loss: 0.8151403665542603, Discriminator loss: 1.2671786546707153\n",
      "\tGenerator loss: 0.7947788238525391, Discriminator loss: 1.2586705684661865\n",
      "\tGenerator loss: 0.8286939263343811, Discriminator loss: 1.2236652374267578\n",
      "\tGenerator loss: 0.8480340242385864, Discriminator loss: 1.2243916988372803\n",
      "\tGenerator loss: 0.8667582273483276, Discriminator loss: 1.2324470281600952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8676144480705261, Discriminator loss: 1.2569063901901245\n",
      "\tGenerator loss: 0.8783162832260132, Discriminator loss: 1.2738263607025146\n",
      "\tGenerator loss: 0.8705034852027893, Discriminator loss: 1.2486953735351562\n",
      "\tGenerator loss: 0.8590814471244812, Discriminator loss: 1.2596077919006348\n",
      "\tGenerator loss: 0.8457789421081543, Discriminator loss: 1.2996013164520264\n",
      "\tGenerator loss: 0.8262256383895874, Discriminator loss: 1.3273476362228394\n",
      "\tGenerator loss: 0.8087654709815979, Discriminator loss: 1.3087129592895508\n",
      "\tGenerator loss: 0.8058909177780151, Discriminator loss: 1.3229243755340576\n",
      "\tGenerator loss: 0.8047347068786621, Discriminator loss: 1.339302897453308\n",
      "\tGenerator loss: 0.8064897060394287, Discriminator loss: 1.34969162940979\n",
      "\tGenerator loss: 0.7927385568618774, Discriminator loss: 1.361842393875122\n",
      "\tGenerator loss: 0.7754727602005005, Discriminator loss: 1.3410590887069702\n",
      "\tGenerator loss: 0.7585559487342834, Discriminator loss: 1.3865221738815308\n",
      "\tGenerator loss: 0.7545158863067627, Discriminator loss: 1.4184958934783936\n",
      "\tGenerator loss: 0.7540276646614075, Discriminator loss: 1.4490658044815063\n",
      "\tGenerator loss: 0.7383573055267334, Discriminator loss: 1.50600266456604\n",
      "\tGenerator loss: 0.7493728399276733, Discriminator loss: 1.4986822605133057\n",
      "\tGenerator loss: 0.7405879497528076, Discriminator loss: 1.4627765417099\n",
      "\tGenerator loss: 0.7245056629180908, Discriminator loss: 1.4833765029907227\n",
      "\tGenerator loss: 0.7144134640693665, Discriminator loss: 1.4506680965423584\n",
      "\tGenerator loss: 0.7080097198486328, Discriminator loss: 1.4363117218017578\n",
      "\tGenerator loss: 0.6941468715667725, Discriminator loss: 1.4899306297302246\n",
      "\tGenerator loss: 0.7033134698867798, Discriminator loss: 1.4809471368789673\n",
      "\tGenerator loss: 0.7094389200210571, Discriminator loss: 1.4863815307617188\n",
      "\tGenerator loss: 0.7311766147613525, Discriminator loss: 1.4512245655059814\n",
      "\tGenerator loss: 0.7271840572357178, Discriminator loss: 1.4409085512161255\n",
      "\tGenerator loss: 0.7293636798858643, Discriminator loss: 1.473064661026001\n",
      "\tGenerator loss: 0.7210254669189453, Discriminator loss: 1.4915268421173096\n",
      "\tGenerator loss: 0.7217486500740051, Discriminator loss: 1.4497785568237305\n",
      "\tGenerator loss: 0.7208566665649414, Discriminator loss: 1.434783935546875\n",
      "\tGenerator loss: 0.7151273488998413, Discriminator loss: 1.3988020420074463\n",
      "\tGenerator loss: 0.6970139145851135, Discriminator loss: 1.4133830070495605\n",
      "\tGenerator loss: 0.699265718460083, Discriminator loss: 1.4436043500900269\n",
      "\tGenerator loss: 0.7109547853469849, Discriminator loss: 1.4229795932769775\n",
      "\tGenerator loss: 0.7350258231163025, Discriminator loss: 1.4152791500091553\n",
      "\tGenerator loss: 0.7345430254936218, Discriminator loss: 1.3861167430877686\n",
      "\tGenerator loss: 0.7419731616973877, Discriminator loss: 1.379716396331787\n",
      "\tGenerator loss: 0.749420166015625, Discriminator loss: 1.3643877506256104\n",
      "\tGenerator loss: 0.770798921585083, Discriminator loss: 1.3389770984649658\n",
      "\tGenerator loss: 0.7867282629013062, Discriminator loss: 1.3428795337677002\n",
      "\tGenerator loss: 0.7902061939239502, Discriminator loss: 1.339003324508667\n",
      "\tGenerator loss: 0.7814489006996155, Discriminator loss: 1.3101683855056763\n",
      "\tGenerator loss: 0.7827475666999817, Discriminator loss: 1.2901036739349365\n",
      "\tGenerator loss: 0.7918792963027954, Discriminator loss: 1.2934988737106323\n",
      "\tGenerator loss: 0.7773017287254333, Discriminator loss: 1.2473361492156982\n",
      "\tGenerator loss: 0.7873904705047607, Discriminator loss: 1.2429543733596802\n",
      "\tGenerator loss: 0.7928279638290405, Discriminator loss: 1.2122249603271484\n",
      "\tGenerator loss: 0.814093291759491, Discriminator loss: 1.2059944868087769\n",
      "\tGenerator loss: 0.8321595191955566, Discriminator loss: 1.207266092300415\n",
      "\tGenerator loss: 0.8424333333969116, Discriminator loss: 1.195489525794983\n",
      "\tGenerator loss: 0.8617939949035645, Discriminator loss: 1.1606251001358032\n",
      "\tGenerator loss: 0.880150556564331, Discriminator loss: 1.1774752140045166\n",
      "\tGenerator loss: 0.8816986083984375, Discriminator loss: 1.2506357431411743\n",
      "\tGenerator loss: 0.8617909550666809, Discriminator loss: 1.2173820734024048\n",
      "\tGenerator loss: 0.8488974571228027, Discriminator loss: 1.1779875755310059\n",
      "\tGenerator loss: 0.844902515411377, Discriminator loss: 1.2094208002090454\n",
      "\tGenerator loss: 0.827775239944458, Discriminator loss: 1.2151076793670654\n",
      "\tGenerator loss: 0.8264878988265991, Discriminator loss: 1.1689488887786865\n",
      "\tGenerator loss: 0.8465774059295654, Discriminator loss: 1.1703665256500244\n",
      "\tGenerator loss: 0.8605161309242249, Discriminator loss: 1.1737293004989624\n",
      "\tGenerator loss: 0.8673003911972046, Discriminator loss: 1.1824355125427246\n",
      "\tGenerator loss: 0.8801771402359009, Discriminator loss: 1.1978585720062256\n",
      "\tGenerator loss: 0.8926596641540527, Discriminator loss: 1.214971899986267\n",
      "\tGenerator loss: 0.8810334205627441, Discriminator loss: 1.2093465328216553\n",
      "\tGenerator loss: 0.8707799911499023, Discriminator loss: 1.2332661151885986\n",
      "\tGenerator loss: 0.8483210206031799, Discriminator loss: 1.2140514850616455\n",
      "\tGenerator loss: 0.8217153549194336, Discriminator loss: 1.1980364322662354\n",
      "\tGenerator loss: 0.8120684623718262, Discriminator loss: 1.2709993124008179\n",
      "\tGenerator loss: 0.8085013628005981, Discriminator loss: 1.2897186279296875\n",
      "\tGenerator loss: 0.8113158345222473, Discriminator loss: 1.3664577007293701\n",
      "\tGenerator loss: 0.8160795569419861, Discriminator loss: 1.3622509241104126\n",
      "\tGenerator loss: 0.8371095657348633, Discriminator loss: 1.3737528324127197\n",
      "\tGenerator loss: 0.8302067518234253, Discriminator loss: 1.29666006565094\n",
      "\tGenerator loss: 0.8326778411865234, Discriminator loss: 1.3087565898895264\n",
      "\tGenerator loss: 0.8291686177253723, Discriminator loss: 1.2757840156555176\n",
      "\tGenerator loss: 0.834417462348938, Discriminator loss: 1.2665975093841553\n",
      "\tGenerator loss: 0.8240113854408264, Discriminator loss: 1.2860395908355713\n",
      "\tGenerator loss: 0.8228738307952881, Discriminator loss: 1.2672688961029053\n",
      "\tGenerator loss: 0.845200777053833, Discriminator loss: 1.2369518280029297\n",
      "\tGenerator loss: 0.8552881479263306, Discriminator loss: 1.3055585622787476\n",
      "\tGenerator loss: 0.8535059690475464, Discriminator loss: 1.3234515190124512\n",
      "\tGenerator loss: 0.8639108538627625, Discriminator loss: 1.269899845123291\n",
      "\tGenerator loss: 0.856101393699646, Discriminator loss: 1.2811448574066162\n",
      "\tGenerator loss: 0.8522824645042419, Discriminator loss: 1.2664463520050049\n",
      "\tGenerator loss: 0.8546656966209412, Discriminator loss: 1.2921411991119385\n",
      "\tGenerator loss: 0.8452171087265015, Discriminator loss: 1.2253928184509277\n",
      "\tGenerator loss: 0.8430370092391968, Discriminator loss: 1.2018771171569824\n",
      "\tGenerator loss: 0.8612561821937561, Discriminator loss: 1.212988257408142\n",
      "\tGenerator loss: 0.8739320039749146, Discriminator loss: 1.2010048627853394\n",
      "\tGenerator loss: 0.9057061672210693, Discriminator loss: 1.2072749137878418\n",
      "\tGenerator loss: 0.9165037870407104, Discriminator loss: 1.248455286026001\n",
      "\tGenerator loss: 0.9212789535522461, Discriminator loss: 1.2146598100662231\n",
      "\tGenerator loss: 0.903464674949646, Discriminator loss: 1.223288655281067\n",
      "\tGenerator loss: 0.8840757608413696, Discriminator loss: 1.221372365951538\n",
      "\tGenerator loss: 0.8648620843887329, Discriminator loss: 1.2064749002456665\n",
      "\tGenerator loss: 0.8762804269790649, Discriminator loss: 1.1722614765167236\n",
      "\tGenerator loss: 0.8916279077529907, Discriminator loss: 1.1600747108459473\n",
      "\tGenerator loss: 0.8971450924873352, Discriminator loss: 1.163037896156311\n",
      "\tGenerator loss: 0.9013994932174683, Discriminator loss: 1.1648955345153809\n",
      "\tGenerator loss: 0.9353551864624023, Discriminator loss: 1.14913809299469\n",
      "\tGenerator loss: 0.9475345611572266, Discriminator loss: 1.1050639152526855\n",
      "\tGenerator loss: 0.972983717918396, Discriminator loss: 1.1255803108215332\n",
      "\tGenerator loss: 0.982086181640625, Discriminator loss: 1.1281492710113525\n",
      "\tGenerator loss: 0.9749528169631958, Discriminator loss: 1.1283994913101196\n",
      "\tGenerator loss: 0.9564415216445923, Discriminator loss: 1.116167426109314\n",
      "\tGenerator loss: 0.9377676248550415, Discriminator loss: 1.16011643409729\n",
      "\tGenerator loss: 0.9243340492248535, Discriminator loss: 1.1571106910705566\n",
      "\tGenerator loss: 0.9064828753471375, Discriminator loss: 1.166405200958252\n",
      "\tGenerator loss: 0.8928090333938599, Discriminator loss: 1.165205478668213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9129897952079773, Discriminator loss: 1.1489176750183105\n",
      "\tGenerator loss: 0.9217965602874756, Discriminator loss: 1.159055233001709\n",
      "\tGenerator loss: 0.9282954931259155, Discriminator loss: 1.1911392211914062\n",
      "\tGenerator loss: 0.9220679998397827, Discriminator loss: 1.1849063634872437\n",
      "\tGenerator loss: 0.9203366637229919, Discriminator loss: 1.1844091415405273\n",
      "\tGenerator loss: 0.9490193724632263, Discriminator loss: 1.1907048225402832\n",
      "\tGenerator loss: 0.9394166469573975, Discriminator loss: 1.1995753049850464\n",
      "\tGenerator loss: 0.94858717918396, Discriminator loss: 1.2002499103546143\n",
      "\tGenerator loss: 0.9310312867164612, Discriminator loss: 1.2584880590438843\n",
      "\tGenerator loss: 0.8983174562454224, Discriminator loss: 1.2742857933044434\n",
      "\tGenerator loss: 0.8639998435974121, Discriminator loss: 1.2909126281738281\n",
      "\tGenerator loss: 0.8268740177154541, Discriminator loss: 1.270039439201355\n",
      "\tGenerator loss: 0.8163841366767883, Discriminator loss: 1.2650647163391113\n",
      "\tGenerator loss: 0.8091593980789185, Discriminator loss: 1.2954498529434204\n",
      "\tGenerator loss: 0.8139939308166504, Discriminator loss: 1.3120133876800537\n",
      "\tGenerator loss: 0.8539746403694153, Discriminator loss: 1.2960907220840454\n",
      "\tGenerator loss: 0.8623174428939819, Discriminator loss: 1.3247768878936768\n",
      "\tGenerator loss: 0.8800210952758789, Discriminator loss: 1.3097257614135742\n",
      "\tGenerator loss: 0.8634649515151978, Discriminator loss: 1.3234840631484985\n",
      "\tGenerator loss: 0.8451576232910156, Discriminator loss: 1.390805721282959\n",
      "\tGenerator loss: 0.8147037029266357, Discriminator loss: 1.457209587097168\n",
      "\tGenerator loss: 0.7818146347999573, Discriminator loss: 1.4372068643569946\n",
      "\tGenerator loss: 0.7395696640014648, Discriminator loss: 1.4322876930236816\n",
      "\tGenerator loss: 0.716280460357666, Discriminator loss: 1.4581663608551025\n",
      "\tGenerator loss: 0.6958799362182617, Discriminator loss: 1.487333059310913\n",
      "\tGenerator loss: 0.7118988037109375, Discriminator loss: 1.4807288646697998\n",
      "\tGenerator loss: 0.7339411973953247, Discriminator loss: 1.509408712387085\n",
      "\tGenerator loss: 0.7503221035003662, Discriminator loss: 1.5147465467453003\n",
      "\tGenerator loss: 0.7399340867996216, Discriminator loss: 1.5668449401855469\n",
      "\tGenerator loss: 0.7190746068954468, Discriminator loss: 1.5005146265029907\n",
      "\tGenerator loss: 0.7173211574554443, Discriminator loss: 1.501068353652954\n",
      "\tGenerator loss: 0.7184650897979736, Discriminator loss: 1.5559645891189575\n",
      "\tGenerator loss: 0.7246175408363342, Discriminator loss: 1.5202035903930664\n",
      "\tGenerator loss: 0.7092211842536926, Discriminator loss: 1.5484720468521118\n",
      "\tGenerator loss: 0.7037066221237183, Discriminator loss: 1.5145790576934814\n",
      "\tGenerator loss: 0.6940929889678955, Discriminator loss: 1.5024681091308594\n",
      "\tGenerator loss: 0.7089650630950928, Discriminator loss: 1.5597068071365356\n",
      "\tGenerator loss: 0.7085636258125305, Discriminator loss: 1.5777194499969482\n",
      "\tGenerator loss: 0.6918399930000305, Discriminator loss: 1.5558345317840576\n",
      "\tGenerator loss: 0.689308762550354, Discriminator loss: 1.5558712482452393\n",
      "\tGenerator loss: 0.6846146583557129, Discriminator loss: 1.5699135065078735\n",
      "\tGenerator loss: 0.6744871735572815, Discriminator loss: 1.5673003196716309\n",
      "\tGenerator loss: 0.6639513969421387, Discriminator loss: 1.5516009330749512\n",
      "\tGenerator loss: 0.6685917973518372, Discriminator loss: 1.5091361999511719\n",
      "\tGenerator loss: 0.6753664016723633, Discriminator loss: 1.5166064500808716\n",
      "\tGenerator loss: 0.7118782997131348, Discriminator loss: 1.4689316749572754\n",
      "\tGenerator loss: 0.7345064878463745, Discriminator loss: 1.497673511505127\n",
      "\tGenerator loss: 0.7317132949829102, Discriminator loss: 1.441540241241455\n",
      "\tGenerator loss: 0.7436057329177856, Discriminator loss: 1.431777000427246\n",
      "\tGenerator loss: 0.7826142311096191, Discriminator loss: 1.397956371307373\n",
      "\tGenerator loss: 0.789339005947113, Discriminator loss: 1.4231981039047241\n",
      "\tGenerator loss: 0.8011369705200195, Discriminator loss: 1.5017061233520508\n",
      "Time for epoch 9 is 475.55791997909546 sec\n",
      "\tGenerator loss: 0.7601158618927002, Discriminator loss: 1.4339122772216797\n",
      "\tGenerator loss: 0.7271133065223694, Discriminator loss: 1.4131684303283691\n",
      "\tGenerator loss: 0.6822514533996582, Discriminator loss: 1.4553922414779663\n",
      "\tGenerator loss: 0.6716354489326477, Discriminator loss: 1.4417898654937744\n",
      "\tGenerator loss: 0.7045093774795532, Discriminator loss: 1.4243240356445312\n",
      "\tGenerator loss: 0.7334994077682495, Discriminator loss: 1.4318387508392334\n",
      "\tGenerator loss: 0.7791887521743774, Discriminator loss: 1.3679240942001343\n",
      "\tGenerator loss: 0.8076615929603577, Discriminator loss: 1.3340044021606445\n",
      "\tGenerator loss: 0.8446602821350098, Discriminator loss: 1.2926595211029053\n",
      "\tGenerator loss: 0.8629956245422363, Discriminator loss: 1.3257535696029663\n",
      "\tGenerator loss: 0.8618854880332947, Discriminator loss: 1.298283338546753\n",
      "\tGenerator loss: 0.8425478935241699, Discriminator loss: 1.2971975803375244\n",
      "\tGenerator loss: 0.8188192844390869, Discriminator loss: 1.2881931066513062\n",
      "\tGenerator loss: 0.809529721736908, Discriminator loss: 1.2494497299194336\n",
      "\tGenerator loss: 0.806383490562439, Discriminator loss: 1.2319860458374023\n",
      "\tGenerator loss: 0.8249585032463074, Discriminator loss: 1.1943072080612183\n",
      "\tGenerator loss: 0.8664635419845581, Discriminator loss: 1.1915533542633057\n",
      "\tGenerator loss: 0.8940272331237793, Discriminator loss: 1.1944775581359863\n",
      "\tGenerator loss: 0.925091564655304, Discriminator loss: 1.2125663757324219\n",
      "\tGenerator loss: 0.9181408882141113, Discriminator loss: 1.2112736701965332\n",
      "\tGenerator loss: 0.9113819003105164, Discriminator loss: 1.207084059715271\n",
      "\tGenerator loss: 0.8938591480255127, Discriminator loss: 1.2184007167816162\n",
      "\tGenerator loss: 0.8650194406509399, Discriminator loss: 1.2169885635375977\n",
      "\tGenerator loss: 0.857276439666748, Discriminator loss: 1.2387244701385498\n",
      "\tGenerator loss: 0.8454407453536987, Discriminator loss: 1.2341413497924805\n",
      "\tGenerator loss: 0.8464882373809814, Discriminator loss: 1.1877377033233643\n",
      "\tGenerator loss: 0.8917781114578247, Discriminator loss: 1.1688451766967773\n",
      "\tGenerator loss: 0.9195706248283386, Discriminator loss: 1.1628533601760864\n",
      "\tGenerator loss: 0.9490312337875366, Discriminator loss: 1.1694875955581665\n",
      "\tGenerator loss: 0.9315701723098755, Discriminator loss: 1.1310172080993652\n",
      "\tGenerator loss: 0.9371958374977112, Discriminator loss: 1.1448187828063965\n",
      "\tGenerator loss: 0.9088566303253174, Discriminator loss: 1.1776962280273438\n",
      "\tGenerator loss: 0.8872804045677185, Discriminator loss: 1.1904025077819824\n",
      "\tGenerator loss: 0.888046383857727, Discriminator loss: 1.2376956939697266\n",
      "\tGenerator loss: 0.8795193433761597, Discriminator loss: 1.199934482574463\n",
      "\tGenerator loss: 0.8712215423583984, Discriminator loss: 1.1614004373550415\n",
      "\tGenerator loss: 0.900559663772583, Discriminator loss: 1.153686761856079\n",
      "\tGenerator loss: 0.9408175945281982, Discriminator loss: 1.150838851928711\n",
      "\tGenerator loss: 0.9727413654327393, Discriminator loss: 1.131432294845581\n",
      "\tGenerator loss: 0.9680092334747314, Discriminator loss: 1.1636967658996582\n",
      "\tGenerator loss: 0.9669169187545776, Discriminator loss: 1.1832787990570068\n",
      "\tGenerator loss: 0.9520072340965271, Discriminator loss: 1.1427992582321167\n",
      "\tGenerator loss: 0.9144688844680786, Discriminator loss: 1.1542773246765137\n",
      "\tGenerator loss: 0.9082390666007996, Discriminator loss: 1.1454358100891113\n",
      "\tGenerator loss: 0.9239574670791626, Discriminator loss: 1.1173975467681885\n",
      "\tGenerator loss: 0.9438669681549072, Discriminator loss: 1.1320674419403076\n",
      "\tGenerator loss: 0.9824752807617188, Discriminator loss: 1.1354577541351318\n",
      "\tGenerator loss: 0.9858845472335815, Discriminator loss: 1.1552684307098389\n",
      "\tGenerator loss: 0.9638558626174927, Discriminator loss: 1.1529619693756104\n",
      "\tGenerator loss: 0.9472051858901978, Discriminator loss: 1.1146440505981445\n",
      "\tGenerator loss: 0.9425957798957825, Discriminator loss: 1.1334059238433838\n",
      "\tGenerator loss: 0.9501867294311523, Discriminator loss: 1.1504764556884766\n",
      "\tGenerator loss: 0.9546212553977966, Discriminator loss: 1.1199963092803955\n",
      "\tGenerator loss: 0.9745863676071167, Discriminator loss: 1.1135927438735962\n",
      "\tGenerator loss: 0.9907285571098328, Discriminator loss: 1.1160218715667725\n",
      "\tGenerator loss: 0.9652128219604492, Discriminator loss: 1.1864475011825562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9549434185028076, Discriminator loss: 1.171032428741455\n",
      "\tGenerator loss: 0.9364749193191528, Discriminator loss: 1.1729638576507568\n",
      "\tGenerator loss: 0.8978453278541565, Discriminator loss: 1.178868055343628\n",
      "\tGenerator loss: 0.890349268913269, Discriminator loss: 1.1544018983840942\n",
      "\tGenerator loss: 0.8980491757392883, Discriminator loss: 1.1423611640930176\n",
      "\tGenerator loss: 0.9548701047897339, Discriminator loss: 1.1236220598220825\n",
      "\tGenerator loss: 0.9724345803260803, Discriminator loss: 1.1604893207550049\n",
      "\tGenerator loss: 0.9901049137115479, Discriminator loss: 1.1507647037506104\n",
      "\tGenerator loss: 0.9639198780059814, Discriminator loss: 1.1480915546417236\n",
      "\tGenerator loss: 0.9326220750808716, Discriminator loss: 1.1715809106826782\n",
      "\tGenerator loss: 0.9072001576423645, Discriminator loss: 1.190438985824585\n",
      "\tGenerator loss: 0.8713319301605225, Discriminator loss: 1.1660243272781372\n",
      "\tGenerator loss: 0.8751628398895264, Discriminator loss: 1.186306118965149\n",
      "\tGenerator loss: 0.8919275999069214, Discriminator loss: 1.258937954902649\n",
      "\tGenerator loss: 0.9196197390556335, Discriminator loss: 1.244335412979126\n",
      "\tGenerator loss: 0.8888232707977295, Discriminator loss: 1.2471327781677246\n",
      "\tGenerator loss: 0.8695583343505859, Discriminator loss: 1.2392381429672241\n",
      "\tGenerator loss: 0.8507423400878906, Discriminator loss: 1.2384085655212402\n",
      "\tGenerator loss: 0.8551958799362183, Discriminator loss: 1.233622431755066\n",
      "\tGenerator loss: 0.8740066289901733, Discriminator loss: 1.2237602472305298\n",
      "\tGenerator loss: 0.8936059474945068, Discriminator loss: 1.2364146709442139\n",
      "\tGenerator loss: 0.9058545827865601, Discriminator loss: 1.2449958324432373\n",
      "\tGenerator loss: 0.9154280424118042, Discriminator loss: 1.267662525177002\n",
      "\tGenerator loss: 0.9317467212677002, Discriminator loss: 1.242701530456543\n",
      "\tGenerator loss: 0.913672685623169, Discriminator loss: 1.2353639602661133\n",
      "\tGenerator loss: 0.8651478290557861, Discriminator loss: 1.2628397941589355\n",
      "\tGenerator loss: 0.825786828994751, Discriminator loss: 1.2657262086868286\n",
      "\tGenerator loss: 0.8074859380722046, Discriminator loss: 1.2764368057250977\n",
      "\tGenerator loss: 0.8291743993759155, Discriminator loss: 1.27652907371521\n",
      "\tGenerator loss: 0.8460284471511841, Discriminator loss: 1.2844834327697754\n",
      "\tGenerator loss: 0.8612012267112732, Discriminator loss: 1.27402925491333\n",
      "\tGenerator loss: 0.8948513269424438, Discriminator loss: 1.2823370695114136\n",
      "\tGenerator loss: 0.8803117871284485, Discriminator loss: 1.2863579988479614\n",
      "\tGenerator loss: 0.849799394607544, Discriminator loss: 1.323763132095337\n",
      "\tGenerator loss: 0.818349301815033, Discriminator loss: 1.3095203638076782\n",
      "\tGenerator loss: 0.8060604333877563, Discriminator loss: 1.2729748487472534\n",
      "\tGenerator loss: 0.8266890048980713, Discriminator loss: 1.254028081893921\n",
      "\tGenerator loss: 0.8513388633728027, Discriminator loss: 1.2340737581253052\n",
      "\tGenerator loss: 0.8901957273483276, Discriminator loss: 1.2341728210449219\n",
      "\tGenerator loss: 0.877820611000061, Discriminator loss: 1.2441318035125732\n",
      "\tGenerator loss: 0.861044704914093, Discriminator loss: 1.237821340560913\n",
      "\tGenerator loss: 0.8312634229660034, Discriminator loss: 1.293510913848877\n",
      "\tGenerator loss: 0.7946348786354065, Discriminator loss: 1.27419114112854\n",
      "\tGenerator loss: 0.7941387891769409, Discriminator loss: 1.2640804052352905\n",
      "\tGenerator loss: 0.8135021328926086, Discriminator loss: 1.279884696006775\n",
      "\tGenerator loss: 0.8266751170158386, Discriminator loss: 1.300645112991333\n",
      "\tGenerator loss: 0.8356592655181885, Discriminator loss: 1.2776941061019897\n",
      "\tGenerator loss: 0.8478842973709106, Discriminator loss: 1.2569431066513062\n",
      "\tGenerator loss: 0.8140971064567566, Discriminator loss: 1.263143539428711\n",
      "\tGenerator loss: 0.7978515625, Discriminator loss: 1.2512600421905518\n",
      "\tGenerator loss: 0.8075059652328491, Discriminator loss: 1.2636604309082031\n",
      "\tGenerator loss: 0.8119544982910156, Discriminator loss: 1.2574328184127808\n",
      "\tGenerator loss: 0.8272610902786255, Discriminator loss: 1.268707275390625\n",
      "\tGenerator loss: 0.8327112197875977, Discriminator loss: 1.2920100688934326\n",
      "\tGenerator loss: 0.8275154829025269, Discriminator loss: 1.3032100200653076\n",
      "\tGenerator loss: 0.8079692125320435, Discriminator loss: 1.3042323589324951\n",
      "\tGenerator loss: 0.7984915971755981, Discriminator loss: 1.2894868850708008\n",
      "\tGenerator loss: 0.783983588218689, Discriminator loss: 1.2904038429260254\n",
      "\tGenerator loss: 0.8029496669769287, Discriminator loss: 1.322648048400879\n",
      "\tGenerator loss: 0.7942606210708618, Discriminator loss: 1.328106164932251\n",
      "\tGenerator loss: 0.7862324714660645, Discriminator loss: 1.335357427597046\n",
      "\tGenerator loss: 0.7743262052536011, Discriminator loss: 1.3667802810668945\n",
      "\tGenerator loss: 0.741497278213501, Discriminator loss: 1.3628331422805786\n",
      "\tGenerator loss: 0.7323896288871765, Discriminator loss: 1.353338599205017\n",
      "\tGenerator loss: 0.7587864398956299, Discriminator loss: 1.3286950588226318\n",
      "\tGenerator loss: 0.7429453134536743, Discriminator loss: 1.3556233644485474\n",
      "\tGenerator loss: 0.7557186484336853, Discriminator loss: 1.3574533462524414\n",
      "\tGenerator loss: 0.7800508141517639, Discriminator loss: 1.329715371131897\n",
      "\tGenerator loss: 0.7728794813156128, Discriminator loss: 1.3616669178009033\n",
      "\tGenerator loss: 0.771917462348938, Discriminator loss: 1.3702963590621948\n",
      "\tGenerator loss: 0.7712271809577942, Discriminator loss: 1.4218244552612305\n",
      "\tGenerator loss: 0.7582370042800903, Discriminator loss: 1.3983615636825562\n",
      "\tGenerator loss: 0.7567912340164185, Discriminator loss: 1.3789372444152832\n",
      "\tGenerator loss: 0.7606099843978882, Discriminator loss: 1.354041337966919\n",
      "\tGenerator loss: 0.7649211287498474, Discriminator loss: 1.3471909761428833\n",
      "\tGenerator loss: 0.7669520378112793, Discriminator loss: 1.3400368690490723\n",
      "\tGenerator loss: 0.7693046927452087, Discriminator loss: 1.3516240119934082\n",
      "\tGenerator loss: 0.7938894033432007, Discriminator loss: 1.3435909748077393\n",
      "\tGenerator loss: 0.8087265491485596, Discriminator loss: 1.3138031959533691\n",
      "\tGenerator loss: 0.8215500116348267, Discriminator loss: 1.3344844579696655\n",
      "\tGenerator loss: 0.8222248554229736, Discriminator loss: 1.3208463191986084\n",
      "\tGenerator loss: 0.8043039441108704, Discriminator loss: 1.3027981519699097\n",
      "\tGenerator loss: 0.7943985462188721, Discriminator loss: 1.3073148727416992\n",
      "\tGenerator loss: 0.8025837540626526, Discriminator loss: 1.3024606704711914\n",
      "\tGenerator loss: 0.8057646751403809, Discriminator loss: 1.2936809062957764\n",
      "\tGenerator loss: 0.8201035261154175, Discriminator loss: 1.3481426239013672\n",
      "\tGenerator loss: 0.8270509839057922, Discriminator loss: 1.3278316259384155\n",
      "\tGenerator loss: 0.8365358114242554, Discriminator loss: 1.353659749031067\n",
      "\tGenerator loss: 0.8194041848182678, Discriminator loss: 1.328441858291626\n",
      "\tGenerator loss: 0.824244499206543, Discriminator loss: 1.360111951828003\n",
      "\tGenerator loss: 0.8219653964042664, Discriminator loss: 1.321837067604065\n",
      "\tGenerator loss: 0.8127694725990295, Discriminator loss: 1.3282084465026855\n",
      "\tGenerator loss: 0.8260864615440369, Discriminator loss: 1.283287763595581\n",
      "\tGenerator loss: 0.8392986059188843, Discriminator loss: 1.2549943923950195\n",
      "\tGenerator loss: 0.8552624583244324, Discriminator loss: 1.2553637027740479\n",
      "\tGenerator loss: 0.8746224045753479, Discriminator loss: 1.2264511585235596\n",
      "\tGenerator loss: 0.8807088136672974, Discriminator loss: 1.2176897525787354\n",
      "\tGenerator loss: 0.8933905363082886, Discriminator loss: 1.2382644414901733\n",
      "\tGenerator loss: 0.9001944661140442, Discriminator loss: 1.242119312286377\n",
      "\tGenerator loss: 0.8989952802658081, Discriminator loss: 1.2056777477264404\n",
      "\tGenerator loss: 0.8727993965148926, Discriminator loss: 1.2114105224609375\n",
      "\tGenerator loss: 0.8550187349319458, Discriminator loss: 1.1751688718795776\n",
      "\tGenerator loss: 0.8779609203338623, Discriminator loss: 1.2062017917633057\n",
      "\tGenerator loss: 0.8900676369667053, Discriminator loss: 1.205342173576355\n",
      "\tGenerator loss: 0.8895124793052673, Discriminator loss: 1.1801693439483643\n",
      "\tGenerator loss: 0.8872076272964478, Discriminator loss: 1.1882244348526\n",
      "\tGenerator loss: 0.8943163156509399, Discriminator loss: 1.180081844329834\n",
      "\tGenerator loss: 0.9011389017105103, Discriminator loss: 1.1820462942123413\n",
      "\tGenerator loss: 0.8837699890136719, Discriminator loss: 1.2062270641326904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8964946269989014, Discriminator loss: 1.2107021808624268\n",
      "\tGenerator loss: 0.8916354775428772, Discriminator loss: 1.230694055557251\n",
      "\tGenerator loss: 0.8924233913421631, Discriminator loss: 1.2009259462356567\n",
      "\tGenerator loss: 0.894657552242279, Discriminator loss: 1.1689672470092773\n",
      "\tGenerator loss: 0.9052095413208008, Discriminator loss: 1.1518515348434448\n",
      "\tGenerator loss: 0.9156458377838135, Discriminator loss: 1.1503713130950928\n",
      "\tGenerator loss: 0.9281065464019775, Discriminator loss: 1.1395875215530396\n",
      "\tGenerator loss: 0.9266172647476196, Discriminator loss: 1.1371996402740479\n",
      "\tGenerator loss: 0.9366685152053833, Discriminator loss: 1.1403872966766357\n",
      "\tGenerator loss: 0.9382916688919067, Discriminator loss: 1.1333739757537842\n",
      "\tGenerator loss: 0.9345287680625916, Discriminator loss: 1.1492100954055786\n",
      "\tGenerator loss: 0.936711311340332, Discriminator loss: 1.1547114849090576\n",
      "\tGenerator loss: 0.9230527281761169, Discriminator loss: 1.1525830030441284\n",
      "\tGenerator loss: 0.926255464553833, Discriminator loss: 1.1501532793045044\n",
      "\tGenerator loss: 0.9263768196105957, Discriminator loss: 1.1642873287200928\n",
      "\tGenerator loss: 0.9111387729644775, Discriminator loss: 1.156486988067627\n",
      "\tGenerator loss: 0.9122961759567261, Discriminator loss: 1.1727510690689087\n",
      "\tGenerator loss: 0.9124084711074829, Discriminator loss: 1.1668031215667725\n",
      "\tGenerator loss: 0.8922891616821289, Discriminator loss: 1.1932058334350586\n",
      "\tGenerator loss: 0.9036761522293091, Discriminator loss: 1.1759028434753418\n",
      "\tGenerator loss: 0.9108524918556213, Discriminator loss: 1.1871285438537598\n",
      "\tGenerator loss: 0.9019687175750732, Discriminator loss: 1.196541428565979\n",
      "\tGenerator loss: 0.9036315679550171, Discriminator loss: 1.197589635848999\n",
      "\tGenerator loss: 0.9263383150100708, Discriminator loss: 1.208059549331665\n",
      "\tGenerator loss: 0.9324637651443481, Discriminator loss: 1.1910271644592285\n",
      "\tGenerator loss: 0.9358004331588745, Discriminator loss: 1.1693347692489624\n",
      "\tGenerator loss: 0.9248737692832947, Discriminator loss: 1.2066079378128052\n",
      "\tGenerator loss: 0.902262806892395, Discriminator loss: 1.1990840435028076\n",
      "\tGenerator loss: 0.8828462958335876, Discriminator loss: 1.1964540481567383\n",
      "\tGenerator loss: 0.8759404420852661, Discriminator loss: 1.1861441135406494\n",
      "\tGenerator loss: 0.8757579326629639, Discriminator loss: 1.2036664485931396\n",
      "\tGenerator loss: 0.8752847909927368, Discriminator loss: 1.2107118368148804\n",
      "\tGenerator loss: 0.8742538690567017, Discriminator loss: 1.2207567691802979\n",
      "\tGenerator loss: 0.8735514879226685, Discriminator loss: 1.190157413482666\n",
      "\tGenerator loss: 0.8972640037536621, Discriminator loss: 1.1887123584747314\n",
      "\tGenerator loss: 0.9004013538360596, Discriminator loss: 1.223651647567749\n",
      "\tGenerator loss: 0.9088789820671082, Discriminator loss: 1.2033557891845703\n",
      "\tGenerator loss: 0.9258451461791992, Discriminator loss: 1.2012859582901\n",
      "\tGenerator loss: 0.921197772026062, Discriminator loss: 1.2226684093475342\n",
      "\tGenerator loss: 0.8980132341384888, Discriminator loss: 1.1994221210479736\n",
      "\tGenerator loss: 0.8674349784851074, Discriminator loss: 1.184784173965454\n",
      "\tGenerator loss: 0.8482885360717773, Discriminator loss: 1.193442702293396\n",
      "\tGenerator loss: 0.839212954044342, Discriminator loss: 1.184818983078003\n",
      "\tGenerator loss: 0.8611717224121094, Discriminator loss: 1.185953974723816\n",
      "\tGenerator loss: 0.8908424973487854, Discriminator loss: 1.2094948291778564\n",
      "\tGenerator loss: 0.9199408292770386, Discriminator loss: 1.1935529708862305\n",
      "\tGenerator loss: 0.9131782054901123, Discriminator loss: 1.2280586957931519\n",
      "\tGenerator loss: 0.8933805823326111, Discriminator loss: 1.213735580444336\n",
      "\tGenerator loss: 0.8567098379135132, Discriminator loss: 1.2264580726623535\n",
      "\tGenerator loss: 0.842006266117096, Discriminator loss: 1.2380988597869873\n",
      "\tGenerator loss: 0.8411285877227783, Discriminator loss: 1.222956657409668\n",
      "\tGenerator loss: 0.8534190058708191, Discriminator loss: 1.221179723739624\n",
      "\tGenerator loss: 0.8526161909103394, Discriminator loss: 1.2302863597869873\n",
      "\tGenerator loss: 0.8511470556259155, Discriminator loss: 1.2258031368255615\n",
      "\tGenerator loss: 0.8721937537193298, Discriminator loss: 1.2553603649139404\n",
      "\tGenerator loss: 0.8911176919937134, Discriminator loss: 1.2593506574630737\n",
      "\tGenerator loss: 0.874891996383667, Discriminator loss: 1.2507107257843018\n",
      "\tGenerator loss: 0.8722857236862183, Discriminator loss: 1.2386186122894287\n",
      "\tGenerator loss: 0.8551682233810425, Discriminator loss: 1.2447679042816162\n",
      "\tGenerator loss: 0.8149160742759705, Discriminator loss: 1.2457363605499268\n",
      "\tGenerator loss: 0.7938365936279297, Discriminator loss: 1.2634466886520386\n",
      "\tGenerator loss: 0.8061657547950745, Discriminator loss: 1.2691657543182373\n",
      "\tGenerator loss: 0.8153219223022461, Discriminator loss: 1.2408658266067505\n",
      "\tGenerator loss: 0.8180302977561951, Discriminator loss: 1.2596848011016846\n",
      "\tGenerator loss: 0.8507643938064575, Discriminator loss: 1.2569478750228882\n",
      "\tGenerator loss: 0.8523815870285034, Discriminator loss: 1.242781162261963\n",
      "\tGenerator loss: 0.8486813306808472, Discriminator loss: 1.24398934841156\n",
      "\tGenerator loss: 0.8457635641098022, Discriminator loss: 1.2723196744918823\n",
      "\tGenerator loss: 0.8616580367088318, Discriminator loss: 1.2508705854415894\n",
      "\tGenerator loss: 0.8415899872779846, Discriminator loss: 1.2742516994476318\n",
      "Time for epoch 10 is 473.61444330215454 sec\n",
      "\tGenerator loss: 0.8283348083496094, Discriminator loss: 1.2628931999206543\n",
      "\tGenerator loss: 0.8277059197425842, Discriminator loss: 1.2644507884979248\n",
      "\tGenerator loss: 0.8212487697601318, Discriminator loss: 1.257863998413086\n",
      "\tGenerator loss: 0.8157277703285217, Discriminator loss: 1.2506887912750244\n",
      "\tGenerator loss: 0.8089895248413086, Discriminator loss: 1.314507007598877\n",
      "\tGenerator loss: 0.8000572323799133, Discriminator loss: 1.3429770469665527\n",
      "\tGenerator loss: 0.7965600490570068, Discriminator loss: 1.313173770904541\n",
      "\tGenerator loss: 0.8035454750061035, Discriminator loss: 1.3218849897384644\n",
      "\tGenerator loss: 0.8091140985488892, Discriminator loss: 1.3110206127166748\n",
      "\tGenerator loss: 0.8136497735977173, Discriminator loss: 1.3131422996520996\n",
      "\tGenerator loss: 0.8212071061134338, Discriminator loss: 1.3099684715270996\n",
      "\tGenerator loss: 0.832074761390686, Discriminator loss: 1.3199090957641602\n",
      "\tGenerator loss: 0.8143151998519897, Discriminator loss: 1.3158302307128906\n",
      "\tGenerator loss: 0.8012388348579407, Discriminator loss: 1.295995831489563\n",
      "\tGenerator loss: 0.7801893949508667, Discriminator loss: 1.3290131092071533\n",
      "\tGenerator loss: 0.78859543800354, Discriminator loss: 1.2952861785888672\n",
      "\tGenerator loss: 0.8061462640762329, Discriminator loss: 1.2940647602081299\n",
      "\tGenerator loss: 0.8353618383407593, Discriminator loss: 1.2845516204833984\n",
      "\tGenerator loss: 0.8480203747749329, Discriminator loss: 1.3246722221374512\n",
      "\tGenerator loss: 0.8584526777267456, Discriminator loss: 1.3133792877197266\n",
      "\tGenerator loss: 0.8559908866882324, Discriminator loss: 1.3228464126586914\n",
      "\tGenerator loss: 0.805998682975769, Discriminator loss: 1.3626115322113037\n",
      "\tGenerator loss: 0.7813524603843689, Discriminator loss: 1.369876503944397\n",
      "\tGenerator loss: 0.7578831911087036, Discriminator loss: 1.4471709728240967\n",
      "\tGenerator loss: 0.7554080486297607, Discriminator loss: 1.445439338684082\n",
      "\tGenerator loss: 0.7660431861877441, Discriminator loss: 1.3823442459106445\n",
      "\tGenerator loss: 0.7881395816802979, Discriminator loss: 1.3562148809432983\n",
      "\tGenerator loss: 0.8149317502975464, Discriminator loss: 1.3437559604644775\n",
      "\tGenerator loss: 0.8311449289321899, Discriminator loss: 1.340919017791748\n",
      "\tGenerator loss: 0.8186026811599731, Discriminator loss: 1.3363078832626343\n",
      "\tGenerator loss: 0.800557553768158, Discriminator loss: 1.3650577068328857\n",
      "\tGenerator loss: 0.7816051244735718, Discriminator loss: 1.4081933498382568\n",
      "\tGenerator loss: 0.7805169224739075, Discriminator loss: 1.3876004219055176\n",
      "\tGenerator loss: 0.7722964286804199, Discriminator loss: 1.5009633302688599\n",
      "\tGenerator loss: 0.7562629580497742, Discriminator loss: 1.4294159412384033\n",
      "\tGenerator loss: 0.7786322832107544, Discriminator loss: 1.3416006565093994\n",
      "\tGenerator loss: 0.7874577641487122, Discriminator loss: 1.3365058898925781\n",
      "\tGenerator loss: 0.8008081912994385, Discriminator loss: 1.3313111066818237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8220793008804321, Discriminator loss: 1.320894479751587\n",
      "\tGenerator loss: 0.849591076374054, Discriminator loss: 1.3514842987060547\n",
      "\tGenerator loss: 0.8622727394104004, Discriminator loss: 1.4299280643463135\n",
      "\tGenerator loss: 0.850556492805481, Discriminator loss: 1.3818714618682861\n",
      "\tGenerator loss: 0.8384478092193604, Discriminator loss: 1.3698185682296753\n",
      "\tGenerator loss: 0.818827748298645, Discriminator loss: 1.3423871994018555\n",
      "\tGenerator loss: 0.8006455302238464, Discriminator loss: 1.3090198040008545\n",
      "\tGenerator loss: 0.7878315448760986, Discriminator loss: 1.281208872795105\n",
      "\tGenerator loss: 0.8047963976860046, Discriminator loss: 1.2705698013305664\n",
      "\tGenerator loss: 0.832579493522644, Discriminator loss: 1.287712812423706\n",
      "\tGenerator loss: 0.8719552755355835, Discriminator loss: 1.2612693309783936\n",
      "\tGenerator loss: 0.8951555490493774, Discriminator loss: 1.2362520694732666\n",
      "\tGenerator loss: 0.919838547706604, Discriminator loss: 1.2524234056472778\n",
      "\tGenerator loss: 0.9165367484092712, Discriminator loss: 1.2550485134124756\n",
      "\tGenerator loss: 0.8976247310638428, Discriminator loss: 1.2232388257980347\n",
      "\tGenerator loss: 0.8895516395568848, Discriminator loss: 1.1948051452636719\n",
      "\tGenerator loss: 0.8733758926391602, Discriminator loss: 1.182602882385254\n",
      "\tGenerator loss: 0.8894468545913696, Discriminator loss: 1.2074007987976074\n",
      "\tGenerator loss: 0.9053282737731934, Discriminator loss: 1.1895757913589478\n",
      "\tGenerator loss: 0.9125170707702637, Discriminator loss: 1.1863915920257568\n",
      "\tGenerator loss: 0.9389886260032654, Discriminator loss: 1.1504186391830444\n",
      "\tGenerator loss: 0.951198935508728, Discriminator loss: 1.1177148818969727\n",
      "\tGenerator loss: 0.9520576000213623, Discriminator loss: 1.0856767892837524\n",
      "\tGenerator loss: 0.9569461345672607, Discriminator loss: 1.071312665939331\n",
      "\tGenerator loss: 0.9499574899673462, Discriminator loss: 1.094087839126587\n",
      "\tGenerator loss: 0.9523972272872925, Discriminator loss: 1.086337685585022\n",
      "\tGenerator loss: 0.9700628519058228, Discriminator loss: 1.0625872611999512\n",
      "\tGenerator loss: 0.9785566329956055, Discriminator loss: 1.0599626302719116\n",
      "\tGenerator loss: 0.9911202788352966, Discriminator loss: 1.080572247505188\n",
      "\tGenerator loss: 1.0006483793258667, Discriminator loss: 1.0537598133087158\n",
      "\tGenerator loss: 1.0074188709259033, Discriminator loss: 1.0618534088134766\n",
      "\tGenerator loss: 1.0110969543457031, Discriminator loss: 1.0738439559936523\n",
      "\tGenerator loss: 0.996084451675415, Discriminator loss: 1.0565800666809082\n",
      "\tGenerator loss: 0.9553516507148743, Discriminator loss: 1.0769877433776855\n",
      "\tGenerator loss: 0.9313727617263794, Discriminator loss: 1.0729783773422241\n",
      "\tGenerator loss: 0.9338341355323792, Discriminator loss: 1.05977201461792\n",
      "\tGenerator loss: 0.9821305274963379, Discriminator loss: 1.0304114818572998\n",
      "\tGenerator loss: 1.0214979648590088, Discriminator loss: 1.0246453285217285\n",
      "\tGenerator loss: 1.077385663986206, Discriminator loss: 1.0230873823165894\n",
      "\tGenerator loss: 1.081079125404358, Discriminator loss: 1.0169363021850586\n",
      "\tGenerator loss: 1.1043434143066406, Discriminator loss: 1.0208102464675903\n",
      "\tGenerator loss: 1.0716971158981323, Discriminator loss: 1.0398797988891602\n",
      "\tGenerator loss: 1.0360264778137207, Discriminator loss: 1.0352879762649536\n",
      "\tGenerator loss: 0.998547375202179, Discriminator loss: 1.0537633895874023\n",
      "\tGenerator loss: 0.9738336801528931, Discriminator loss: 1.0736815929412842\n",
      "\tGenerator loss: 0.9701599478721619, Discriminator loss: 1.060592770576477\n",
      "\tGenerator loss: 0.9894318580627441, Discriminator loss: 1.0760524272918701\n",
      "\tGenerator loss: 1.0256683826446533, Discriminator loss: 1.0689783096313477\n",
      "\tGenerator loss: 1.0467060804367065, Discriminator loss: 1.0674769878387451\n",
      "\tGenerator loss: 1.0518522262573242, Discriminator loss: 1.1022522449493408\n",
      "\tGenerator loss: 1.0293372869491577, Discriminator loss: 1.085947871208191\n",
      "\tGenerator loss: 1.012939453125, Discriminator loss: 1.1045116186141968\n",
      "\tGenerator loss: 1.0006495714187622, Discriminator loss: 1.1070058345794678\n",
      "\tGenerator loss: 0.9989060759544373, Discriminator loss: 1.0961380004882812\n",
      "\tGenerator loss: 0.9927623271942139, Discriminator loss: 1.117719054222107\n",
      "\tGenerator loss: 0.964928150177002, Discriminator loss: 1.1305806636810303\n",
      "\tGenerator loss: 0.9431686401367188, Discriminator loss: 1.1611629724502563\n",
      "\tGenerator loss: 0.9484153985977173, Discriminator loss: 1.155733585357666\n",
      "\tGenerator loss: 0.9527292847633362, Discriminator loss: 1.1584484577178955\n",
      "\tGenerator loss: 0.9669598340988159, Discriminator loss: 1.19529128074646\n",
      "\tGenerator loss: 0.9623425006866455, Discriminator loss: 1.1881256103515625\n",
      "\tGenerator loss: 0.9652554392814636, Discriminator loss: 1.1717860698699951\n",
      "\tGenerator loss: 0.9573624134063721, Discriminator loss: 1.2248538732528687\n",
      "\tGenerator loss: 0.9695432186126709, Discriminator loss: 1.2377028465270996\n",
      "\tGenerator loss: 0.9358949661254883, Discriminator loss: 1.2593929767608643\n",
      "\tGenerator loss: 0.8979752659797668, Discriminator loss: 1.306015133857727\n",
      "\tGenerator loss: 0.8798577785491943, Discriminator loss: 1.249550223350525\n",
      "\tGenerator loss: 0.8532030582427979, Discriminator loss: 1.2358200550079346\n",
      "\tGenerator loss: 0.8876539468765259, Discriminator loss: 1.2286115884780884\n",
      "\tGenerator loss: 0.9337337613105774, Discriminator loss: 1.2525080442428589\n",
      "\tGenerator loss: 0.9605023860931396, Discriminator loss: 1.2917377948760986\n",
      "\tGenerator loss: 0.9575853943824768, Discriminator loss: 1.243903398513794\n",
      "\tGenerator loss: 0.9688042402267456, Discriminator loss: 1.2060747146606445\n",
      "\tGenerator loss: 0.9482696652412415, Discriminator loss: 1.220329999923706\n",
      "\tGenerator loss: 0.9563668370246887, Discriminator loss: 1.233866810798645\n",
      "\tGenerator loss: 0.9345631003379822, Discriminator loss: 1.249993085861206\n",
      "\tGenerator loss: 0.8974087834358215, Discriminator loss: 1.2513158321380615\n",
      "\tGenerator loss: 0.8963289856910706, Discriminator loss: 1.239928126335144\n",
      "\tGenerator loss: 0.8983330726623535, Discriminator loss: 1.315870761871338\n",
      "\tGenerator loss: 0.8594347238540649, Discriminator loss: 1.3666579723358154\n",
      "\tGenerator loss: 0.8223567008972168, Discriminator loss: 1.2997304201126099\n",
      "\tGenerator loss: 0.7959787845611572, Discriminator loss: 1.3414154052734375\n",
      "\tGenerator loss: 0.7798553705215454, Discriminator loss: 1.3360791206359863\n",
      "\tGenerator loss: 0.8091812133789062, Discriminator loss: 1.3324460983276367\n",
      "\tGenerator loss: 0.8295553922653198, Discriminator loss: 1.3441091775894165\n",
      "\tGenerator loss: 0.834657609462738, Discriminator loss: 1.4067447185516357\n",
      "\tGenerator loss: 0.8213716745376587, Discriminator loss: 1.3684213161468506\n",
      "\tGenerator loss: 0.7994083762168884, Discriminator loss: 1.3575360774993896\n",
      "\tGenerator loss: 0.7958600521087646, Discriminator loss: 1.3436468839645386\n",
      "\tGenerator loss: 0.8034728765487671, Discriminator loss: 1.3747434616088867\n",
      "\tGenerator loss: 0.8005353212356567, Discriminator loss: 1.341590166091919\n",
      "\tGenerator loss: 0.7969930171966553, Discriminator loss: 1.3459506034851074\n",
      "\tGenerator loss: 0.822149395942688, Discriminator loss: 1.3767178058624268\n",
      "\tGenerator loss: 0.8021397590637207, Discriminator loss: 1.3780181407928467\n",
      "\tGenerator loss: 0.7821159362792969, Discriminator loss: 1.3878297805786133\n",
      "\tGenerator loss: 0.7717127799987793, Discriminator loss: 1.3895163536071777\n",
      "\tGenerator loss: 0.7707837820053101, Discriminator loss: 1.3818567991256714\n",
      "\tGenerator loss: 0.7749525308609009, Discriminator loss: 1.3932290077209473\n",
      "\tGenerator loss: 0.769904375076294, Discriminator loss: 1.401185393333435\n",
      "\tGenerator loss: 0.7668627500534058, Discriminator loss: 1.4400098323822021\n",
      "\tGenerator loss: 0.7497421503067017, Discriminator loss: 1.422199010848999\n",
      "\tGenerator loss: 0.7384166717529297, Discriminator loss: 1.4156230688095093\n",
      "\tGenerator loss: 0.7670248746871948, Discriminator loss: 1.4398422241210938\n",
      "\tGenerator loss: 0.7419196367263794, Discriminator loss: 1.4029698371887207\n",
      "\tGenerator loss: 0.7339435815811157, Discriminator loss: 1.393974781036377\n",
      "\tGenerator loss: 0.732563853263855, Discriminator loss: 1.3913865089416504\n",
      "\tGenerator loss: 0.7562969923019409, Discriminator loss: 1.3684213161468506\n",
      "\tGenerator loss: 0.7733524441719055, Discriminator loss: 1.3918895721435547\n",
      "\tGenerator loss: 0.79085773229599, Discriminator loss: 1.394911527633667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.7965567111968994, Discriminator loss: 1.387878179550171\n",
      "\tGenerator loss: 0.7954652905464172, Discriminator loss: 1.3601934909820557\n",
      "\tGenerator loss: 0.7829986810684204, Discriminator loss: 1.3586770296096802\n",
      "\tGenerator loss: 0.760439395904541, Discriminator loss: 1.3322036266326904\n",
      "\tGenerator loss: 0.7577024698257446, Discriminator loss: 1.3132423162460327\n",
      "\tGenerator loss: 0.7581074833869934, Discriminator loss: 1.3040568828582764\n",
      "\tGenerator loss: 0.7845916748046875, Discriminator loss: 1.31977117061615\n",
      "\tGenerator loss: 0.8137033581733704, Discriminator loss: 1.313279628753662\n",
      "\tGenerator loss: 0.8236311674118042, Discriminator loss: 1.2775931358337402\n",
      "\tGenerator loss: 0.8239811062812805, Discriminator loss: 1.2846786975860596\n",
      "\tGenerator loss: 0.8326379060745239, Discriminator loss: 1.2524832487106323\n",
      "\tGenerator loss: 0.8644267320632935, Discriminator loss: 1.2549781799316406\n",
      "\tGenerator loss: 0.8730207681655884, Discriminator loss: 1.2008649110794067\n",
      "\tGenerator loss: 0.8730382919311523, Discriminator loss: 1.1627434492111206\n",
      "\tGenerator loss: 0.8848612904548645, Discriminator loss: 1.161030650138855\n",
      "\tGenerator loss: 0.9102849960327148, Discriminator loss: 1.1515202522277832\n",
      "\tGenerator loss: 0.943366289138794, Discriminator loss: 1.133408784866333\n",
      "\tGenerator loss: 0.9582341909408569, Discriminator loss: 1.1894433498382568\n",
      "\tGenerator loss: 0.9621449708938599, Discriminator loss: 1.146156907081604\n",
      "\tGenerator loss: 0.9716860055923462, Discriminator loss: 1.1479694843292236\n",
      "\tGenerator loss: 0.968318521976471, Discriminator loss: 1.0956774950027466\n",
      "\tGenerator loss: 0.9608926773071289, Discriminator loss: 1.0641100406646729\n",
      "\tGenerator loss: 0.9767675399780273, Discriminator loss: 1.042569875717163\n",
      "\tGenerator loss: 1.0075629949569702, Discriminator loss: 1.0292532444000244\n",
      "\tGenerator loss: 1.044764518737793, Discriminator loss: 0.9793992638587952\n",
      "\tGenerator loss: 1.0532543659210205, Discriminator loss: 0.993281364440918\n",
      "\tGenerator loss: 1.0739126205444336, Discriminator loss: 0.9962126612663269\n",
      "\tGenerator loss: 1.0747359991073608, Discriminator loss: 0.9828810691833496\n",
      "\tGenerator loss: 1.0587167739868164, Discriminator loss: 1.0250232219696045\n",
      "\tGenerator loss: 1.052790880203247, Discriminator loss: 1.0153337717056274\n",
      "\tGenerator loss: 1.0117950439453125, Discriminator loss: 0.9888738393783569\n",
      "\tGenerator loss: 1.0000336170196533, Discriminator loss: 1.0406895875930786\n",
      "\tGenerator loss: 0.9976537227630615, Discriminator loss: 1.025864839553833\n",
      "\tGenerator loss: 1.0193219184875488, Discriminator loss: 1.0354899168014526\n",
      "\tGenerator loss: 1.0307402610778809, Discriminator loss: 1.0843415260314941\n",
      "\tGenerator loss: 1.0399243831634521, Discriminator loss: 1.1368473768234253\n",
      "\tGenerator loss: 1.0169799327850342, Discriminator loss: 1.1661150455474854\n",
      "\tGenerator loss: 0.9725551605224609, Discriminator loss: 1.1287295818328857\n",
      "\tGenerator loss: 0.9280240535736084, Discriminator loss: 1.2619571685791016\n",
      "\tGenerator loss: 0.8990375995635986, Discriminator loss: 1.3593356609344482\n",
      "\tGenerator loss: 0.8584758043289185, Discriminator loss: 1.4382107257843018\n",
      "\tGenerator loss: 0.8208218216896057, Discriminator loss: 1.5197105407714844\n",
      "\tGenerator loss: 0.8292192220687866, Discriminator loss: 1.4812191724777222\n",
      "\tGenerator loss: 0.8063308000564575, Discriminator loss: 1.4754793643951416\n",
      "\tGenerator loss: 0.8120084404945374, Discriminator loss: 1.3981707096099854\n",
      "\tGenerator loss: 0.8167095184326172, Discriminator loss: 1.391585350036621\n",
      "\tGenerator loss: 0.8624475002288818, Discriminator loss: 1.3912863731384277\n",
      "\tGenerator loss: 0.9007123708724976, Discriminator loss: 1.3699219226837158\n",
      "\tGenerator loss: 0.9153562188148499, Discriminator loss: 1.3439223766326904\n",
      "\tGenerator loss: 0.8693737983703613, Discriminator loss: 1.368607759475708\n",
      "\tGenerator loss: 0.8426028490066528, Discriminator loss: 1.3735440969467163\n",
      "\tGenerator loss: 0.8224402070045471, Discriminator loss: 1.463987112045288\n",
      "\tGenerator loss: 0.7828503251075745, Discriminator loss: 1.4921852350234985\n",
      "\tGenerator loss: 0.7728525996208191, Discriminator loss: 1.5467876195907593\n",
      "\tGenerator loss: 0.774733304977417, Discriminator loss: 1.4680182933807373\n",
      "\tGenerator loss: 0.7818886637687683, Discriminator loss: 1.416306972503662\n",
      "\tGenerator loss: 0.8119404315948486, Discriminator loss: 1.4121055603027344\n",
      "\tGenerator loss: 0.8546751737594604, Discriminator loss: 1.4071764945983887\n",
      "\tGenerator loss: 0.8920026421546936, Discriminator loss: 1.3629150390625\n",
      "\tGenerator loss: 0.8831179738044739, Discriminator loss: 1.3645341396331787\n",
      "\tGenerator loss: 0.8778834939002991, Discriminator loss: 1.3830676078796387\n",
      "\tGenerator loss: 0.8530159592628479, Discriminator loss: 1.3262723684310913\n",
      "\tGenerator loss: 0.8496139645576477, Discriminator loss: 1.3043622970581055\n",
      "\tGenerator loss: 0.8748271465301514, Discriminator loss: 1.2734142541885376\n",
      "\tGenerator loss: 0.9039742350578308, Discriminator loss: 1.2552671432495117\n",
      "\tGenerator loss: 0.9297493696212769, Discriminator loss: 1.2254831790924072\n",
      "\tGenerator loss: 0.9687185883522034, Discriminator loss: 1.2374992370605469\n",
      "\tGenerator loss: 0.9823195934295654, Discriminator loss: 1.2362110614776611\n",
      "\tGenerator loss: 0.9842031598091125, Discriminator loss: 1.194859266281128\n",
      "\tGenerator loss: 0.9667402505874634, Discriminator loss: 1.1604398488998413\n",
      "\tGenerator loss: 0.9569659233093262, Discriminator loss: 1.1682748794555664\n",
      "\tGenerator loss: 0.9713013768196106, Discriminator loss: 1.1202375888824463\n",
      "\tGenerator loss: 1.001590609550476, Discriminator loss: 1.1169819831848145\n",
      "\tGenerator loss: 1.0396111011505127, Discriminator loss: 1.0999088287353516\n",
      "\tGenerator loss: 1.075513243675232, Discriminator loss: 1.0640244483947754\n",
      "\tGenerator loss: 1.0948233604431152, Discriminator loss: 1.03805673122406\n",
      "\tGenerator loss: 1.1208730936050415, Discriminator loss: 1.0195395946502686\n",
      "\tGenerator loss: 1.126241683959961, Discriminator loss: 1.0019255876541138\n",
      "\tGenerator loss: 1.1118237972259521, Discriminator loss: 0.9702802896499634\n",
      "\tGenerator loss: 1.1208537817001343, Discriminator loss: 0.9536703824996948\n",
      "\tGenerator loss: 1.1193796396255493, Discriminator loss: 0.9320817589759827\n",
      "\tGenerator loss: 1.1521148681640625, Discriminator loss: 0.9215836524963379\n",
      "\tGenerator loss: 1.206801414489746, Discriminator loss: 0.895267128944397\n",
      "\tGenerator loss: 1.2368448972702026, Discriminator loss: 0.8706302642822266\n",
      "\tGenerator loss: 1.2615025043487549, Discriminator loss: 0.8383452892303467\n",
      "\tGenerator loss: 1.2974708080291748, Discriminator loss: 0.8271891474723816\n",
      "\tGenerator loss: 1.334590196609497, Discriminator loss: 0.8519327640533447\n",
      "\tGenerator loss: 1.348125696182251, Discriminator loss: 1.0145591497421265\n",
      "Time for epoch 11 is 475.24506282806396 sec\n",
      "\tGenerator loss: 1.2604247331619263, Discriminator loss: 0.9386698007583618\n",
      "\tGenerator loss: 1.1558866500854492, Discriminator loss: 0.9310699701309204\n",
      "\tGenerator loss: 1.0877342224121094, Discriminator loss: 0.9406680464744568\n",
      "\tGenerator loss: 1.0764495134353638, Discriminator loss: 0.9397132396697998\n",
      "\tGenerator loss: 1.1328203678131104, Discriminator loss: 0.9470000267028809\n",
      "\tGenerator loss: 1.2340071201324463, Discriminator loss: 0.9140501618385315\n",
      "\tGenerator loss: 1.30641770362854, Discriminator loss: 0.9229996204376221\n",
      "\tGenerator loss: 1.323030948638916, Discriminator loss: 0.916202962398529\n",
      "\tGenerator loss: 1.301052451133728, Discriminator loss: 0.8968782424926758\n",
      "\tGenerator loss: 1.2835898399353027, Discriminator loss: 0.9306307435035706\n",
      "\tGenerator loss: 1.21532142162323, Discriminator loss: 0.9421988129615784\n",
      "\tGenerator loss: 1.1508064270019531, Discriminator loss: 0.9730379581451416\n",
      "\tGenerator loss: 1.1156412363052368, Discriminator loss: 1.030250072479248\n",
      "\tGenerator loss: 1.109648585319519, Discriminator loss: 1.0585187673568726\n",
      "\tGenerator loss: 1.0691471099853516, Discriminator loss: 1.0904839038848877\n",
      "\tGenerator loss: 1.0398304462432861, Discriminator loss: 1.0903288125991821\n",
      "\tGenerator loss: 1.0521936416625977, Discriminator loss: 1.1211494207382202\n",
      "\tGenerator loss: 1.0301074981689453, Discriminator loss: 1.1451342105865479\n",
      "\tGenerator loss: 1.0493417978286743, Discriminator loss: 1.1222076416015625\n",
      "\tGenerator loss: 1.0377311706542969, Discriminator loss: 1.1572550535202026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0150750875473022, Discriminator loss: 1.1754822731018066\n",
      "\tGenerator loss: 0.9927456974983215, Discriminator loss: 1.1879538297653198\n",
      "\tGenerator loss: 0.9836533069610596, Discriminator loss: 1.2635197639465332\n",
      "\tGenerator loss: 0.9354265928268433, Discriminator loss: 1.2549735307693481\n",
      "\tGenerator loss: 0.9171154499053955, Discriminator loss: 1.2544777393341064\n",
      "\tGenerator loss: 0.9144794344902039, Discriminator loss: 1.313220500946045\n",
      "\tGenerator loss: 0.9031832218170166, Discriminator loss: 1.499903917312622\n",
      "\tGenerator loss: 0.81777024269104, Discriminator loss: 1.50007164478302\n",
      "\tGenerator loss: 0.7156343460083008, Discriminator loss: 1.68873929977417\n",
      "\tGenerator loss: 0.6275153756141663, Discriminator loss: 1.642732858657837\n",
      "\tGenerator loss: 0.5870851278305054, Discriminator loss: 1.5914493799209595\n",
      "\tGenerator loss: 0.5951526165008545, Discriminator loss: 1.5660929679870605\n",
      "\tGenerator loss: 0.6891221404075623, Discriminator loss: 1.5636274814605713\n",
      "\tGenerator loss: 0.7905310392379761, Discriminator loss: 1.4691585302352905\n",
      "\tGenerator loss: 0.8651767373085022, Discriminator loss: 1.5160739421844482\n",
      "\tGenerator loss: 0.8782608509063721, Discriminator loss: 1.5936954021453857\n",
      "\tGenerator loss: 0.800423264503479, Discriminator loss: 1.5868178606033325\n",
      "\tGenerator loss: 0.6812642812728882, Discriminator loss: 1.5975823402404785\n",
      "\tGenerator loss: 0.6129242777824402, Discriminator loss: 1.5464519262313843\n",
      "\tGenerator loss: 0.5850540399551392, Discriminator loss: 1.516308069229126\n",
      "\tGenerator loss: 0.6137271523475647, Discriminator loss: 1.485087275505066\n",
      "\tGenerator loss: 0.6913491487503052, Discriminator loss: 1.5023796558380127\n",
      "\tGenerator loss: 0.7997660636901855, Discriminator loss: 1.4507697820663452\n",
      "\tGenerator loss: 0.8697693943977356, Discriminator loss: 1.4231534004211426\n",
      "\tGenerator loss: 0.9050548076629639, Discriminator loss: 1.3961756229400635\n",
      "\tGenerator loss: 0.8594743013381958, Discriminator loss: 1.3780007362365723\n",
      "\tGenerator loss: 0.7911062836647034, Discriminator loss: 1.332023024559021\n",
      "\tGenerator loss: 0.7448686361312866, Discriminator loss: 1.299458384513855\n",
      "\tGenerator loss: 0.7125650644302368, Discriminator loss: 1.2759170532226562\n",
      "\tGenerator loss: 0.7411167025566101, Discriminator loss: 1.2394089698791504\n",
      "\tGenerator loss: 0.8052180409431458, Discriminator loss: 1.2386500835418701\n",
      "\tGenerator loss: 0.8820793628692627, Discriminator loss: 1.2080965042114258\n",
      "\tGenerator loss: 0.9551855325698853, Discriminator loss: 1.1656979322433472\n",
      "\tGenerator loss: 1.0047543048858643, Discriminator loss: 1.1476261615753174\n",
      "\tGenerator loss: 0.9980475306510925, Discriminator loss: 1.136866807937622\n",
      "\tGenerator loss: 1.0042812824249268, Discriminator loss: 1.1690748929977417\n",
      "\tGenerator loss: 0.9695402979850769, Discriminator loss: 1.1223514080047607\n",
      "\tGenerator loss: 0.9387704730033875, Discriminator loss: 1.1476433277130127\n",
      "\tGenerator loss: 0.9227551221847534, Discriminator loss: 1.0610452890396118\n",
      "\tGenerator loss: 0.9468302130699158, Discriminator loss: 1.0077587366104126\n",
      "\tGenerator loss: 0.9836312532424927, Discriminator loss: 0.9676189422607422\n",
      "\tGenerator loss: 1.045142412185669, Discriminator loss: 0.9398354887962341\n",
      "\tGenerator loss: 1.120774745941162, Discriminator loss: 0.9815288782119751\n",
      "\tGenerator loss: 1.1784484386444092, Discriminator loss: 1.0069940090179443\n",
      "\tGenerator loss: 1.1948174238204956, Discriminator loss: 0.9810315370559692\n",
      "\tGenerator loss: 1.1979094743728638, Discriminator loss: 0.9322189092636108\n",
      "\tGenerator loss: 1.119560718536377, Discriminator loss: 0.9666285514831543\n",
      "\tGenerator loss: 1.056138038635254, Discriminator loss: 0.9869263172149658\n",
      "\tGenerator loss: 1.0034021139144897, Discriminator loss: 0.9684321880340576\n",
      "\tGenerator loss: 0.9966415166854858, Discriminator loss: 0.9785568118095398\n",
      "\tGenerator loss: 1.01842200756073, Discriminator loss: 1.005135416984558\n",
      "\tGenerator loss: 1.074471354484558, Discriminator loss: 1.0591964721679688\n",
      "\tGenerator loss: 1.0965936183929443, Discriminator loss: 1.0449628829956055\n",
      "\tGenerator loss: 1.0984913110733032, Discriminator loss: 1.0556464195251465\n",
      "\tGenerator loss: 1.0912806987762451, Discriminator loss: 1.0098261833190918\n",
      "\tGenerator loss: 1.0343027114868164, Discriminator loss: 1.1881604194641113\n",
      "\tGenerator loss: 0.9781671762466431, Discriminator loss: 1.3589516878128052\n",
      "\tGenerator loss: 0.9080676436424255, Discriminator loss: 1.3895021677017212\n",
      "\tGenerator loss: 0.8329077959060669, Discriminator loss: 1.4064217805862427\n",
      "\tGenerator loss: 0.8201675415039062, Discriminator loss: 1.3185079097747803\n",
      "\tGenerator loss: 0.859190046787262, Discriminator loss: 1.3306491374969482\n",
      "\tGenerator loss: 0.934736967086792, Discriminator loss: 1.3353818655014038\n",
      "\tGenerator loss: 0.9811197519302368, Discriminator loss: 1.2684751749038696\n",
      "\tGenerator loss: 0.9786241054534912, Discriminator loss: 1.3378558158874512\n",
      "\tGenerator loss: 0.961957573890686, Discriminator loss: 1.3212463855743408\n",
      "\tGenerator loss: 0.9025677442550659, Discriminator loss: 1.5963865518569946\n",
      "\tGenerator loss: 0.8343636989593506, Discriminator loss: 1.4875825643539429\n",
      "\tGenerator loss: 0.7891550660133362, Discriminator loss: 1.4340941905975342\n",
      "\tGenerator loss: 0.7922815680503845, Discriminator loss: 1.5767301321029663\n",
      "\tGenerator loss: 0.8175995349884033, Discriminator loss: 1.5878283977508545\n",
      "\tGenerator loss: 0.8413479328155518, Discriminator loss: 1.563474416732788\n",
      "\tGenerator loss: 0.880580723285675, Discriminator loss: 1.5137168169021606\n",
      "\tGenerator loss: 0.8501708507537842, Discriminator loss: 1.4019699096679688\n",
      "\tGenerator loss: 0.8409398794174194, Discriminator loss: 1.4217820167541504\n",
      "\tGenerator loss: 0.8368146419525146, Discriminator loss: 1.4682207107543945\n",
      "\tGenerator loss: 0.8259502649307251, Discriminator loss: 1.4221467971801758\n",
      "\tGenerator loss: 0.8099657893180847, Discriminator loss: 1.5057809352874756\n",
      "\tGenerator loss: 0.8036565780639648, Discriminator loss: 1.437272310256958\n",
      "\tGenerator loss: 0.812362790107727, Discriminator loss: 1.440643548965454\n",
      "\tGenerator loss: 0.8627721667289734, Discriminator loss: 1.493675708770752\n",
      "\tGenerator loss: 0.9133971929550171, Discriminator loss: 1.4051138162612915\n",
      "\tGenerator loss: 0.9102896451950073, Discriminator loss: 1.3956735134124756\n",
      "\tGenerator loss: 0.9155310988426208, Discriminator loss: 1.3617370128631592\n",
      "\tGenerator loss: 0.8893237113952637, Discriminator loss: 1.3060362339019775\n",
      "\tGenerator loss: 0.8788017630577087, Discriminator loss: 1.3265490531921387\n",
      "\tGenerator loss: 0.8531476259231567, Discriminator loss: 1.2885291576385498\n",
      "\tGenerator loss: 0.8609764575958252, Discriminator loss: 1.3008490800857544\n",
      "\tGenerator loss: 0.8974552154541016, Discriminator loss: 1.2469912767410278\n",
      "\tGenerator loss: 0.9314731955528259, Discriminator loss: 1.218825101852417\n",
      "\tGenerator loss: 0.9582405686378479, Discriminator loss: 1.2403953075408936\n",
      "\tGenerator loss: 0.9712293148040771, Discriminator loss: 1.2926816940307617\n",
      "\tGenerator loss: 0.9852674603462219, Discriminator loss: 1.3066620826721191\n",
      "\tGenerator loss: 0.9644551277160645, Discriminator loss: 1.2532546520233154\n",
      "\tGenerator loss: 0.9439002275466919, Discriminator loss: 1.2157825231552124\n",
      "\tGenerator loss: 0.9244322180747986, Discriminator loss: 1.2200101613998413\n",
      "\tGenerator loss: 0.9207923412322998, Discriminator loss: 1.1781882047653198\n",
      "\tGenerator loss: 0.9353881478309631, Discriminator loss: 1.2116379737854004\n",
      "\tGenerator loss: 0.9699403047561646, Discriminator loss: 1.1984689235687256\n",
      "\tGenerator loss: 0.9681103229522705, Discriminator loss: 1.170290231704712\n",
      "\tGenerator loss: 0.9694571495056152, Discriminator loss: 1.1816010475158691\n",
      "\tGenerator loss: 0.9657251834869385, Discriminator loss: 1.180033564567566\n",
      "\tGenerator loss: 0.9776833057403564, Discriminator loss: 1.161839246749878\n",
      "\tGenerator loss: 0.9771673679351807, Discriminator loss: 1.1830918788909912\n",
      "\tGenerator loss: 0.9425339698791504, Discriminator loss: 1.2438088655471802\n",
      "\tGenerator loss: 0.9238171577453613, Discriminator loss: 1.1948412656784058\n",
      "\tGenerator loss: 0.9432706832885742, Discriminator loss: 1.189831018447876\n",
      "\tGenerator loss: 0.9579606056213379, Discriminator loss: 1.2031469345092773\n",
      "\tGenerator loss: 0.9618259072303772, Discriminator loss: 1.2383759021759033\n",
      "\tGenerator loss: 0.9720903635025024, Discriminator loss: 1.175499677658081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9753454923629761, Discriminator loss: 1.1994740962982178\n",
      "\tGenerator loss: 0.9932922720909119, Discriminator loss: 1.2108311653137207\n",
      "\tGenerator loss: 1.002764105796814, Discriminator loss: 1.2446867227554321\n",
      "\tGenerator loss: 0.9772118330001831, Discriminator loss: 1.2553434371948242\n",
      "\tGenerator loss: 0.9414644241333008, Discriminator loss: 1.2580739259719849\n",
      "\tGenerator loss: 0.8952119946479797, Discriminator loss: 1.2308802604675293\n",
      "\tGenerator loss: 0.8682364225387573, Discriminator loss: 1.2533702850341797\n",
      "\tGenerator loss: 0.8857778310775757, Discriminator loss: 1.2692749500274658\n",
      "\tGenerator loss: 0.8943547606468201, Discriminator loss: 1.3439667224884033\n",
      "\tGenerator loss: 0.9005395174026489, Discriminator loss: 1.33375084400177\n",
      "\tGenerator loss: 0.904474139213562, Discriminator loss: 1.3071606159210205\n",
      "\tGenerator loss: 0.889045774936676, Discriminator loss: 1.4203699827194214\n",
      "\tGenerator loss: 0.84792160987854, Discriminator loss: 1.3242855072021484\n",
      "\tGenerator loss: 0.8241826295852661, Discriminator loss: 1.3018267154693604\n",
      "\tGenerator loss: 0.8175646066665649, Discriminator loss: 1.2890996932983398\n",
      "\tGenerator loss: 0.8266696929931641, Discriminator loss: 1.3338439464569092\n",
      "\tGenerator loss: 0.8740593791007996, Discriminator loss: 1.3281136751174927\n",
      "\tGenerator loss: 0.8981077075004578, Discriminator loss: 1.3848769664764404\n",
      "\tGenerator loss: 0.9031281471252441, Discriminator loss: 1.3912134170532227\n",
      "\tGenerator loss: 0.8797367811203003, Discriminator loss: 1.3900314569473267\n",
      "\tGenerator loss: 0.8250101804733276, Discriminator loss: 1.4414305686950684\n",
      "\tGenerator loss: 0.7887904644012451, Discriminator loss: 1.4122185707092285\n",
      "\tGenerator loss: 0.765816330909729, Discriminator loss: 1.3909235000610352\n",
      "\tGenerator loss: 0.7423760294914246, Discriminator loss: 1.3903785943984985\n",
      "\tGenerator loss: 0.7457630634307861, Discriminator loss: 1.3964629173278809\n",
      "\tGenerator loss: 0.7537327408790588, Discriminator loss: 1.3917012214660645\n",
      "\tGenerator loss: 0.7801367044448853, Discriminator loss: 1.4485238790512085\n",
      "\tGenerator loss: 0.7874499559402466, Discriminator loss: 1.416214942932129\n",
      "\tGenerator loss: 0.8081876635551453, Discriminator loss: 1.3759703636169434\n",
      "\tGenerator loss: 0.798907995223999, Discriminator loss: 1.3776702880859375\n",
      "\tGenerator loss: 0.7900480031967163, Discriminator loss: 1.3492683172225952\n",
      "\tGenerator loss: 0.7877392172813416, Discriminator loss: 1.3041236400604248\n",
      "\tGenerator loss: 0.8011972904205322, Discriminator loss: 1.3099713325500488\n",
      "\tGenerator loss: 0.7911059856414795, Discriminator loss: 1.3474903106689453\n",
      "\tGenerator loss: 0.7768710255622864, Discriminator loss: 1.361715316772461\n",
      "\tGenerator loss: 0.7737505435943604, Discriminator loss: 1.3036210536956787\n",
      "\tGenerator loss: 0.7762854695320129, Discriminator loss: 1.277176856994629\n",
      "\tGenerator loss: 0.7844372987747192, Discriminator loss: 1.2285808324813843\n",
      "\tGenerator loss: 0.8162634372711182, Discriminator loss: 1.1978871822357178\n",
      "\tGenerator loss: 0.8484348058700562, Discriminator loss: 1.173832893371582\n",
      "\tGenerator loss: 0.8978602886199951, Discriminator loss: 1.1266491413116455\n",
      "\tGenerator loss: 0.9506848454475403, Discriminator loss: 1.1183220148086548\n",
      "\tGenerator loss: 0.9804233312606812, Discriminator loss: 1.1065263748168945\n",
      "\tGenerator loss: 0.9862412810325623, Discriminator loss: 1.112390160560608\n",
      "\tGenerator loss: 0.969558835029602, Discriminator loss: 1.0831232070922852\n",
      "\tGenerator loss: 0.9358661770820618, Discriminator loss: 1.0580260753631592\n",
      "\tGenerator loss: 0.9089317321777344, Discriminator loss: 1.0657991170883179\n",
      "\tGenerator loss: 0.899111270904541, Discriminator loss: 1.0400199890136719\n",
      "\tGenerator loss: 0.9312077760696411, Discriminator loss: 1.0290805101394653\n",
      "\tGenerator loss: 0.9581449031829834, Discriminator loss: 1.013674020767212\n",
      "\tGenerator loss: 0.9838715195655823, Discriminator loss: 1.028045415878296\n",
      "\tGenerator loss: 1.004463791847229, Discriminator loss: 1.0276641845703125\n",
      "\tGenerator loss: 1.0409958362579346, Discriminator loss: 1.007829189300537\n",
      "\tGenerator loss: 1.054131269454956, Discriminator loss: 0.9809444546699524\n",
      "\tGenerator loss: 1.0737738609313965, Discriminator loss: 0.972808837890625\n",
      "\tGenerator loss: 1.068832516670227, Discriminator loss: 0.9717762470245361\n",
      "\tGenerator loss: 1.0658501386642456, Discriminator loss: 1.007249355316162\n",
      "\tGenerator loss: 1.0511798858642578, Discriminator loss: 1.013043999671936\n",
      "\tGenerator loss: 1.0479191541671753, Discriminator loss: 1.0168406963348389\n",
      "\tGenerator loss: 1.0163562297821045, Discriminator loss: 1.0506372451782227\n",
      "\tGenerator loss: 0.9932278394699097, Discriminator loss: 1.0497686862945557\n",
      "\tGenerator loss: 0.97007155418396, Discriminator loss: 1.0589561462402344\n",
      "\tGenerator loss: 1.0059539079666138, Discriminator loss: 1.0129519701004028\n",
      "\tGenerator loss: 1.0235047340393066, Discriminator loss: 1.0219879150390625\n",
      "\tGenerator loss: 1.0440768003463745, Discriminator loss: 1.0500121116638184\n",
      "\tGenerator loss: 1.0683398246765137, Discriminator loss: 1.0201148986816406\n",
      "\tGenerator loss: 1.0663765668869019, Discriminator loss: 1.0035284757614136\n",
      "\tGenerator loss: 1.0726561546325684, Discriminator loss: 1.008730411529541\n",
      "\tGenerator loss: 1.0394418239593506, Discriminator loss: 1.0234870910644531\n",
      "\tGenerator loss: 1.041237711906433, Discriminator loss: 1.0447094440460205\n",
      "\tGenerator loss: 1.017538070678711, Discriminator loss: 1.0831334590911865\n",
      "\tGenerator loss: 0.9919141530990601, Discriminator loss: 1.1395905017852783\n",
      "\tGenerator loss: 0.9569904804229736, Discriminator loss: 1.1156766414642334\n",
      "\tGenerator loss: 0.9365051984786987, Discriminator loss: 1.1076949834823608\n",
      "\tGenerator loss: 0.9391559362411499, Discriminator loss: 1.120240569114685\n",
      "\tGenerator loss: 0.9543310403823853, Discriminator loss: 1.1707866191864014\n",
      "\tGenerator loss: 0.9794225096702576, Discriminator loss: 1.1691397428512573\n",
      "\tGenerator loss: 0.9559489488601685, Discriminator loss: 1.2135963439941406\n",
      "\tGenerator loss: 0.9606947898864746, Discriminator loss: 1.2643120288848877\n",
      "\tGenerator loss: 0.9386417865753174, Discriminator loss: 1.2011715173721313\n",
      "\tGenerator loss: 0.9028764367103577, Discriminator loss: 1.1818902492523193\n",
      "\tGenerator loss: 0.8690731525421143, Discriminator loss: 1.2147316932678223\n",
      "\tGenerator loss: 0.8736362457275391, Discriminator loss: 1.2240749597549438\n",
      "\tGenerator loss: 0.9128426909446716, Discriminator loss: 1.2646279335021973\n",
      "\tGenerator loss: 0.9259860515594482, Discriminator loss: 1.310746192932129\n",
      "\tGenerator loss: 0.9471420645713806, Discriminator loss: 1.3351950645446777\n",
      "\tGenerator loss: 0.9258041381835938, Discriminator loss: 1.364789605140686\n",
      "\tGenerator loss: 0.8983644247055054, Discriminator loss: 1.3432092666625977\n",
      "\tGenerator loss: 0.848037600517273, Discriminator loss: 1.4487502574920654\n",
      "\tGenerator loss: 0.8043843507766724, Discriminator loss: 1.4072959423065186\n",
      "\tGenerator loss: 0.7731695771217346, Discriminator loss: 1.4043636322021484\n",
      "\tGenerator loss: 0.8027828931808472, Discriminator loss: 1.3474429845809937\n",
      "\tGenerator loss: 0.8712853789329529, Discriminator loss: 1.3184754848480225\n",
      "\tGenerator loss: 0.9213800430297852, Discriminator loss: 1.3010764122009277\n",
      "\tGenerator loss: 0.9407891035079956, Discriminator loss: 1.3248412609100342\n",
      "\tGenerator loss: 0.9278438091278076, Discriminator loss: 1.3708927631378174\n",
      "\tGenerator loss: 0.872617781162262, Discriminator loss: 1.3133050203323364\n",
      "\tGenerator loss: 0.8253995180130005, Discriminator loss: 1.3153432607650757\n",
      "\tGenerator loss: 0.8183732032775879, Discriminator loss: 1.3283861875534058\n",
      "\tGenerator loss: 0.8127175569534302, Discriminator loss: 1.3295924663543701\n",
      "\tGenerator loss: 0.8403501510620117, Discriminator loss: 1.2927119731903076\n",
      "\tGenerator loss: 0.9082995653152466, Discriminator loss: 1.2748401165008545\n",
      "\tGenerator loss: 0.9352235794067383, Discriminator loss: 1.299794316291809\n",
      "\tGenerator loss: 0.9339553117752075, Discriminator loss: 1.3188822269439697\n",
      "\tGenerator loss: 0.9281456470489502, Discriminator loss: 1.3106532096862793\n",
      "\tGenerator loss: 0.8840457201004028, Discriminator loss: 1.329131841659546\n",
      "Time for epoch 12 is 478.3692367076874 sec\n",
      "\tGenerator loss: 0.8448513746261597, Discriminator loss: 1.2738820314407349\n",
      "\tGenerator loss: 0.8407489061355591, Discriminator loss: 1.2406768798828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8385183215141296, Discriminator loss: 1.2342251539230347\n",
      "\tGenerator loss: 0.8924382925033569, Discriminator loss: 1.2091410160064697\n",
      "\tGenerator loss: 0.9440481066703796, Discriminator loss: 1.2443872690200806\n",
      "\tGenerator loss: 0.9873712062835693, Discriminator loss: 1.2197740077972412\n",
      "\tGenerator loss: 0.9896985292434692, Discriminator loss: 1.1867294311523438\n",
      "\tGenerator loss: 0.988008975982666, Discriminator loss: 1.1725906133651733\n",
      "\tGenerator loss: 0.9534133672714233, Discriminator loss: 1.1359541416168213\n",
      "\tGenerator loss: 0.9449670314788818, Discriminator loss: 1.146583080291748\n",
      "\tGenerator loss: 0.9603672027587891, Discriminator loss: 1.1188843250274658\n",
      "\tGenerator loss: 0.9927060604095459, Discriminator loss: 1.1014496088027954\n",
      "\tGenerator loss: 1.0180730819702148, Discriminator loss: 1.097277045249939\n",
      "\tGenerator loss: 1.0365549325942993, Discriminator loss: 1.075824499130249\n",
      "\tGenerator loss: 1.0021488666534424, Discriminator loss: 1.1002824306488037\n",
      "\tGenerator loss: 1.0121958255767822, Discriminator loss: 1.0848597288131714\n",
      "\tGenerator loss: 1.0120131969451904, Discriminator loss: 1.096017837524414\n",
      "\tGenerator loss: 1.015885829925537, Discriminator loss: 1.0862830877304077\n",
      "\tGenerator loss: 1.0048613548278809, Discriminator loss: 1.0763285160064697\n",
      "\tGenerator loss: 1.0321743488311768, Discriminator loss: 1.0645183324813843\n",
      "\tGenerator loss: 1.0415247678756714, Discriminator loss: 1.0807421207427979\n",
      "\tGenerator loss: 1.0634870529174805, Discriminator loss: 1.068640947341919\n",
      "\tGenerator loss: 1.0538239479064941, Discriminator loss: 1.1321138143539429\n",
      "\tGenerator loss: 1.0434882640838623, Discriminator loss: 1.1092816591262817\n",
      "\tGenerator loss: 1.01609468460083, Discriminator loss: 1.1087722778320312\n",
      "\tGenerator loss: 1.0043256282806396, Discriminator loss: 1.1233737468719482\n",
      "\tGenerator loss: 0.9929088354110718, Discriminator loss: 1.2329238653182983\n",
      "\tGenerator loss: 0.955915093421936, Discriminator loss: 1.2168391942977905\n",
      "\tGenerator loss: 0.9155119061470032, Discriminator loss: 1.3484227657318115\n",
      "\tGenerator loss: 0.8464221954345703, Discriminator loss: 1.3374298810958862\n",
      "\tGenerator loss: 0.7896952629089355, Discriminator loss: 1.3061695098876953\n",
      "\tGenerator loss: 0.8054419755935669, Discriminator loss: 1.2684838771820068\n",
      "\tGenerator loss: 0.8444800972938538, Discriminator loss: 1.2969413995742798\n",
      "\tGenerator loss: 0.9087414741516113, Discriminator loss: 1.245865821838379\n",
      "\tGenerator loss: 0.9855509400367737, Discriminator loss: 1.295061469078064\n",
      "\tGenerator loss: 1.0094525814056396, Discriminator loss: 1.3561882972717285\n",
      "\tGenerator loss: 0.9652432203292847, Discriminator loss: 1.399855136871338\n",
      "\tGenerator loss: 0.8564772605895996, Discriminator loss: 1.4039959907531738\n",
      "\tGenerator loss: 0.739475429058075, Discriminator loss: 1.4305297136306763\n",
      "\tGenerator loss: 0.7040534019470215, Discriminator loss: 1.4240541458129883\n",
      "\tGenerator loss: 0.7159689664840698, Discriminator loss: 1.356519103050232\n",
      "\tGenerator loss: 0.7916796207427979, Discriminator loss: 1.4252395629882812\n",
      "\tGenerator loss: 0.8651291728019714, Discriminator loss: 1.4006729125976562\n",
      "\tGenerator loss: 0.9008105993270874, Discriminator loss: 1.405187726020813\n",
      "\tGenerator loss: 0.895327091217041, Discriminator loss: 1.462003469467163\n",
      "\tGenerator loss: 0.8285143375396729, Discriminator loss: 1.4797329902648926\n",
      "\tGenerator loss: 0.7627041339874268, Discriminator loss: 1.485064148902893\n",
      "\tGenerator loss: 0.6937837600708008, Discriminator loss: 1.487583875656128\n",
      "\tGenerator loss: 0.6457467675209045, Discriminator loss: 1.5150914192199707\n",
      "\tGenerator loss: 0.6610441207885742, Discriminator loss: 1.525775671005249\n",
      "\tGenerator loss: 0.6971118450164795, Discriminator loss: 1.5266730785369873\n",
      "\tGenerator loss: 0.752917468547821, Discriminator loss: 1.5090086460113525\n",
      "\tGenerator loss: 0.798310399055481, Discriminator loss: 1.460604190826416\n",
      "\tGenerator loss: 0.7954686284065247, Discriminator loss: 1.553888201713562\n",
      "\tGenerator loss: 0.7797455787658691, Discriminator loss: 1.554551124572754\n",
      "\tGenerator loss: 0.7213993072509766, Discriminator loss: 1.4960033893585205\n",
      "\tGenerator loss: 0.668993353843689, Discriminator loss: 1.540680170059204\n",
      "\tGenerator loss: 0.6559898853302002, Discriminator loss: 1.5317978858947754\n",
      "\tGenerator loss: 0.644946277141571, Discriminator loss: 1.5003725290298462\n",
      "\tGenerator loss: 0.6597546339035034, Discriminator loss: 1.5110397338867188\n",
      "\tGenerator loss: 0.71068274974823, Discriminator loss: 1.4840266704559326\n",
      "\tGenerator loss: 0.7490694522857666, Discriminator loss: 1.4599992036819458\n",
      "\tGenerator loss: 0.7416194677352905, Discriminator loss: 1.3984977006912231\n",
      "\tGenerator loss: 0.7562733292579651, Discriminator loss: 1.362572431564331\n",
      "\tGenerator loss: 0.7613505125045776, Discriminator loss: 1.347519874572754\n",
      "\tGenerator loss: 0.78077632188797, Discriminator loss: 1.3458181619644165\n",
      "\tGenerator loss: 0.7847834229469299, Discriminator loss: 1.3319041728973389\n",
      "\tGenerator loss: 0.8079811334609985, Discriminator loss: 1.276964545249939\n",
      "\tGenerator loss: 0.8095942735671997, Discriminator loss: 1.2716341018676758\n",
      "\tGenerator loss: 0.8051216006278992, Discriminator loss: 1.2629978656768799\n",
      "\tGenerator loss: 0.805869460105896, Discriminator loss: 1.2227833271026611\n",
      "\tGenerator loss: 0.8290283679962158, Discriminator loss: 1.196087121963501\n",
      "\tGenerator loss: 0.8448787927627563, Discriminator loss: 1.1797860860824585\n",
      "\tGenerator loss: 0.864018440246582, Discriminator loss: 1.1655246019363403\n",
      "\tGenerator loss: 0.8974347710609436, Discriminator loss: 1.1480917930603027\n",
      "\tGenerator loss: 0.926645040512085, Discriminator loss: 1.1175419092178345\n",
      "\tGenerator loss: 0.9545542597770691, Discriminator loss: 1.1225532293319702\n",
      "\tGenerator loss: 0.974414587020874, Discriminator loss: 1.1107829809188843\n",
      "\tGenerator loss: 0.9778929352760315, Discriminator loss: 1.1097712516784668\n",
      "\tGenerator loss: 0.9691051244735718, Discriminator loss: 1.0725154876708984\n",
      "\tGenerator loss: 0.9843090772628784, Discriminator loss: 1.0677279233932495\n",
      "\tGenerator loss: 0.9813063144683838, Discriminator loss: 1.0442867279052734\n",
      "\tGenerator loss: 0.9740298986434937, Discriminator loss: 1.0318405628204346\n",
      "\tGenerator loss: 0.9857341051101685, Discriminator loss: 1.0397114753723145\n",
      "\tGenerator loss: 1.008507251739502, Discriminator loss: 1.0302046537399292\n",
      "\tGenerator loss: 1.0455095767974854, Discriminator loss: 1.0509366989135742\n",
      "\tGenerator loss: 1.059211254119873, Discriminator loss: 1.0224089622497559\n",
      "\tGenerator loss: 1.0665415525436401, Discriminator loss: 0.9836050271987915\n",
      "\tGenerator loss: 1.0791943073272705, Discriminator loss: 0.9939612746238708\n",
      "\tGenerator loss: 1.056915283203125, Discriminator loss: 0.9964545965194702\n",
      "\tGenerator loss: 1.0431722402572632, Discriminator loss: 1.0023224353790283\n",
      "\tGenerator loss: 1.0542712211608887, Discriminator loss: 1.0059332847595215\n",
      "\tGenerator loss: 1.0655349493026733, Discriminator loss: 0.9877992868423462\n",
      "\tGenerator loss: 1.0301902294158936, Discriminator loss: 1.0098154544830322\n",
      "\tGenerator loss: 1.0342625379562378, Discriminator loss: 1.0033231973648071\n",
      "\tGenerator loss: 1.0274038314819336, Discriminator loss: 0.9858193397521973\n",
      "\tGenerator loss: 1.0246418714523315, Discriminator loss: 1.0112788677215576\n",
      "\tGenerator loss: 1.0310354232788086, Discriminator loss: 1.0068202018737793\n",
      "\tGenerator loss: 1.0235109329223633, Discriminator loss: 1.0471445322036743\n",
      "\tGenerator loss: 1.0370962619781494, Discriminator loss: 1.097804069519043\n",
      "\tGenerator loss: 1.0235741138458252, Discriminator loss: 1.0925014019012451\n",
      "\tGenerator loss: 0.9911896586418152, Discriminator loss: 1.0979758501052856\n",
      "\tGenerator loss: 0.9586774110794067, Discriminator loss: 1.1099964380264282\n",
      "\tGenerator loss: 0.9348145127296448, Discriminator loss: 1.096771240234375\n",
      "\tGenerator loss: 0.9535925388336182, Discriminator loss: 1.1432075500488281\n",
      "\tGenerator loss: 0.9626843333244324, Discriminator loss: 1.1679041385650635\n",
      "\tGenerator loss: 0.9674254655838013, Discriminator loss: 1.1949374675750732\n",
      "\tGenerator loss: 0.9390039443969727, Discriminator loss: 1.1783602237701416\n",
      "\tGenerator loss: 0.9097633361816406, Discriminator loss: 1.1500189304351807\n",
      "\tGenerator loss: 0.9013863801956177, Discriminator loss: 1.2025671005249023\n",
      "\tGenerator loss: 0.8973015546798706, Discriminator loss: 1.2631618976593018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9074985980987549, Discriminator loss: 1.2410366535186768\n",
      "\tGenerator loss: 0.9210914373397827, Discriminator loss: 1.2374517917633057\n",
      "\tGenerator loss: 0.9450584650039673, Discriminator loss: 1.2211248874664307\n",
      "\tGenerator loss: 0.9352706670761108, Discriminator loss: 1.2429819107055664\n",
      "\tGenerator loss: 0.9313020706176758, Discriminator loss: 1.2326834201812744\n",
      "\tGenerator loss: 0.9363552927970886, Discriminator loss: 1.188978672027588\n",
      "\tGenerator loss: 0.9153138399124146, Discriminator loss: 1.1800867319107056\n",
      "\tGenerator loss: 0.9032595157623291, Discriminator loss: 1.2105505466461182\n",
      "\tGenerator loss: 0.8902249336242676, Discriminator loss: 1.205736756324768\n",
      "\tGenerator loss: 0.8988539576530457, Discriminator loss: 1.2198219299316406\n",
      "\tGenerator loss: 0.9067087173461914, Discriminator loss: 1.192873477935791\n",
      "\tGenerator loss: 0.9098707437515259, Discriminator loss: 1.1935455799102783\n",
      "\tGenerator loss: 0.9092051982879639, Discriminator loss: 1.1986459493637085\n",
      "\tGenerator loss: 0.9191120862960815, Discriminator loss: 1.208618402481079\n",
      "\tGenerator loss: 0.924591064453125, Discriminator loss: 1.229705572128296\n",
      "\tGenerator loss: 0.9052165746688843, Discriminator loss: 1.2559075355529785\n",
      "\tGenerator loss: 0.9095215797424316, Discriminator loss: 1.225632905960083\n",
      "\tGenerator loss: 0.8964028358459473, Discriminator loss: 1.187893033027649\n",
      "\tGenerator loss: 0.8991820812225342, Discriminator loss: 1.1713087558746338\n",
      "\tGenerator loss: 0.9205541610717773, Discriminator loss: 1.1432445049285889\n",
      "\tGenerator loss: 0.951887845993042, Discriminator loss: 1.1878315210342407\n",
      "\tGenerator loss: 0.9920099973678589, Discriminator loss: 1.1964290142059326\n",
      "\tGenerator loss: 0.9943745136260986, Discriminator loss: 1.1548150777816772\n",
      "\tGenerator loss: 0.9669918417930603, Discriminator loss: 1.1276295185089111\n",
      "\tGenerator loss: 0.965514063835144, Discriminator loss: 1.1162455081939697\n",
      "\tGenerator loss: 0.9668745994567871, Discriminator loss: 1.1157329082489014\n",
      "\tGenerator loss: 0.9802565574645996, Discriminator loss: 1.0964056253433228\n",
      "\tGenerator loss: 1.0219454765319824, Discriminator loss: 1.0907912254333496\n",
      "\tGenerator loss: 1.072654128074646, Discriminator loss: 1.0658818483352661\n",
      "\tGenerator loss: 1.0649032592773438, Discriminator loss: 1.1029260158538818\n",
      "\tGenerator loss: 1.044491171836853, Discriminator loss: 1.0896806716918945\n",
      "\tGenerator loss: 1.0061274766921997, Discriminator loss: 1.0690393447875977\n",
      "\tGenerator loss: 1.0018917322158813, Discriminator loss: 1.0598764419555664\n",
      "\tGenerator loss: 1.003739356994629, Discriminator loss: 1.0755531787872314\n",
      "\tGenerator loss: 1.0301532745361328, Discriminator loss: 1.0805026292800903\n",
      "\tGenerator loss: 1.0616809129714966, Discriminator loss: 1.0738329887390137\n",
      "\tGenerator loss: 1.0758068561553955, Discriminator loss: 1.0413585901260376\n",
      "\tGenerator loss: 1.1126470565795898, Discriminator loss: 1.0448014736175537\n",
      "\tGenerator loss: 1.1016960144042969, Discriminator loss: 1.0493619441986084\n",
      "\tGenerator loss: 1.0590333938598633, Discriminator loss: 1.0451266765594482\n",
      "\tGenerator loss: 1.03904390335083, Discriminator loss: 1.0322558879852295\n",
      "\tGenerator loss: 1.03364896774292, Discriminator loss: 1.044209361076355\n",
      "\tGenerator loss: 1.038654088973999, Discriminator loss: 1.0432932376861572\n",
      "\tGenerator loss: 1.0952216386795044, Discriminator loss: 1.048776626586914\n",
      "\tGenerator loss: 1.0824302434921265, Discriminator loss: 1.0824048519134521\n",
      "\tGenerator loss: 1.0852816104888916, Discriminator loss: 1.0748891830444336\n",
      "\tGenerator loss: 1.064026117324829, Discriminator loss: 1.0675917863845825\n",
      "\tGenerator loss: 1.0493155717849731, Discriminator loss: 1.0536216497421265\n",
      "\tGenerator loss: 1.0561712980270386, Discriminator loss: 1.0762348175048828\n",
      "\tGenerator loss: 1.0373387336730957, Discriminator loss: 1.073677659034729\n",
      "\tGenerator loss: 1.0380280017852783, Discriminator loss: 1.055995225906372\n",
      "\tGenerator loss: 1.0727925300598145, Discriminator loss: 1.0997273921966553\n",
      "\tGenerator loss: 1.0904380083084106, Discriminator loss: 1.1204664707183838\n",
      "\tGenerator loss: 1.0257360935211182, Discriminator loss: 1.111016035079956\n",
      "\tGenerator loss: 0.9896234273910522, Discriminator loss: 1.1243432760238647\n",
      "\tGenerator loss: 0.9686760902404785, Discriminator loss: 1.1138641834259033\n",
      "\tGenerator loss: 0.9755598306655884, Discriminator loss: 1.0899877548217773\n",
      "\tGenerator loss: 1.006852626800537, Discriminator loss: 1.106497049331665\n",
      "\tGenerator loss: 1.0121145248413086, Discriminator loss: 1.0989488363265991\n",
      "\tGenerator loss: 1.061434030532837, Discriminator loss: 1.103973388671875\n",
      "\tGenerator loss: 1.0823092460632324, Discriminator loss: 1.1314952373504639\n",
      "\tGenerator loss: 1.0574969053268433, Discriminator loss: 1.0948596000671387\n",
      "\tGenerator loss: 1.0010167360305786, Discriminator loss: 1.1047003269195557\n",
      "\tGenerator loss: 0.9714351892471313, Discriminator loss: 1.1077797412872314\n",
      "\tGenerator loss: 0.9448806643486023, Discriminator loss: 1.1385250091552734\n",
      "\tGenerator loss: 0.9480697512626648, Discriminator loss: 1.1094343662261963\n",
      "\tGenerator loss: 0.9598535299301147, Discriminator loss: 1.1372889280319214\n",
      "\tGenerator loss: 0.993945837020874, Discriminator loss: 1.126551866531372\n",
      "\tGenerator loss: 1.0197312831878662, Discriminator loss: 1.165658712387085\n",
      "\tGenerator loss: 0.9971615076065063, Discriminator loss: 1.1618616580963135\n",
      "\tGenerator loss: 0.9503228664398193, Discriminator loss: 1.1374163627624512\n",
      "\tGenerator loss: 0.9161731600761414, Discriminator loss: 1.1106053590774536\n",
      "\tGenerator loss: 0.9242019653320312, Discriminator loss: 1.0885941982269287\n",
      "\tGenerator loss: 0.9434804320335388, Discriminator loss: 1.1343824863433838\n",
      "\tGenerator loss: 0.9775621891021729, Discriminator loss: 1.1344395875930786\n",
      "\tGenerator loss: 0.990736722946167, Discriminator loss: 1.1299176216125488\n",
      "\tGenerator loss: 1.0051655769348145, Discriminator loss: 1.1362571716308594\n",
      "\tGenerator loss: 1.0031647682189941, Discriminator loss: 1.1490495204925537\n",
      "\tGenerator loss: 0.985010027885437, Discriminator loss: 1.1117044687271118\n",
      "\tGenerator loss: 0.9613766670227051, Discriminator loss: 1.1067888736724854\n",
      "\tGenerator loss: 0.9649191498756409, Discriminator loss: 1.1410585641860962\n",
      "\tGenerator loss: 0.9451727271080017, Discriminator loss: 1.1338436603546143\n",
      "\tGenerator loss: 0.9587669372558594, Discriminator loss: 1.1239991188049316\n",
      "\tGenerator loss: 0.9740300178527832, Discriminator loss: 1.0925533771514893\n",
      "\tGenerator loss: 0.9698431491851807, Discriminator loss: 1.1196954250335693\n",
      "\tGenerator loss: 0.9924715757369995, Discriminator loss: 1.1198844909667969\n",
      "\tGenerator loss: 0.9755834937095642, Discriminator loss: 1.1311410665512085\n",
      "\tGenerator loss: 0.9618472456932068, Discriminator loss: 1.1370537281036377\n",
      "\tGenerator loss: 0.9537376165390015, Discriminator loss: 1.125438928604126\n",
      "\tGenerator loss: 0.9644677042961121, Discriminator loss: 1.1351985931396484\n",
      "\tGenerator loss: 0.9640430808067322, Discriminator loss: 1.091802954673767\n",
      "\tGenerator loss: 0.9886746406555176, Discriminator loss: 1.093869686126709\n",
      "\tGenerator loss: 0.9928202629089355, Discriminator loss: 1.123724341392517\n",
      "\tGenerator loss: 1.0141136646270752, Discriminator loss: 1.1490222215652466\n",
      "\tGenerator loss: 0.9821586608886719, Discriminator loss: 1.116999864578247\n",
      "\tGenerator loss: 0.9705022573471069, Discriminator loss: 1.1189348697662354\n",
      "\tGenerator loss: 0.9536886215209961, Discriminator loss: 1.1269023418426514\n",
      "\tGenerator loss: 0.9498170018196106, Discriminator loss: 1.108914852142334\n",
      "\tGenerator loss: 0.9269291758537292, Discriminator loss: 1.125460147857666\n",
      "\tGenerator loss: 0.9495673179626465, Discriminator loss: 1.1201868057250977\n",
      "\tGenerator loss: 0.9769048690795898, Discriminator loss: 1.1249480247497559\n",
      "\tGenerator loss: 0.967821478843689, Discriminator loss: 1.175691843032837\n",
      "\tGenerator loss: 0.9995001554489136, Discriminator loss: 1.1834889650344849\n",
      "\tGenerator loss: 0.9997895359992981, Discriminator loss: 1.1909005641937256\n",
      "\tGenerator loss: 0.9865887761116028, Discriminator loss: 1.162333369255066\n",
      "\tGenerator loss: 0.956641674041748, Discriminator loss: 1.1693222522735596\n",
      "\tGenerator loss: 0.9093927145004272, Discriminator loss: 1.2004934549331665\n",
      "\tGenerator loss: 0.8896278142929077, Discriminator loss: 1.1742210388183594\n",
      "\tGenerator loss: 0.8958530426025391, Discriminator loss: 1.1913714408874512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9190933704376221, Discriminator loss: 1.210587978363037\n",
      "\tGenerator loss: 0.9600999355316162, Discriminator loss: 1.2032383680343628\n",
      "\tGenerator loss: 0.9707713723182678, Discriminator loss: 1.2007076740264893\n",
      "\tGenerator loss: 0.9479838609695435, Discriminator loss: 1.207177758216858\n",
      "\tGenerator loss: 0.9238078594207764, Discriminator loss: 1.2325506210327148\n",
      "\tGenerator loss: 0.9034467935562134, Discriminator loss: 1.2135348320007324\n",
      "\tGenerator loss: 0.8594430685043335, Discriminator loss: 1.2301771640777588\n",
      "\tGenerator loss: 0.8389135599136353, Discriminator loss: 1.243873119354248\n",
      "\tGenerator loss: 0.8591191172599792, Discriminator loss: 1.2183336019515991\n",
      "\tGenerator loss: 0.8665889501571655, Discriminator loss: 1.2262687683105469\n",
      "\tGenerator loss: 0.919751763343811, Discriminator loss: 1.195753574371338\n",
      "\tGenerator loss: 0.9586556553840637, Discriminator loss: 1.2209010124206543\n",
      "\tGenerator loss: 0.9704403877258301, Discriminator loss: 1.2959859371185303\n",
      "\tGenerator loss: 0.9591435194015503, Discriminator loss: 1.3431891202926636\n",
      "\tGenerator loss: 0.9106742143630981, Discriminator loss: 1.3614600896835327\n",
      "Time for epoch 13 is 478.63201999664307 sec\n",
      "\tGenerator loss: 0.8383201956748962, Discriminator loss: 1.3306111097335815\n",
      "\tGenerator loss: 0.7795122861862183, Discriminator loss: 1.321195125579834\n",
      "\tGenerator loss: 0.7586528658866882, Discriminator loss: 1.3324047327041626\n",
      "\tGenerator loss: 0.7827708721160889, Discriminator loss: 1.326235055923462\n",
      "\tGenerator loss: 0.8160750865936279, Discriminator loss: 1.413906455039978\n",
      "\tGenerator loss: 0.854211151599884, Discriminator loss: 1.448988914489746\n",
      "\tGenerator loss: 0.8890647292137146, Discriminator loss: 1.3601728677749634\n",
      "\tGenerator loss: 0.8836489915847778, Discriminator loss: 1.3809764385223389\n",
      "\tGenerator loss: 0.8689483404159546, Discriminator loss: 1.334079384803772\n",
      "\tGenerator loss: 0.8364987373352051, Discriminator loss: 1.3316402435302734\n",
      "\tGenerator loss: 0.8415478467941284, Discriminator loss: 1.2937012910842896\n",
      "\tGenerator loss: 0.8376760482788086, Discriminator loss: 1.301397681236267\n",
      "\tGenerator loss: 0.8452612161636353, Discriminator loss: 1.279845952987671\n",
      "\tGenerator loss: 0.8388434052467346, Discriminator loss: 1.3004143238067627\n",
      "\tGenerator loss: 0.8589582443237305, Discriminator loss: 1.308499813079834\n",
      "\tGenerator loss: 0.8604853749275208, Discriminator loss: 1.3062711954116821\n",
      "\tGenerator loss: 0.8758993744850159, Discriminator loss: 1.3147881031036377\n",
      "\tGenerator loss: 0.8581861257553101, Discriminator loss: 1.3134254217147827\n",
      "\tGenerator loss: 0.8279513716697693, Discriminator loss: 1.3400139808654785\n",
      "\tGenerator loss: 0.8250634670257568, Discriminator loss: 1.303755283355713\n",
      "\tGenerator loss: 0.8110052347183228, Discriminator loss: 1.3177928924560547\n",
      "\tGenerator loss: 0.8394062519073486, Discriminator loss: 1.3053439855575562\n",
      "\tGenerator loss: 0.8400303721427917, Discriminator loss: 1.3202178478240967\n",
      "\tGenerator loss: 0.8601526021957397, Discriminator loss: 1.3776342868804932\n",
      "\tGenerator loss: 0.8532851934432983, Discriminator loss: 1.3570809364318848\n",
      "\tGenerator loss: 0.8548280000686646, Discriminator loss: 1.2990021705627441\n",
      "\tGenerator loss: 0.8445440530776978, Discriminator loss: 1.3437013626098633\n",
      "\tGenerator loss: 0.8286436796188354, Discriminator loss: 1.3327916860580444\n",
      "\tGenerator loss: 0.8146592378616333, Discriminator loss: 1.3681094646453857\n",
      "\tGenerator loss: 0.7789241671562195, Discriminator loss: 1.313817024230957\n",
      "\tGenerator loss: 0.7658641338348389, Discriminator loss: 1.333028793334961\n",
      "\tGenerator loss: 0.7856316566467285, Discriminator loss: 1.3694276809692383\n",
      "\tGenerator loss: 0.8150144815444946, Discriminator loss: 1.3742828369140625\n",
      "\tGenerator loss: 0.8194175958633423, Discriminator loss: 1.409698247909546\n",
      "\tGenerator loss: 0.8407536149024963, Discriminator loss: 1.3744919300079346\n",
      "\tGenerator loss: 0.8559646010398865, Discriminator loss: 1.3232136964797974\n",
      "\tGenerator loss: 0.8329826593399048, Discriminator loss: 1.3223698139190674\n",
      "\tGenerator loss: 0.8107649683952332, Discriminator loss: 1.3203704357147217\n",
      "\tGenerator loss: 0.7992068529129028, Discriminator loss: 1.2845252752304077\n",
      "\tGenerator loss: 0.8171294927597046, Discriminator loss: 1.3125395774841309\n",
      "\tGenerator loss: 0.837082028388977, Discriminator loss: 1.3277113437652588\n",
      "\tGenerator loss: 0.8571232557296753, Discriminator loss: 1.2949650287628174\n",
      "\tGenerator loss: 0.8988199234008789, Discriminator loss: 1.2593460083007812\n",
      "\tGenerator loss: 0.9075222015380859, Discriminator loss: 1.2416996955871582\n",
      "\tGenerator loss: 0.8911300301551819, Discriminator loss: 1.219770908355713\n",
      "\tGenerator loss: 0.8848570585250854, Discriminator loss: 1.222886085510254\n",
      "\tGenerator loss: 0.8564105033874512, Discriminator loss: 1.2239313125610352\n",
      "\tGenerator loss: 0.853631317615509, Discriminator loss: 1.2412657737731934\n",
      "\tGenerator loss: 0.8598387241363525, Discriminator loss: 1.2827718257904053\n",
      "\tGenerator loss: 0.8650698661804199, Discriminator loss: 1.2570250034332275\n",
      "\tGenerator loss: 0.9034134745597839, Discriminator loss: 1.2809371948242188\n",
      "\tGenerator loss: 0.9285010099411011, Discriminator loss: 1.3027375936508179\n",
      "\tGenerator loss: 0.9163804054260254, Discriminator loss: 1.2531923055648804\n",
      "\tGenerator loss: 0.9049199223518372, Discriminator loss: 1.2305948734283447\n",
      "\tGenerator loss: 0.8839488625526428, Discriminator loss: 1.2416439056396484\n",
      "\tGenerator loss: 0.879815936088562, Discriminator loss: 1.2986315488815308\n",
      "\tGenerator loss: 0.8714299201965332, Discriminator loss: 1.2746378183364868\n",
      "\tGenerator loss: 0.8579798936843872, Discriminator loss: 1.2603349685668945\n",
      "\tGenerator loss: 0.8625336289405823, Discriminator loss: 1.2101290225982666\n",
      "\tGenerator loss: 0.8991913795471191, Discriminator loss: 1.1642197370529175\n",
      "\tGenerator loss: 0.9555163979530334, Discriminator loss: 1.139951467514038\n",
      "\tGenerator loss: 0.9664039611816406, Discriminator loss: 1.145682692527771\n",
      "\tGenerator loss: 0.9971680045127869, Discriminator loss: 1.1558752059936523\n",
      "\tGenerator loss: 0.9876725673675537, Discriminator loss: 1.156322717666626\n",
      "\tGenerator loss: 0.9585833549499512, Discriminator loss: 1.1374194622039795\n",
      "\tGenerator loss: 0.926216721534729, Discriminator loss: 1.1222983598709106\n",
      "\tGenerator loss: 0.9112280607223511, Discriminator loss: 1.1432453393936157\n",
      "\tGenerator loss: 0.9251165390014648, Discriminator loss: 1.1686031818389893\n",
      "\tGenerator loss: 0.9510224461555481, Discriminator loss: 1.170751929283142\n",
      "\tGenerator loss: 0.9461275339126587, Discriminator loss: 1.1551740169525146\n",
      "\tGenerator loss: 0.9394447803497314, Discriminator loss: 1.140256404876709\n",
      "\tGenerator loss: 0.9324610233306885, Discriminator loss: 1.140857219696045\n",
      "\tGenerator loss: 0.9377707839012146, Discriminator loss: 1.1306095123291016\n",
      "\tGenerator loss: 0.93938148021698, Discriminator loss: 1.1407289505004883\n",
      "\tGenerator loss: 0.9514189958572388, Discriminator loss: 1.1166008710861206\n",
      "\tGenerator loss: 0.9507850408554077, Discriminator loss: 1.2024321556091309\n",
      "\tGenerator loss: 0.9476825594902039, Discriminator loss: 1.2661027908325195\n",
      "\tGenerator loss: 0.9541884064674377, Discriminator loss: 1.262434482574463\n",
      "\tGenerator loss: 0.9335237741470337, Discriminator loss: 1.2352814674377441\n",
      "\tGenerator loss: 0.9066858887672424, Discriminator loss: 1.218109130859375\n",
      "\tGenerator loss: 0.8751273155212402, Discriminator loss: 1.227186918258667\n",
      "\tGenerator loss: 0.8900712132453918, Discriminator loss: 1.2206332683563232\n",
      "\tGenerator loss: 0.9131540656089783, Discriminator loss: 1.204298734664917\n",
      "\tGenerator loss: 0.9493381977081299, Discriminator loss: 1.2148351669311523\n",
      "\tGenerator loss: 0.9601762890815735, Discriminator loss: 1.1767771244049072\n",
      "\tGenerator loss: 0.9621593952178955, Discriminator loss: 1.2687615156173706\n",
      "\tGenerator loss: 0.9511327743530273, Discriminator loss: 1.2191712856292725\n",
      "\tGenerator loss: 0.9285197257995605, Discriminator loss: 1.2187992334365845\n",
      "\tGenerator loss: 0.9123799204826355, Discriminator loss: 1.3103399276733398\n",
      "\tGenerator loss: 0.8999381065368652, Discriminator loss: 1.3253369331359863\n",
      "\tGenerator loss: 0.8550533056259155, Discriminator loss: 1.3331010341644287\n",
      "\tGenerator loss: 0.8713177442550659, Discriminator loss: 1.2893602848052979\n",
      "\tGenerator loss: 0.8761177062988281, Discriminator loss: 1.2732670307159424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9058629870414734, Discriminator loss: 1.2796480655670166\n",
      "\tGenerator loss: 0.9026737213134766, Discriminator loss: 1.2708616256713867\n",
      "\tGenerator loss: 0.9233061671257019, Discriminator loss: 1.2603473663330078\n",
      "\tGenerator loss: 0.9117555022239685, Discriminator loss: 1.2710256576538086\n",
      "\tGenerator loss: 0.9049423933029175, Discriminator loss: 1.233664870262146\n",
      "\tGenerator loss: 0.8966498374938965, Discriminator loss: 1.239055871963501\n",
      "\tGenerator loss: 0.8883569240570068, Discriminator loss: 1.270477533340454\n",
      "\tGenerator loss: 0.907305896282196, Discriminator loss: 1.258115291595459\n",
      "\tGenerator loss: 0.9279472827911377, Discriminator loss: 1.2559019327163696\n",
      "\tGenerator loss: 0.922886312007904, Discriminator loss: 1.25640869140625\n",
      "\tGenerator loss: 0.8964253664016724, Discriminator loss: 1.2576061487197876\n",
      "\tGenerator loss: 0.8654519319534302, Discriminator loss: 1.2845087051391602\n",
      "\tGenerator loss: 0.8500645160675049, Discriminator loss: 1.2884891033172607\n",
      "\tGenerator loss: 0.8456101417541504, Discriminator loss: 1.3463585376739502\n",
      "\tGenerator loss: 0.8573843836784363, Discriminator loss: 1.3215892314910889\n",
      "\tGenerator loss: 0.8760286569595337, Discriminator loss: 1.3099169731140137\n",
      "\tGenerator loss: 0.8894864320755005, Discriminator loss: 1.3169074058532715\n",
      "\tGenerator loss: 0.890652060508728, Discriminator loss: 1.3369982242584229\n",
      "\tGenerator loss: 0.875934898853302, Discriminator loss: 1.339951992034912\n",
      "\tGenerator loss: 0.8744536638259888, Discriminator loss: 1.3323533535003662\n",
      "\tGenerator loss: 0.8588236570358276, Discriminator loss: 1.3834668397903442\n",
      "\tGenerator loss: 0.8531011343002319, Discriminator loss: 1.365093469619751\n",
      "\tGenerator loss: 0.8352190256118774, Discriminator loss: 1.3285048007965088\n",
      "\tGenerator loss: 0.8191120028495789, Discriminator loss: 1.355738639831543\n",
      "\tGenerator loss: 0.8082157373428345, Discriminator loss: 1.4139094352722168\n",
      "\tGenerator loss: 0.813960611820221, Discriminator loss: 1.3296153545379639\n",
      "\tGenerator loss: 0.8012733459472656, Discriminator loss: 1.3777886629104614\n",
      "\tGenerator loss: 0.8207135200500488, Discriminator loss: 1.3450509309768677\n",
      "\tGenerator loss: 0.8015806078910828, Discriminator loss: 1.3512383699417114\n",
      "\tGenerator loss: 0.811409592628479, Discriminator loss: 1.3656797409057617\n",
      "\tGenerator loss: 0.8289937376976013, Discriminator loss: 1.3819847106933594\n",
      "\tGenerator loss: 0.8233863115310669, Discriminator loss: 1.3291728496551514\n",
      "\tGenerator loss: 0.8024129867553711, Discriminator loss: 1.3592095375061035\n",
      "\tGenerator loss: 0.7928334474563599, Discriminator loss: 1.395851969718933\n",
      "\tGenerator loss: 0.7997006177902222, Discriminator loss: 1.393446683883667\n",
      "\tGenerator loss: 0.8092374801635742, Discriminator loss: 1.3509408235549927\n",
      "\tGenerator loss: 0.8284496068954468, Discriminator loss: 1.3616434335708618\n",
      "\tGenerator loss: 0.8231792449951172, Discriminator loss: 1.3571066856384277\n",
      "\tGenerator loss: 0.8285027742385864, Discriminator loss: 1.358087420463562\n",
      "\tGenerator loss: 0.8235039710998535, Discriminator loss: 1.3331084251403809\n",
      "\tGenerator loss: 0.8036987781524658, Discriminator loss: 1.321473240852356\n",
      "\tGenerator loss: 0.7923521995544434, Discriminator loss: 1.309230089187622\n",
      "\tGenerator loss: 0.7960982918739319, Discriminator loss: 1.334778070449829\n",
      "\tGenerator loss: 0.8280128240585327, Discriminator loss: 1.319171667098999\n",
      "\tGenerator loss: 0.8521651029586792, Discriminator loss: 1.314441204071045\n",
      "\tGenerator loss: 0.8377030491828918, Discriminator loss: 1.3118863105773926\n",
      "\tGenerator loss: 0.850202202796936, Discriminator loss: 1.290987253189087\n",
      "\tGenerator loss: 0.8400914669036865, Discriminator loss: 1.2934868335723877\n",
      "\tGenerator loss: 0.8384842872619629, Discriminator loss: 1.2518178224563599\n",
      "\tGenerator loss: 0.8334097266197205, Discriminator loss: 1.2506725788116455\n",
      "\tGenerator loss: 0.8421683311462402, Discriminator loss: 1.2759119272232056\n",
      "\tGenerator loss: 0.863682746887207, Discriminator loss: 1.261481761932373\n",
      "\tGenerator loss: 0.88594651222229, Discriminator loss: 1.2589027881622314\n",
      "\tGenerator loss: 0.8986892700195312, Discriminator loss: 1.232686996459961\n",
      "\tGenerator loss: 0.9109426736831665, Discriminator loss: 1.201096534729004\n",
      "\tGenerator loss: 0.915672779083252, Discriminator loss: 1.1612778902053833\n",
      "\tGenerator loss: 0.9024754762649536, Discriminator loss: 1.1589949131011963\n",
      "\tGenerator loss: 0.8957860469818115, Discriminator loss: 1.134299874305725\n",
      "\tGenerator loss: 0.9042495489120483, Discriminator loss: 1.1032793521881104\n",
      "\tGenerator loss: 0.9223426580429077, Discriminator loss: 1.0900168418884277\n",
      "\tGenerator loss: 0.9613584876060486, Discriminator loss: 1.1505944728851318\n",
      "\tGenerator loss: 0.977118968963623, Discriminator loss: 1.1665678024291992\n",
      "\tGenerator loss: 0.9705042839050293, Discriminator loss: 1.1282026767730713\n",
      "\tGenerator loss: 0.9685760736465454, Discriminator loss: 1.1264877319335938\n",
      "\tGenerator loss: 0.9367407560348511, Discriminator loss: 1.104057788848877\n",
      "\tGenerator loss: 0.9354153871536255, Discriminator loss: 1.0966625213623047\n",
      "\tGenerator loss: 0.955698549747467, Discriminator loss: 1.0480868816375732\n",
      "\tGenerator loss: 0.9952878952026367, Discriminator loss: 1.0208019018173218\n",
      "\tGenerator loss: 1.0180456638336182, Discriminator loss: 1.0498594045639038\n",
      "\tGenerator loss: 1.0437196493148804, Discriminator loss: 1.0457220077514648\n",
      "\tGenerator loss: 1.0575165748596191, Discriminator loss: 1.057982087135315\n",
      "\tGenerator loss: 1.0324194431304932, Discriminator loss: 1.098949670791626\n",
      "\tGenerator loss: 0.9878494739532471, Discriminator loss: 1.0769150257110596\n",
      "\tGenerator loss: 0.974431037902832, Discriminator loss: 1.103851318359375\n",
      "\tGenerator loss: 0.9759401082992554, Discriminator loss: 1.061353325843811\n",
      "\tGenerator loss: 1.0188007354736328, Discriminator loss: 1.0157583951950073\n",
      "\tGenerator loss: 1.0788609981536865, Discriminator loss: 0.9934514760971069\n",
      "\tGenerator loss: 1.1197333335876465, Discriminator loss: 1.0289745330810547\n",
      "\tGenerator loss: 1.1231616735458374, Discriminator loss: 1.0157357454299927\n",
      "\tGenerator loss: 1.1011786460876465, Discriminator loss: 0.9947347044944763\n",
      "\tGenerator loss: 1.0566413402557373, Discriminator loss: 1.0123571157455444\n",
      "\tGenerator loss: 1.04940927028656, Discriminator loss: 0.97751784324646\n",
      "\tGenerator loss: 1.0451018810272217, Discriminator loss: 1.0374529361724854\n",
      "\tGenerator loss: 1.0301485061645508, Discriminator loss: 1.0217264890670776\n",
      "\tGenerator loss: 1.041767954826355, Discriminator loss: 1.0060791969299316\n",
      "\tGenerator loss: 1.0572855472564697, Discriminator loss: 1.0348575115203857\n",
      "\tGenerator loss: 1.0847078561782837, Discriminator loss: 1.014176368713379\n",
      "\tGenerator loss: 1.0713722705841064, Discriminator loss: 1.0134905576705933\n",
      "\tGenerator loss: 1.0855703353881836, Discriminator loss: 1.05660080909729\n",
      "\tGenerator loss: 1.064429521560669, Discriminator loss: 1.1132564544677734\n",
      "\tGenerator loss: 1.0035386085510254, Discriminator loss: 1.1099486351013184\n",
      "\tGenerator loss: 0.9908432364463806, Discriminator loss: 1.0872704982757568\n",
      "\tGenerator loss: 0.9624472260475159, Discriminator loss: 1.1775749921798706\n",
      "\tGenerator loss: 0.9442304968833923, Discriminator loss: 1.234748125076294\n",
      "\tGenerator loss: 0.9610686302185059, Discriminator loss: 1.2433513402938843\n",
      "\tGenerator loss: 0.9845502376556396, Discriminator loss: 1.3335022926330566\n",
      "\tGenerator loss: 0.9666244983673096, Discriminator loss: 1.304213523864746\n",
      "\tGenerator loss: 0.9340118765830994, Discriminator loss: 1.2701365947723389\n",
      "\tGenerator loss: 0.9291366338729858, Discriminator loss: 1.217665433883667\n",
      "\tGenerator loss: 0.931770920753479, Discriminator loss: 1.1907809972763062\n",
      "\tGenerator loss: 0.95502769947052, Discriminator loss: 1.1883301734924316\n",
      "\tGenerator loss: 0.9636945128440857, Discriminator loss: 1.1657500267028809\n",
      "\tGenerator loss: 0.9831794500350952, Discriminator loss: 1.1793326139450073\n",
      "\tGenerator loss: 0.9698383808135986, Discriminator loss: 1.1847577095031738\n",
      "\tGenerator loss: 0.9487950801849365, Discriminator loss: 1.1919384002685547\n",
      "\tGenerator loss: 0.9172118902206421, Discriminator loss: 1.265358805656433\n",
      "\tGenerator loss: 0.8702765703201294, Discriminator loss: 1.2582557201385498\n",
      "\tGenerator loss: 0.872665286064148, Discriminator loss: 1.2731475830078125\n",
      "\tGenerator loss: 0.9049729108810425, Discriminator loss: 1.2211627960205078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.977277934551239, Discriminator loss: 1.216627597808838\n",
      "\tGenerator loss: 1.0148760080337524, Discriminator loss: 1.2235281467437744\n",
      "\tGenerator loss: 0.9867841005325317, Discriminator loss: 1.2278504371643066\n",
      "\tGenerator loss: 0.9339505434036255, Discriminator loss: 1.2171380519866943\n",
      "\tGenerator loss: 0.8906319737434387, Discriminator loss: 1.227601408958435\n",
      "\tGenerator loss: 0.8876975178718567, Discriminator loss: 1.218240737915039\n",
      "\tGenerator loss: 0.9091156721115112, Discriminator loss: 1.1939187049865723\n",
      "\tGenerator loss: 0.9343799352645874, Discriminator loss: 1.1955070495605469\n",
      "\tGenerator loss: 0.9526145458221436, Discriminator loss: 1.1942191123962402\n",
      "\tGenerator loss: 0.9561806917190552, Discriminator loss: 1.2411370277404785\n",
      "\tGenerator loss: 0.9693303108215332, Discriminator loss: 1.2129898071289062\n",
      "\tGenerator loss: 0.9369093179702759, Discriminator loss: 1.2303342819213867\n",
      "\tGenerator loss: 0.9242357611656189, Discriminator loss: 1.2332335710525513\n",
      "\tGenerator loss: 0.9065696597099304, Discriminator loss: 1.2169511318206787\n",
      "\tGenerator loss: 0.8913843631744385, Discriminator loss: 1.2530457973480225\n",
      "\tGenerator loss: 0.8954529762268066, Discriminator loss: 1.2463147640228271\n",
      "\tGenerator loss: 0.9460412263870239, Discriminator loss: 1.1904411315917969\n",
      "\tGenerator loss: 0.9786350727081299, Discriminator loss: 1.2383155822753906\n",
      "\tGenerator loss: 0.9875098466873169, Discriminator loss: 1.2920688390731812\n",
      "\tGenerator loss: 0.9441975355148315, Discriminator loss: 1.2553901672363281\n",
      "\tGenerator loss: 0.8789582848548889, Discriminator loss: 1.2813278436660767\n",
      "\tGenerator loss: 0.8331702947616577, Discriminator loss: 1.2797741889953613\n",
      "\tGenerator loss: 0.8362607359886169, Discriminator loss: 1.254154086112976\n",
      "\tGenerator loss: 0.9007587432861328, Discriminator loss: 1.2583391666412354\n",
      "\tGenerator loss: 0.924971342086792, Discriminator loss: 1.2848232984542847\n",
      "\tGenerator loss: 0.9233996868133545, Discriminator loss: 1.2411599159240723\n",
      "\tGenerator loss: 0.9193878173828125, Discriminator loss: 1.2173937559127808\n",
      "\tGenerator loss: 0.8859848976135254, Discriminator loss: 1.2458767890930176\n",
      "\tGenerator loss: 0.8962054252624512, Discriminator loss: 1.19384765625\n",
      "\tGenerator loss: 0.9085391163825989, Discriminator loss: 1.1468782424926758\n",
      "\tGenerator loss: 0.9670083522796631, Discriminator loss: 1.1093051433563232\n",
      "\tGenerator loss: 1.0594969987869263, Discriminator loss: 1.1201562881469727\n",
      "\tGenerator loss: 1.124619483947754, Discriminator loss: 1.2360854148864746\n",
      "Time for epoch 14 is 334.01575803756714 sec\n",
      "\tGenerator loss: 1.059278964996338, Discriminator loss: 1.2139015197753906\n",
      "\tGenerator loss: 0.9387236833572388, Discriminator loss: 1.2176077365875244\n",
      "\tGenerator loss: 0.8159287571907043, Discriminator loss: 1.2414145469665527\n",
      "\tGenerator loss: 0.7590011954307556, Discriminator loss: 1.2369736433029175\n",
      "\tGenerator loss: 0.7786737680435181, Discriminator loss: 1.26576566696167\n",
      "\tGenerator loss: 0.8592888116836548, Discriminator loss: 1.2218722105026245\n",
      "\tGenerator loss: 0.9933438897132874, Discriminator loss: 1.224705457687378\n",
      "\tGenerator loss: 1.057045817375183, Discriminator loss: 1.1966328620910645\n",
      "\tGenerator loss: 1.0589207410812378, Discriminator loss: 1.1883660554885864\n",
      "\tGenerator loss: 1.0259015560150146, Discriminator loss: 1.1745035648345947\n",
      "\tGenerator loss: 0.9379671216011047, Discriminator loss: 1.1564292907714844\n",
      "\tGenerator loss: 0.8737464547157288, Discriminator loss: 1.1762222051620483\n",
      "\tGenerator loss: 0.8727478981018066, Discriminator loss: 1.1641428470611572\n",
      "\tGenerator loss: 0.8819713592529297, Discriminator loss: 1.1337480545043945\n",
      "\tGenerator loss: 0.9185850620269775, Discriminator loss: 1.1460740566253662\n",
      "\tGenerator loss: 0.9569294452667236, Discriminator loss: 1.1143736839294434\n",
      "\tGenerator loss: 1.0066331624984741, Discriminator loss: 1.119692087173462\n",
      "\tGenerator loss: 1.01240074634552, Discriminator loss: 1.1256515979766846\n",
      "\tGenerator loss: 0.9959439039230347, Discriminator loss: 1.1432216167449951\n",
      "\tGenerator loss: 0.979415774345398, Discriminator loss: 1.1352167129516602\n",
      "\tGenerator loss: 0.9127606749534607, Discriminator loss: 1.1055803298950195\n",
      "\tGenerator loss: 0.8987990617752075, Discriminator loss: 1.0880005359649658\n",
      "\tGenerator loss: 0.956359326839447, Discriminator loss: 1.081502914428711\n",
      "\tGenerator loss: 1.005757451057434, Discriminator loss: 1.0824733972549438\n",
      "\tGenerator loss: 1.0426506996154785, Discriminator loss: 1.081592082977295\n",
      "\tGenerator loss: 1.0482165813446045, Discriminator loss: 1.0695993900299072\n",
      "\tGenerator loss: 1.0232570171356201, Discriminator loss: 1.1139378547668457\n",
      "\tGenerator loss: 0.9800595045089722, Discriminator loss: 1.0753673315048218\n",
      "\tGenerator loss: 0.9444416761398315, Discriminator loss: 1.0659823417663574\n",
      "\tGenerator loss: 0.8981456160545349, Discriminator loss: 1.053301215171814\n",
      "\tGenerator loss: 0.899552583694458, Discriminator loss: 1.036936640739441\n",
      "\tGenerator loss: 0.9195816516876221, Discriminator loss: 1.0746104717254639\n",
      "\tGenerator loss: 1.0196095705032349, Discriminator loss: 1.0337169170379639\n",
      "\tGenerator loss: 1.0741407871246338, Discriminator loss: 1.1065409183502197\n",
      "\tGenerator loss: 1.091019630432129, Discriminator loss: 1.063387155532837\n",
      "\tGenerator loss: 1.0965176820755005, Discriminator loss: 1.0509634017944336\n",
      "\tGenerator loss: 1.040672779083252, Discriminator loss: 1.0468971729278564\n",
      "\tGenerator loss: 0.9989936947822571, Discriminator loss: 1.0709497928619385\n",
      "\tGenerator loss: 0.9587734937667847, Discriminator loss: 1.0153734683990479\n",
      "\tGenerator loss: 0.9340518116950989, Discriminator loss: 1.0261019468307495\n",
      "\tGenerator loss: 0.9746125936508179, Discriminator loss: 1.0654239654541016\n",
      "\tGenerator loss: 1.0470373630523682, Discriminator loss: 1.013891577720642\n",
      "\tGenerator loss: 1.129347801208496, Discriminator loss: 1.0443308353424072\n",
      "\tGenerator loss: 1.139560580253601, Discriminator loss: 1.0563875436782837\n",
      "\tGenerator loss: 1.104271650314331, Discriminator loss: 1.0578622817993164\n",
      "\tGenerator loss: 1.0621018409729004, Discriminator loss: 1.0416430234909058\n",
      "\tGenerator loss: 1.0074530839920044, Discriminator loss: 1.0711314678192139\n",
      "\tGenerator loss: 0.9418583512306213, Discriminator loss: 1.108009696006775\n",
      "\tGenerator loss: 0.9215972423553467, Discriminator loss: 1.1161551475524902\n",
      "\tGenerator loss: 0.9336131811141968, Discriminator loss: 1.0967795848846436\n",
      "\tGenerator loss: 1.0035762786865234, Discriminator loss: 1.1294217109680176\n",
      "\tGenerator loss: 1.0365824699401855, Discriminator loss: 1.1692122220993042\n",
      "\tGenerator loss: 1.0525283813476562, Discriminator loss: 1.1721398830413818\n",
      "\tGenerator loss: 1.0625088214874268, Discriminator loss: 1.1278481483459473\n",
      "\tGenerator loss: 1.0354430675506592, Discriminator loss: 1.143746018409729\n",
      "\tGenerator loss: 0.9828993678092957, Discriminator loss: 1.2699928283691406\n",
      "\tGenerator loss: 0.931793212890625, Discriminator loss: 1.2137866020202637\n",
      "\tGenerator loss: 0.8958264589309692, Discriminator loss: 1.250527024269104\n",
      "\tGenerator loss: 0.8870896697044373, Discriminator loss: 1.2068004608154297\n",
      "\tGenerator loss: 0.9095736742019653, Discriminator loss: 1.1642606258392334\n",
      "\tGenerator loss: 0.9659496545791626, Discriminator loss: 1.1387896537780762\n",
      "\tGenerator loss: 1.0079909563064575, Discriminator loss: 1.1308255195617676\n",
      "\tGenerator loss: 1.0519652366638184, Discriminator loss: 1.2515348196029663\n",
      "\tGenerator loss: 1.0213587284088135, Discriminator loss: 1.2811338901519775\n",
      "\tGenerator loss: 0.9408060908317566, Discriminator loss: 1.2565518617630005\n",
      "\tGenerator loss: 0.8576323390007019, Discriminator loss: 1.2406275272369385\n",
      "\tGenerator loss: 0.8404363393783569, Discriminator loss: 1.2713462114334106\n",
      "\tGenerator loss: 0.8690449595451355, Discriminator loss: 1.2236227989196777\n",
      "\tGenerator loss: 0.9011645913124084, Discriminator loss: 1.2022253274917603\n",
      "\tGenerator loss: 0.972758412361145, Discriminator loss: 1.2356231212615967\n",
      "\tGenerator loss: 1.009448766708374, Discriminator loss: 1.2554616928100586\n",
      "\tGenerator loss: 0.9922442436218262, Discriminator loss: 1.2919726371765137\n",
      "\tGenerator loss: 0.9372236728668213, Discriminator loss: 1.2705461978912354\n",
      "\tGenerator loss: 0.8841984868049622, Discriminator loss: 1.230593204498291\n",
      "\tGenerator loss: 0.8485546112060547, Discriminator loss: 1.2111252546310425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8688698410987854, Discriminator loss: 1.2543754577636719\n",
      "\tGenerator loss: 0.9321621060371399, Discriminator loss: 1.3304466009140015\n",
      "\tGenerator loss: 0.9696325063705444, Discriminator loss: 1.3087818622589111\n",
      "\tGenerator loss: 1.0399763584136963, Discriminator loss: 1.2602407932281494\n",
      "\tGenerator loss: 1.0197932720184326, Discriminator loss: 1.253008246421814\n",
      "\tGenerator loss: 0.9610944986343384, Discriminator loss: 1.2524805068969727\n",
      "\tGenerator loss: 0.9277141094207764, Discriminator loss: 1.2442452907562256\n",
      "\tGenerator loss: 0.9003275632858276, Discriminator loss: 1.1971580982208252\n",
      "\tGenerator loss: 0.9241144061088562, Discriminator loss: 1.189602017402649\n",
      "\tGenerator loss: 0.9886512756347656, Discriminator loss: 1.16056227684021\n",
      "\tGenerator loss: 1.0296214818954468, Discriminator loss: 1.2315754890441895\n",
      "\tGenerator loss: 1.0520391464233398, Discriminator loss: 1.1682207584381104\n",
      "\tGenerator loss: 1.0377161502838135, Discriminator loss: 1.1726245880126953\n",
      "\tGenerator loss: 0.9868987202644348, Discriminator loss: 1.2145342826843262\n",
      "\tGenerator loss: 0.9261430501937866, Discriminator loss: 1.2452878952026367\n",
      "\tGenerator loss: 0.914950430393219, Discriminator loss: 1.2353770732879639\n",
      "\tGenerator loss: 0.9387855529785156, Discriminator loss: 1.2117037773132324\n",
      "\tGenerator loss: 0.9690772294998169, Discriminator loss: 1.1798299551010132\n",
      "\tGenerator loss: 0.995945394039154, Discriminator loss: 1.1921839714050293\n",
      "\tGenerator loss: 1.0138202905654907, Discriminator loss: 1.2021511793136597\n",
      "\tGenerator loss: 1.0148510932922363, Discriminator loss: 1.196723461151123\n",
      "\tGenerator loss: 0.9711423516273499, Discriminator loss: 1.2279152870178223\n",
      "\tGenerator loss: 0.9668451547622681, Discriminator loss: 1.2410985231399536\n",
      "\tGenerator loss: 0.9364175200462341, Discriminator loss: 1.1943907737731934\n",
      "\tGenerator loss: 0.8958619832992554, Discriminator loss: 1.2387621402740479\n",
      "\tGenerator loss: 0.9267641305923462, Discriminator loss: 1.2874938249588013\n",
      "\tGenerator loss: 0.9639579653739929, Discriminator loss: 1.3125245571136475\n",
      "\tGenerator loss: 0.951802134513855, Discriminator loss: 1.2959263324737549\n",
      "\tGenerator loss: 0.9233093857765198, Discriminator loss: 1.3242838382720947\n",
      "\tGenerator loss: 0.8589434623718262, Discriminator loss: 1.3102149963378906\n",
      "\tGenerator loss: 0.8279658555984497, Discriminator loss: 1.329474925994873\n",
      "\tGenerator loss: 0.8516744375228882, Discriminator loss: 1.3219869136810303\n",
      "\tGenerator loss: 0.9152556657791138, Discriminator loss: 1.3289802074432373\n",
      "\tGenerator loss: 0.9355288147926331, Discriminator loss: 1.4089295864105225\n",
      "\tGenerator loss: 0.9110628366470337, Discriminator loss: 1.367110252380371\n",
      "\tGenerator loss: 0.8790214657783508, Discriminator loss: 1.3692340850830078\n",
      "\tGenerator loss: 0.8748464584350586, Discriminator loss: 1.359311580657959\n",
      "\tGenerator loss: 0.9018287658691406, Discriminator loss: 1.3730735778808594\n",
      "\tGenerator loss: 0.9144847989082336, Discriminator loss: 1.3944358825683594\n",
      "\tGenerator loss: 0.8752262592315674, Discriminator loss: 1.3874422311782837\n",
      "\tGenerator loss: 0.857582688331604, Discriminator loss: 1.3759013414382935\n",
      "\tGenerator loss: 0.8551234006881714, Discriminator loss: 1.4275245666503906\n",
      "\tGenerator loss: 0.8142874240875244, Discriminator loss: 1.4508854150772095\n",
      "\tGenerator loss: 0.7794978618621826, Discriminator loss: 1.3787424564361572\n",
      "\tGenerator loss: 0.7584528923034668, Discriminator loss: 1.436369776725769\n",
      "\tGenerator loss: 0.7624692320823669, Discriminator loss: 1.3830687999725342\n",
      "\tGenerator loss: 0.8186849355697632, Discriminator loss: 1.3557772636413574\n",
      "\tGenerator loss: 0.8526464104652405, Discriminator loss: 1.3828542232513428\n",
      "\tGenerator loss: 0.8848555088043213, Discriminator loss: 1.3903905153274536\n",
      "\tGenerator loss: 0.8312880396842957, Discriminator loss: 1.3411247730255127\n",
      "\tGenerator loss: 0.8252990245819092, Discriminator loss: 1.3144724369049072\n",
      "\tGenerator loss: 0.8301485180854797, Discriminator loss: 1.297964334487915\n",
      "\tGenerator loss: 0.8274333477020264, Discriminator loss: 1.303329586982727\n",
      "\tGenerator loss: 0.8334039449691772, Discriminator loss: 1.2559373378753662\n",
      "\tGenerator loss: 0.8798387050628662, Discriminator loss: 1.2427526712417603\n",
      "\tGenerator loss: 0.9361431002616882, Discriminator loss: 1.2325835227966309\n",
      "\tGenerator loss: 0.9573481678962708, Discriminator loss: 1.2155072689056396\n",
      "\tGenerator loss: 0.9341778755187988, Discriminator loss: 1.177257776260376\n",
      "\tGenerator loss: 0.889212965965271, Discriminator loss: 1.18026602268219\n",
      "\tGenerator loss: 0.8950808048248291, Discriminator loss: 1.113281488418579\n",
      "\tGenerator loss: 0.9143655300140381, Discriminator loss: 1.1214317083358765\n",
      "\tGenerator loss: 0.9125961065292358, Discriminator loss: 1.112933874130249\n",
      "\tGenerator loss: 0.9525481462478638, Discriminator loss: 1.1139800548553467\n",
      "\tGenerator loss: 0.9665110111236572, Discriminator loss: 1.1102811098098755\n",
      "\tGenerator loss: 0.9824048280715942, Discriminator loss: 1.0722131729125977\n",
      "\tGenerator loss: 1.0069537162780762, Discriminator loss: 1.0760010480880737\n",
      "\tGenerator loss: 0.9662688970565796, Discriminator loss: 1.0234944820404053\n",
      "\tGenerator loss: 0.9542627334594727, Discriminator loss: 1.027921438217163\n",
      "\tGenerator loss: 0.9788897037506104, Discriminator loss: 0.9928897619247437\n",
      "\tGenerator loss: 1.0389944314956665, Discriminator loss: 0.9556930661201477\n",
      "\tGenerator loss: 1.0840129852294922, Discriminator loss: 0.9575130939483643\n",
      "\tGenerator loss: 1.140070915222168, Discriminator loss: 0.9431954622268677\n",
      "\tGenerator loss: 1.127471923828125, Discriminator loss: 0.9714990258216858\n",
      "\tGenerator loss: 1.1136995553970337, Discriminator loss: 0.9393341541290283\n",
      "\tGenerator loss: 1.0693798065185547, Discriminator loss: 0.9339902997016907\n",
      "\tGenerator loss: 1.0465061664581299, Discriminator loss: 0.9253751039505005\n",
      "\tGenerator loss: 1.0302239656448364, Discriminator loss: 0.9090697765350342\n",
      "\tGenerator loss: 1.0627682209014893, Discriminator loss: 0.8623276948928833\n",
      "\tGenerator loss: 1.1251665353775024, Discriminator loss: 0.8884281516075134\n",
      "\tGenerator loss: 1.1691083908081055, Discriminator loss: 0.8671025037765503\n",
      "\tGenerator loss: 1.2097480297088623, Discriminator loss: 0.8993245959281921\n",
      "\tGenerator loss: 1.2237991094589233, Discriminator loss: 0.8892667293548584\n",
      "\tGenerator loss: 1.1781152486801147, Discriminator loss: 0.8715092539787292\n",
      "\tGenerator loss: 1.1226930618286133, Discriminator loss: 0.8761920928955078\n",
      "\tGenerator loss: 1.0941189527511597, Discriminator loss: 0.8364013433456421\n",
      "\tGenerator loss: 1.0773334503173828, Discriminator loss: 0.8277832865715027\n",
      "\tGenerator loss: 1.1289538145065308, Discriminator loss: 0.8371646404266357\n",
      "\tGenerator loss: 1.1744816303253174, Discriminator loss: 0.8493414521217346\n",
      "\tGenerator loss: 1.203690767288208, Discriminator loss: 0.8357497453689575\n",
      "\tGenerator loss: 1.2188379764556885, Discriminator loss: 0.8466067314147949\n",
      "\tGenerator loss: 1.2066311836242676, Discriminator loss: 0.8263902068138123\n",
      "\tGenerator loss: 1.2279196977615356, Discriminator loss: 0.8472402095794678\n",
      "\tGenerator loss: 1.2075555324554443, Discriminator loss: 0.835249125957489\n",
      "\tGenerator loss: 1.1986286640167236, Discriminator loss: 0.8000507354736328\n",
      "\tGenerator loss: 1.2138824462890625, Discriminator loss: 0.7930159568786621\n",
      "\tGenerator loss: 1.2317144870758057, Discriminator loss: 0.7939977645874023\n",
      "\tGenerator loss: 1.2465107440948486, Discriminator loss: 0.8104066848754883\n",
      "\tGenerator loss: 1.2553586959838867, Discriminator loss: 0.8223519921302795\n",
      "\tGenerator loss: 1.2327677011489868, Discriminator loss: 0.82694411277771\n",
      "\tGenerator loss: 1.1939977407455444, Discriminator loss: 0.8181159496307373\n",
      "\tGenerator loss: 1.2126507759094238, Discriminator loss: 0.8141586780548096\n",
      "\tGenerator loss: 1.1926698684692383, Discriminator loss: 0.8186320066452026\n",
      "\tGenerator loss: 1.206430196762085, Discriminator loss: 0.8219830989837646\n",
      "\tGenerator loss: 1.252817153930664, Discriminator loss: 0.8165249228477478\n",
      "\tGenerator loss: 1.2660958766937256, Discriminator loss: 0.8501948118209839\n",
      "\tGenerator loss: 1.2780027389526367, Discriminator loss: 0.8273042440414429\n",
      "\tGenerator loss: 1.230858564376831, Discriminator loss: 0.8388252258300781\n",
      "\tGenerator loss: 1.1872122287750244, Discriminator loss: 0.8334434032440186\n",
      "\tGenerator loss: 1.1684508323669434, Discriminator loss: 0.8768895864486694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1695886850357056, Discriminator loss: 0.8669902086257935\n",
      "\tGenerator loss: 1.2048871517181396, Discriminator loss: 0.9500128626823425\n",
      "\tGenerator loss: 1.2577625513076782, Discriminator loss: 0.968930721282959\n",
      "\tGenerator loss: 1.229140043258667, Discriminator loss: 0.9763683080673218\n",
      "\tGenerator loss: 1.209860920906067, Discriminator loss: 1.0199313163757324\n",
      "\tGenerator loss: 1.1724523305892944, Discriminator loss: 1.0252187252044678\n",
      "\tGenerator loss: 1.0939326286315918, Discriminator loss: 1.0192533731460571\n",
      "\tGenerator loss: 1.0636646747589111, Discriminator loss: 1.0126655101776123\n",
      "\tGenerator loss: 1.0567786693572998, Discriminator loss: 1.0304980278015137\n",
      "\tGenerator loss: 1.08061683177948, Discriminator loss: 1.0773260593414307\n",
      "\tGenerator loss: 1.100780963897705, Discriminator loss: 1.0227196216583252\n",
      "\tGenerator loss: 1.059814691543579, Discriminator loss: 1.0158476829528809\n",
      "\tGenerator loss: 1.0806246995925903, Discriminator loss: 1.0387136936187744\n",
      "\tGenerator loss: 1.0842957496643066, Discriminator loss: 1.0602073669433594\n",
      "\tGenerator loss: 1.0714117288589478, Discriminator loss: 1.0906260013580322\n",
      "\tGenerator loss: 1.0425505638122559, Discriminator loss: 1.1486551761627197\n",
      "\tGenerator loss: 1.0253715515136719, Discriminator loss: 1.2259471416473389\n",
      "\tGenerator loss: 0.9859362244606018, Discriminator loss: 1.173865556716919\n",
      "\tGenerator loss: 0.9553221464157104, Discriminator loss: 1.1767621040344238\n",
      "\tGenerator loss: 0.9483736753463745, Discriminator loss: 1.1960526704788208\n",
      "\tGenerator loss: 0.9306381940841675, Discriminator loss: 1.2069123983383179\n",
      "\tGenerator loss: 0.9201710224151611, Discriminator loss: 1.2221591472625732\n",
      "\tGenerator loss: 0.9589276313781738, Discriminator loss: 1.2642323970794678\n",
      "\tGenerator loss: 0.9627849459648132, Discriminator loss: 1.3460232019424438\n",
      "\tGenerator loss: 0.9478651285171509, Discriminator loss: 1.2792514562606812\n",
      "\tGenerator loss: 0.9193348288536072, Discriminator loss: 1.2564327716827393\n",
      "\tGenerator loss: 0.8866841793060303, Discriminator loss: 1.245581865310669\n",
      "\tGenerator loss: 0.8707348108291626, Discriminator loss: 1.2907203435897827\n",
      "\tGenerator loss: 0.8708308935165405, Discriminator loss: 1.3324730396270752\n",
      "\tGenerator loss: 0.8910783529281616, Discriminator loss: 1.4061524868011475\n",
      "\tGenerator loss: 0.9092588424682617, Discriminator loss: 1.4622578620910645\n",
      "\tGenerator loss: 0.9423099160194397, Discriminator loss: 1.4262193441390991\n",
      "\tGenerator loss: 0.886637806892395, Discriminator loss: 1.477168321609497\n",
      "\tGenerator loss: 0.7995378971099854, Discriminator loss: 1.6083636283874512\n",
      "\tGenerator loss: 0.7581160068511963, Discriminator loss: 1.5285542011260986\n",
      "\tGenerator loss: 0.739467978477478, Discriminator loss: 1.5536428689956665\n",
      "\tGenerator loss: 0.7894321084022522, Discriminator loss: 1.5285696983337402\n",
      "\tGenerator loss: 0.8435602188110352, Discriminator loss: 1.4919016361236572\n",
      "\tGenerator loss: 0.8714892864227295, Discriminator loss: 1.475856065750122\n",
      "\tGenerator loss: 0.8607286810874939, Discriminator loss: 1.5273089408874512\n",
      "\tGenerator loss: 0.828315019607544, Discriminator loss: 1.528362512588501\n",
      "\tGenerator loss: 0.7811861634254456, Discriminator loss: 1.4650065898895264\n",
      "\tGenerator loss: 0.7411023378372192, Discriminator loss: 1.5136624574661255\n",
      "\tGenerator loss: 0.7446094751358032, Discriminator loss: 1.5101845264434814\n",
      "\tGenerator loss: 0.7752202153205872, Discriminator loss: 1.5167300701141357\n",
      "\tGenerator loss: 0.8001722097396851, Discriminator loss: 1.460129976272583\n",
      "\tGenerator loss: 0.8244670629501343, Discriminator loss: 1.40324068069458\n",
      "\tGenerator loss: 0.8529558181762695, Discriminator loss: 1.5705158710479736\n",
      "\tGenerator loss: 0.8343096971511841, Discriminator loss: 1.6808656454086304\n",
      "\tGenerator loss: 0.8300477266311646, Discriminator loss: 1.6837794780731201\n",
      "\tGenerator loss: 0.7829582691192627, Discriminator loss: 1.639944076538086\n",
      "Time for epoch 15 is 233.66107439994812 sec\n",
      "\tGenerator loss: 0.7159995436668396, Discriminator loss: 1.6172523498535156\n",
      "\tGenerator loss: 0.6853511333465576, Discriminator loss: 1.5372194051742554\n",
      "\tGenerator loss: 0.6982382535934448, Discriminator loss: 1.5249302387237549\n",
      "\tGenerator loss: 0.7778897285461426, Discriminator loss: 1.4959954023361206\n",
      "\tGenerator loss: 0.8762490749359131, Discriminator loss: 1.5743091106414795\n",
      "\tGenerator loss: 0.9222397208213806, Discriminator loss: 1.6064255237579346\n",
      "\tGenerator loss: 0.8884974718093872, Discriminator loss: 1.4779117107391357\n",
      "\tGenerator loss: 0.8458225131034851, Discriminator loss: 1.4639374017715454\n",
      "\tGenerator loss: 0.8066213130950928, Discriminator loss: 1.3770310878753662\n",
      "\tGenerator loss: 0.8097348213195801, Discriminator loss: 1.3473857641220093\n",
      "\tGenerator loss: 0.8762626647949219, Discriminator loss: 1.311070442199707\n",
      "\tGenerator loss: 0.9491276741027832, Discriminator loss: 1.2834547758102417\n",
      "\tGenerator loss: 0.9954042434692383, Discriminator loss: 1.2571284770965576\n",
      "\tGenerator loss: 1.0061033964157104, Discriminator loss: 1.228392481803894\n",
      "\tGenerator loss: 0.9617526531219482, Discriminator loss: 1.1920064687728882\n",
      "\tGenerator loss: 0.9051285982131958, Discriminator loss: 1.175938367843628\n",
      "\tGenerator loss: 0.922579288482666, Discriminator loss: 1.125766634941101\n",
      "\tGenerator loss: 0.9637848138809204, Discriminator loss: 1.1047914028167725\n",
      "\tGenerator loss: 1.0524723529815674, Discriminator loss: 1.1090024709701538\n",
      "\tGenerator loss: 1.1184574365615845, Discriminator loss: 1.087083339691162\n",
      "\tGenerator loss: 1.1314911842346191, Discriminator loss: 1.0698648691177368\n",
      "\tGenerator loss: 1.1178113222122192, Discriminator loss: 1.058315396308899\n",
      "\tGenerator loss: 1.1004359722137451, Discriminator loss: 1.0352733135223389\n",
      "\tGenerator loss: 1.0491514205932617, Discriminator loss: 1.0452461242675781\n",
      "\tGenerator loss: 1.0303601026535034, Discriminator loss: 1.0253596305847168\n",
      "\tGenerator loss: 1.059514045715332, Discriminator loss: 0.9973581433296204\n",
      "\tGenerator loss: 1.1257915496826172, Discriminator loss: 1.0149301290512085\n",
      "\tGenerator loss: 1.1339293718338013, Discriminator loss: 1.0033618211746216\n",
      "\tGenerator loss: 1.1410561800003052, Discriminator loss: 1.0470309257507324\n",
      "\tGenerator loss: 1.0802028179168701, Discriminator loss: 1.0181881189346313\n",
      "\tGenerator loss: 1.0485366582870483, Discriminator loss: 0.9918897747993469\n",
      "\tGenerator loss: 1.0496740341186523, Discriminator loss: 0.9698877334594727\n",
      "\tGenerator loss: 1.0839850902557373, Discriminator loss: 0.9692009091377258\n",
      "\tGenerator loss: 1.1387648582458496, Discriminator loss: 0.9739648103713989\n",
      "\tGenerator loss: 1.222102165222168, Discriminator loss: 0.968948245048523\n",
      "\tGenerator loss: 1.2545909881591797, Discriminator loss: 0.9716623425483704\n",
      "\tGenerator loss: 1.2274585962295532, Discriminator loss: 0.9998070001602173\n",
      "\tGenerator loss: 1.158210039138794, Discriminator loss: 1.0290253162384033\n",
      "\tGenerator loss: 1.0955235958099365, Discriminator loss: 1.0084503889083862\n",
      "\tGenerator loss: 1.0307948589324951, Discriminator loss: 0.9921641945838928\n",
      "\tGenerator loss: 1.0261403322219849, Discriminator loss: 0.980120837688446\n",
      "\tGenerator loss: 1.1089738607406616, Discriminator loss: 0.9833498001098633\n",
      "\tGenerator loss: 1.1818403005599976, Discriminator loss: 1.0002295970916748\n",
      "\tGenerator loss: 1.2542473077774048, Discriminator loss: 1.0086228847503662\n",
      "\tGenerator loss: 1.2579150199890137, Discriminator loss: 1.0375256538391113\n",
      "\tGenerator loss: 1.1726925373077393, Discriminator loss: 1.0287370681762695\n",
      "\tGenerator loss: 1.060746669769287, Discriminator loss: 1.0127969980239868\n",
      "\tGenerator loss: 0.9993652701377869, Discriminator loss: 1.0290656089782715\n",
      "\tGenerator loss: 1.020210862159729, Discriminator loss: 1.021604061126709\n",
      "\tGenerator loss: 1.070378065109253, Discriminator loss: 1.0268880128860474\n",
      "\tGenerator loss: 1.1464658975601196, Discriminator loss: 1.062985897064209\n",
      "\tGenerator loss: 1.1611628532409668, Discriminator loss: 1.0398143529891968\n",
      "\tGenerator loss: 1.1862592697143555, Discriminator loss: 1.006195306777954\n",
      "\tGenerator loss: 1.1578131914138794, Discriminator loss: 1.0979225635528564\n",
      "\tGenerator loss: 1.0719913244247437, Discriminator loss: 1.1025631427764893\n",
      "\tGenerator loss: 1.0151554346084595, Discriminator loss: 1.0818556547164917\n",
      "\tGenerator loss: 0.9499626159667969, Discriminator loss: 1.1129682064056396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9539426565170288, Discriminator loss: 1.1980185508728027\n",
      "\tGenerator loss: 0.974156379699707, Discriminator loss: 1.1298437118530273\n",
      "\tGenerator loss: 1.0066429376602173, Discriminator loss: 1.110741376876831\n",
      "\tGenerator loss: 1.0264573097229004, Discriminator loss: 1.1091331243515015\n",
      "\tGenerator loss: 1.0545220375061035, Discriminator loss: 1.1120131015777588\n",
      "\tGenerator loss: 1.0712487697601318, Discriminator loss: 1.092154622077942\n",
      "\tGenerator loss: 1.0566456317901611, Discriminator loss: 1.0835151672363281\n",
      "\tGenerator loss: 1.062584400177002, Discriminator loss: 1.0413668155670166\n",
      "\tGenerator loss: 1.0395567417144775, Discriminator loss: 1.062269926071167\n",
      "\tGenerator loss: 1.0397608280181885, Discriminator loss: 1.0592166185379028\n",
      "\tGenerator loss: 1.0109177827835083, Discriminator loss: 1.033005952835083\n",
      "\tGenerator loss: 0.9881452918052673, Discriminator loss: 1.0904755592346191\n",
      "\tGenerator loss: 1.0025279521942139, Discriminator loss: 1.1092638969421387\n",
      "\tGenerator loss: 1.0533510446548462, Discriminator loss: 1.0439202785491943\n",
      "\tGenerator loss: 1.0805506706237793, Discriminator loss: 1.0518606901168823\n",
      "\tGenerator loss: 1.0910239219665527, Discriminator loss: 1.0243394374847412\n",
      "\tGenerator loss: 1.0840744972229004, Discriminator loss: 1.0000742673873901\n",
      "\tGenerator loss: 1.08544921875, Discriminator loss: 0.9772793054580688\n",
      "\tGenerator loss: 1.1297152042388916, Discriminator loss: 0.9777185916900635\n",
      "\tGenerator loss: 1.146113634109497, Discriminator loss: 0.997286319732666\n",
      "\tGenerator loss: 1.14296293258667, Discriminator loss: 1.0188862085342407\n",
      "\tGenerator loss: 1.136796474456787, Discriminator loss: 1.0479669570922852\n",
      "\tGenerator loss: 1.115755558013916, Discriminator loss: 1.004941463470459\n",
      "\tGenerator loss: 1.1156518459320068, Discriminator loss: 0.9701798558235168\n",
      "\tGenerator loss: 1.1226439476013184, Discriminator loss: 0.9629644751548767\n",
      "\tGenerator loss: 1.1170235872268677, Discriminator loss: 0.9617733359336853\n",
      "\tGenerator loss: 1.1294825077056885, Discriminator loss: 0.9906424283981323\n",
      "\tGenerator loss: 1.1644854545593262, Discriminator loss: 0.9785355925559998\n",
      "\tGenerator loss: 1.1478015184402466, Discriminator loss: 1.048256754875183\n",
      "\tGenerator loss: 1.1294220685958862, Discriminator loss: 1.0486676692962646\n",
      "\tGenerator loss: 1.080209732055664, Discriminator loss: 1.0154311656951904\n",
      "\tGenerator loss: 1.0387054681777954, Discriminator loss: 1.0333547592163086\n",
      "\tGenerator loss: 1.0347545146942139, Discriminator loss: 1.053491234779358\n",
      "\tGenerator loss: 1.0660929679870605, Discriminator loss: 1.0665690898895264\n",
      "\tGenerator loss: 1.07731032371521, Discriminator loss: 1.0785412788391113\n",
      "\tGenerator loss: 1.0668275356292725, Discriminator loss: 1.063842535018921\n",
      "\tGenerator loss: 1.0718402862548828, Discriminator loss: 1.0864259004592896\n",
      "\tGenerator loss: 1.1113256216049194, Discriminator loss: 1.0644268989562988\n",
      "\tGenerator loss: 1.0669746398925781, Discriminator loss: 1.0409157276153564\n",
      "\tGenerator loss: 1.0384820699691772, Discriminator loss: 1.0754995346069336\n",
      "\tGenerator loss: 1.0116405487060547, Discriminator loss: 1.1131293773651123\n",
      "\tGenerator loss: 0.9755972027778625, Discriminator loss: 1.1615538597106934\n",
      "\tGenerator loss: 0.9813886880874634, Discriminator loss: 1.2143105268478394\n",
      "\tGenerator loss: 0.9724127054214478, Discriminator loss: 1.206451177597046\n",
      "\tGenerator loss: 0.9820308685302734, Discriminator loss: 1.2112196683883667\n",
      "\tGenerator loss: 0.9699712991714478, Discriminator loss: 1.1566929817199707\n",
      "\tGenerator loss: 0.9364364147186279, Discriminator loss: 1.1856294870376587\n",
      "\tGenerator loss: 0.9205493330955505, Discriminator loss: 1.2354611158370972\n",
      "\tGenerator loss: 0.9300116300582886, Discriminator loss: 1.1890771389007568\n",
      "\tGenerator loss: 0.9804126620292664, Discriminator loss: 1.1882598400115967\n",
      "\tGenerator loss: 1.012621521949768, Discriminator loss: 1.2033345699310303\n",
      "\tGenerator loss: 1.0200302600860596, Discriminator loss: 1.2147729396820068\n",
      "\tGenerator loss: 0.9763387441635132, Discriminator loss: 1.2733901739120483\n",
      "\tGenerator loss: 0.935501217842102, Discriminator loss: 1.2856285572052002\n",
      "\tGenerator loss: 0.8872381448745728, Discriminator loss: 1.303647756576538\n",
      "\tGenerator loss: 0.8803168535232544, Discriminator loss: 1.2480220794677734\n",
      "\tGenerator loss: 0.8993701934814453, Discriminator loss: 1.2343515157699585\n",
      "\tGenerator loss: 0.9816405177116394, Discriminator loss: 1.2569303512573242\n",
      "\tGenerator loss: 1.019884467124939, Discriminator loss: 1.2144712209701538\n",
      "\tGenerator loss: 0.9979674816131592, Discriminator loss: 1.2257962226867676\n",
      "\tGenerator loss: 0.9467563629150391, Discriminator loss: 1.2217628955841064\n",
      "\tGenerator loss: 0.8875041007995605, Discriminator loss: 1.23319411277771\n",
      "\tGenerator loss: 0.8467166423797607, Discriminator loss: 1.2244455814361572\n",
      "\tGenerator loss: 0.8584534525871277, Discriminator loss: 1.227851390838623\n",
      "\tGenerator loss: 0.941834568977356, Discriminator loss: 1.1851344108581543\n",
      "\tGenerator loss: 1.0198688507080078, Discriminator loss: 1.1775375604629517\n",
      "\tGenerator loss: 1.0513368844985962, Discriminator loss: 1.1741304397583008\n",
      "\tGenerator loss: 1.0092804431915283, Discriminator loss: 1.166283130645752\n",
      "\tGenerator loss: 0.9639116525650024, Discriminator loss: 1.196118950843811\n",
      "\tGenerator loss: 0.9254231452941895, Discriminator loss: 1.1899816989898682\n",
      "\tGenerator loss: 0.9257489442825317, Discriminator loss: 1.1352688074111938\n",
      "\tGenerator loss: 0.9537836313247681, Discriminator loss: 1.1438181400299072\n",
      "\tGenerator loss: 1.037201166152954, Discriminator loss: 1.1307127475738525\n",
      "\tGenerator loss: 1.057428240776062, Discriminator loss: 1.1535069942474365\n",
      "\tGenerator loss: 1.087167739868164, Discriminator loss: 1.162980318069458\n",
      "\tGenerator loss: 1.035776972770691, Discriminator loss: 1.164846420288086\n",
      "\tGenerator loss: 0.9566363096237183, Discriminator loss: 1.1503313779830933\n",
      "\tGenerator loss: 0.900354266166687, Discriminator loss: 1.1192188262939453\n",
      "\tGenerator loss: 0.9379474520683289, Discriminator loss: 1.129150152206421\n",
      "\tGenerator loss: 1.032640814781189, Discriminator loss: 1.1159930229187012\n",
      "\tGenerator loss: 1.1505522727966309, Discriminator loss: 1.1261647939682007\n",
      "\tGenerator loss: 1.1046254634857178, Discriminator loss: 1.1154398918151855\n",
      "\tGenerator loss: 1.0522648096084595, Discriminator loss: 1.0750799179077148\n",
      "\tGenerator loss: 0.9699758291244507, Discriminator loss: 1.1277930736541748\n",
      "\tGenerator loss: 0.9142389893531799, Discriminator loss: 1.1234959363937378\n",
      "\tGenerator loss: 0.9275099039077759, Discriminator loss: 1.139925479888916\n",
      "\tGenerator loss: 1.0378789901733398, Discriminator loss: 1.1212337017059326\n",
      "\tGenerator loss: 1.1159305572509766, Discriminator loss: 1.1408275365829468\n",
      "\tGenerator loss: 1.1326653957366943, Discriminator loss: 1.097327709197998\n",
      "\tGenerator loss: 1.0921539068222046, Discriminator loss: 1.104373574256897\n",
      "\tGenerator loss: 1.017257809638977, Discriminator loss: 1.097989559173584\n",
      "\tGenerator loss: 0.945462703704834, Discriminator loss: 1.1286425590515137\n",
      "\tGenerator loss: 0.9393987059593201, Discriminator loss: 1.1531805992126465\n",
      "\tGenerator loss: 0.9501183032989502, Discriminator loss: 1.1659481525421143\n",
      "\tGenerator loss: 1.0243542194366455, Discriminator loss: 1.1400511264801025\n",
      "\tGenerator loss: 1.0403287410736084, Discriminator loss: 1.1401963233947754\n",
      "\tGenerator loss: 0.9995580315589905, Discriminator loss: 1.164495825767517\n",
      "\tGenerator loss: 0.9847979545593262, Discriminator loss: 1.1731507778167725\n",
      "\tGenerator loss: 0.9406450986862183, Discriminator loss: 1.2373218536376953\n",
      "\tGenerator loss: 0.8956602215766907, Discriminator loss: 1.224793553352356\n",
      "\tGenerator loss: 0.8731502890586853, Discriminator loss: 1.2098817825317383\n",
      "\tGenerator loss: 0.8724057674407959, Discriminator loss: 1.2217926979064941\n",
      "\tGenerator loss: 0.9153536558151245, Discriminator loss: 1.1979448795318604\n",
      "\tGenerator loss: 0.9771994352340698, Discriminator loss: 1.202744722366333\n",
      "\tGenerator loss: 1.0103731155395508, Discriminator loss: 1.2060420513153076\n",
      "\tGenerator loss: 1.0075310468673706, Discriminator loss: 1.2071574926376343\n",
      "\tGenerator loss: 0.9235246777534485, Discriminator loss: 1.2494111061096191\n",
      "\tGenerator loss: 0.8514844179153442, Discriminator loss: 1.256331205368042\n",
      "\tGenerator loss: 0.8105742931365967, Discriminator loss: 1.2339175939559937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8305795192718506, Discriminator loss: 1.2179160118103027\n",
      "\tGenerator loss: 0.9225785136222839, Discriminator loss: 1.2398300170898438\n",
      "\tGenerator loss: 0.9993644952774048, Discriminator loss: 1.2325422763824463\n",
      "\tGenerator loss: 1.0348906517028809, Discriminator loss: 1.2063500881195068\n",
      "\tGenerator loss: 1.013181447982788, Discriminator loss: 1.1924070119857788\n",
      "\tGenerator loss: 0.9204620122909546, Discriminator loss: 1.2062342166900635\n",
      "\tGenerator loss: 0.8759362697601318, Discriminator loss: 1.161821722984314\n",
      "\tGenerator loss: 0.8789107799530029, Discriminator loss: 1.1256206035614014\n",
      "\tGenerator loss: 0.9044004678726196, Discriminator loss: 1.1228539943695068\n",
      "\tGenerator loss: 0.9640948176383972, Discriminator loss: 1.1633623838424683\n",
      "\tGenerator loss: 1.0246973037719727, Discriminator loss: 1.1174516677856445\n",
      "\tGenerator loss: 1.0328246355056763, Discriminator loss: 1.1317367553710938\n",
      "\tGenerator loss: 1.0292589664459229, Discriminator loss: 1.1075711250305176\n",
      "\tGenerator loss: 0.9686994552612305, Discriminator loss: 1.119792103767395\n",
      "\tGenerator loss: 0.9322930574417114, Discriminator loss: 1.1225440502166748\n",
      "\tGenerator loss: 0.9117391109466553, Discriminator loss: 1.1032062768936157\n",
      "\tGenerator loss: 0.9594125151634216, Discriminator loss: 1.1127166748046875\n",
      "\tGenerator loss: 1.034489631652832, Discriminator loss: 1.1073811054229736\n",
      "\tGenerator loss: 1.0763349533081055, Discriminator loss: 1.1158596277236938\n",
      "\tGenerator loss: 1.05033278465271, Discriminator loss: 1.135098934173584\n",
      "\tGenerator loss: 1.0285892486572266, Discriminator loss: 1.1504979133605957\n",
      "\tGenerator loss: 0.9851530194282532, Discriminator loss: 1.1965436935424805\n",
      "\tGenerator loss: 0.9506689310073853, Discriminator loss: 1.221490502357483\n",
      "\tGenerator loss: 0.9425418972969055, Discriminator loss: 1.194148063659668\n",
      "\tGenerator loss: 0.9630262851715088, Discriminator loss: 1.1618458032608032\n",
      "\tGenerator loss: 1.0165965557098389, Discriminator loss: 1.1453542709350586\n",
      "\tGenerator loss: 1.0717791318893433, Discriminator loss: 1.1399250030517578\n",
      "\tGenerator loss: 1.08341383934021, Discriminator loss: 1.115871548652649\n",
      "\tGenerator loss: 1.0393589735031128, Discriminator loss: 1.0856518745422363\n",
      "\tGenerator loss: 0.995682418346405, Discriminator loss: 1.10770583152771\n",
      "\tGenerator loss: 0.9573527574539185, Discriminator loss: 1.1504004001617432\n",
      "\tGenerator loss: 0.9736549854278564, Discriminator loss: 1.149275541305542\n",
      "\tGenerator loss: 0.9992813467979431, Discriminator loss: 1.244725227355957\n",
      "\tGenerator loss: 1.0005300045013428, Discriminator loss: 1.217535376548767\n",
      "\tGenerator loss: 0.9701460599899292, Discriminator loss: 1.2281608581542969\n",
      "\tGenerator loss: 0.9557837247848511, Discriminator loss: 1.1608312129974365\n",
      "\tGenerator loss: 0.9636445045471191, Discriminator loss: 1.1559021472930908\n",
      "\tGenerator loss: 0.9758358597755432, Discriminator loss: 1.176557183265686\n",
      "\tGenerator loss: 1.017092227935791, Discriminator loss: 1.1815311908721924\n",
      "\tGenerator loss: 1.0004169940948486, Discriminator loss: 1.1760218143463135\n",
      "\tGenerator loss: 1.007651686668396, Discriminator loss: 1.1829323768615723\n",
      "\tGenerator loss: 0.9562508463859558, Discriminator loss: 1.219391107559204\n",
      "\tGenerator loss: 0.9266617298126221, Discriminator loss: 1.1685311794281006\n",
      "\tGenerator loss: 0.9156522154808044, Discriminator loss: 1.1897690296173096\n",
      "\tGenerator loss: 0.9837996959686279, Discriminator loss: 1.178370714187622\n",
      "\tGenerator loss: 1.028583288192749, Discriminator loss: 1.2040026187896729\n",
      "\tGenerator loss: 1.0339325666427612, Discriminator loss: 1.2280024290084839\n",
      "\tGenerator loss: 1.0247128009796143, Discriminator loss: 1.2277525663375854\n",
      "\tGenerator loss: 0.9643793106079102, Discriminator loss: 1.242293119430542\n",
      "\tGenerator loss: 0.9293289184570312, Discriminator loss: 1.234653353691101\n",
      "\tGenerator loss: 0.9139217138290405, Discriminator loss: 1.2671971321105957\n",
      "\tGenerator loss: 0.948793888092041, Discriminator loss: 1.3050934076309204\n",
      "\tGenerator loss: 0.988154411315918, Discriminator loss: 1.2675635814666748\n",
      "\tGenerator loss: 1.0227458477020264, Discriminator loss: 1.2541661262512207\n",
      "\tGenerator loss: 1.0291383266448975, Discriminator loss: 1.2443411350250244\n",
      "\tGenerator loss: 0.9540102481842041, Discriminator loss: 1.2211296558380127\n",
      "\tGenerator loss: 0.9520162343978882, Discriminator loss: 1.2072982788085938\n",
      "\tGenerator loss: 0.9722423553466797, Discriminator loss: 1.2036750316619873\n",
      "\tGenerator loss: 0.9934837222099304, Discriminator loss: 1.1909189224243164\n",
      "\tGenerator loss: 1.0502129793167114, Discriminator loss: 1.163694143295288\n",
      "\tGenerator loss: 1.0605688095092773, Discriminator loss: 1.188538908958435\n",
      "\tGenerator loss: 1.0528494119644165, Discriminator loss: 1.1500563621520996\n",
      "\tGenerator loss: 0.9944753646850586, Discriminator loss: 1.1512056589126587\n",
      "\tGenerator loss: 0.984399676322937, Discriminator loss: 1.1709030866622925\n",
      "\tGenerator loss: 0.9848926067352295, Discriminator loss: 1.1278576850891113\n",
      "\tGenerator loss: 1.050986409187317, Discriminator loss: 1.1238999366760254\n",
      "\tGenerator loss: 1.1474380493164062, Discriminator loss: 1.1276193857192993\n",
      "\tGenerator loss: 1.1857304573059082, Discriminator loss: 1.1456799507141113\n",
      "\tGenerator loss: 1.1758977174758911, Discriminator loss: 1.191892147064209\n",
      "Time for epoch 16 is 230.2227807044983 sec\n",
      "\tGenerator loss: 1.0035432577133179, Discriminator loss: 1.1983429193496704\n",
      "\tGenerator loss: 0.905121922492981, Discriminator loss: 1.1721861362457275\n",
      "\tGenerator loss: 0.8663970828056335, Discriminator loss: 1.1717934608459473\n",
      "\tGenerator loss: 0.9321842193603516, Discriminator loss: 1.1665668487548828\n",
      "\tGenerator loss: 1.0978507995605469, Discriminator loss: 1.197775959968567\n",
      "\tGenerator loss: 1.1854488849639893, Discriminator loss: 1.1704866886138916\n",
      "\tGenerator loss: 1.1609268188476562, Discriminator loss: 1.1265268325805664\n",
      "\tGenerator loss: 1.0819847583770752, Discriminator loss: 1.117113709449768\n",
      "\tGenerator loss: 0.9839307069778442, Discriminator loss: 1.0769031047821045\n",
      "\tGenerator loss: 0.9407355189323425, Discriminator loss: 1.0914711952209473\n",
      "\tGenerator loss: 0.9873666763305664, Discriminator loss: 1.0921663045883179\n",
      "\tGenerator loss: 1.0941699743270874, Discriminator loss: 1.1016812324523926\n",
      "\tGenerator loss: 1.1898040771484375, Discriminator loss: 1.1349345445632935\n",
      "\tGenerator loss: 1.1613383293151855, Discriminator loss: 1.1128644943237305\n",
      "\tGenerator loss: 1.1027326583862305, Discriminator loss: 1.088588833808899\n",
      "\tGenerator loss: 1.0086333751678467, Discriminator loss: 1.0694401264190674\n",
      "\tGenerator loss: 0.9275709390640259, Discriminator loss: 1.0949578285217285\n",
      "\tGenerator loss: 0.9487186670303345, Discriminator loss: 1.0827555656433105\n",
      "\tGenerator loss: 1.0421357154846191, Discriminator loss: 1.065185546875\n",
      "\tGenerator loss: 1.1406173706054688, Discriminator loss: 1.069376826286316\n",
      "\tGenerator loss: 1.2292985916137695, Discriminator loss: 1.0469049215316772\n",
      "\tGenerator loss: 1.2311943769454956, Discriminator loss: 1.0327885150909424\n",
      "\tGenerator loss: 1.15386962890625, Discriminator loss: 1.048756718635559\n",
      "\tGenerator loss: 1.049486517906189, Discriminator loss: 1.0420678853988647\n",
      "\tGenerator loss: 0.9884618520736694, Discriminator loss: 1.0383028984069824\n",
      "\tGenerator loss: 1.0137696266174316, Discriminator loss: 1.0354009866714478\n",
      "\tGenerator loss: 1.0818102359771729, Discriminator loss: 1.0977723598480225\n",
      "\tGenerator loss: 1.114350438117981, Discriminator loss: 1.0886614322662354\n",
      "\tGenerator loss: 1.0822176933288574, Discriminator loss: 1.1629828214645386\n",
      "\tGenerator loss: 1.0101394653320312, Discriminator loss: 1.1180695295333862\n",
      "\tGenerator loss: 0.9393651485443115, Discriminator loss: 1.1187098026275635\n",
      "\tGenerator loss: 0.9131051301956177, Discriminator loss: 1.1159398555755615\n",
      "\tGenerator loss: 0.9972660541534424, Discriminator loss: 1.0658886432647705\n",
      "\tGenerator loss: 1.077775478363037, Discriminator loss: 1.031082034111023\n",
      "\tGenerator loss: 1.1445032358169556, Discriminator loss: 1.07431161403656\n",
      "\tGenerator loss: 1.1904921531677246, Discriminator loss: 1.0637485980987549\n",
      "\tGenerator loss: 1.1494247913360596, Discriminator loss: 1.0800285339355469\n",
      "\tGenerator loss: 1.0480657815933228, Discriminator loss: 1.0970648527145386\n",
      "\tGenerator loss: 0.9833559393882751, Discriminator loss: 1.08262300491333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9124709367752075, Discriminator loss: 1.0976338386535645\n",
      "\tGenerator loss: 0.9618801474571228, Discriminator loss: 1.0493669509887695\n",
      "\tGenerator loss: 1.042169213294983, Discriminator loss: 1.054236650466919\n",
      "\tGenerator loss: 1.169609785079956, Discriminator loss: 1.0665591955184937\n",
      "\tGenerator loss: 1.2713615894317627, Discriminator loss: 1.0676243305206299\n",
      "\tGenerator loss: 1.2397719621658325, Discriminator loss: 1.0647777318954468\n",
      "\tGenerator loss: 1.1388030052185059, Discriminator loss: 1.0772240161895752\n",
      "\tGenerator loss: 1.0015791654586792, Discriminator loss: 1.069488525390625\n",
      "\tGenerator loss: 0.9216441512107849, Discriminator loss: 1.073464274406433\n",
      "\tGenerator loss: 0.9116811752319336, Discriminator loss: 1.1033225059509277\n",
      "\tGenerator loss: 0.9953083992004395, Discriminator loss: 1.0678874254226685\n",
      "\tGenerator loss: 1.0807543992996216, Discriminator loss: 1.0979187488555908\n",
      "\tGenerator loss: 1.1848225593566895, Discriminator loss: 1.13228440284729\n",
      "\tGenerator loss: 1.1772515773773193, Discriminator loss: 1.1127147674560547\n",
      "\tGenerator loss: 1.127073884010315, Discriminator loss: 1.1316431760787964\n",
      "\tGenerator loss: 1.054162859916687, Discriminator loss: 1.1399235725402832\n",
      "\tGenerator loss: 0.9857408404350281, Discriminator loss: 1.1607468128204346\n",
      "\tGenerator loss: 0.934399425983429, Discriminator loss: 1.1131020784378052\n",
      "\tGenerator loss: 0.9492913484573364, Discriminator loss: 1.1647546291351318\n",
      "\tGenerator loss: 0.9762027859687805, Discriminator loss: 1.0987849235534668\n",
      "\tGenerator loss: 1.0816527605056763, Discriminator loss: 1.0424017906188965\n",
      "\tGenerator loss: 1.197127103805542, Discriminator loss: 1.03365957736969\n",
      "\tGenerator loss: 1.2118737697601318, Discriminator loss: 1.0484943389892578\n",
      "\tGenerator loss: 1.17779541015625, Discriminator loss: 1.060682773590088\n",
      "\tGenerator loss: 1.0971451997756958, Discriminator loss: 1.034002661705017\n",
      "\tGenerator loss: 1.041109323501587, Discriminator loss: 0.9891204833984375\n",
      "\tGenerator loss: 1.0150868892669678, Discriminator loss: 1.0340921878814697\n",
      "\tGenerator loss: 1.0463268756866455, Discriminator loss: 1.0239830017089844\n",
      "\tGenerator loss: 1.1219298839569092, Discriminator loss: 1.0533733367919922\n",
      "\tGenerator loss: 1.199634075164795, Discriminator loss: 1.071256160736084\n",
      "\tGenerator loss: 1.1452544927597046, Discriminator loss: 1.027392864227295\n",
      "\tGenerator loss: 1.112363338470459, Discriminator loss: 0.979956328868866\n",
      "\tGenerator loss: 1.0602898597717285, Discriminator loss: 1.0229148864746094\n",
      "\tGenerator loss: 1.1046926975250244, Discriminator loss: 0.9924919605255127\n",
      "\tGenerator loss: 1.1620044708251953, Discriminator loss: 0.9670165181159973\n",
      "\tGenerator loss: 1.1949739456176758, Discriminator loss: 0.9413248300552368\n",
      "\tGenerator loss: 1.2099347114562988, Discriminator loss: 1.1069223880767822\n",
      "\tGenerator loss: 1.1702247858047485, Discriminator loss: 1.1798837184906006\n",
      "\tGenerator loss: 1.1081678867340088, Discriminator loss: 1.1950255632400513\n",
      "\tGenerator loss: 1.0688587427139282, Discriminator loss: 1.1787824630737305\n",
      "\tGenerator loss: 1.014570951461792, Discriminator loss: 1.160970687866211\n",
      "\tGenerator loss: 1.0133885145187378, Discriminator loss: 1.148921251296997\n",
      "\tGenerator loss: 1.0750410556793213, Discriminator loss: 1.136156439781189\n",
      "\tGenerator loss: 1.1489590406417847, Discriminator loss: 1.0922718048095703\n",
      "\tGenerator loss: 1.166872262954712, Discriminator loss: 1.1298385858535767\n",
      "\tGenerator loss: 1.1548640727996826, Discriminator loss: 1.0889348983764648\n",
      "\tGenerator loss: 1.1386990547180176, Discriminator loss: 1.1832375526428223\n",
      "\tGenerator loss: 1.107175588607788, Discriminator loss: 1.1308220624923706\n",
      "\tGenerator loss: 1.049300193786621, Discriminator loss: 1.1166746616363525\n",
      "\tGenerator loss: 1.0637377500534058, Discriminator loss: 1.2746243476867676\n",
      "\tGenerator loss: 1.0421173572540283, Discriminator loss: 1.3276700973510742\n",
      "\tGenerator loss: 1.009774088859558, Discriminator loss: 1.357651948928833\n",
      "\tGenerator loss: 1.0146493911743164, Discriminator loss: 1.271669864654541\n",
      "\tGenerator loss: 1.0255005359649658, Discriminator loss: 1.1480979919433594\n",
      "\tGenerator loss: 1.074599266052246, Discriminator loss: 1.1064046621322632\n",
      "\tGenerator loss: 1.1224933862686157, Discriminator loss: 1.1298527717590332\n",
      "\tGenerator loss: 1.1439599990844727, Discriminator loss: 1.1225934028625488\n",
      "\tGenerator loss: 1.1254271268844604, Discriminator loss: 1.1404953002929688\n",
      "\tGenerator loss: 1.085660457611084, Discriminator loss: 1.0857951641082764\n",
      "\tGenerator loss: 1.0740833282470703, Discriminator loss: 1.0793590545654297\n",
      "\tGenerator loss: 1.0850518941879272, Discriminator loss: 1.0977431535720825\n",
      "\tGenerator loss: 1.1580663919448853, Discriminator loss: 1.0543484687805176\n",
      "\tGenerator loss: 1.2148761749267578, Discriminator loss: 1.054819107055664\n",
      "\tGenerator loss: 1.2018463611602783, Discriminator loss: 1.0417091846466064\n",
      "\tGenerator loss: 1.1514708995819092, Discriminator loss: 1.0317950248718262\n",
      "\tGenerator loss: 1.098168969154358, Discriminator loss: 1.0143871307373047\n",
      "\tGenerator loss: 1.0759718418121338, Discriminator loss: 0.997627854347229\n",
      "\tGenerator loss: 1.1371500492095947, Discriminator loss: 1.0504422187805176\n",
      "\tGenerator loss: 1.1868577003479004, Discriminator loss: 1.0321755409240723\n",
      "\tGenerator loss: 1.2126142978668213, Discriminator loss: 0.994994044303894\n",
      "\tGenerator loss: 1.2107059955596924, Discriminator loss: 0.9824100732803345\n",
      "\tGenerator loss: 1.1532478332519531, Discriminator loss: 1.0442142486572266\n",
      "\tGenerator loss: 1.136431097984314, Discriminator loss: 1.0572185516357422\n",
      "\tGenerator loss: 1.1051826477050781, Discriminator loss: 1.0697956085205078\n",
      "\tGenerator loss: 1.141796350479126, Discriminator loss: 1.0544971227645874\n",
      "\tGenerator loss: 1.1728968620300293, Discriminator loss: 1.0563833713531494\n",
      "\tGenerator loss: 1.1752028465270996, Discriminator loss: 0.974018931388855\n",
      "\tGenerator loss: 1.172093152999878, Discriminator loss: 0.9905983805656433\n",
      "\tGenerator loss: 1.1338564157485962, Discriminator loss: 1.0636091232299805\n",
      "\tGenerator loss: 1.1160638332366943, Discriminator loss: 1.0062167644500732\n",
      "\tGenerator loss: 1.1164782047271729, Discriminator loss: 1.0436933040618896\n",
      "\tGenerator loss: 1.108760952949524, Discriminator loss: 1.0199158191680908\n",
      "\tGenerator loss: 1.1245007514953613, Discriminator loss: 1.0175565481185913\n",
      "\tGenerator loss: 1.1337717771530151, Discriminator loss: 1.052427053451538\n",
      "\tGenerator loss: 1.1268644332885742, Discriminator loss: 1.1050690412521362\n",
      "\tGenerator loss: 1.0776984691619873, Discriminator loss: 1.0434322357177734\n",
      "\tGenerator loss: 1.0671706199645996, Discriminator loss: 1.0482885837554932\n",
      "\tGenerator loss: 1.0529693365097046, Discriminator loss: 1.0952863693237305\n",
      "\tGenerator loss: 1.093489646911621, Discriminator loss: 1.087842583656311\n",
      "\tGenerator loss: 1.1149399280548096, Discriminator loss: 1.005086064338684\n",
      "\tGenerator loss: 1.10335373878479, Discriminator loss: 1.059758186340332\n",
      "\tGenerator loss: 1.1269558668136597, Discriminator loss: 1.1117907762527466\n",
      "\tGenerator loss: 1.090433120727539, Discriminator loss: 1.1325936317443848\n",
      "\tGenerator loss: 1.0326128005981445, Discriminator loss: 1.1586518287658691\n",
      "\tGenerator loss: 0.9872751832008362, Discriminator loss: 1.121652603149414\n",
      "\tGenerator loss: 0.9607809782028198, Discriminator loss: 1.151444435119629\n",
      "\tGenerator loss: 0.9763478636741638, Discriminator loss: 1.2272114753723145\n",
      "\tGenerator loss: 1.0253396034240723, Discriminator loss: 1.196584939956665\n",
      "\tGenerator loss: 1.0486042499542236, Discriminator loss: 1.2025986909866333\n",
      "\tGenerator loss: 1.0518852472305298, Discriminator loss: 1.234771966934204\n",
      "\tGenerator loss: 0.9872044920921326, Discriminator loss: 1.2008768320083618\n",
      "\tGenerator loss: 0.9459384679794312, Discriminator loss: 1.2509756088256836\n",
      "\tGenerator loss: 0.8955906629562378, Discriminator loss: 1.27399480342865\n",
      "\tGenerator loss: 0.9277507662773132, Discriminator loss: 1.238133430480957\n",
      "\tGenerator loss: 0.9108220338821411, Discriminator loss: 1.2459497451782227\n",
      "\tGenerator loss: 0.9713634252548218, Discriminator loss: 1.2207543849945068\n",
      "\tGenerator loss: 1.0484535694122314, Discriminator loss: 1.258509635925293\n",
      "\tGenerator loss: 1.0516927242279053, Discriminator loss: 1.2351969480514526\n",
      "\tGenerator loss: 1.0420690774917603, Discriminator loss: 1.22398042678833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9729505181312561, Discriminator loss: 1.2136198282241821\n",
      "\tGenerator loss: 0.9081200361251831, Discriminator loss: 1.24265718460083\n",
      "\tGenerator loss: 0.8638412356376648, Discriminator loss: 1.2896991968154907\n",
      "\tGenerator loss: 0.8744030594825745, Discriminator loss: 1.2236881256103516\n",
      "\tGenerator loss: 0.9284651279449463, Discriminator loss: 1.1994853019714355\n",
      "\tGenerator loss: 0.9771522879600525, Discriminator loss: 1.304084300994873\n",
      "\tGenerator loss: 1.0002714395523071, Discriminator loss: 1.326377511024475\n",
      "\tGenerator loss: 0.9570332765579224, Discriminator loss: 1.3084919452667236\n",
      "\tGenerator loss: 0.9173668622970581, Discriminator loss: 1.2773313522338867\n",
      "\tGenerator loss: 0.8244267106056213, Discriminator loss: 1.2992613315582275\n",
      "\tGenerator loss: 0.8323116302490234, Discriminator loss: 1.3266973495483398\n",
      "\tGenerator loss: 0.8458656072616577, Discriminator loss: 1.230798363685608\n",
      "\tGenerator loss: 0.9075525999069214, Discriminator loss: 1.2241342067718506\n",
      "\tGenerator loss: 0.9723702669143677, Discriminator loss: 1.2892980575561523\n",
      "\tGenerator loss: 1.0097579956054688, Discriminator loss: 1.3073796033859253\n",
      "\tGenerator loss: 0.9662004709243774, Discriminator loss: 1.3034543991088867\n",
      "\tGenerator loss: 0.8415564298629761, Discriminator loss: 1.4191943407058716\n",
      "\tGenerator loss: 0.7684136629104614, Discriminator loss: 1.404475212097168\n",
      "\tGenerator loss: 0.7780863642692566, Discriminator loss: 1.4416472911834717\n",
      "\tGenerator loss: 0.8117010593414307, Discriminator loss: 1.3563982248306274\n",
      "\tGenerator loss: 0.8679988980293274, Discriminator loss: 1.289337158203125\n",
      "\tGenerator loss: 0.9496077299118042, Discriminator loss: 1.3117443323135376\n",
      "\tGenerator loss: 1.0023226737976074, Discriminator loss: 1.3266346454620361\n",
      "\tGenerator loss: 0.9893312454223633, Discriminator loss: 1.2687044143676758\n",
      "\tGenerator loss: 0.9303963780403137, Discriminator loss: 1.2962546348571777\n",
      "\tGenerator loss: 0.9202961325645447, Discriminator loss: 1.2383277416229248\n",
      "\tGenerator loss: 0.8467835187911987, Discriminator loss: 1.2487304210662842\n",
      "\tGenerator loss: 0.8431601524353027, Discriminator loss: 1.346001148223877\n",
      "\tGenerator loss: 0.874125599861145, Discriminator loss: 1.3170820474624634\n",
      "\tGenerator loss: 0.9328550100326538, Discriminator loss: 1.275930643081665\n",
      "\tGenerator loss: 0.9509478807449341, Discriminator loss: 1.3232355117797852\n",
      "\tGenerator loss: 0.971610963344574, Discriminator loss: 1.3025453090667725\n",
      "\tGenerator loss: 0.9474040269851685, Discriminator loss: 1.2867366075515747\n",
      "\tGenerator loss: 0.8964473009109497, Discriminator loss: 1.317864179611206\n",
      "\tGenerator loss: 0.875770628452301, Discriminator loss: 1.3607347011566162\n",
      "\tGenerator loss: 0.861289381980896, Discriminator loss: 1.3728621006011963\n",
      "\tGenerator loss: 0.8707813024520874, Discriminator loss: 1.3200849294662476\n",
      "\tGenerator loss: 0.8948490023612976, Discriminator loss: 1.4319889545440674\n",
      "\tGenerator loss: 0.9028582572937012, Discriminator loss: 1.4798721075057983\n",
      "\tGenerator loss: 0.9019671082496643, Discriminator loss: 1.5186026096343994\n",
      "\tGenerator loss: 0.8741694688796997, Discriminator loss: 1.617091417312622\n",
      "\tGenerator loss: 0.8308931589126587, Discriminator loss: 1.545548439025879\n",
      "\tGenerator loss: 0.8334051966667175, Discriminator loss: 1.4983532428741455\n",
      "\tGenerator loss: 0.8278477191925049, Discriminator loss: 1.3977292776107788\n",
      "\tGenerator loss: 0.8928748369216919, Discriminator loss: 1.3212850093841553\n",
      "\tGenerator loss: 0.9370734691619873, Discriminator loss: 1.3086867332458496\n",
      "\tGenerator loss: 0.9903066158294678, Discriminator loss: 1.2601709365844727\n",
      "\tGenerator loss: 1.0191388130187988, Discriminator loss: 1.235168218612671\n",
      "\tGenerator loss: 1.0120011568069458, Discriminator loss: 1.197441577911377\n",
      "\tGenerator loss: 0.9726404547691345, Discriminator loss: 1.177409052848816\n",
      "\tGenerator loss: 0.96567702293396, Discriminator loss: 1.2142208814620972\n",
      "\tGenerator loss: 0.9564657807350159, Discriminator loss: 1.168694257736206\n",
      "\tGenerator loss: 0.985815167427063, Discriminator loss: 1.1539275646209717\n",
      "\tGenerator loss: 1.0347299575805664, Discriminator loss: 1.0849090814590454\n",
      "\tGenerator loss: 1.0936850309371948, Discriminator loss: 1.0648102760314941\n",
      "\tGenerator loss: 1.1688332557678223, Discriminator loss: 0.9993895292282104\n",
      "\tGenerator loss: 1.18833327293396, Discriminator loss: 0.9895265102386475\n",
      "\tGenerator loss: 1.1608104705810547, Discriminator loss: 0.9661896228790283\n",
      "\tGenerator loss: 1.1204091310501099, Discriminator loss: 0.9327367544174194\n",
      "\tGenerator loss: 1.132116675376892, Discriminator loss: 0.9158952236175537\n",
      "\tGenerator loss: 1.1586241722106934, Discriminator loss: 0.882910966873169\n",
      "\tGenerator loss: 1.2566120624542236, Discriminator loss: 0.8576241135597229\n",
      "\tGenerator loss: 1.333513855934143, Discriminator loss: 0.8151237964630127\n",
      "\tGenerator loss: 1.3632816076278687, Discriminator loss: 0.8069390058517456\n",
      "\tGenerator loss: 1.3333098888397217, Discriminator loss: 0.7998137474060059\n",
      "\tGenerator loss: 1.28087317943573, Discriminator loss: 0.8151516914367676\n",
      "\tGenerator loss: 1.2649595737457275, Discriminator loss: 0.8068863153457642\n",
      "\tGenerator loss: 1.2676507234573364, Discriminator loss: 0.7901454567909241\n",
      "\tGenerator loss: 1.2865684032440186, Discriminator loss: 0.7766025066375732\n",
      "\tGenerator loss: 1.3663140535354614, Discriminator loss: 0.7793070673942566\n",
      "\tGenerator loss: 1.4296255111694336, Discriminator loss: 0.7509763240814209\n",
      "\tGenerator loss: 1.477552056312561, Discriminator loss: 0.7507957220077515\n",
      "\tGenerator loss: 1.4414076805114746, Discriminator loss: 0.7732648849487305\n",
      "\tGenerator loss: 1.3531978130340576, Discriminator loss: 0.8063148856163025\n",
      "\tGenerator loss: 1.2946343421936035, Discriminator loss: 0.8005279302597046\n",
      "\tGenerator loss: 1.2608814239501953, Discriminator loss: 0.7801368236541748\n",
      "\tGenerator loss: 1.2874571084976196, Discriminator loss: 0.7577979564666748\n",
      "\tGenerator loss: 1.3594985008239746, Discriminator loss: 0.7989996671676636\n",
      "\tGenerator loss: 1.4262405633926392, Discriminator loss: 0.8278666734695435\n",
      "\tGenerator loss: 1.3893849849700928, Discriminator loss: 0.7896134853363037\n",
      "\tGenerator loss: 1.3243134021759033, Discriminator loss: 0.7990096807479858\n",
      "\tGenerator loss: 1.2932469844818115, Discriminator loss: 0.8035045266151428\n",
      "\tGenerator loss: 1.291454792022705, Discriminator loss: 0.7900153398513794\n",
      "\tGenerator loss: 1.32472825050354, Discriminator loss: 0.7672603726387024\n",
      "\tGenerator loss: 1.3640602827072144, Discriminator loss: 0.8035494089126587\n",
      "\tGenerator loss: 1.4660851955413818, Discriminator loss: 0.8274697065353394\n",
      "\tGenerator loss: 1.4949114322662354, Discriminator loss: 0.9125494956970215\n",
      "Time for epoch 17 is 499.22456789016724 sec\n",
      "\tGenerator loss: 1.3801028728485107, Discriminator loss: 0.9374002814292908\n",
      "\tGenerator loss: 1.1898224353790283, Discriminator loss: 0.9860678911209106\n",
      "\tGenerator loss: 1.0719530582427979, Discriminator loss: 1.0037150382995605\n",
      "\tGenerator loss: 1.107319712638855, Discriminator loss: 0.9988808035850525\n",
      "\tGenerator loss: 1.2146649360656738, Discriminator loss: 1.0342907905578613\n",
      "\tGenerator loss: 1.3251676559448242, Discriminator loss: 0.9871362447738647\n",
      "\tGenerator loss: 1.3184423446655273, Discriminator loss: 1.0308588743209839\n",
      "\tGenerator loss: 1.2770724296569824, Discriminator loss: 1.0480629205703735\n",
      "\tGenerator loss: 1.1873316764831543, Discriminator loss: 1.0584256649017334\n",
      "\tGenerator loss: 1.1227049827575684, Discriminator loss: 1.0707345008850098\n",
      "\tGenerator loss: 1.0917835235595703, Discriminator loss: 1.1033210754394531\n",
      "\tGenerator loss: 1.1256301403045654, Discriminator loss: 1.0964537858963013\n",
      "\tGenerator loss: 1.1731525659561157, Discriminator loss: 1.1173462867736816\n",
      "\tGenerator loss: 1.1618947982788086, Discriminator loss: 1.1031885147094727\n",
      "\tGenerator loss: 1.1119626760482788, Discriminator loss: 1.138085961341858\n",
      "\tGenerator loss: 1.0424914360046387, Discriminator loss: 1.138822317123413\n",
      "\tGenerator loss: 1.0180246829986572, Discriminator loss: 1.147524118423462\n",
      "\tGenerator loss: 0.9988564848899841, Discriminator loss: 1.2024633884429932\n",
      "\tGenerator loss: 1.0467559099197388, Discriminator loss: 1.2259818315505981\n",
      "\tGenerator loss: 1.072864294052124, Discriminator loss: 1.2199006080627441\n",
      "\tGenerator loss: 1.0721858739852905, Discriminator loss: 1.1362943649291992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0291497707366943, Discriminator loss: 1.1345129013061523\n",
      "\tGenerator loss: 1.0315126180648804, Discriminator loss: 1.1429132223129272\n",
      "\tGenerator loss: 1.0654118061065674, Discriminator loss: 1.1221261024475098\n",
      "\tGenerator loss: 1.0889379978179932, Discriminator loss: 1.1411573886871338\n",
      "\tGenerator loss: 1.101294994354248, Discriminator loss: 1.1284549236297607\n",
      "\tGenerator loss: 1.068058967590332, Discriminator loss: 1.1828436851501465\n",
      "\tGenerator loss: 1.011212706565857, Discriminator loss: 1.160064697265625\n",
      "\tGenerator loss: 0.9283735156059265, Discriminator loss: 1.21843421459198\n",
      "\tGenerator loss: 0.8910201787948608, Discriminator loss: 1.2024211883544922\n",
      "\tGenerator loss: 0.8834913372993469, Discriminator loss: 1.1767555475234985\n",
      "\tGenerator loss: 0.9443397521972656, Discriminator loss: 1.1855757236480713\n",
      "\tGenerator loss: 1.0556588172912598, Discriminator loss: 1.1363165378570557\n",
      "\tGenerator loss: 1.1133993864059448, Discriminator loss: 1.2079746723175049\n",
      "\tGenerator loss: 1.086836814880371, Discriminator loss: 1.1979789733886719\n",
      "\tGenerator loss: 0.9917963743209839, Discriminator loss: 1.1987192630767822\n",
      "\tGenerator loss: 0.9393876194953918, Discriminator loss: 1.1810359954833984\n",
      "\tGenerator loss: 0.9108952283859253, Discriminator loss: 1.2362608909606934\n",
      "\tGenerator loss: 0.9072591066360474, Discriminator loss: 1.167075753211975\n",
      "\tGenerator loss: 0.9490487575531006, Discriminator loss: 1.189920425415039\n",
      "\tGenerator loss: 1.0191264152526855, Discriminator loss: 1.2020833492279053\n",
      "\tGenerator loss: 1.1089643239974976, Discriminator loss: 1.1575753688812256\n",
      "\tGenerator loss: 1.1062219142913818, Discriminator loss: 1.1854004859924316\n",
      "\tGenerator loss: 1.0503833293914795, Discriminator loss: 1.1950052976608276\n",
      "\tGenerator loss: 0.9578053951263428, Discriminator loss: 1.200680136680603\n",
      "\tGenerator loss: 0.91078782081604, Discriminator loss: 1.214902400970459\n",
      "\tGenerator loss: 0.874199628829956, Discriminator loss: 1.2558081150054932\n",
      "\tGenerator loss: 0.9095380306243896, Discriminator loss: 1.2341015338897705\n",
      "\tGenerator loss: 0.9569432735443115, Discriminator loss: 1.2570708990097046\n",
      "\tGenerator loss: 0.9869077801704407, Discriminator loss: 1.2427995204925537\n",
      "\tGenerator loss: 1.0047448873519897, Discriminator loss: 1.3292796611785889\n",
      "\tGenerator loss: 0.9709017872810364, Discriminator loss: 1.3523287773132324\n",
      "\tGenerator loss: 0.8736681938171387, Discriminator loss: 1.36659574508667\n",
      "\tGenerator loss: 0.8221327066421509, Discriminator loss: 1.3592685461044312\n",
      "\tGenerator loss: 0.8506380915641785, Discriminator loss: 1.3730671405792236\n",
      "\tGenerator loss: 0.8800739049911499, Discriminator loss: 1.449296236038208\n",
      "\tGenerator loss: 0.905877411365509, Discriminator loss: 1.412826657295227\n",
      "\tGenerator loss: 0.9370992183685303, Discriminator loss: 1.474424123764038\n",
      "\tGenerator loss: 0.8553966283798218, Discriminator loss: 1.4145400524139404\n",
      "\tGenerator loss: 0.8216517567634583, Discriminator loss: 1.3501214981079102\n",
      "\tGenerator loss: 0.8000497817993164, Discriminator loss: 1.3748316764831543\n",
      "\tGenerator loss: 0.8597974181175232, Discriminator loss: 1.3473923206329346\n",
      "\tGenerator loss: 0.9300466775894165, Discriminator loss: 1.466138243675232\n",
      "\tGenerator loss: 0.916043221950531, Discriminator loss: 1.4777462482452393\n",
      "\tGenerator loss: 0.8475347757339478, Discriminator loss: 1.420876145362854\n",
      "\tGenerator loss: 0.7963552474975586, Discriminator loss: 1.4187994003295898\n",
      "\tGenerator loss: 0.7928079962730408, Discriminator loss: 1.4378842115402222\n",
      "\tGenerator loss: 0.8126329183578491, Discriminator loss: 1.4332687854766846\n",
      "\tGenerator loss: 0.8928549289703369, Discriminator loss: 1.4299945831298828\n",
      "\tGenerator loss: 0.9096480011940002, Discriminator loss: 1.4575752019882202\n",
      "\tGenerator loss: 0.8584696054458618, Discriminator loss: 1.4122593402862549\n",
      "\tGenerator loss: 0.8128383159637451, Discriminator loss: 1.4510579109191895\n",
      "\tGenerator loss: 0.7894971370697021, Discriminator loss: 1.4294514656066895\n",
      "\tGenerator loss: 0.8068641424179077, Discriminator loss: 1.3948581218719482\n",
      "\tGenerator loss: 0.8513163328170776, Discriminator loss: 1.4148050546646118\n",
      "\tGenerator loss: 0.9142812490463257, Discriminator loss: 1.4033942222595215\n",
      "\tGenerator loss: 0.9585855603218079, Discriminator loss: 1.4015321731567383\n",
      "\tGenerator loss: 0.9435667991638184, Discriminator loss: 1.3705165386199951\n",
      "\tGenerator loss: 0.9055647850036621, Discriminator loss: 1.3844634294509888\n",
      "\tGenerator loss: 0.8966856002807617, Discriminator loss: 1.3709497451782227\n",
      "\tGenerator loss: 0.879826009273529, Discriminator loss: 1.3551303148269653\n",
      "\tGenerator loss: 0.8744322657585144, Discriminator loss: 1.3763946294784546\n",
      "\tGenerator loss: 0.8872843980789185, Discriminator loss: 1.3411169052124023\n",
      "\tGenerator loss: 0.8902525305747986, Discriminator loss: 1.311989665031433\n",
      "\tGenerator loss: 0.902042031288147, Discriminator loss: 1.3084077835083008\n",
      "\tGenerator loss: 0.9344275593757629, Discriminator loss: 1.2848143577575684\n",
      "\tGenerator loss: 0.9814903736114502, Discriminator loss: 1.2902896404266357\n",
      "\tGenerator loss: 1.0066388845443726, Discriminator loss: 1.2724720239639282\n",
      "\tGenerator loss: 0.9661431312561035, Discriminator loss: 1.278916835784912\n",
      "\tGenerator loss: 0.9246753454208374, Discriminator loss: 1.2605221271514893\n",
      "\tGenerator loss: 0.9118245244026184, Discriminator loss: 1.256150484085083\n",
      "\tGenerator loss: 0.9429702162742615, Discriminator loss: 1.2417041063308716\n",
      "\tGenerator loss: 0.9735537767410278, Discriminator loss: 1.2328946590423584\n",
      "\tGenerator loss: 1.0045474767684937, Discriminator loss: 1.1990280151367188\n",
      "\tGenerator loss: 1.006639003753662, Discriminator loss: 1.2185274362564087\n",
      "\tGenerator loss: 0.9904912710189819, Discriminator loss: 1.1967926025390625\n",
      "\tGenerator loss: 0.9750407338142395, Discriminator loss: 1.1688613891601562\n",
      "\tGenerator loss: 0.9726961851119995, Discriminator loss: 1.170297384262085\n",
      "\tGenerator loss: 0.9845376014709473, Discriminator loss: 1.1316004991531372\n",
      "\tGenerator loss: 1.0241340398788452, Discriminator loss: 1.1248500347137451\n",
      "\tGenerator loss: 1.0731174945831299, Discriminator loss: 1.1177501678466797\n",
      "\tGenerator loss: 1.1059365272521973, Discriminator loss: 1.1331849098205566\n",
      "\tGenerator loss: 1.0696090459823608, Discriminator loss: 1.1090625524520874\n",
      "\tGenerator loss: 1.0086277723312378, Discriminator loss: 1.1709034442901611\n",
      "\tGenerator loss: 0.9735734462738037, Discriminator loss: 1.122441053390503\n",
      "\tGenerator loss: 0.9409052133560181, Discriminator loss: 1.1002037525177002\n",
      "\tGenerator loss: 0.9772909283638, Discriminator loss: 1.095386266708374\n",
      "\tGenerator loss: 1.031887412071228, Discriminator loss: 1.0669212341308594\n",
      "\tGenerator loss: 1.1185309886932373, Discriminator loss: 1.076974630355835\n",
      "\tGenerator loss: 1.1538598537445068, Discriminator loss: 1.0424753427505493\n",
      "\tGenerator loss: 1.1486384868621826, Discriminator loss: 1.044830560684204\n",
      "\tGenerator loss: 1.1468132734298706, Discriminator loss: 1.0365934371948242\n",
      "\tGenerator loss: 1.1066040992736816, Discriminator loss: 1.0364998579025269\n",
      "\tGenerator loss: 1.1028717756271362, Discriminator loss: 1.0254194736480713\n",
      "\tGenerator loss: 1.0964446067810059, Discriminator loss: 1.0373426675796509\n",
      "\tGenerator loss: 1.07551908493042, Discriminator loss: 0.9883976578712463\n",
      "\tGenerator loss: 1.1274453401565552, Discriminator loss: 1.0296971797943115\n",
      "\tGenerator loss: 1.1487197875976562, Discriminator loss: 1.0105698108673096\n",
      "\tGenerator loss: 1.1430904865264893, Discriminator loss: 0.9597612619400024\n",
      "\tGenerator loss: 1.1018155813217163, Discriminator loss: 0.9996959567070007\n",
      "\tGenerator loss: 1.121109962463379, Discriminator loss: 0.9592489004135132\n",
      "\tGenerator loss: 1.1213431358337402, Discriminator loss: 0.9267793893814087\n",
      "\tGenerator loss: 1.162158727645874, Discriminator loss: 0.9192788600921631\n",
      "\tGenerator loss: 1.2366747856140137, Discriminator loss: 0.9286589622497559\n",
      "\tGenerator loss: 1.3058884143829346, Discriminator loss: 0.8887200355529785\n",
      "\tGenerator loss: 1.2923403978347778, Discriminator loss: 0.8819719552993774\n",
      "\tGenerator loss: 1.2671515941619873, Discriminator loss: 0.8957962393760681\n",
      "\tGenerator loss: 1.250326156616211, Discriminator loss: 0.8760635852813721\n",
      "\tGenerator loss: 1.221935510635376, Discriminator loss: 0.8588709831237793\n",
      "\tGenerator loss: 1.28459894657135, Discriminator loss: 0.8771849274635315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.3514058589935303, Discriminator loss: 0.8536235690116882\n",
      "\tGenerator loss: 1.382513165473938, Discriminator loss: 0.8814073801040649\n",
      "\tGenerator loss: 1.3549222946166992, Discriminator loss: 0.8848307132720947\n",
      "\tGenerator loss: 1.3140653371810913, Discriminator loss: 0.83579021692276\n",
      "\tGenerator loss: 1.2671146392822266, Discriminator loss: 0.8584389686584473\n",
      "\tGenerator loss: 1.2503150701522827, Discriminator loss: 0.896740198135376\n",
      "\tGenerator loss: 1.264075756072998, Discriminator loss: 0.8874111175537109\n",
      "\tGenerator loss: 1.3196938037872314, Discriminator loss: 0.8304603695869446\n",
      "\tGenerator loss: 1.3531665802001953, Discriminator loss: 0.8825922012329102\n",
      "\tGenerator loss: 1.3611308336257935, Discriminator loss: 0.8689641356468201\n",
      "\tGenerator loss: 1.347013235092163, Discriminator loss: 0.864254891872406\n",
      "\tGenerator loss: 1.3025513887405396, Discriminator loss: 0.9835330247879028\n",
      "\tGenerator loss: 1.2587916851043701, Discriminator loss: 0.973103404045105\n",
      "\tGenerator loss: 1.2094197273254395, Discriminator loss: 1.0471422672271729\n",
      "\tGenerator loss: 1.1902825832366943, Discriminator loss: 1.0204765796661377\n",
      "\tGenerator loss: 1.1618901491165161, Discriminator loss: 1.0764058828353882\n",
      "\tGenerator loss: 1.2075109481811523, Discriminator loss: 1.0227651596069336\n",
      "\tGenerator loss: 1.2329257726669312, Discriminator loss: 0.9935097098350525\n",
      "\tGenerator loss: 1.2608916759490967, Discriminator loss: 0.9668382406234741\n",
      "\tGenerator loss: 1.2135151624679565, Discriminator loss: 0.9922202825546265\n",
      "\tGenerator loss: 1.2034825086593628, Discriminator loss: 1.002469539642334\n",
      "\tGenerator loss: 1.201771855354309, Discriminator loss: 0.9906315803527832\n",
      "\tGenerator loss: 1.2082111835479736, Discriminator loss: 1.0121194124221802\n",
      "\tGenerator loss: 1.1972501277923584, Discriminator loss: 1.0820738077163696\n",
      "\tGenerator loss: 1.159623384475708, Discriminator loss: 1.0815067291259766\n",
      "\tGenerator loss: 1.1479504108428955, Discriminator loss: 1.0536417961120605\n",
      "\tGenerator loss: 1.1254695653915405, Discriminator loss: 1.053490161895752\n",
      "\tGenerator loss: 1.1653201580047607, Discriminator loss: 1.048776388168335\n",
      "\tGenerator loss: 1.216628074645996, Discriminator loss: 1.090364694595337\n",
      "\tGenerator loss: 1.2059967517852783, Discriminator loss: 1.0409311056137085\n",
      "\tGenerator loss: 1.1355265378952026, Discriminator loss: 1.0632400512695312\n",
      "\tGenerator loss: 1.1147246360778809, Discriminator loss: 1.0982496738433838\n",
      "\tGenerator loss: 1.1127883195877075, Discriminator loss: 1.0868399143218994\n",
      "\tGenerator loss: 1.1257164478302002, Discriminator loss: 1.0869700908660889\n",
      "\tGenerator loss: 1.1410272121429443, Discriminator loss: 1.092660665512085\n",
      "\tGenerator loss: 1.1178092956542969, Discriminator loss: 1.0860916376113892\n",
      "\tGenerator loss: 1.106222152709961, Discriminator loss: 1.139737606048584\n",
      "\tGenerator loss: 1.1129088401794434, Discriminator loss: 1.0762218236923218\n",
      "\tGenerator loss: 1.1882424354553223, Discriminator loss: 1.0642235279083252\n",
      "\tGenerator loss: 1.2128956317901611, Discriminator loss: 1.062755823135376\n",
      "\tGenerator loss: 1.2226555347442627, Discriminator loss: 1.0444908142089844\n",
      "\tGenerator loss: 1.1808476448059082, Discriminator loss: 1.032963514328003\n",
      "\tGenerator loss: 1.1612420082092285, Discriminator loss: 1.0403698682785034\n",
      "\tGenerator loss: 1.1336427927017212, Discriminator loss: 1.0098700523376465\n",
      "\tGenerator loss: 1.1026111841201782, Discriminator loss: 1.0128908157348633\n",
      "\tGenerator loss: 1.1600959300994873, Discriminator loss: 1.0328059196472168\n",
      "\tGenerator loss: 1.2140817642211914, Discriminator loss: 0.9840609431266785\n",
      "\tGenerator loss: 1.2731122970581055, Discriminator loss: 1.0123361349105835\n",
      "\tGenerator loss: 1.2513229846954346, Discriminator loss: 1.0145759582519531\n",
      "\tGenerator loss: 1.1789929866790771, Discriminator loss: 1.110778570175171\n",
      "\tGenerator loss: 1.088071346282959, Discriminator loss: 1.0879406929016113\n",
      "\tGenerator loss: 0.9898871183395386, Discriminator loss: 1.0740282535552979\n",
      "\tGenerator loss: 0.9858956336975098, Discriminator loss: 1.0153790712356567\n",
      "\tGenerator loss: 1.1195133924484253, Discriminator loss: 1.0008383989334106\n",
      "\tGenerator loss: 1.2811787128448486, Discriminator loss: 1.053719401359558\n",
      "\tGenerator loss: 1.338054895401001, Discriminator loss: 1.0735931396484375\n",
      "\tGenerator loss: 1.2788231372833252, Discriminator loss: 1.0579450130462646\n",
      "\tGenerator loss: 1.1604580879211426, Discriminator loss: 1.1022595167160034\n",
      "\tGenerator loss: 1.0542352199554443, Discriminator loss: 1.1293127536773682\n",
      "\tGenerator loss: 1.0330405235290527, Discriminator loss: 1.12429940700531\n",
      "\tGenerator loss: 1.0871610641479492, Discriminator loss: 1.076723575592041\n",
      "\tGenerator loss: 1.131869912147522, Discriminator loss: 1.1917153596878052\n",
      "\tGenerator loss: 1.0920403003692627, Discriminator loss: 1.245842695236206\n",
      "\tGenerator loss: 1.0672245025634766, Discriminator loss: 1.2465898990631104\n",
      "\tGenerator loss: 0.9806076288223267, Discriminator loss: 1.2344753742218018\n",
      "\tGenerator loss: 0.9141318202018738, Discriminator loss: 1.208366870880127\n",
      "\tGenerator loss: 0.8841357231140137, Discriminator loss: 1.2265450954437256\n",
      "\tGenerator loss: 0.9504677653312683, Discriminator loss: 1.1949102878570557\n",
      "\tGenerator loss: 1.0191758871078491, Discriminator loss: 1.1979470252990723\n",
      "\tGenerator loss: 1.1026561260223389, Discriminator loss: 1.2201461791992188\n",
      "\tGenerator loss: 1.0893903970718384, Discriminator loss: 1.2597203254699707\n",
      "\tGenerator loss: 1.0141533613204956, Discriminator loss: 1.2383649349212646\n",
      "\tGenerator loss: 0.9405524730682373, Discriminator loss: 1.3170053958892822\n",
      "\tGenerator loss: 0.8936102986335754, Discriminator loss: 1.3615797758102417\n",
      "\tGenerator loss: 0.815159797668457, Discriminator loss: 1.379509449005127\n",
      "\tGenerator loss: 0.7860298156738281, Discriminator loss: 1.3469042778015137\n",
      "\tGenerator loss: 0.8074638843536377, Discriminator loss: 1.3471077680587769\n",
      "\tGenerator loss: 0.9037758111953735, Discriminator loss: 1.3444955348968506\n",
      "\tGenerator loss: 0.9858329892158508, Discriminator loss: 1.3293297290802002\n",
      "\tGenerator loss: 0.9816929697990417, Discriminator loss: 1.32401442527771\n",
      "\tGenerator loss: 0.9175748825073242, Discriminator loss: 1.348482608795166\n",
      "\tGenerator loss: 0.850216805934906, Discriminator loss: 1.3282146453857422\n",
      "\tGenerator loss: 0.8502604961395264, Discriminator loss: 1.298964262008667\n",
      "\tGenerator loss: 0.865263819694519, Discriminator loss: 1.295426368713379\n",
      "\tGenerator loss: 0.8812417984008789, Discriminator loss: 1.3420252799987793\n",
      "\tGenerator loss: 0.9159760475158691, Discriminator loss: 1.325148582458496\n",
      "\tGenerator loss: 0.9179362058639526, Discriminator loss: 1.2941155433654785\n",
      "\tGenerator loss: 0.9323403835296631, Discriminator loss: 1.3157765865325928\n",
      "\tGenerator loss: 0.9253262877464294, Discriminator loss: 1.2570840120315552\n",
      "\tGenerator loss: 0.9441913366317749, Discriminator loss: 1.242842435836792\n",
      "\tGenerator loss: 0.9334710836410522, Discriminator loss: 1.219299077987671\n",
      "\tGenerator loss: 0.966323971748352, Discriminator loss: 1.1810270547866821\n",
      "\tGenerator loss: 0.9901728630065918, Discriminator loss: 1.1762738227844238\n",
      "\tGenerator loss: 1.0155304670333862, Discriminator loss: 1.1974525451660156\n",
      "\tGenerator loss: 0.9775405526161194, Discriminator loss: 1.2259342670440674\n",
      "\tGenerator loss: 0.9302804470062256, Discriminator loss: 1.1975057125091553\n",
      "\tGenerator loss: 0.9152899980545044, Discriminator loss: 1.1525853872299194\n",
      "\tGenerator loss: 0.9192829132080078, Discriminator loss: 1.1917953491210938\n",
      "\tGenerator loss: 0.9735556840896606, Discriminator loss: 1.139597773551941\n",
      "\tGenerator loss: 1.0257041454315186, Discriminator loss: 1.070878028869629\n",
      "\tGenerator loss: 1.0964090824127197, Discriminator loss: 1.0683871507644653\n",
      "\tGenerator loss: 1.1125763654708862, Discriminator loss: 1.141681432723999\n",
      "\tGenerator loss: 1.0749883651733398, Discriminator loss: 1.196803331375122\n",
      "\tGenerator loss: 1.0418083667755127, Discriminator loss: 1.245315432548523\n",
      "\tGenerator loss: 0.966779887676239, Discriminator loss: 1.2282590866088867\n",
      "Time for epoch 18 is 220.16208171844482 sec\n",
      "\tGenerator loss: 0.891387939453125, Discriminator loss: 1.191177248954773\n",
      "\tGenerator loss: 0.8827064037322998, Discriminator loss: 1.1272692680358887\n",
      "\tGenerator loss: 0.9430286884307861, Discriminator loss: 1.1405558586120605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0314273834228516, Discriminator loss: 1.1480863094329834\n",
      "\tGenerator loss: 1.0700932741165161, Discriminator loss: 1.2313321828842163\n",
      "\tGenerator loss: 1.0926363468170166, Discriminator loss: 1.3000924587249756\n",
      "\tGenerator loss: 1.0513145923614502, Discriminator loss: 1.1597373485565186\n",
      "\tGenerator loss: 1.0545673370361328, Discriminator loss: 1.1710665225982666\n",
      "\tGenerator loss: 1.0580871105194092, Discriminator loss: 1.0915007591247559\n",
      "\tGenerator loss: 1.0574367046356201, Discriminator loss: 1.1009304523468018\n",
      "\tGenerator loss: 1.0539484024047852, Discriminator loss: 1.1077961921691895\n",
      "\tGenerator loss: 1.0636931657791138, Discriminator loss: 1.1222261190414429\n",
      "\tGenerator loss: 1.078935980796814, Discriminator loss: 1.117215871810913\n",
      "\tGenerator loss: 1.0827956199645996, Discriminator loss: 1.0894763469696045\n",
      "\tGenerator loss: 1.0495781898498535, Discriminator loss: 1.0842869281768799\n",
      "\tGenerator loss: 1.0249159336090088, Discriminator loss: 1.1290814876556396\n",
      "\tGenerator loss: 1.0398362874984741, Discriminator loss: 1.1551485061645508\n",
      "\tGenerator loss: 1.0001085996627808, Discriminator loss: 1.1727206707000732\n",
      "\tGenerator loss: 0.9784947037696838, Discriminator loss: 1.201592206954956\n",
      "\tGenerator loss: 0.9776821136474609, Discriminator loss: 1.197939157485962\n",
      "\tGenerator loss: 1.0281941890716553, Discriminator loss: 1.2909016609191895\n",
      "\tGenerator loss: 1.0307129621505737, Discriminator loss: 1.3320941925048828\n",
      "\tGenerator loss: 1.0263266563415527, Discriminator loss: 1.2800923585891724\n",
      "\tGenerator loss: 0.9688246250152588, Discriminator loss: 1.4375567436218262\n",
      "\tGenerator loss: 0.9324361085891724, Discriminator loss: 1.4264711141586304\n",
      "\tGenerator loss: 0.9200195074081421, Discriminator loss: 1.2948391437530518\n",
      "\tGenerator loss: 0.9773170351982117, Discriminator loss: 1.192201852798462\n",
      "\tGenerator loss: 1.051613450050354, Discriminator loss: 1.1681149005889893\n",
      "\tGenerator loss: 1.100888729095459, Discriminator loss: 1.1714770793914795\n",
      "\tGenerator loss: 1.1321730613708496, Discriminator loss: 1.1107959747314453\n",
      "\tGenerator loss: 1.0955394506454468, Discriminator loss: 1.1537941694259644\n",
      "\tGenerator loss: 1.0417921543121338, Discriminator loss: 1.1522085666656494\n",
      "\tGenerator loss: 0.9841054677963257, Discriminator loss: 1.1632028818130493\n",
      "\tGenerator loss: 0.976362943649292, Discriminator loss: 1.2333842515945435\n",
      "\tGenerator loss: 1.0334285497665405, Discriminator loss: 1.1642918586730957\n",
      "\tGenerator loss: 1.0924766063690186, Discriminator loss: 1.0497937202453613\n",
      "\tGenerator loss: 1.2278568744659424, Discriminator loss: 0.9846228361129761\n",
      "\tGenerator loss: 1.2977278232574463, Discriminator loss: 0.9160013198852539\n",
      "\tGenerator loss: 1.3132191896438599, Discriminator loss: 0.8859149217605591\n",
      "\tGenerator loss: 1.2794194221496582, Discriminator loss: 0.9137680530548096\n",
      "\tGenerator loss: 1.2254294157028198, Discriminator loss: 0.9042788743972778\n",
      "\tGenerator loss: 1.210587978363037, Discriminator loss: 0.868858814239502\n",
      "\tGenerator loss: 1.1713545322418213, Discriminator loss: 0.8520569205284119\n",
      "\tGenerator loss: 1.2652130126953125, Discriminator loss: 0.8199132680892944\n",
      "\tGenerator loss: 1.3371437788009644, Discriminator loss: 0.8283456563949585\n",
      "\tGenerator loss: 1.3980603218078613, Discriminator loss: 0.8394994735717773\n",
      "\tGenerator loss: 1.3832682371139526, Discriminator loss: 0.8246943950653076\n",
      "\tGenerator loss: 1.3214741945266724, Discriminator loss: 0.8295693397521973\n",
      "\tGenerator loss: 1.3005256652832031, Discriminator loss: 0.8107527494430542\n",
      "\tGenerator loss: 1.2650845050811768, Discriminator loss: 0.7881373167037964\n",
      "\tGenerator loss: 1.2900787591934204, Discriminator loss: 0.7941873073577881\n",
      "\tGenerator loss: 1.3601386547088623, Discriminator loss: 0.8145396113395691\n",
      "\tGenerator loss: 1.4297263622283936, Discriminator loss: 0.7732729911804199\n",
      "\tGenerator loss: 1.4660124778747559, Discriminator loss: 0.8195780515670776\n",
      "\tGenerator loss: 1.4564838409423828, Discriminator loss: 0.824495792388916\n",
      "\tGenerator loss: 1.346775770187378, Discriminator loss: 0.8011070489883423\n",
      "\tGenerator loss: 1.273402452468872, Discriminator loss: 0.8376432657241821\n",
      "\tGenerator loss: 1.234602689743042, Discriminator loss: 0.8260072469711304\n",
      "\tGenerator loss: 1.2701348066329956, Discriminator loss: 0.8349502086639404\n",
      "\tGenerator loss: 1.337930679321289, Discriminator loss: 0.87264084815979\n",
      "\tGenerator loss: 1.366786003112793, Discriminator loss: 0.9307779669761658\n",
      "\tGenerator loss: 1.3458244800567627, Discriminator loss: 0.9418530464172363\n",
      "\tGenerator loss: 1.2485239505767822, Discriminator loss: 0.9631075859069824\n",
      "\tGenerator loss: 1.1939027309417725, Discriminator loss: 0.9360635280609131\n",
      "\tGenerator loss: 1.1678271293640137, Discriminator loss: 0.9185316562652588\n",
      "\tGenerator loss: 1.1752777099609375, Discriminator loss: 1.0017262697219849\n",
      "\tGenerator loss: 1.2138285636901855, Discriminator loss: 1.0567691326141357\n",
      "\tGenerator loss: 1.2358494997024536, Discriminator loss: 1.090592384338379\n",
      "\tGenerator loss: 1.2226033210754395, Discriminator loss: 1.190091609954834\n",
      "\tGenerator loss: 1.1390464305877686, Discriminator loss: 1.1699581146240234\n",
      "\tGenerator loss: 0.9999021291732788, Discriminator loss: 1.175809383392334\n",
      "\tGenerator loss: 0.9501973986625671, Discriminator loss: 1.1987663507461548\n",
      "\tGenerator loss: 0.9784266948699951, Discriminator loss: 1.2023921012878418\n",
      "\tGenerator loss: 1.0835957527160645, Discriminator loss: 1.2310309410095215\n",
      "\tGenerator loss: 1.1478075981140137, Discriminator loss: 1.3050698041915894\n",
      "\tGenerator loss: 1.1380233764648438, Discriminator loss: 1.2349743843078613\n",
      "\tGenerator loss: 1.0475149154663086, Discriminator loss: 1.2257239818572998\n",
      "\tGenerator loss: 0.9513087868690491, Discriminator loss: 1.2079540491104126\n",
      "\tGenerator loss: 0.9305585622787476, Discriminator loss: 1.2372257709503174\n",
      "\tGenerator loss: 0.9727635979652405, Discriminator loss: 1.2937971353530884\n",
      "\tGenerator loss: 0.9809246063232422, Discriminator loss: 1.271754264831543\n",
      "\tGenerator loss: 1.004971981048584, Discriminator loss: 1.2984342575073242\n",
      "\tGenerator loss: 0.9698048233985901, Discriminator loss: 1.333550214767456\n",
      "\tGenerator loss: 0.9496424198150635, Discriminator loss: 1.3172811269760132\n",
      "\tGenerator loss: 0.8889073133468628, Discriminator loss: 1.302004098892212\n",
      "\tGenerator loss: 0.832804262638092, Discriminator loss: 1.2938241958618164\n",
      "\tGenerator loss: 0.8311234712600708, Discriminator loss: 1.2840278148651123\n",
      "\tGenerator loss: 0.8897919654846191, Discriminator loss: 1.2840296030044556\n",
      "\tGenerator loss: 0.9404478073120117, Discriminator loss: 1.2792904376983643\n",
      "\tGenerator loss: 0.9476065635681152, Discriminator loss: 1.289459466934204\n",
      "\tGenerator loss: 0.9484692811965942, Discriminator loss: 1.265441656112671\n",
      "\tGenerator loss: 0.9259973168373108, Discriminator loss: 1.2361557483673096\n",
      "\tGenerator loss: 0.8829555511474609, Discriminator loss: 1.2183438539505005\n",
      "\tGenerator loss: 0.8870744109153748, Discriminator loss: 1.189326524734497\n",
      "\tGenerator loss: 0.9134203791618347, Discriminator loss: 1.186389446258545\n",
      "\tGenerator loss: 0.9530808925628662, Discriminator loss: 1.1660962104797363\n",
      "\tGenerator loss: 0.9795221090316772, Discriminator loss: 1.1803789138793945\n",
      "\tGenerator loss: 1.0219347476959229, Discriminator loss: 1.1411323547363281\n",
      "\tGenerator loss: 1.0277847051620483, Discriminator loss: 1.1422290802001953\n",
      "\tGenerator loss: 1.0127770900726318, Discriminator loss: 1.176539659500122\n",
      "\tGenerator loss: 1.008171796798706, Discriminator loss: 1.1156564950942993\n",
      "\tGenerator loss: 0.9874471426010132, Discriminator loss: 1.128319501876831\n",
      "\tGenerator loss: 0.9970224499702454, Discriminator loss: 1.0837879180908203\n",
      "\tGenerator loss: 1.0432332754135132, Discriminator loss: 1.0665373802185059\n",
      "\tGenerator loss: 1.06441330909729, Discriminator loss: 1.124938726425171\n",
      "\tGenerator loss: 1.0561612844467163, Discriminator loss: 1.1095513105392456\n",
      "\tGenerator loss: 1.0267589092254639, Discriminator loss: 1.1432218551635742\n",
      "\tGenerator loss: 0.9919581413269043, Discriminator loss: 1.0976306200027466\n",
      "\tGenerator loss: 1.024932622909546, Discriminator loss: 1.0586737394332886\n",
      "\tGenerator loss: 1.0584220886230469, Discriminator loss: 1.2145719528198242\n",
      "\tGenerator loss: 1.0167536735534668, Discriminator loss: 1.3267583847045898\n",
      "\tGenerator loss: 0.9936543703079224, Discriminator loss: 1.388123631477356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.941802978515625, Discriminator loss: 1.328334093093872\n",
      "\tGenerator loss: 0.927669882774353, Discriminator loss: 1.2756166458129883\n",
      "\tGenerator loss: 0.9097307920455933, Discriminator loss: 1.421079397201538\n",
      "\tGenerator loss: 0.89943528175354, Discriminator loss: 1.3286731243133545\n",
      "\tGenerator loss: 0.9521931409835815, Discriminator loss: 1.2831969261169434\n",
      "\tGenerator loss: 1.0264058113098145, Discriminator loss: 1.232161283493042\n",
      "\tGenerator loss: 1.0550892353057861, Discriminator loss: 1.2428410053253174\n",
      "\tGenerator loss: 1.0083961486816406, Discriminator loss: 1.2667129039764404\n",
      "\tGenerator loss: 0.9463835954666138, Discriminator loss: 1.3117865324020386\n",
      "\tGenerator loss: 0.8893039226531982, Discriminator loss: 1.302415132522583\n",
      "\tGenerator loss: 0.8627177476882935, Discriminator loss: 1.3357505798339844\n",
      "\tGenerator loss: 0.880629301071167, Discriminator loss: 1.3090870380401611\n",
      "\tGenerator loss: 0.9511040449142456, Discriminator loss: 1.3628194332122803\n",
      "\tGenerator loss: 0.9725377559661865, Discriminator loss: 1.4813895225524902\n",
      "\tGenerator loss: 0.9436372518539429, Discriminator loss: 1.692802906036377\n",
      "\tGenerator loss: 0.8224571943283081, Discriminator loss: 1.5696215629577637\n",
      "\tGenerator loss: 0.7530203461647034, Discriminator loss: 1.5426011085510254\n",
      "\tGenerator loss: 0.784968912601471, Discriminator loss: 1.6209046840667725\n",
      "\tGenerator loss: 0.8409669399261475, Discriminator loss: 1.5118134021759033\n",
      "\tGenerator loss: 0.9321483969688416, Discriminator loss: 1.5479376316070557\n",
      "\tGenerator loss: 0.9718323945999146, Discriminator loss: 1.6252737045288086\n",
      "\tGenerator loss: 0.9295594692230225, Discriminator loss: 1.5392186641693115\n",
      "\tGenerator loss: 0.8519330024719238, Discriminator loss: 1.5562694072723389\n",
      "\tGenerator loss: 0.7752680778503418, Discriminator loss: 1.5843764543533325\n",
      "\tGenerator loss: 0.7434935569763184, Discriminator loss: 1.6063506603240967\n",
      "\tGenerator loss: 0.7625815272331238, Discriminator loss: 1.496293067932129\n",
      "\tGenerator loss: 0.864419162273407, Discriminator loss: 1.4849809408187866\n",
      "\tGenerator loss: 0.9568301439285278, Discriminator loss: 1.4026741981506348\n",
      "\tGenerator loss: 1.0119616985321045, Discriminator loss: 1.367619514465332\n",
      "\tGenerator loss: 0.9945807456970215, Discriminator loss: 1.5099480152130127\n",
      "\tGenerator loss: 0.9371445178985596, Discriminator loss: 1.4470233917236328\n",
      "\tGenerator loss: 0.8803505301475525, Discriminator loss: 1.5146186351776123\n",
      "\tGenerator loss: 0.8607045412063599, Discriminator loss: 1.444883942604065\n",
      "\tGenerator loss: 0.8681727051734924, Discriminator loss: 1.4475646018981934\n",
      "\tGenerator loss: 0.9212099313735962, Discriminator loss: 1.3619414567947388\n",
      "\tGenerator loss: 0.9709883332252502, Discriminator loss: 1.2385380268096924\n",
      "\tGenerator loss: 1.0618613958358765, Discriminator loss: 1.1731486320495605\n",
      "\tGenerator loss: 1.101656198501587, Discriminator loss: 1.1025018692016602\n",
      "\tGenerator loss: 1.1197654008865356, Discriminator loss: 1.0922197103500366\n",
      "\tGenerator loss: 1.1256532669067383, Discriminator loss: 1.0310674905776978\n",
      "\tGenerator loss: 1.087899923324585, Discriminator loss: 1.040589451789856\n",
      "\tGenerator loss: 1.1020251512527466, Discriminator loss: 1.0491745471954346\n",
      "\tGenerator loss: 1.1153807640075684, Discriminator loss: 1.0459961891174316\n",
      "\tGenerator loss: 1.1180094480514526, Discriminator loss: 1.0390671491622925\n",
      "\tGenerator loss: 1.152343988418579, Discriminator loss: 0.9944997429847717\n",
      "\tGenerator loss: 1.184037208557129, Discriminator loss: 0.9331580400466919\n",
      "\tGenerator loss: 1.2373676300048828, Discriminator loss: 0.9250224232673645\n",
      "\tGenerator loss: 1.2925273180007935, Discriminator loss: 0.9175056219100952\n",
      "\tGenerator loss: 1.2785429954528809, Discriminator loss: 0.9190257787704468\n",
      "\tGenerator loss: 1.2520194053649902, Discriminator loss: 0.9177282452583313\n",
      "\tGenerator loss: 1.192505121231079, Discriminator loss: 0.9558541774749756\n",
      "\tGenerator loss: 1.1291728019714355, Discriminator loss: 0.9991856813430786\n",
      "\tGenerator loss: 1.0949922800064087, Discriminator loss: 0.9469857215881348\n",
      "\tGenerator loss: 1.1522517204284668, Discriminator loss: 0.9396786689758301\n",
      "\tGenerator loss: 1.2349845170974731, Discriminator loss: 0.9166868925094604\n",
      "\tGenerator loss: 1.321640968322754, Discriminator loss: 0.8810639381408691\n",
      "\tGenerator loss: 1.3649847507476807, Discriminator loss: 0.8609802722930908\n",
      "\tGenerator loss: 1.3493483066558838, Discriminator loss: 0.8412238359451294\n",
      "\tGenerator loss: 1.3157038688659668, Discriminator loss: 0.8699493408203125\n",
      "\tGenerator loss: 1.2857638597488403, Discriminator loss: 0.9076548218727112\n",
      "\tGenerator loss: 1.2282264232635498, Discriminator loss: 0.8995052576065063\n",
      "\tGenerator loss: 1.1576206684112549, Discriminator loss: 0.9356043338775635\n",
      "\tGenerator loss: 1.1553484201431274, Discriminator loss: 0.9144001007080078\n",
      "\tGenerator loss: 1.2238073348999023, Discriminator loss: 0.9364948272705078\n",
      "\tGenerator loss: 1.27041494846344, Discriminator loss: 0.921100914478302\n",
      "\tGenerator loss: 1.2804687023162842, Discriminator loss: 0.98095703125\n",
      "\tGenerator loss: 1.225711703300476, Discriminator loss: 0.9967633485794067\n",
      "\tGenerator loss: 1.1806106567382812, Discriminator loss: 1.0956768989562988\n",
      "\tGenerator loss: 1.0818462371826172, Discriminator loss: 1.0545064210891724\n",
      "\tGenerator loss: 0.9989268183708191, Discriminator loss: 1.0592231750488281\n",
      "\tGenerator loss: 0.984515905380249, Discriminator loss: 1.0302263498306274\n",
      "\tGenerator loss: 1.0880961418151855, Discriminator loss: 1.001996636390686\n",
      "\tGenerator loss: 1.2163281440734863, Discriminator loss: 1.100973129272461\n",
      "\tGenerator loss: 1.2427763938903809, Discriminator loss: 1.0216724872589111\n",
      "\tGenerator loss: 1.2218687534332275, Discriminator loss: 0.9902685880661011\n",
      "\tGenerator loss: 1.162819266319275, Discriminator loss: 1.015373945236206\n",
      "\tGenerator loss: 1.105837345123291, Discriminator loss: 1.0157790184020996\n",
      "\tGenerator loss: 1.074293851852417, Discriminator loss: 1.0088720321655273\n",
      "\tGenerator loss: 1.0842866897583008, Discriminator loss: 0.994158148765564\n",
      "\tGenerator loss: 1.062319278717041, Discriminator loss: 1.0729033946990967\n",
      "\tGenerator loss: 1.0938612222671509, Discriminator loss: 1.0530790090560913\n",
      "\tGenerator loss: 1.1220283508300781, Discriminator loss: 1.0404212474822998\n",
      "\tGenerator loss: 1.0864135026931763, Discriminator loss: 1.03754723072052\n",
      "\tGenerator loss: 1.0933656692504883, Discriminator loss: 1.011768102645874\n",
      "\tGenerator loss: 1.0655561685562134, Discriminator loss: 1.0072259902954102\n",
      "\tGenerator loss: 1.0497472286224365, Discriminator loss: 1.0048288106918335\n",
      "\tGenerator loss: 1.0782475471496582, Discriminator loss: 1.0014762878417969\n",
      "\tGenerator loss: 1.090657114982605, Discriminator loss: 0.9821559190750122\n",
      "\tGenerator loss: 1.140895128250122, Discriminator loss: 0.9860928654670715\n",
      "\tGenerator loss: 1.1968250274658203, Discriminator loss: 0.9447246789932251\n",
      "\tGenerator loss: 1.2203031778335571, Discriminator loss: 0.9497430324554443\n",
      "\tGenerator loss: 1.2088468074798584, Discriminator loss: 0.9436758756637573\n",
      "\tGenerator loss: 1.1379826068878174, Discriminator loss: 0.966605007648468\n",
      "\tGenerator loss: 1.098684310913086, Discriminator loss: 0.9354966878890991\n",
      "\tGenerator loss: 1.098090410232544, Discriminator loss: 0.9419519305229187\n",
      "\tGenerator loss: 1.1763737201690674, Discriminator loss: 0.9305005073547363\n",
      "\tGenerator loss: 1.239119291305542, Discriminator loss: 0.9449241161346436\n",
      "\tGenerator loss: 1.2751753330230713, Discriminator loss: 0.9307810068130493\n",
      "\tGenerator loss: 1.2381682395935059, Discriminator loss: 0.9215920567512512\n",
      "\tGenerator loss: 1.232272982597351, Discriminator loss: 0.9315863251686096\n",
      "\tGenerator loss: 1.2165718078613281, Discriminator loss: 1.0047956705093384\n",
      "\tGenerator loss: 1.1845495700836182, Discriminator loss: 1.0604054927825928\n",
      "\tGenerator loss: 1.1288120746612549, Discriminator loss: 1.0159555673599243\n",
      "\tGenerator loss: 1.114941954612732, Discriminator loss: 1.022528886795044\n",
      "\tGenerator loss: 1.1034493446350098, Discriminator loss: 1.0510971546173096\n",
      "\tGenerator loss: 1.1467971801757812, Discriminator loss: 1.1752583980560303\n",
      "\tGenerator loss: 1.141664981842041, Discriminator loss: 1.1021510362625122\n",
      "\tGenerator loss: 1.1356167793273926, Discriminator loss: 1.1175503730773926\n",
      "\tGenerator loss: 1.149800181388855, Discriminator loss: 1.148409366607666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1232385635375977, Discriminator loss: 1.1753437519073486\n",
      "\tGenerator loss: 1.0966981649398804, Discriminator loss: 1.1606595516204834\n",
      "\tGenerator loss: 1.0223338603973389, Discriminator loss: 1.1566628217697144\n",
      "\tGenerator loss: 0.9613373279571533, Discriminator loss: 1.1537501811981201\n",
      "\tGenerator loss: 0.9818730354309082, Discriminator loss: 1.1729321479797363\n",
      "\tGenerator loss: 1.0653209686279297, Discriminator loss: 1.2014747858047485\n",
      "\tGenerator loss: 1.1038737297058105, Discriminator loss: 1.1549952030181885\n",
      "\tGenerator loss: 1.119039535522461, Discriminator loss: 1.1628501415252686\n",
      "\tGenerator loss: 1.0953243970870972, Discriminator loss: 1.1226096153259277\n",
      "\tGenerator loss: 1.0294275283813477, Discriminator loss: 1.1164546012878418\n",
      "\tGenerator loss: 0.9947919249534607, Discriminator loss: 1.2799726724624634\n",
      "\tGenerator loss: 0.9948060512542725, Discriminator loss: 1.4657728672027588\n",
      "\tGenerator loss: 1.0238957405090332, Discriminator loss: 1.4333956241607666\n",
      "\tGenerator loss: 0.9756463170051575, Discriminator loss: 1.2810490131378174\n",
      "Time for epoch 19 is 274.90842962265015 sec\n",
      "\tGenerator loss: 0.9325054883956909, Discriminator loss: 1.3424702882766724\n",
      "\tGenerator loss: 0.9425946474075317, Discriminator loss: 1.3555752038955688\n",
      "\tGenerator loss: 0.9378097057342529, Discriminator loss: 1.3511791229248047\n",
      "\tGenerator loss: 0.8933387994766235, Discriminator loss: 1.3633613586425781\n",
      "\tGenerator loss: 0.9139305353164673, Discriminator loss: 1.5132744312286377\n",
      "\tGenerator loss: 0.9383594393730164, Discriminator loss: 1.5778300762176514\n",
      "\tGenerator loss: 0.889376163482666, Discriminator loss: 1.4576897621154785\n",
      "\tGenerator loss: 0.8751468658447266, Discriminator loss: 1.5412404537200928\n",
      "\tGenerator loss: 0.8823879957199097, Discriminator loss: 1.4917864799499512\n",
      "\tGenerator loss: 0.8747662305831909, Discriminator loss: 1.4437012672424316\n",
      "\tGenerator loss: 0.935692310333252, Discriminator loss: 1.4213825464248657\n",
      "\tGenerator loss: 0.9656559228897095, Discriminator loss: 1.391751766204834\n",
      "\tGenerator loss: 0.9496157765388489, Discriminator loss: 1.3923487663269043\n",
      "\tGenerator loss: 0.9133750200271606, Discriminator loss: 1.343314528465271\n",
      "\tGenerator loss: 0.8870207071304321, Discriminator loss: 1.3259820938110352\n",
      "\tGenerator loss: 0.870631217956543, Discriminator loss: 1.3432345390319824\n",
      "\tGenerator loss: 0.9259495735168457, Discriminator loss: 1.351050615310669\n",
      "\tGenerator loss: 0.9942082166671753, Discriminator loss: 1.328528881072998\n",
      "\tGenerator loss: 1.0131251811981201, Discriminator loss: 1.3667125701904297\n",
      "\tGenerator loss: 1.0082297325134277, Discriminator loss: 1.329710841178894\n",
      "\tGenerator loss: 0.9762316942214966, Discriminator loss: 1.3011479377746582\n",
      "\tGenerator loss: 0.9526921510696411, Discriminator loss: 1.32029390335083\n",
      "\tGenerator loss: 0.9657490253448486, Discriminator loss: 1.2881345748901367\n",
      "\tGenerator loss: 0.9266141057014465, Discriminator loss: 1.3500698804855347\n",
      "\tGenerator loss: 0.9377281665802002, Discriminator loss: 1.3222346305847168\n",
      "\tGenerator loss: 0.9876044988632202, Discriminator loss: 1.2864148616790771\n",
      "\tGenerator loss: 1.0232945680618286, Discriminator loss: 1.3102854490280151\n",
      "\tGenerator loss: 0.9590064883232117, Discriminator loss: 1.2551969289779663\n",
      "\tGenerator loss: 0.9218456745147705, Discriminator loss: 1.3451244831085205\n",
      "\tGenerator loss: 0.8347265720367432, Discriminator loss: 1.3415281772613525\n",
      "\tGenerator loss: 0.8050576448440552, Discriminator loss: 1.3209106922149658\n",
      "\tGenerator loss: 0.8799787759780884, Discriminator loss: 1.2949775457382202\n",
      "\tGenerator loss: 0.9658147692680359, Discriminator loss: 1.2949910163879395\n",
      "\tGenerator loss: 1.0698386430740356, Discriminator loss: 1.2804805040359497\n",
      "\tGenerator loss: 1.0520665645599365, Discriminator loss: 1.2679517269134521\n",
      "\tGenerator loss: 0.9794366359710693, Discriminator loss: 1.262587070465088\n",
      "\tGenerator loss: 0.9080339670181274, Discriminator loss: 1.2599151134490967\n",
      "\tGenerator loss: 0.8524593710899353, Discriminator loss: 1.297129511833191\n",
      "\tGenerator loss: 0.8599951267242432, Discriminator loss: 1.26017427444458\n",
      "\tGenerator loss: 0.9027500152587891, Discriminator loss: 1.2750298976898193\n",
      "\tGenerator loss: 0.9745712876319885, Discriminator loss: 1.253671407699585\n",
      "\tGenerator loss: 1.0271143913269043, Discriminator loss: 1.2784112691879272\n",
      "\tGenerator loss: 1.0196025371551514, Discriminator loss: 1.2513102293014526\n",
      "\tGenerator loss: 0.9814720153808594, Discriminator loss: 1.234018325805664\n",
      "\tGenerator loss: 0.9161295890808105, Discriminator loss: 1.2698386907577515\n",
      "\tGenerator loss: 0.86659836769104, Discriminator loss: 1.2633055448532104\n",
      "\tGenerator loss: 0.8285204768180847, Discriminator loss: 1.2845256328582764\n",
      "\tGenerator loss: 0.8520744442939758, Discriminator loss: 1.2684729099273682\n",
      "\tGenerator loss: 0.9096426963806152, Discriminator loss: 1.2618765830993652\n",
      "\tGenerator loss: 0.9553524255752563, Discriminator loss: 1.2520419359207153\n",
      "\tGenerator loss: 0.9597880244255066, Discriminator loss: 1.2795867919921875\n",
      "\tGenerator loss: 0.9323875904083252, Discriminator loss: 1.276198148727417\n",
      "\tGenerator loss: 0.8839759826660156, Discriminator loss: 1.2713172435760498\n",
      "\tGenerator loss: 0.8797708749771118, Discriminator loss: 1.3050625324249268\n",
      "\tGenerator loss: 0.8477287292480469, Discriminator loss: 1.296028971672058\n",
      "\tGenerator loss: 0.8196160793304443, Discriminator loss: 1.2852041721343994\n",
      "\tGenerator loss: 0.8274489641189575, Discriminator loss: 1.3020662069320679\n",
      "\tGenerator loss: 0.8613500595092773, Discriminator loss: 1.2642216682434082\n",
      "\tGenerator loss: 0.8940467238426208, Discriminator loss: 1.2554996013641357\n",
      "\tGenerator loss: 0.936921238899231, Discriminator loss: 1.2410004138946533\n",
      "\tGenerator loss: 0.9100109338760376, Discriminator loss: 1.2388547658920288\n",
      "\tGenerator loss: 0.8664883375167847, Discriminator loss: 1.2362947463989258\n",
      "\tGenerator loss: 0.8675787448883057, Discriminator loss: 1.2204017639160156\n",
      "\tGenerator loss: 0.859426736831665, Discriminator loss: 1.2027628421783447\n",
      "\tGenerator loss: 0.8950377106666565, Discriminator loss: 1.147237777709961\n",
      "\tGenerator loss: 0.9476373195648193, Discriminator loss: 1.1359896659851074\n",
      "\tGenerator loss: 0.9501923322677612, Discriminator loss: 1.157280445098877\n",
      "\tGenerator loss: 0.9707176685333252, Discriminator loss: 1.1251802444458008\n",
      "\tGenerator loss: 0.9890551567077637, Discriminator loss: 1.1523287296295166\n",
      "\tGenerator loss: 0.9802654981613159, Discriminator loss: 1.1065404415130615\n",
      "\tGenerator loss: 0.9566993117332458, Discriminator loss: 1.079443097114563\n",
      "\tGenerator loss: 0.941800594329834, Discriminator loss: 1.070495843887329\n",
      "\tGenerator loss: 0.9739245772361755, Discriminator loss: 1.02728271484375\n",
      "\tGenerator loss: 1.0357762575149536, Discriminator loss: 0.984963059425354\n",
      "\tGenerator loss: 1.0750818252563477, Discriminator loss: 0.9630697965621948\n",
      "\tGenerator loss: 1.0972726345062256, Discriminator loss: 1.0068185329437256\n",
      "\tGenerator loss: 1.1164772510528564, Discriminator loss: 1.0451151132583618\n",
      "\tGenerator loss: 1.1300846338272095, Discriminator loss: 0.9815212488174438\n",
      "\tGenerator loss: 1.1511461734771729, Discriminator loss: 0.9326709508895874\n",
      "\tGenerator loss: 1.1615885496139526, Discriminator loss: 0.9049528241157532\n",
      "\tGenerator loss: 1.1553242206573486, Discriminator loss: 0.9173464775085449\n",
      "\tGenerator loss: 1.1633596420288086, Discriminator loss: 0.910987377166748\n",
      "\tGenerator loss: 1.1806988716125488, Discriminator loss: 0.8605952858924866\n",
      "\tGenerator loss: 1.200303554534912, Discriminator loss: 0.8912786841392517\n",
      "\tGenerator loss: 1.211094617843628, Discriminator loss: 0.8563954830169678\n",
      "\tGenerator loss: 1.2276639938354492, Discriminator loss: 0.9637609124183655\n",
      "\tGenerator loss: 1.2127013206481934, Discriminator loss: 0.8853769302368164\n",
      "\tGenerator loss: 1.2216763496398926, Discriminator loss: 0.8871676921844482\n",
      "\tGenerator loss: 1.2488715648651123, Discriminator loss: 0.9885424375534058\n",
      "\tGenerator loss: 1.2155855894088745, Discriminator loss: 0.9964202046394348\n",
      "\tGenerator loss: 1.18882155418396, Discriminator loss: 1.0050303936004639\n",
      "\tGenerator loss: 1.1112024784088135, Discriminator loss: 0.9756840467453003\n",
      "\tGenerator loss: 1.0484681129455566, Discriminator loss: 0.9374790787696838\n",
      "\tGenerator loss: 1.0709056854248047, Discriminator loss: 0.9541434049606323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1469981670379639, Discriminator loss: 0.9773880243301392\n",
      "\tGenerator loss: 1.194307565689087, Discriminator loss: 0.9647737741470337\n",
      "\tGenerator loss: 1.2322518825531006, Discriminator loss: 1.0347998142242432\n",
      "\tGenerator loss: 1.194992184638977, Discriminator loss: 0.9746452569961548\n",
      "\tGenerator loss: 1.129868984222412, Discriminator loss: 1.0028722286224365\n",
      "\tGenerator loss: 1.0821024179458618, Discriminator loss: 1.041326642036438\n",
      "\tGenerator loss: 1.0437982082366943, Discriminator loss: 0.9948692321777344\n",
      "\tGenerator loss: 1.0364201068878174, Discriminator loss: 1.0215418338775635\n",
      "\tGenerator loss: 1.0887823104858398, Discriminator loss: 1.0015157461166382\n",
      "\tGenerator loss: 1.1531031131744385, Discriminator loss: 1.0028431415557861\n",
      "\tGenerator loss: 1.1736557483673096, Discriminator loss: 1.0223703384399414\n",
      "\tGenerator loss: 1.1339046955108643, Discriminator loss: 1.0432652235031128\n",
      "\tGenerator loss: 1.099708080291748, Discriminator loss: 1.0472066402435303\n",
      "\tGenerator loss: 1.0796000957489014, Discriminator loss: 1.0112162828445435\n",
      "\tGenerator loss: 1.0832018852233887, Discriminator loss: 1.022371530532837\n",
      "\tGenerator loss: 1.080721378326416, Discriminator loss: 1.1004542112350464\n",
      "\tGenerator loss: 1.0761611461639404, Discriminator loss: 1.1534748077392578\n",
      "\tGenerator loss: 1.0635606050491333, Discriminator loss: 1.1552156209945679\n",
      "\tGenerator loss: 1.0528367757797241, Discriminator loss: 1.113922357559204\n",
      "\tGenerator loss: 1.0395598411560059, Discriminator loss: 1.100264549255371\n",
      "\tGenerator loss: 1.0543053150177002, Discriminator loss: 1.1525697708129883\n",
      "\tGenerator loss: 1.0633234977722168, Discriminator loss: 1.0700727701187134\n",
      "\tGenerator loss: 1.1003390550613403, Discriminator loss: 1.0400378704071045\n",
      "\tGenerator loss: 1.0857497453689575, Discriminator loss: 1.0541226863861084\n",
      "\tGenerator loss: 1.059024453163147, Discriminator loss: 0.9888631105422974\n",
      "\tGenerator loss: 1.1204956769943237, Discriminator loss: 1.0156482458114624\n",
      "\tGenerator loss: 1.1605982780456543, Discriminator loss: 0.9577245712280273\n",
      "\tGenerator loss: 1.178715705871582, Discriminator loss: 0.9249330163002014\n",
      "\tGenerator loss: 1.184021234512329, Discriminator loss: 0.9427614212036133\n",
      "\tGenerator loss: 1.189746618270874, Discriminator loss: 0.9254908561706543\n",
      "\tGenerator loss: 1.1559537649154663, Discriminator loss: 0.8984294533729553\n",
      "\tGenerator loss: 1.1529672145843506, Discriminator loss: 0.9276137948036194\n",
      "\tGenerator loss: 1.1719309091567993, Discriminator loss: 0.9544810056686401\n",
      "\tGenerator loss: 1.1763174533843994, Discriminator loss: 0.9025615453720093\n",
      "\tGenerator loss: 1.235058069229126, Discriminator loss: 0.8346497416496277\n",
      "\tGenerator loss: 1.3020529747009277, Discriminator loss: 0.8798023462295532\n",
      "\tGenerator loss: 1.348010540008545, Discriminator loss: 0.8714090585708618\n",
      "\tGenerator loss: 1.3459230661392212, Discriminator loss: 0.8667406439781189\n",
      "\tGenerator loss: 1.2948038578033447, Discriminator loss: 0.8384379148483276\n",
      "\tGenerator loss: 1.2204058170318604, Discriminator loss: 0.8270334005355835\n",
      "\tGenerator loss: 1.196338176727295, Discriminator loss: 0.8164359331130981\n",
      "\tGenerator loss: 1.2799289226531982, Discriminator loss: 0.8583933115005493\n",
      "\tGenerator loss: 1.382075548171997, Discriminator loss: 0.8320752382278442\n",
      "\tGenerator loss: 1.4033987522125244, Discriminator loss: 0.8693364858627319\n",
      "\tGenerator loss: 1.3800100088119507, Discriminator loss: 0.8375679850578308\n",
      "\tGenerator loss: 1.2953890562057495, Discriminator loss: 0.8209648132324219\n",
      "\tGenerator loss: 1.2481086254119873, Discriminator loss: 0.867546796798706\n",
      "\tGenerator loss: 1.2227935791015625, Discriminator loss: 0.8318121433258057\n",
      "\tGenerator loss: 1.3072917461395264, Discriminator loss: 0.815565824508667\n",
      "\tGenerator loss: 1.4023756980895996, Discriminator loss: 0.7783137559890747\n",
      "\tGenerator loss: 1.473590612411499, Discriminator loss: 0.8320120573043823\n",
      "\tGenerator loss: 1.5033284425735474, Discriminator loss: 0.8278207778930664\n",
      "\tGenerator loss: 1.4401919841766357, Discriminator loss: 0.855284571647644\n",
      "\tGenerator loss: 1.3299623727798462, Discriminator loss: 0.8455715775489807\n",
      "\tGenerator loss: 1.2217798233032227, Discriminator loss: 0.9030287265777588\n",
      "\tGenerator loss: 1.1432390213012695, Discriminator loss: 0.9387626647949219\n",
      "\tGenerator loss: 1.16778564453125, Discriminator loss: 0.9675600528717041\n",
      "\tGenerator loss: 1.2042996883392334, Discriminator loss: 0.9535322785377502\n",
      "\tGenerator loss: 1.230647087097168, Discriminator loss: 1.0045849084854126\n",
      "\tGenerator loss: 1.289957046508789, Discriminator loss: 1.024466872215271\n",
      "\tGenerator loss: 1.2366385459899902, Discriminator loss: 1.0529165267944336\n",
      "\tGenerator loss: 1.1307873725891113, Discriminator loss: 1.1895570755004883\n",
      "\tGenerator loss: 1.0055086612701416, Discriminator loss: 1.1946728229522705\n",
      "\tGenerator loss: 0.905888557434082, Discriminator loss: 1.2056349515914917\n",
      "\tGenerator loss: 0.8769318461418152, Discriminator loss: 1.208040475845337\n",
      "\tGenerator loss: 0.9560664892196655, Discriminator loss: 1.1935346126556396\n",
      "\tGenerator loss: 1.0299328565597534, Discriminator loss: 1.1982418298721313\n",
      "\tGenerator loss: 1.1196538209915161, Discriminator loss: 1.279666781425476\n",
      "\tGenerator loss: 1.0871069431304932, Discriminator loss: 1.4034745693206787\n",
      "\tGenerator loss: 0.9631248712539673, Discriminator loss: 1.4031795263290405\n",
      "\tGenerator loss: 0.8380992412567139, Discriminator loss: 1.3534070253372192\n",
      "\tGenerator loss: 0.7519633173942566, Discriminator loss: 1.3528964519500732\n",
      "\tGenerator loss: 0.7499711513519287, Discriminator loss: 1.3446860313415527\n",
      "\tGenerator loss: 0.813188910484314, Discriminator loss: 1.3054885864257812\n",
      "\tGenerator loss: 0.9533297419548035, Discriminator loss: 1.32811439037323\n",
      "\tGenerator loss: 1.0560137033462524, Discriminator loss: 1.2979404926300049\n",
      "\tGenerator loss: 1.086925745010376, Discriminator loss: 1.2822778224945068\n",
      "\tGenerator loss: 1.064239263534546, Discriminator loss: 1.2947590351104736\n",
      "\tGenerator loss: 0.9548505544662476, Discriminator loss: 1.2481164932250977\n",
      "\tGenerator loss: 0.8446940183639526, Discriminator loss: 1.24061918258667\n",
      "\tGenerator loss: 0.7908154726028442, Discriminator loss: 1.2234373092651367\n",
      "\tGenerator loss: 0.8179906606674194, Discriminator loss: 1.199542760848999\n",
      "\tGenerator loss: 0.9020044207572937, Discriminator loss: 1.1372504234313965\n",
      "\tGenerator loss: 1.0072910785675049, Discriminator loss: 1.1349533796310425\n",
      "\tGenerator loss: 1.1623942852020264, Discriminator loss: 1.1346921920776367\n",
      "\tGenerator loss: 1.237908959388733, Discriminator loss: 1.1881117820739746\n",
      "\tGenerator loss: 1.228562831878662, Discriminator loss: 1.0947508811950684\n",
      "\tGenerator loss: 1.1595773696899414, Discriminator loss: 1.0355908870697021\n",
      "\tGenerator loss: 1.0598015785217285, Discriminator loss: 1.0080208778381348\n",
      "\tGenerator loss: 1.0220074653625488, Discriminator loss: 1.0382285118103027\n",
      "\tGenerator loss: 1.0317389965057373, Discriminator loss: 1.0070135593414307\n",
      "\tGenerator loss: 1.0726258754730225, Discriminator loss: 1.0609822273254395\n",
      "\tGenerator loss: 1.1471400260925293, Discriminator loss: 1.0858149528503418\n",
      "\tGenerator loss: 1.19290030002594, Discriminator loss: 1.1060373783111572\n",
      "\tGenerator loss: 1.230707049369812, Discriminator loss: 1.1735384464263916\n",
      "\tGenerator loss: 1.2425451278686523, Discriminator loss: 1.1933255195617676\n",
      "\tGenerator loss: 1.1862850189208984, Discriminator loss: 1.1596648693084717\n",
      "\tGenerator loss: 1.1405346393585205, Discriminator loss: 1.0846400260925293\n",
      "\tGenerator loss: 1.1042425632476807, Discriminator loss: 1.0751359462738037\n",
      "\tGenerator loss: 1.071415662765503, Discriminator loss: 1.0859580039978027\n",
      "\tGenerator loss: 1.091395616531372, Discriminator loss: 1.0224943161010742\n",
      "\tGenerator loss: 1.1338329315185547, Discriminator loss: 1.0413658618927002\n",
      "\tGenerator loss: 1.155598521232605, Discriminator loss: 1.0589457750320435\n",
      "\tGenerator loss: 1.1945891380310059, Discriminator loss: 1.050508737564087\n",
      "\tGenerator loss: 1.196392297744751, Discriminator loss: 1.2418962717056274\n",
      "\tGenerator loss: 1.1463673114776611, Discriminator loss: 1.2391276359558105\n",
      "\tGenerator loss: 1.076200008392334, Discriminator loss: 1.3397316932678223\n",
      "\tGenerator loss: 0.9758950471878052, Discriminator loss: 1.2331148386001587\n",
      "\tGenerator loss: 0.9426143169403076, Discriminator loss: 1.206803798675537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9181649684906006, Discriminator loss: 1.1880689859390259\n",
      "\tGenerator loss: 0.9874368906021118, Discriminator loss: 1.2569971084594727\n",
      "\tGenerator loss: 1.055537223815918, Discriminator loss: 1.279083013534546\n",
      "\tGenerator loss: 1.1160708665847778, Discriminator loss: 1.2990702390670776\n",
      "\tGenerator loss: 1.1022268533706665, Discriminator loss: 1.388603925704956\n",
      "\tGenerator loss: 1.0295583009719849, Discriminator loss: 1.2795546054840088\n",
      "\tGenerator loss: 0.9346847534179688, Discriminator loss: 1.2412803173065186\n",
      "\tGenerator loss: 0.9037485122680664, Discriminator loss: 1.2337349653244019\n",
      "\tGenerator loss: 0.9075667858123779, Discriminator loss: 1.293382167816162\n",
      "\tGenerator loss: 0.9703245759010315, Discriminator loss: 1.3809335231781006\n",
      "\tGenerator loss: 1.0364832878112793, Discriminator loss: 1.4861118793487549\n",
      "\tGenerator loss: 1.016672134399414, Discriminator loss: 1.544271469116211\n",
      "\tGenerator loss: 0.9694236516952515, Discriminator loss: 1.507361650466919\n",
      "\tGenerator loss: 0.8808761239051819, Discriminator loss: 1.52378511428833\n",
      "\tGenerator loss: 0.8401693105697632, Discriminator loss: 1.654077172279358\n",
      "\tGenerator loss: 0.8108612895011902, Discriminator loss: 1.5188605785369873\n",
      "\tGenerator loss: 0.8278863430023193, Discriminator loss: 1.4844213724136353\n",
      "\tGenerator loss: 0.8875932693481445, Discriminator loss: 1.4233977794647217\n",
      "\tGenerator loss: 1.0114099979400635, Discriminator loss: 1.3984153270721436\n",
      "\tGenerator loss: 1.0594369173049927, Discriminator loss: 1.3575512170791626\n",
      "\tGenerator loss: 1.0535228252410889, Discriminator loss: 1.3073718547821045\n",
      "\tGenerator loss: 1.0156484842300415, Discriminator loss: 1.2782976627349854\n",
      "\tGenerator loss: 0.9400076270103455, Discriminator loss: 1.253598928451538\n",
      "\tGenerator loss: 0.9231021404266357, Discriminator loss: 1.2518287897109985\n",
      "\tGenerator loss: 0.9248146414756775, Discriminator loss: 1.227100133895874\n",
      "\tGenerator loss: 0.9801061153411865, Discriminator loss: 1.2470794916152954\n",
      "\tGenerator loss: 1.0263304710388184, Discriminator loss: 1.159609079360962\n",
      "\tGenerator loss: 1.0797041654586792, Discriminator loss: 1.126235842704773\n",
      "\tGenerator loss: 1.1146421432495117, Discriminator loss: 1.2261247634887695\n",
      "\tGenerator loss: 1.089634656906128, Discriminator loss: 1.3383837938308716\n",
      "\tGenerator loss: 1.079332947731018, Discriminator loss: 1.3186063766479492\n",
      "\tGenerator loss: 1.0446679592132568, Discriminator loss: 1.2209299802780151\n",
      "Time for epoch 20 is 219.82572078704834 sec\n",
      "\tGenerator loss: 0.9894389510154724, Discriminator loss: 1.211977481842041\n",
      "\tGenerator loss: 0.9847409725189209, Discriminator loss: 1.1822773218154907\n",
      "\tGenerator loss: 0.9930259585380554, Discriminator loss: 1.1605231761932373\n",
      "\tGenerator loss: 1.0423588752746582, Discriminator loss: 1.1091820001602173\n",
      "\tGenerator loss: 1.088792085647583, Discriminator loss: 1.2291436195373535\n",
      "\tGenerator loss: 1.1116174459457397, Discriminator loss: 1.2427680492401123\n",
      "\tGenerator loss: 1.1046159267425537, Discriminator loss: 1.1644186973571777\n",
      "\tGenerator loss: 1.0691665410995483, Discriminator loss: 1.1884468793869019\n",
      "\tGenerator loss: 1.0717418193817139, Discriminator loss: 1.1081624031066895\n",
      "\tGenerator loss: 1.1228466033935547, Discriminator loss: 1.041635513305664\n",
      "\tGenerator loss: 1.178248643875122, Discriminator loss: 1.0319948196411133\n",
      "\tGenerator loss: 1.2077875137329102, Discriminator loss: 1.0503664016723633\n",
      "\tGenerator loss: 1.2083027362823486, Discriminator loss: 1.0757156610488892\n",
      "\tGenerator loss: 1.188523769378662, Discriminator loss: 1.041681170463562\n",
      "\tGenerator loss: 1.127055048942566, Discriminator loss: 1.0450875759124756\n",
      "\tGenerator loss: 1.0904269218444824, Discriminator loss: 1.0303751230239868\n",
      "\tGenerator loss: 1.1313248872756958, Discriminator loss: 1.032540202140808\n",
      "\tGenerator loss: 1.1845083236694336, Discriminator loss: 1.009303331375122\n",
      "\tGenerator loss: 1.2352845668792725, Discriminator loss: 1.0366071462631226\n",
      "\tGenerator loss: 1.2772611379623413, Discriminator loss: 1.0422778129577637\n",
      "\tGenerator loss: 1.2592053413391113, Discriminator loss: 1.0205148458480835\n",
      "\tGenerator loss: 1.2352931499481201, Discriminator loss: 1.0271246433258057\n",
      "\tGenerator loss: 1.2223533391952515, Discriminator loss: 1.0244982242584229\n",
      "\tGenerator loss: 1.1962721347808838, Discriminator loss: 1.029600739479065\n",
      "\tGenerator loss: 1.1885792016983032, Discriminator loss: 1.019164800643921\n",
      "\tGenerator loss: 1.1583211421966553, Discriminator loss: 1.0401846170425415\n",
      "\tGenerator loss: 1.2007802724838257, Discriminator loss: 1.126544713973999\n",
      "\tGenerator loss: 1.1913731098175049, Discriminator loss: 1.0828897953033447\n",
      "\tGenerator loss: 1.1768827438354492, Discriminator loss: 1.1889673471450806\n",
      "\tGenerator loss: 1.0538740158081055, Discriminator loss: 1.1766357421875\n",
      "\tGenerator loss: 0.969225287437439, Discriminator loss: 1.1640077829360962\n",
      "\tGenerator loss: 0.9593362808227539, Discriminator loss: 1.1465299129486084\n",
      "\tGenerator loss: 1.0128875970840454, Discriminator loss: 1.1116180419921875\n",
      "\tGenerator loss: 1.1176598072052002, Discriminator loss: 1.1110732555389404\n",
      "\tGenerator loss: 1.2668147087097168, Discriminator loss: 1.090153694152832\n",
      "\tGenerator loss: 1.348333716392517, Discriminator loss: 1.1199990510940552\n",
      "\tGenerator loss: 1.291799783706665, Discriminator loss: 1.1275455951690674\n",
      "\tGenerator loss: 1.1778998374938965, Discriminator loss: 1.1069390773773193\n",
      "\tGenerator loss: 1.0783790349960327, Discriminator loss: 1.0747188329696655\n",
      "\tGenerator loss: 0.978446364402771, Discriminator loss: 1.073467493057251\n",
      "\tGenerator loss: 0.9660933017730713, Discriminator loss: 1.070647954940796\n",
      "\tGenerator loss: 1.039306640625, Discriminator loss: 1.0367300510406494\n",
      "\tGenerator loss: 1.1596324443817139, Discriminator loss: 1.0401320457458496\n",
      "\tGenerator loss: 1.2835960388183594, Discriminator loss: 1.0485475063323975\n",
      "\tGenerator loss: 1.3854591846466064, Discriminator loss: 1.0658433437347412\n",
      "\tGenerator loss: 1.328654170036316, Discriminator loss: 1.0488898754119873\n",
      "\tGenerator loss: 1.2146271467208862, Discriminator loss: 1.0154423713684082\n",
      "\tGenerator loss: 1.0785973072052002, Discriminator loss: 1.01264488697052\n",
      "\tGenerator loss: 1.0091726779937744, Discriminator loss: 1.0093913078308105\n",
      "\tGenerator loss: 1.020178198814392, Discriminator loss: 0.9798933267593384\n",
      "\tGenerator loss: 1.0600712299346924, Discriminator loss: 0.9797881245613098\n",
      "\tGenerator loss: 1.132553219795227, Discriminator loss: 0.9608842134475708\n",
      "\tGenerator loss: 1.2247238159179688, Discriminator loss: 0.9471639394760132\n",
      "\tGenerator loss: 1.3068253993988037, Discriminator loss: 1.0253279209136963\n",
      "\tGenerator loss: 1.3159031867980957, Discriminator loss: 1.0203769207000732\n",
      "\tGenerator loss: 1.254349946975708, Discriminator loss: 1.028254747390747\n",
      "\tGenerator loss: 1.185811161994934, Discriminator loss: 1.0029103755950928\n",
      "\tGenerator loss: 1.096124291419983, Discriminator loss: 1.0296167135238647\n",
      "\tGenerator loss: 1.0189955234527588, Discriminator loss: 0.9952471852302551\n",
      "\tGenerator loss: 1.006387710571289, Discriminator loss: 0.9684959650039673\n",
      "\tGenerator loss: 1.012692928314209, Discriminator loss: 0.9799608588218689\n",
      "\tGenerator loss: 1.11036217212677, Discriminator loss: 0.9475893974304199\n",
      "\tGenerator loss: 1.2281668186187744, Discriminator loss: 0.9672963619232178\n",
      "\tGenerator loss: 1.2781364917755127, Discriminator loss: 0.965146541595459\n",
      "\tGenerator loss: 1.320497989654541, Discriminator loss: 0.9584019184112549\n",
      "\tGenerator loss: 1.3084626197814941, Discriminator loss: 0.930690586566925\n",
      "\tGenerator loss: 1.236328363418579, Discriminator loss: 0.9574860334396362\n",
      "\tGenerator loss: 1.1630771160125732, Discriminator loss: 0.9482834339141846\n",
      "\tGenerator loss: 1.1277124881744385, Discriminator loss: 0.9519095420837402\n",
      "\tGenerator loss: 1.1048592329025269, Discriminator loss: 0.9607919454574585\n",
      "\tGenerator loss: 1.1124906539916992, Discriminator loss: 0.9435549974441528\n",
      "\tGenerator loss: 1.1687566041946411, Discriminator loss: 0.968173086643219\n",
      "\tGenerator loss: 1.2365758419036865, Discriminator loss: 0.9519593119621277\n",
      "\tGenerator loss: 1.2922494411468506, Discriminator loss: 0.8963537812232971\n",
      "\tGenerator loss: 1.324949026107788, Discriminator loss: 0.8793457746505737\n",
      "\tGenerator loss: 1.3360629081726074, Discriminator loss: 0.9637991189956665\n",
      "\tGenerator loss: 1.260066270828247, Discriminator loss: 1.080230951309204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2091927528381348, Discriminator loss: 1.0512077808380127\n",
      "\tGenerator loss: 1.1417235136032104, Discriminator loss: 1.0300027132034302\n",
      "\tGenerator loss: 1.103837013244629, Discriminator loss: 0.9739386439323425\n",
      "\tGenerator loss: 1.1163129806518555, Discriminator loss: 0.9971534013748169\n",
      "\tGenerator loss: 1.1617975234985352, Discriminator loss: 0.9789623022079468\n",
      "\tGenerator loss: 1.2528185844421387, Discriminator loss: 0.9201955199241638\n",
      "\tGenerator loss: 1.2912629842758179, Discriminator loss: 0.9427841901779175\n",
      "\tGenerator loss: 1.338080644607544, Discriminator loss: 0.940101683139801\n",
      "\tGenerator loss: 1.30364191532135, Discriminator loss: 1.0720611810684204\n",
      "\tGenerator loss: 1.249497413635254, Discriminator loss: 0.9857158064842224\n",
      "\tGenerator loss: 1.1814935207366943, Discriminator loss: 0.98960280418396\n",
      "\tGenerator loss: 1.1423962116241455, Discriminator loss: 1.0321636199951172\n",
      "\tGenerator loss: 1.1534851789474487, Discriminator loss: 1.053833246231079\n",
      "\tGenerator loss: 1.116926908493042, Discriminator loss: 1.0990747213363647\n",
      "\tGenerator loss: 1.131564736366272, Discriminator loss: 1.0740399360656738\n",
      "\tGenerator loss: 1.1300134658813477, Discriminator loss: 1.0085970163345337\n",
      "\tGenerator loss: 1.175658106803894, Discriminator loss: 1.0107858180999756\n",
      "\tGenerator loss: 1.1925239562988281, Discriminator loss: 1.0800987482070923\n",
      "\tGenerator loss: 1.1853702068328857, Discriminator loss: 1.0312974452972412\n",
      "\tGenerator loss: 1.1593812704086304, Discriminator loss: 1.0434465408325195\n",
      "\tGenerator loss: 1.1105737686157227, Discriminator loss: 1.0552724599838257\n",
      "\tGenerator loss: 1.0765677690505981, Discriminator loss: 1.0892634391784668\n",
      "\tGenerator loss: 1.0882899761199951, Discriminator loss: 1.1568448543548584\n",
      "\tGenerator loss: 1.090024471282959, Discriminator loss: 1.0884687900543213\n",
      "\tGenerator loss: 1.0784227848052979, Discriminator loss: 1.1272876262664795\n",
      "\tGenerator loss: 1.087751865386963, Discriminator loss: 1.1015946865081787\n",
      "\tGenerator loss: 1.1039854288101196, Discriminator loss: 1.1007283926010132\n",
      "\tGenerator loss: 1.094687581062317, Discriminator loss: 1.153707504272461\n",
      "\tGenerator loss: 1.0229437351226807, Discriminator loss: 1.1468985080718994\n",
      "\tGenerator loss: 1.0309133529663086, Discriminator loss: 1.106337070465088\n",
      "\tGenerator loss: 1.0638036727905273, Discriminator loss: 1.0645161867141724\n",
      "\tGenerator loss: 1.100412130355835, Discriminator loss: 1.064906120300293\n",
      "\tGenerator loss: 1.1416455507278442, Discriminator loss: 1.151705026626587\n",
      "\tGenerator loss: 1.1542048454284668, Discriminator loss: 1.1802237033843994\n",
      "\tGenerator loss: 1.0843327045440674, Discriminator loss: 1.201230525970459\n",
      "\tGenerator loss: 1.0211725234985352, Discriminator loss: 1.1930675506591797\n",
      "\tGenerator loss: 0.9876750707626343, Discriminator loss: 1.182023525238037\n",
      "\tGenerator loss: 1.0239450931549072, Discriminator loss: 1.2180070877075195\n",
      "\tGenerator loss: 1.0458706617355347, Discriminator loss: 1.174618124961853\n",
      "\tGenerator loss: 1.0700730085372925, Discriminator loss: 1.1783411502838135\n",
      "\tGenerator loss: 1.082792043685913, Discriminator loss: 1.1943448781967163\n",
      "\tGenerator loss: 1.0447983741760254, Discriminator loss: 1.1567211151123047\n",
      "\tGenerator loss: 1.014248251914978, Discriminator loss: 1.1517449617385864\n",
      "\tGenerator loss: 1.0100164413452148, Discriminator loss: 1.187219500541687\n",
      "\tGenerator loss: 1.0037376880645752, Discriminator loss: 1.1695473194122314\n",
      "\tGenerator loss: 1.015260934829712, Discriminator loss: 1.1625542640686035\n",
      "\tGenerator loss: 1.0195634365081787, Discriminator loss: 1.167380452156067\n",
      "\tGenerator loss: 1.0000438690185547, Discriminator loss: 1.161902904510498\n",
      "\tGenerator loss: 1.0015017986297607, Discriminator loss: 1.2711589336395264\n",
      "\tGenerator loss: 1.0472474098205566, Discriminator loss: 1.2972276210784912\n",
      "\tGenerator loss: 1.0096545219421387, Discriminator loss: 1.2340848445892334\n",
      "\tGenerator loss: 0.9847099184989929, Discriminator loss: 1.183982014656067\n",
      "\tGenerator loss: 0.988282322883606, Discriminator loss: 1.2243154048919678\n",
      "\tGenerator loss: 0.9845404624938965, Discriminator loss: 1.2183890342712402\n",
      "\tGenerator loss: 1.0445036888122559, Discriminator loss: 1.22915780544281\n",
      "\tGenerator loss: 0.9916533827781677, Discriminator loss: 1.2977628707885742\n",
      "\tGenerator loss: 0.9785283803939819, Discriminator loss: 1.2437900304794312\n",
      "\tGenerator loss: 0.9850143194198608, Discriminator loss: 1.1953153610229492\n",
      "\tGenerator loss: 0.9643527269363403, Discriminator loss: 1.271153450012207\n",
      "\tGenerator loss: 1.016993522644043, Discriminator loss: 1.2759218215942383\n",
      "\tGenerator loss: 0.9977181553840637, Discriminator loss: 1.2747266292572021\n",
      "\tGenerator loss: 1.0124940872192383, Discriminator loss: 1.2723731994628906\n",
      "\tGenerator loss: 0.9457896947860718, Discriminator loss: 1.2685132026672363\n",
      "\tGenerator loss: 0.9339612126350403, Discriminator loss: 1.2615302801132202\n",
      "\tGenerator loss: 0.9629693031311035, Discriminator loss: 1.236279845237732\n",
      "\tGenerator loss: 0.9936635494232178, Discriminator loss: 1.259504795074463\n",
      "\tGenerator loss: 1.0206561088562012, Discriminator loss: 1.332798719406128\n",
      "\tGenerator loss: 1.0135740041732788, Discriminator loss: 1.3258533477783203\n",
      "\tGenerator loss: 1.0133559703826904, Discriminator loss: 1.314961314201355\n",
      "\tGenerator loss: 1.0156476497650146, Discriminator loss: 1.2182121276855469\n",
      "\tGenerator loss: 0.9559650421142578, Discriminator loss: 1.2256395816802979\n",
      "\tGenerator loss: 0.9634105563163757, Discriminator loss: 1.2668612003326416\n",
      "\tGenerator loss: 0.9733785390853882, Discriminator loss: 1.2825852632522583\n",
      "\tGenerator loss: 1.0021501779556274, Discriminator loss: 1.2442588806152344\n",
      "\tGenerator loss: 1.0138964653015137, Discriminator loss: 1.2120822668075562\n",
      "\tGenerator loss: 1.005592703819275, Discriminator loss: 1.209843635559082\n",
      "\tGenerator loss: 0.9980876445770264, Discriminator loss: 1.25691819190979\n",
      "\tGenerator loss: 1.018240213394165, Discriminator loss: 1.248246431350708\n",
      "\tGenerator loss: 1.004439115524292, Discriminator loss: 1.2530931234359741\n",
      "\tGenerator loss: 0.9645949006080627, Discriminator loss: 1.263076663017273\n",
      "\tGenerator loss: 0.97083580493927, Discriminator loss: 1.223111629486084\n",
      "\tGenerator loss: 1.0022847652435303, Discriminator loss: 1.2059329748153687\n",
      "\tGenerator loss: 1.0023308992385864, Discriminator loss: 1.182875394821167\n",
      "\tGenerator loss: 1.05640709400177, Discriminator loss: 1.140714168548584\n",
      "\tGenerator loss: 1.0986944437026978, Discriminator loss: 1.1629267930984497\n",
      "\tGenerator loss: 1.1072938442230225, Discriminator loss: 1.17112398147583\n",
      "\tGenerator loss: 1.0236034393310547, Discriminator loss: 1.197507381439209\n",
      "\tGenerator loss: 0.953389048576355, Discriminator loss: 1.2002683877944946\n",
      "\tGenerator loss: 0.9048841595649719, Discriminator loss: 1.171051025390625\n",
      "\tGenerator loss: 0.9344944953918457, Discriminator loss: 1.175162672996521\n",
      "\tGenerator loss: 1.090057373046875, Discriminator loss: 1.1473243236541748\n",
      "\tGenerator loss: 1.2331514358520508, Discriminator loss: 1.1347354650497437\n",
      "\tGenerator loss: 1.2218928337097168, Discriminator loss: 1.1332616806030273\n",
      "\tGenerator loss: 1.142602562904358, Discriminator loss: 1.1038093566894531\n",
      "\tGenerator loss: 1.0418959856033325, Discriminator loss: 1.0992779731750488\n",
      "\tGenerator loss: 0.9694933891296387, Discriminator loss: 1.1048507690429688\n",
      "\tGenerator loss: 0.968786895275116, Discriminator loss: 1.0843088626861572\n",
      "\tGenerator loss: 1.031780481338501, Discriminator loss: 1.0508999824523926\n",
      "\tGenerator loss: 1.1564857959747314, Discriminator loss: 1.0635936260223389\n",
      "\tGenerator loss: 1.2355049848556519, Discriminator loss: 1.021010160446167\n",
      "\tGenerator loss: 1.2517883777618408, Discriminator loss: 1.046910285949707\n",
      "\tGenerator loss: 1.2274420261383057, Discriminator loss: 1.0131988525390625\n",
      "\tGenerator loss: 1.107282042503357, Discriminator loss: 1.1051994562149048\n",
      "\tGenerator loss: 0.9927203059196472, Discriminator loss: 1.0771220922470093\n",
      "\tGenerator loss: 0.9084106683731079, Discriminator loss: 1.0935001373291016\n",
      "\tGenerator loss: 0.9817764163017273, Discriminator loss: 1.032696008682251\n",
      "\tGenerator loss: 1.170586347579956, Discriminator loss: 1.0472190380096436\n",
      "\tGenerator loss: 1.3093971014022827, Discriminator loss: 1.0881597995758057\n",
      "\tGenerator loss: 1.3480746746063232, Discriminator loss: 1.0684857368469238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2450764179229736, Discriminator loss: 1.0190629959106445\n",
      "\tGenerator loss: 1.1378810405731201, Discriminator loss: 1.057677149772644\n",
      "\tGenerator loss: 1.0319650173187256, Discriminator loss: 1.0515902042388916\n",
      "\tGenerator loss: 1.0176750421524048, Discriminator loss: 1.0219249725341797\n",
      "\tGenerator loss: 1.0672171115875244, Discriminator loss: 1.018298625946045\n",
      "\tGenerator loss: 1.1960092782974243, Discriminator loss: 1.0066864490509033\n",
      "\tGenerator loss: 1.1917335987091064, Discriminator loss: 1.0360894203186035\n",
      "\tGenerator loss: 1.2486145496368408, Discriminator loss: 1.028762936592102\n",
      "\tGenerator loss: 1.1711519956588745, Discriminator loss: 1.0326862335205078\n",
      "\tGenerator loss: 1.1032963991165161, Discriminator loss: 1.0179603099822998\n",
      "\tGenerator loss: 1.0431323051452637, Discriminator loss: 1.0386934280395508\n",
      "\tGenerator loss: 1.0370148420333862, Discriminator loss: 1.0378762483596802\n",
      "\tGenerator loss: 1.0789117813110352, Discriminator loss: 1.045724630355835\n",
      "\tGenerator loss: 1.1447269916534424, Discriminator loss: 1.0318021774291992\n",
      "\tGenerator loss: 1.1666022539138794, Discriminator loss: 1.0587425231933594\n",
      "\tGenerator loss: 1.1642529964447021, Discriminator loss: 1.0205482244491577\n",
      "\tGenerator loss: 1.163905143737793, Discriminator loss: 1.0511316061019897\n",
      "\tGenerator loss: 1.113888144493103, Discriminator loss: 1.044776439666748\n",
      "\tGenerator loss: 1.0346524715423584, Discriminator loss: 1.044572353363037\n",
      "\tGenerator loss: 1.0313348770141602, Discriminator loss: 1.027322769165039\n",
      "\tGenerator loss: 1.0745141506195068, Discriminator loss: 1.0361238718032837\n",
      "\tGenerator loss: 1.1210145950317383, Discriminator loss: 1.0313568115234375\n",
      "\tGenerator loss: 1.1946747303009033, Discriminator loss: 0.9993546009063721\n",
      "\tGenerator loss: 1.1799187660217285, Discriminator loss: 1.0083210468292236\n",
      "\tGenerator loss: 1.158158540725708, Discriminator loss: 0.9926232099533081\n",
      "\tGenerator loss: 1.102858304977417, Discriminator loss: 1.004396677017212\n",
      "\tGenerator loss: 1.0636494159698486, Discriminator loss: 1.0192785263061523\n",
      "\tGenerator loss: 1.0697710514068604, Discriminator loss: 1.0323944091796875\n",
      "\tGenerator loss: 1.1375821828842163, Discriminator loss: 1.0179764032363892\n",
      "\tGenerator loss: 1.159653663635254, Discriminator loss: 1.044328212738037\n",
      "\tGenerator loss: 1.13552725315094, Discriminator loss: 1.0382343530654907\n",
      "\tGenerator loss: 1.1244220733642578, Discriminator loss: 1.0449004173278809\n",
      "\tGenerator loss: 1.0870283842086792, Discriminator loss: 1.0634799003601074\n",
      "\tGenerator loss: 1.1092615127563477, Discriminator loss: 1.050599217414856\n",
      "\tGenerator loss: 1.1018180847167969, Discriminator loss: 1.0322723388671875\n",
      "\tGenerator loss: 1.0648547410964966, Discriminator loss: 1.0215529203414917\n",
      "\tGenerator loss: 1.0867489576339722, Discriminator loss: 1.0481568574905396\n",
      "\tGenerator loss: 1.1604413986206055, Discriminator loss: 1.0362043380737305\n",
      "\tGenerator loss: 1.1396610736846924, Discriminator loss: 1.0180538892745972\n",
      "\tGenerator loss: 1.0786869525909424, Discriminator loss: 1.021103858947754\n",
      "\tGenerator loss: 1.0390719175338745, Discriminator loss: 1.0312516689300537\n",
      "\tGenerator loss: 1.0369956493377686, Discriminator loss: 1.0023880004882812\n",
      "\tGenerator loss: 1.1206454038619995, Discriminator loss: 0.9899502396583557\n",
      "\tGenerator loss: 1.1378850936889648, Discriminator loss: 0.9619978666305542\n",
      "\tGenerator loss: 1.145818829536438, Discriminator loss: 0.9550821185112\n",
      "\tGenerator loss: 1.1898553371429443, Discriminator loss: 1.0082563161849976\n",
      "\tGenerator loss: 1.168844223022461, Discriminator loss: 1.0587685108184814\n",
      "\tGenerator loss: 1.1199820041656494, Discriminator loss: 1.0856900215148926\n",
      "\tGenerator loss: 1.0958175659179688, Discriminator loss: 1.1003260612487793\n",
      "Time for epoch 21 is 216.76751732826233 sec\n",
      "\tGenerator loss: 1.043418526649475, Discriminator loss: 1.0747759342193604\n",
      "\tGenerator loss: 0.9834710955619812, Discriminator loss: 1.0982853174209595\n",
      "\tGenerator loss: 0.9790900945663452, Discriminator loss: 1.0778532028198242\n",
      "\tGenerator loss: 1.0308847427368164, Discriminator loss: 1.0424907207489014\n",
      "\tGenerator loss: 1.1350009441375732, Discriminator loss: 1.1004680395126343\n",
      "\tGenerator loss: 1.152045726776123, Discriminator loss: 1.1158829927444458\n",
      "\tGenerator loss: 1.1214464902877808, Discriminator loss: 1.0629332065582275\n",
      "\tGenerator loss: 1.059687852859497, Discriminator loss: 1.0800044536590576\n",
      "\tGenerator loss: 1.0185322761535645, Discriminator loss: 1.0544662475585938\n",
      "\tGenerator loss: 1.0276705026626587, Discriminator loss: 1.043875813484192\n",
      "\tGenerator loss: 1.0713257789611816, Discriminator loss: 1.0549395084381104\n",
      "\tGenerator loss: 1.1378567218780518, Discriminator loss: 1.0737521648406982\n",
      "\tGenerator loss: 1.1591267585754395, Discriminator loss: 1.0765798091888428\n",
      "\tGenerator loss: 1.104990839958191, Discriminator loss: 1.058558702468872\n",
      "\tGenerator loss: 1.037116527557373, Discriminator loss: 1.0792168378829956\n",
      "\tGenerator loss: 1.0247193574905396, Discriminator loss: 1.0506608486175537\n",
      "\tGenerator loss: 1.0238564014434814, Discriminator loss: 1.059193730354309\n",
      "\tGenerator loss: 1.102635145187378, Discriminator loss: 1.0353500843048096\n",
      "\tGenerator loss: 1.1038997173309326, Discriminator loss: 1.0713417530059814\n",
      "\tGenerator loss: 1.1323142051696777, Discriminator loss: 1.069643497467041\n",
      "\tGenerator loss: 1.131678819656372, Discriminator loss: 1.0392165184020996\n",
      "\tGenerator loss: 1.1203207969665527, Discriminator loss: 1.0913432836532593\n",
      "\tGenerator loss: 1.0949372053146362, Discriminator loss: 1.072296380996704\n",
      "\tGenerator loss: 1.0332252979278564, Discriminator loss: 1.1162595748901367\n",
      "\tGenerator loss: 1.0100517272949219, Discriminator loss: 1.082547664642334\n",
      "\tGenerator loss: 1.0190916061401367, Discriminator loss: 1.0744917392730713\n",
      "\tGenerator loss: 1.0990650653839111, Discriminator loss: 1.0592141151428223\n",
      "\tGenerator loss: 1.1025700569152832, Discriminator loss: 1.065828800201416\n",
      "\tGenerator loss: 1.1139628887176514, Discriminator loss: 1.1387430429458618\n",
      "\tGenerator loss: 1.0546612739562988, Discriminator loss: 1.090217113494873\n",
      "\tGenerator loss: 0.9842972159385681, Discriminator loss: 1.117066740989685\n",
      "\tGenerator loss: 0.9565780758857727, Discriminator loss: 1.1395535469055176\n",
      "\tGenerator loss: 0.9787185192108154, Discriminator loss: 1.1025655269622803\n",
      "\tGenerator loss: 1.031001329421997, Discriminator loss: 1.1538071632385254\n",
      "\tGenerator loss: 1.0819758176803589, Discriminator loss: 1.1748653650283813\n",
      "\tGenerator loss: 1.1176738739013672, Discriminator loss: 1.124152660369873\n",
      "\tGenerator loss: 1.0681962966918945, Discriminator loss: 1.1280616521835327\n",
      "\tGenerator loss: 0.9990746974945068, Discriminator loss: 1.1913225650787354\n",
      "\tGenerator loss: 0.9741501212120056, Discriminator loss: 1.1583421230316162\n",
      "\tGenerator loss: 0.9726274609565735, Discriminator loss: 1.1658560037612915\n",
      "\tGenerator loss: 0.9872564077377319, Discriminator loss: 1.129575490951538\n",
      "\tGenerator loss: 1.0535238981246948, Discriminator loss: 1.1329066753387451\n",
      "\tGenerator loss: 1.1251320838928223, Discriminator loss: 1.1481809616088867\n",
      "\tGenerator loss: 1.1283538341522217, Discriminator loss: 1.1361358165740967\n",
      "\tGenerator loss: 1.0717006921768188, Discriminator loss: 1.1281826496124268\n",
      "\tGenerator loss: 0.9945387840270996, Discriminator loss: 1.1886006593704224\n",
      "\tGenerator loss: 0.9454582929611206, Discriminator loss: 1.1827056407928467\n",
      "\tGenerator loss: 0.8987356424331665, Discriminator loss: 1.2137686014175415\n",
      "\tGenerator loss: 0.908049464225769, Discriminator loss: 1.2057626247406006\n",
      "\tGenerator loss: 0.9570475220680237, Discriminator loss: 1.1914787292480469\n",
      "\tGenerator loss: 1.0225520133972168, Discriminator loss: 1.2683836221694946\n",
      "\tGenerator loss: 1.0723038911819458, Discriminator loss: 1.2702949047088623\n",
      "\tGenerator loss: 1.083461046218872, Discriminator loss: 1.1678450107574463\n",
      "\tGenerator loss: 1.0360220670700073, Discriminator loss: 1.2192678451538086\n",
      "\tGenerator loss: 0.958184003829956, Discriminator loss: 1.2394134998321533\n",
      "\tGenerator loss: 0.9137274622917175, Discriminator loss: 1.2776072025299072\n",
      "\tGenerator loss: 0.8821455240249634, Discriminator loss: 1.238877773284912\n",
      "\tGenerator loss: 0.9101487994194031, Discriminator loss: 1.228379726409912\n",
      "\tGenerator loss: 0.9530298709869385, Discriminator loss: 1.1754095554351807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0289294719696045, Discriminator loss: 1.1513371467590332\n",
      "\tGenerator loss: 1.0929268598556519, Discriminator loss: 1.1674747467041016\n",
      "\tGenerator loss: 1.0667686462402344, Discriminator loss: 1.180689811706543\n",
      "\tGenerator loss: 0.9748623371124268, Discriminator loss: 1.2522087097167969\n",
      "\tGenerator loss: 0.9086806178092957, Discriminator loss: 1.2257128953933716\n",
      "\tGenerator loss: 0.8706128597259521, Discriminator loss: 1.1822500228881836\n",
      "\tGenerator loss: 0.9038658142089844, Discriminator loss: 1.2079768180847168\n",
      "\tGenerator loss: 0.9707614183425903, Discriminator loss: 1.2321341037750244\n",
      "\tGenerator loss: 1.0374231338500977, Discriminator loss: 1.2448643445968628\n",
      "\tGenerator loss: 1.0744647979736328, Discriminator loss: 1.2611608505249023\n",
      "\tGenerator loss: 1.0137104988098145, Discriminator loss: 1.204576015472412\n",
      "\tGenerator loss: 0.9269498586654663, Discriminator loss: 1.1813310384750366\n",
      "\tGenerator loss: 0.9011547565460205, Discriminator loss: 1.1551074981689453\n",
      "\tGenerator loss: 0.9241214394569397, Discriminator loss: 1.1385043859481812\n",
      "\tGenerator loss: 0.9807025194168091, Discriminator loss: 1.158557653427124\n",
      "\tGenerator loss: 1.036543846130371, Discriminator loss: 1.1261320114135742\n",
      "\tGenerator loss: 1.0738734006881714, Discriminator loss: 1.2036657333374023\n",
      "\tGenerator loss: 1.1029012203216553, Discriminator loss: 1.2672556638717651\n",
      "\tGenerator loss: 1.0405349731445312, Discriminator loss: 1.2539572715759277\n",
      "\tGenerator loss: 0.9706166386604309, Discriminator loss: 1.227573037147522\n",
      "\tGenerator loss: 0.9104841351509094, Discriminator loss: 1.2140095233917236\n",
      "\tGenerator loss: 0.8882977962493896, Discriminator loss: 1.2299761772155762\n",
      "\tGenerator loss: 0.9544883966445923, Discriminator loss: 1.232521414756775\n",
      "\tGenerator loss: 1.0048925876617432, Discriminator loss: 1.1733763217926025\n",
      "\tGenerator loss: 1.0433945655822754, Discriminator loss: 1.1891063451766968\n",
      "\tGenerator loss: 1.1075100898742676, Discriminator loss: 1.1238373517990112\n",
      "\tGenerator loss: 1.0987483263015747, Discriminator loss: 1.2657208442687988\n",
      "\tGenerator loss: 1.0507557392120361, Discriminator loss: 1.1868311166763306\n",
      "\tGenerator loss: 0.9859189391136169, Discriminator loss: 1.2111146450042725\n",
      "\tGenerator loss: 0.9589108228683472, Discriminator loss: 1.3744614124298096\n",
      "\tGenerator loss: 0.9258590936660767, Discriminator loss: 1.4047327041625977\n",
      "\tGenerator loss: 0.9254245758056641, Discriminator loss: 1.3711459636688232\n",
      "\tGenerator loss: 0.9188271760940552, Discriminator loss: 1.3096084594726562\n",
      "\tGenerator loss: 0.9532420039176941, Discriminator loss: 1.2036136388778687\n",
      "\tGenerator loss: 0.9894651174545288, Discriminator loss: 1.2177386283874512\n",
      "\tGenerator loss: 1.0283840894699097, Discriminator loss: 1.2338546514511108\n",
      "\tGenerator loss: 1.065356731414795, Discriminator loss: 1.239574909210205\n",
      "\tGenerator loss: 1.0518277883529663, Discriminator loss: 1.262420415878296\n",
      "\tGenerator loss: 0.9700586199760437, Discriminator loss: 1.2434437274932861\n",
      "\tGenerator loss: 0.9189174175262451, Discriminator loss: 1.2387409210205078\n",
      "\tGenerator loss: 0.9276654124259949, Discriminator loss: 1.2586864233016968\n",
      "\tGenerator loss: 0.9841848611831665, Discriminator loss: 1.185063362121582\n",
      "\tGenerator loss: 1.071225643157959, Discriminator loss: 1.166690468788147\n",
      "\tGenerator loss: 1.1253712177276611, Discriminator loss: 1.1457717418670654\n",
      "\tGenerator loss: 1.1142818927764893, Discriminator loss: 1.13835608959198\n",
      "\tGenerator loss: 1.065166711807251, Discriminator loss: 1.164053201675415\n",
      "\tGenerator loss: 0.9935864210128784, Discriminator loss: 1.1311019659042358\n",
      "\tGenerator loss: 0.9855024218559265, Discriminator loss: 1.1615824699401855\n",
      "\tGenerator loss: 1.0188021659851074, Discriminator loss: 1.1265465021133423\n",
      "\tGenerator loss: 1.0802088975906372, Discriminator loss: 1.1105687618255615\n",
      "\tGenerator loss: 1.1194021701812744, Discriminator loss: 1.1695013046264648\n",
      "\tGenerator loss: 1.1007741689682007, Discriminator loss: 1.2287023067474365\n",
      "\tGenerator loss: 1.08396577835083, Discriminator loss: 1.2445354461669922\n",
      "\tGenerator loss: 1.0032315254211426, Discriminator loss: 1.2152376174926758\n",
      "\tGenerator loss: 0.9563006162643433, Discriminator loss: 1.2086315155029297\n",
      "\tGenerator loss: 0.97530198097229, Discriminator loss: 1.251063585281372\n",
      "\tGenerator loss: 0.990572452545166, Discriminator loss: 1.1702187061309814\n",
      "\tGenerator loss: 1.0743120908737183, Discriminator loss: 1.181555151939392\n",
      "\tGenerator loss: 1.0964546203613281, Discriminator loss: 1.216191053390503\n",
      "\tGenerator loss: 1.0687520503997803, Discriminator loss: 1.1294479370117188\n",
      "\tGenerator loss: 1.0667967796325684, Discriminator loss: 1.1255682706832886\n",
      "\tGenerator loss: 1.0307670831680298, Discriminator loss: 1.0986862182617188\n",
      "\tGenerator loss: 1.018343448638916, Discriminator loss: 1.0863035917282104\n",
      "\tGenerator loss: 1.045917272567749, Discriminator loss: 1.1029226779937744\n",
      "\tGenerator loss: 1.0554755926132202, Discriminator loss: 1.1399786472320557\n",
      "\tGenerator loss: 1.0891172885894775, Discriminator loss: 1.104745626449585\n",
      "\tGenerator loss: 1.1157331466674805, Discriminator loss: 1.1261452436447144\n",
      "\tGenerator loss: 1.1301813125610352, Discriminator loss: 1.2010326385498047\n",
      "\tGenerator loss: 1.1095293760299683, Discriminator loss: 1.1807326078414917\n",
      "\tGenerator loss: 1.030798077583313, Discriminator loss: 1.120086669921875\n",
      "\tGenerator loss: 1.0207096338272095, Discriminator loss: 1.1532467603683472\n",
      "\tGenerator loss: 1.035807728767395, Discriminator loss: 1.1282927989959717\n",
      "\tGenerator loss: 1.0745177268981934, Discriminator loss: 1.1360366344451904\n",
      "\tGenerator loss: 1.116875410079956, Discriminator loss: 1.1589558124542236\n",
      "\tGenerator loss: 1.0649068355560303, Discriminator loss: 1.1807645559310913\n",
      "\tGenerator loss: 1.0808862447738647, Discriminator loss: 1.128709077835083\n",
      "\tGenerator loss: 1.078800916671753, Discriminator loss: 1.1934716701507568\n",
      "\tGenerator loss: 1.0591028928756714, Discriminator loss: 1.171271562576294\n",
      "\tGenerator loss: 1.0410499572753906, Discriminator loss: 1.1463725566864014\n",
      "\tGenerator loss: 1.0403358936309814, Discriminator loss: 1.167938470840454\n",
      "\tGenerator loss: 1.0385444164276123, Discriminator loss: 1.1428364515304565\n",
      "\tGenerator loss: 1.0415791273117065, Discriminator loss: 1.1513144969940186\n",
      "\tGenerator loss: 1.0488574504852295, Discriminator loss: 1.1890249252319336\n",
      "\tGenerator loss: 1.073197841644287, Discriminator loss: 1.1614434719085693\n",
      "\tGenerator loss: 1.069563865661621, Discriminator loss: 1.1831798553466797\n",
      "\tGenerator loss: 1.0319627523422241, Discriminator loss: 1.211173176765442\n",
      "\tGenerator loss: 1.040704369544983, Discriminator loss: 1.2068967819213867\n",
      "\tGenerator loss: 1.074906349182129, Discriminator loss: 1.159561276435852\n",
      "\tGenerator loss: 1.084628939628601, Discriminator loss: 1.1337697505950928\n",
      "\tGenerator loss: 1.0804102420806885, Discriminator loss: 1.1223565340042114\n",
      "\tGenerator loss: 1.0636004209518433, Discriminator loss: 1.1167802810668945\n",
      "\tGenerator loss: 1.023736596107483, Discriminator loss: 1.1419973373413086\n",
      "\tGenerator loss: 1.0073018074035645, Discriminator loss: 1.135448932647705\n",
      "\tGenerator loss: 1.0457477569580078, Discriminator loss: 1.129277229309082\n",
      "\tGenerator loss: 1.0910494327545166, Discriminator loss: 1.1846890449523926\n",
      "\tGenerator loss: 1.0940473079681396, Discriminator loss: 1.2085680961608887\n",
      "\tGenerator loss: 1.0930535793304443, Discriminator loss: 1.192641019821167\n",
      "\tGenerator loss: 1.0415396690368652, Discriminator loss: 1.1884968280792236\n",
      "\tGenerator loss: 1.0082980394363403, Discriminator loss: 1.1374893188476562\n",
      "\tGenerator loss: 1.0063412189483643, Discriminator loss: 1.1677072048187256\n",
      "\tGenerator loss: 1.0229558944702148, Discriminator loss: 1.108607530593872\n",
      "\tGenerator loss: 1.0756443738937378, Discriminator loss: 1.0897514820098877\n",
      "\tGenerator loss: 1.1307504177093506, Discriminator loss: 1.1197593212127686\n",
      "\tGenerator loss: 1.1441230773925781, Discriminator loss: 1.1646602153778076\n",
      "\tGenerator loss: 1.1193455457687378, Discriminator loss: 1.1753748655319214\n",
      "\tGenerator loss: 1.0217607021331787, Discriminator loss: 1.1796164512634277\n",
      "\tGenerator loss: 0.9680177569389343, Discriminator loss: 1.1308093070983887\n",
      "\tGenerator loss: 0.954501211643219, Discriminator loss: 1.143339991569519\n",
      "\tGenerator loss: 0.990453839302063, Discriminator loss: 1.080297827720642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0865416526794434, Discriminator loss: 1.0369460582733154\n",
      "\tGenerator loss: 1.2238852977752686, Discriminator loss: 1.0481700897216797\n",
      "\tGenerator loss: 1.3078734874725342, Discriminator loss: 1.0713317394256592\n",
      "\tGenerator loss: 1.255873680114746, Discriminator loss: 1.0313856601715088\n",
      "\tGenerator loss: 1.1552987098693848, Discriminator loss: 1.0323710441589355\n",
      "\tGenerator loss: 1.0515108108520508, Discriminator loss: 1.0283156633377075\n",
      "\tGenerator loss: 0.9879287481307983, Discriminator loss: 1.0458896160125732\n",
      "\tGenerator loss: 1.0451127290725708, Discriminator loss: 1.0437133312225342\n",
      "\tGenerator loss: 1.1138744354248047, Discriminator loss: 1.0028406381607056\n",
      "\tGenerator loss: 1.198047399520874, Discriminator loss: 0.9933291673660278\n",
      "\tGenerator loss: 1.2330236434936523, Discriminator loss: 1.0175995826721191\n",
      "\tGenerator loss: 1.229794979095459, Discriminator loss: 1.0629217624664307\n",
      "\tGenerator loss: 1.1250355243682861, Discriminator loss: 1.0527421236038208\n",
      "\tGenerator loss: 1.0180468559265137, Discriminator loss: 1.0455940961837769\n",
      "\tGenerator loss: 0.9896247982978821, Discriminator loss: 1.0195057392120361\n",
      "\tGenerator loss: 1.0492277145385742, Discriminator loss: 0.995919942855835\n",
      "\tGenerator loss: 1.1909133195877075, Discriminator loss: 1.018254041671753\n",
      "\tGenerator loss: 1.2609460353851318, Discriminator loss: 1.0215208530426025\n",
      "\tGenerator loss: 1.2800058126449585, Discriminator loss: 1.011910319328308\n",
      "\tGenerator loss: 1.225232720375061, Discriminator loss: 1.0686211585998535\n",
      "\tGenerator loss: 1.155871868133545, Discriminator loss: 1.0896501541137695\n",
      "\tGenerator loss: 1.1131079196929932, Discriminator loss: 1.06599760055542\n",
      "\tGenerator loss: 1.069076418876648, Discriminator loss: 1.0690741539001465\n",
      "\tGenerator loss: 1.0681302547454834, Discriminator loss: 1.0538994073867798\n",
      "\tGenerator loss: 1.0482177734375, Discriminator loss: 1.076232671737671\n",
      "\tGenerator loss: 1.0960988998413086, Discriminator loss: 1.0678832530975342\n",
      "\tGenerator loss: 1.1806551218032837, Discriminator loss: 1.0297486782073975\n",
      "\tGenerator loss: 1.2080767154693604, Discriminator loss: 1.0352219343185425\n",
      "\tGenerator loss: 1.172957181930542, Discriminator loss: 1.0582268238067627\n",
      "\tGenerator loss: 1.1019915342330933, Discriminator loss: 1.0491855144500732\n",
      "\tGenerator loss: 1.0066709518432617, Discriminator loss: 1.1181871891021729\n",
      "\tGenerator loss: 0.9622262716293335, Discriminator loss: 1.102916955947876\n",
      "\tGenerator loss: 0.9932577013969421, Discriminator loss: 1.0981841087341309\n",
      "\tGenerator loss: 1.0502291917800903, Discriminator loss: 1.045602560043335\n",
      "\tGenerator loss: 1.1421312093734741, Discriminator loss: 1.08230721950531\n",
      "\tGenerator loss: 1.1989431381225586, Discriminator loss: 1.056883692741394\n",
      "\tGenerator loss: 1.1388591527938843, Discriminator loss: 1.093982219696045\n",
      "\tGenerator loss: 1.0708630084991455, Discriminator loss: 1.0795245170593262\n",
      "\tGenerator loss: 0.9872183799743652, Discriminator loss: 1.1372392177581787\n",
      "\tGenerator loss: 0.9394900798797607, Discriminator loss: 1.1537187099456787\n",
      "\tGenerator loss: 0.9435418844223022, Discriminator loss: 1.1770955324172974\n",
      "\tGenerator loss: 0.9750111103057861, Discriminator loss: 1.17667555809021\n",
      "\tGenerator loss: 1.0815671682357788, Discriminator loss: 1.1329021453857422\n",
      "\tGenerator loss: 1.1430561542510986, Discriminator loss: 1.1386096477508545\n",
      "\tGenerator loss: 1.1357028484344482, Discriminator loss: 1.172907829284668\n",
      "\tGenerator loss: 1.060312032699585, Discriminator loss: 1.1957392692565918\n",
      "\tGenerator loss: 0.9588314294815063, Discriminator loss: 1.1889333724975586\n",
      "\tGenerator loss: 0.922091007232666, Discriminator loss: 1.181566596031189\n",
      "\tGenerator loss: 0.9139833450317383, Discriminator loss: 1.2250394821166992\n",
      "\tGenerator loss: 0.9790064096450806, Discriminator loss: 1.2405967712402344\n",
      "\tGenerator loss: 1.0681792497634888, Discriminator loss: 1.1850837469100952\n",
      "\tGenerator loss: 1.0880277156829834, Discriminator loss: 1.1985719203948975\n",
      "\tGenerator loss: 1.1009925603866577, Discriminator loss: 1.2014796733856201\n",
      "\tGenerator loss: 1.0108364820480347, Discriminator loss: 1.2203614711761475\n",
      "\tGenerator loss: 0.9608014822006226, Discriminator loss: 1.2477607727050781\n",
      "\tGenerator loss: 0.925125241279602, Discriminator loss: 1.2137365341186523\n",
      "\tGenerator loss: 0.9388304948806763, Discriminator loss: 1.1659572124481201\n",
      "\tGenerator loss: 1.0085041522979736, Discriminator loss: 1.158194899559021\n",
      "\tGenerator loss: 1.0106182098388672, Discriminator loss: 1.2087043523788452\n",
      "\tGenerator loss: 1.064820408821106, Discriminator loss: 1.1184055805206299\n",
      "\tGenerator loss: 1.0906293392181396, Discriminator loss: 1.174053430557251\n",
      "\tGenerator loss: 1.0873637199401855, Discriminator loss: 1.1512095928192139\n",
      "\tGenerator loss: 1.0228564739227295, Discriminator loss: 1.1324008703231812\n",
      "\tGenerator loss: 0.9894624352455139, Discriminator loss: 1.127317190170288\n",
      "\tGenerator loss: 1.0131734609603882, Discriminator loss: 1.18145751953125\n",
      "\tGenerator loss: 1.088148832321167, Discriminator loss: 1.2044398784637451\n",
      "\tGenerator loss: 1.174391508102417, Discriminator loss: 1.0784882307052612\n",
      "Time for epoch 22 is 253.53722429275513 sec\n",
      "\tGenerator loss: 1.1608681678771973, Discriminator loss: 1.1146893501281738\n",
      "\tGenerator loss: 1.0960652828216553, Discriminator loss: 1.1377537250518799\n",
      "\tGenerator loss: 1.0261390209197998, Discriminator loss: 1.1650532484054565\n",
      "\tGenerator loss: 0.9959666132926941, Discriminator loss: 1.1312918663024902\n",
      "\tGenerator loss: 0.9802044630050659, Discriminator loss: 1.1928802728652954\n",
      "\tGenerator loss: 1.0010011196136475, Discriminator loss: 1.1829607486724854\n",
      "\tGenerator loss: 1.0645174980163574, Discriminator loss: 1.1271166801452637\n",
      "\tGenerator loss: 1.1440626382827759, Discriminator loss: 1.1367697715759277\n",
      "\tGenerator loss: 1.2144831418991089, Discriminator loss: 1.1388511657714844\n",
      "\tGenerator loss: 1.2034521102905273, Discriminator loss: 1.0843923091888428\n",
      "\tGenerator loss: 1.1502543687820435, Discriminator loss: 1.1014821529388428\n",
      "\tGenerator loss: 1.0983433723449707, Discriminator loss: 1.1179471015930176\n",
      "\tGenerator loss: 1.0409789085388184, Discriminator loss: 1.1699916124343872\n",
      "\tGenerator loss: 1.012835144996643, Discriminator loss: 1.1410841941833496\n",
      "\tGenerator loss: 1.0222272872924805, Discriminator loss: 1.1410236358642578\n",
      "\tGenerator loss: 1.111928939819336, Discriminator loss: 1.152008056640625\n",
      "\tGenerator loss: 1.1976909637451172, Discriminator loss: 1.1487247943878174\n",
      "\tGenerator loss: 1.1911537647247314, Discriminator loss: 1.1443684101104736\n",
      "\tGenerator loss: 1.1694316864013672, Discriminator loss: 1.130600094795227\n",
      "\tGenerator loss: 1.1349704265594482, Discriminator loss: 1.1164615154266357\n",
      "\tGenerator loss: 1.0771301984786987, Discriminator loss: 1.105571985244751\n",
      "\tGenerator loss: 1.087637186050415, Discriminator loss: 1.0948606729507446\n",
      "\tGenerator loss: 1.1550637483596802, Discriminator loss: 1.1194298267364502\n",
      "\tGenerator loss: 1.1863234043121338, Discriminator loss: 1.116133451461792\n",
      "\tGenerator loss: 1.1749250888824463, Discriminator loss: 1.134660005569458\n",
      "\tGenerator loss: 1.142249345779419, Discriminator loss: 1.126947045326233\n",
      "\tGenerator loss: 1.1331465244293213, Discriminator loss: 1.1755218505859375\n",
      "\tGenerator loss: 1.1076425313949585, Discriminator loss: 1.1820597648620605\n",
      "\tGenerator loss: 1.0548877716064453, Discriminator loss: 1.2293952703475952\n",
      "\tGenerator loss: 1.0061774253845215, Discriminator loss: 1.212151050567627\n",
      "\tGenerator loss: 0.9999204874038696, Discriminator loss: 1.1445294618606567\n",
      "\tGenerator loss: 1.0390300750732422, Discriminator loss: 1.179215908050537\n",
      "\tGenerator loss: 1.1507905721664429, Discriminator loss: 1.157423496246338\n",
      "\tGenerator loss: 1.18007230758667, Discriminator loss: 1.2017064094543457\n",
      "\tGenerator loss: 1.2100064754486084, Discriminator loss: 1.1657936573028564\n",
      "\tGenerator loss: 1.1723982095718384, Discriminator loss: 1.1925318241119385\n",
      "\tGenerator loss: 1.0418198108673096, Discriminator loss: 1.1862167119979858\n",
      "\tGenerator loss: 1.0013281106948853, Discriminator loss: 1.1741352081298828\n",
      "\tGenerator loss: 1.0078620910644531, Discriminator loss: 1.1175055503845215\n",
      "\tGenerator loss: 1.0863827466964722, Discriminator loss: 1.1046169996261597\n",
      "\tGenerator loss: 1.1880199909210205, Discriminator loss: 1.1605134010314941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2905317544937134, Discriminator loss: 1.1471368074417114\n",
      "\tGenerator loss: 1.2721657752990723, Discriminator loss: 1.1726555824279785\n",
      "\tGenerator loss: 1.1707983016967773, Discriminator loss: 1.193760633468628\n",
      "\tGenerator loss: 1.026160717010498, Discriminator loss: 1.1956876516342163\n",
      "\tGenerator loss: 0.9571331143379211, Discriminator loss: 1.2179147005081177\n",
      "\tGenerator loss: 0.9664514064788818, Discriminator loss: 1.2199506759643555\n",
      "\tGenerator loss: 0.9971240758895874, Discriminator loss: 1.2005820274353027\n",
      "\tGenerator loss: 1.0690408945083618, Discriminator loss: 1.157852053642273\n",
      "\tGenerator loss: 1.1846294403076172, Discriminator loss: 1.1388537883758545\n",
      "\tGenerator loss: 1.2241404056549072, Discriminator loss: 1.1781926155090332\n",
      "\tGenerator loss: 1.2177140712738037, Discriminator loss: 1.1290425062179565\n",
      "\tGenerator loss: 1.1728345155715942, Discriminator loss: 1.10896635055542\n",
      "\tGenerator loss: 1.0787750482559204, Discriminator loss: 1.1592302322387695\n",
      "\tGenerator loss: 1.0019006729125977, Discriminator loss: 1.1678543090820312\n",
      "\tGenerator loss: 1.0115078687667847, Discriminator loss: 1.1361019611358643\n",
      "\tGenerator loss: 1.0471792221069336, Discriminator loss: 1.1646630764007568\n",
      "\tGenerator loss: 1.1105260848999023, Discriminator loss: 1.1198729276657104\n",
      "\tGenerator loss: 1.148716688156128, Discriminator loss: 1.148226261138916\n",
      "\tGenerator loss: 1.1547068357467651, Discriminator loss: 1.1752324104309082\n",
      "\tGenerator loss: 1.084437608718872, Discriminator loss: 1.1351813077926636\n",
      "\tGenerator loss: 1.0123491287231445, Discriminator loss: 1.0878527164459229\n",
      "\tGenerator loss: 0.9837897419929504, Discriminator loss: 1.1235935688018799\n",
      "\tGenerator loss: 1.0011122226715088, Discriminator loss: 1.1276503801345825\n",
      "\tGenerator loss: 1.1009272336959839, Discriminator loss: 1.1298763751983643\n",
      "\tGenerator loss: 1.1726441383361816, Discriminator loss: 1.092752456665039\n",
      "\tGenerator loss: 1.2406258583068848, Discriminator loss: 1.0988508462905884\n",
      "\tGenerator loss: 1.2097530364990234, Discriminator loss: 1.0496337413787842\n",
      "\tGenerator loss: 1.1694202423095703, Discriminator loss: 1.057436227798462\n",
      "\tGenerator loss: 1.136549949645996, Discriminator loss: 1.0341883897781372\n",
      "\tGenerator loss: 1.136199712753296, Discriminator loss: 0.9702689051628113\n",
      "\tGenerator loss: 1.1341480016708374, Discriminator loss: 1.0041559934616089\n",
      "\tGenerator loss: 1.177253007888794, Discriminator loss: 0.9905313849449158\n",
      "\tGenerator loss: 1.258206844329834, Discriminator loss: 0.9572699069976807\n",
      "\tGenerator loss: 1.290247917175293, Discriminator loss: 0.9381520748138428\n",
      "\tGenerator loss: 1.2778501510620117, Discriminator loss: 0.9233345985412598\n",
      "\tGenerator loss: 1.2908740043640137, Discriminator loss: 0.9355076551437378\n",
      "\tGenerator loss: 1.2825274467468262, Discriminator loss: 0.895708441734314\n",
      "\tGenerator loss: 1.3115816116333008, Discriminator loss: 0.8812236189842224\n",
      "\tGenerator loss: 1.3318462371826172, Discriminator loss: 0.8637890815734863\n",
      "\tGenerator loss: 1.3674871921539307, Discriminator loss: 0.8475177884101868\n",
      "\tGenerator loss: 1.4178396463394165, Discriminator loss: 0.8391264081001282\n",
      "\tGenerator loss: 1.4277007579803467, Discriminator loss: 0.8336502313613892\n",
      "\tGenerator loss: 1.397406816482544, Discriminator loss: 0.8314374685287476\n",
      "\tGenerator loss: 1.4089531898498535, Discriminator loss: 0.8070345520973206\n",
      "\tGenerator loss: 1.385678768157959, Discriminator loss: 0.8363957405090332\n",
      "\tGenerator loss: 1.3770527839660645, Discriminator loss: 0.8351448178291321\n",
      "\tGenerator loss: 1.3991713523864746, Discriminator loss: 0.817501425743103\n",
      "\tGenerator loss: 1.4195175170898438, Discriminator loss: 0.8442481160163879\n",
      "\tGenerator loss: 1.4536693096160889, Discriminator loss: 0.8486454486846924\n",
      "\tGenerator loss: 1.400856375694275, Discriminator loss: 0.8480684757232666\n",
      "\tGenerator loss: 1.3490374088287354, Discriminator loss: 0.8425971269607544\n",
      "\tGenerator loss: 1.3552429676055908, Discriminator loss: 0.8312472105026245\n",
      "\tGenerator loss: 1.3235851526260376, Discriminator loss: 0.8385406732559204\n",
      "\tGenerator loss: 1.3311262130737305, Discriminator loss: 0.8702986836433411\n",
      "\tGenerator loss: 1.3725342750549316, Discriminator loss: 0.851683497428894\n",
      "\tGenerator loss: 1.3967556953430176, Discriminator loss: 0.8595561981201172\n",
      "\tGenerator loss: 1.3652323484420776, Discriminator loss: 0.8903574347496033\n",
      "\tGenerator loss: 1.3160488605499268, Discriminator loss: 0.885928750038147\n",
      "\tGenerator loss: 1.2723389863967896, Discriminator loss: 0.8851284384727478\n",
      "\tGenerator loss: 1.2208342552185059, Discriminator loss: 0.9291244745254517\n",
      "\tGenerator loss: 1.2091774940490723, Discriminator loss: 0.948657751083374\n",
      "\tGenerator loss: 1.2165061235427856, Discriminator loss: 0.9773305058479309\n",
      "\tGenerator loss: 1.2112598419189453, Discriminator loss: 1.0331132411956787\n",
      "\tGenerator loss: 1.1893501281738281, Discriminator loss: 1.053789496421814\n",
      "\tGenerator loss: 1.1327879428863525, Discriminator loss: 1.0373847484588623\n",
      "\tGenerator loss: 1.1353317499160767, Discriminator loss: 1.0707786083221436\n",
      "\tGenerator loss: 1.1212937831878662, Discriminator loss: 1.0236701965332031\n",
      "\tGenerator loss: 1.1124595403671265, Discriminator loss: 1.0765712261199951\n",
      "\tGenerator loss: 1.1130399703979492, Discriminator loss: 1.1283375024795532\n",
      "\tGenerator loss: 1.0818030834197998, Discriminator loss: 1.1662706136703491\n",
      "\tGenerator loss: 1.0809555053710938, Discriminator loss: 1.1503229141235352\n",
      "\tGenerator loss: 1.0597622394561768, Discriminator loss: 1.1376757621765137\n",
      "\tGenerator loss: 1.022829294204712, Discriminator loss: 1.1797003746032715\n",
      "\tGenerator loss: 0.9791125655174255, Discriminator loss: 1.246722936630249\n",
      "\tGenerator loss: 0.9674285650253296, Discriminator loss: 1.225978970527649\n",
      "\tGenerator loss: 0.9571623206138611, Discriminator loss: 1.2370513677597046\n",
      "\tGenerator loss: 0.9674789905548096, Discriminator loss: 1.2664828300476074\n",
      "\tGenerator loss: 0.9768237471580505, Discriminator loss: 1.2125751972198486\n",
      "\tGenerator loss: 0.9748085737228394, Discriminator loss: 1.2395297288894653\n",
      "\tGenerator loss: 0.9707142114639282, Discriminator loss: 1.2351648807525635\n",
      "\tGenerator loss: 0.9497120380401611, Discriminator loss: 1.2316231727600098\n",
      "\tGenerator loss: 0.9237390756607056, Discriminator loss: 1.2432925701141357\n",
      "\tGenerator loss: 0.9414966106414795, Discriminator loss: 1.1892051696777344\n",
      "\tGenerator loss: 0.9420914053916931, Discriminator loss: 1.2178255319595337\n",
      "\tGenerator loss: 0.9758987426757812, Discriminator loss: 1.2728772163391113\n",
      "\tGenerator loss: 0.992608904838562, Discriminator loss: 1.3810086250305176\n",
      "\tGenerator loss: 0.9715758562088013, Discriminator loss: 1.2582060098648071\n",
      "\tGenerator loss: 0.967076301574707, Discriminator loss: 1.2046968936920166\n",
      "\tGenerator loss: 0.953279972076416, Discriminator loss: 1.2755975723266602\n",
      "\tGenerator loss: 0.9750514626502991, Discriminator loss: 1.164503812789917\n",
      "\tGenerator loss: 1.074496865272522, Discriminator loss: 1.1213167905807495\n",
      "\tGenerator loss: 1.1412479877471924, Discriminator loss: 1.156131625175476\n",
      "\tGenerator loss: 1.1649144887924194, Discriminator loss: 1.130926489830017\n",
      "\tGenerator loss: 1.1471507549285889, Discriminator loss: 1.101571798324585\n",
      "\tGenerator loss: 1.077111005783081, Discriminator loss: 1.1637126207351685\n",
      "\tGenerator loss: 1.0251528024673462, Discriminator loss: 1.2360105514526367\n",
      "\tGenerator loss: 1.0574886798858643, Discriminator loss: 1.1521856784820557\n",
      "\tGenerator loss: 1.090064525604248, Discriminator loss: 1.1624356508255005\n",
      "\tGenerator loss: 1.1340614557266235, Discriminator loss: 1.084958791732788\n",
      "\tGenerator loss: 1.1849524974822998, Discriminator loss: 1.01393723487854\n",
      "\tGenerator loss: 1.252791404724121, Discriminator loss: 1.1213021278381348\n",
      "\tGenerator loss: 1.2496588230133057, Discriminator loss: 1.1146275997161865\n",
      "\tGenerator loss: 1.2368583679199219, Discriminator loss: 1.2501673698425293\n",
      "\tGenerator loss: 1.1779680252075195, Discriminator loss: 1.1869726181030273\n",
      "\tGenerator loss: 1.11239755153656, Discriminator loss: 1.2386776208877563\n",
      "\tGenerator loss: 1.0619816780090332, Discriminator loss: 1.1406095027923584\n",
      "\tGenerator loss: 1.09339439868927, Discriminator loss: 1.0677809715270996\n",
      "\tGenerator loss: 1.1603319644927979, Discriminator loss: 1.0361149311065674\n",
      "\tGenerator loss: 1.2714159488677979, Discriminator loss: 1.0159590244293213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.3114588260650635, Discriminator loss: 1.0207443237304688\n",
      "\tGenerator loss: 1.2674899101257324, Discriminator loss: 0.995807409286499\n",
      "\tGenerator loss: 1.251598834991455, Discriminator loss: 0.9925394058227539\n",
      "\tGenerator loss: 1.2208364009857178, Discriminator loss: 1.0806487798690796\n",
      "\tGenerator loss: 1.204431176185608, Discriminator loss: 1.1082310676574707\n",
      "\tGenerator loss: 1.12679123878479, Discriminator loss: 1.0612022876739502\n",
      "\tGenerator loss: 1.1351721286773682, Discriminator loss: 1.0734224319458008\n",
      "\tGenerator loss: 1.1800692081451416, Discriminator loss: 1.0110421180725098\n",
      "\tGenerator loss: 1.2357807159423828, Discriminator loss: 1.0989758968353271\n",
      "\tGenerator loss: 1.2811808586120605, Discriminator loss: 1.0363776683807373\n",
      "\tGenerator loss: 1.3557931184768677, Discriminator loss: 0.9871517419815063\n",
      "\tGenerator loss: 1.3428072929382324, Discriminator loss: 1.0401371717453003\n",
      "\tGenerator loss: 1.2695900201797485, Discriminator loss: 1.0652306079864502\n",
      "\tGenerator loss: 1.1200740337371826, Discriminator loss: 1.11911141872406\n",
      "\tGenerator loss: 1.0599076747894287, Discriminator loss: 1.1161248683929443\n",
      "\tGenerator loss: 1.0600788593292236, Discriminator loss: 1.1196467876434326\n",
      "\tGenerator loss: 1.164675235748291, Discriminator loss: 1.08772611618042\n",
      "\tGenerator loss: 1.305681586265564, Discriminator loss: 1.020298719406128\n",
      "\tGenerator loss: 1.4170513153076172, Discriminator loss: 1.007009506225586\n",
      "\tGenerator loss: 1.4496076107025146, Discriminator loss: 0.9754248261451721\n",
      "\tGenerator loss: 1.4042284488677979, Discriminator loss: 1.025904655456543\n",
      "\tGenerator loss: 1.2793009281158447, Discriminator loss: 1.0122971534729004\n",
      "\tGenerator loss: 1.1742750406265259, Discriminator loss: 1.0546748638153076\n",
      "\tGenerator loss: 1.167564868927002, Discriminator loss: 1.060821294784546\n",
      "\tGenerator loss: 1.18777596950531, Discriminator loss: 0.9962300658226013\n",
      "\tGenerator loss: 1.252213716506958, Discriminator loss: 1.0503716468811035\n",
      "\tGenerator loss: 1.3788388967514038, Discriminator loss: 1.033420205116272\n",
      "\tGenerator loss: 1.3668773174285889, Discriminator loss: 1.0822551250457764\n",
      "\tGenerator loss: 1.3451851606369019, Discriminator loss: 1.0782337188720703\n",
      "\tGenerator loss: 1.2264400720596313, Discriminator loss: 1.216639518737793\n",
      "\tGenerator loss: 1.1034858226776123, Discriminator loss: 1.1640750169754028\n",
      "\tGenerator loss: 1.046205759048462, Discriminator loss: 1.1518664360046387\n",
      "\tGenerator loss: 1.0943732261657715, Discriminator loss: 1.0557377338409424\n",
      "\tGenerator loss: 1.2238092422485352, Discriminator loss: 1.0905874967575073\n",
      "\tGenerator loss: 1.427917242050171, Discriminator loss: 1.1401684284210205\n",
      "\tGenerator loss: 1.407781958580017, Discriminator loss: 1.2234004735946655\n",
      "\tGenerator loss: 1.3017194271087646, Discriminator loss: 1.181910753250122\n",
      "\tGenerator loss: 1.1846917867660522, Discriminator loss: 1.1540453433990479\n",
      "\tGenerator loss: 1.0900444984436035, Discriminator loss: 1.176052451133728\n",
      "\tGenerator loss: 1.074708342552185, Discriminator loss: 1.1875314712524414\n",
      "\tGenerator loss: 1.1336369514465332, Discriminator loss: 1.1552120447158813\n",
      "\tGenerator loss: 1.223621129989624, Discriminator loss: 1.2761211395263672\n",
      "\tGenerator loss: 1.254593014717102, Discriminator loss: 1.2296394109725952\n",
      "\tGenerator loss: 1.2295942306518555, Discriminator loss: 1.2487926483154297\n",
      "\tGenerator loss: 1.0960283279418945, Discriminator loss: 1.2182644605636597\n",
      "\tGenerator loss: 1.0265262126922607, Discriminator loss: 1.1894512176513672\n",
      "\tGenerator loss: 1.0472639799118042, Discriminator loss: 1.1711252927780151\n",
      "\tGenerator loss: 1.1201412677764893, Discriminator loss: 1.123274803161621\n",
      "\tGenerator loss: 1.1677751541137695, Discriminator loss: 1.1158868074417114\n",
      "\tGenerator loss: 1.2458958625793457, Discriminator loss: 1.1291074752807617\n",
      "\tGenerator loss: 1.2823234796524048, Discriminator loss: 1.1704412698745728\n",
      "\tGenerator loss: 1.2457761764526367, Discriminator loss: 1.1222832202911377\n",
      "\tGenerator loss: 1.1690081357955933, Discriminator loss: 1.149844765663147\n",
      "\tGenerator loss: 1.0887360572814941, Discriminator loss: 1.194122076034546\n",
      "\tGenerator loss: 1.0108284950256348, Discriminator loss: 1.151134729385376\n",
      "\tGenerator loss: 1.003381371498108, Discriminator loss: 1.0893930196762085\n",
      "\tGenerator loss: 1.0970118045806885, Discriminator loss: 1.082498550415039\n",
      "\tGenerator loss: 1.2184123992919922, Discriminator loss: 1.0790939331054688\n",
      "\tGenerator loss: 1.291227102279663, Discriminator loss: 1.0653618574142456\n",
      "\tGenerator loss: 1.3264697790145874, Discriminator loss: 1.0538074970245361\n",
      "\tGenerator loss: 1.288818359375, Discriminator loss: 1.0411715507507324\n",
      "\tGenerator loss: 1.2191710472106934, Discriminator loss: 1.0087251663208008\n",
      "\tGenerator loss: 1.1107289791107178, Discriminator loss: 0.9829153418540955\n",
      "\tGenerator loss: 1.0716488361358643, Discriminator loss: 0.980780303478241\n",
      "\tGenerator loss: 1.1117181777954102, Discriminator loss: 1.0495352745056152\n",
      "\tGenerator loss: 1.2587475776672363, Discriminator loss: 1.0240727663040161\n",
      "\tGenerator loss: 1.3412103652954102, Discriminator loss: 0.9885402917861938\n",
      "\tGenerator loss: 1.3505327701568604, Discriminator loss: 1.016560673713684\n",
      "\tGenerator loss: 1.2507784366607666, Discriminator loss: 0.9556322693824768\n",
      "\tGenerator loss: 1.2150741815567017, Discriminator loss: 0.9815589189529419\n",
      "\tGenerator loss: 1.1139540672302246, Discriminator loss: 1.0138086080551147\n",
      "\tGenerator loss: 1.1239831447601318, Discriminator loss: 0.9898448586463928\n",
      "\tGenerator loss: 1.142106056213379, Discriminator loss: 0.9625180959701538\n",
      "\tGenerator loss: 1.1997978687286377, Discriminator loss: 1.0025346279144287\n",
      "\tGenerator loss: 1.2141164541244507, Discriminator loss: 1.029544472694397\n",
      "\tGenerator loss: 1.2580513954162598, Discriminator loss: 0.9846063852310181\n",
      "\tGenerator loss: 1.2236626148223877, Discriminator loss: 0.9709270000457764\n",
      "\tGenerator loss: 1.1821036338806152, Discriminator loss: 0.9858954548835754\n",
      "\tGenerator loss: 1.1542646884918213, Discriminator loss: 0.9693220853805542\n",
      "\tGenerator loss: 1.1698732376098633, Discriminator loss: 0.9244322180747986\n",
      "\tGenerator loss: 1.163087010383606, Discriminator loss: 0.913811981678009\n",
      "\tGenerator loss: 1.2105140686035156, Discriminator loss: 0.9916898012161255\n",
      "\tGenerator loss: 1.2768735885620117, Discriminator loss: 1.0719833374023438\n",
      "\tGenerator loss: 1.3009121417999268, Discriminator loss: 1.055694341659546\n",
      "\tGenerator loss: 1.242845892906189, Discriminator loss: 1.1459662914276123\n",
      "Time for epoch 23 is 242.2497696876526 sec\n",
      "\tGenerator loss: 1.1309115886688232, Discriminator loss: 1.0852937698364258\n",
      "\tGenerator loss: 1.0275304317474365, Discriminator loss: 1.0581516027450562\n",
      "\tGenerator loss: 1.0249769687652588, Discriminator loss: 1.0465490818023682\n",
      "\tGenerator loss: 1.0549039840698242, Discriminator loss: 1.062187910079956\n",
      "\tGenerator loss: 1.1135553121566772, Discriminator loss: 1.1368253231048584\n",
      "\tGenerator loss: 1.207700252532959, Discriminator loss: 1.129361629486084\n",
      "\tGenerator loss: 1.2234747409820557, Discriminator loss: 1.0545432567596436\n",
      "\tGenerator loss: 1.2119386196136475, Discriminator loss: 1.0779087543487549\n",
      "\tGenerator loss: 1.1882930994033813, Discriminator loss: 1.0130958557128906\n",
      "\tGenerator loss: 1.1891906261444092, Discriminator loss: 1.046226978302002\n",
      "\tGenerator loss: 1.1828802824020386, Discriminator loss: 1.0393234491348267\n",
      "\tGenerator loss: 1.175161600112915, Discriminator loss: 1.045393705368042\n",
      "\tGenerator loss: 1.1582269668579102, Discriminator loss: 1.0097304582595825\n",
      "\tGenerator loss: 1.1509604454040527, Discriminator loss: 1.001427412033081\n",
      "\tGenerator loss: 1.1526000499725342, Discriminator loss: 1.0336487293243408\n",
      "\tGenerator loss: 1.1668635606765747, Discriminator loss: 1.0158863067626953\n",
      "\tGenerator loss: 1.1946699619293213, Discriminator loss: 1.0496402978897095\n",
      "\tGenerator loss: 1.183058738708496, Discriminator loss: 1.0591493844985962\n",
      "\tGenerator loss: 1.1401000022888184, Discriminator loss: 1.1343209743499756\n",
      "\tGenerator loss: 1.0761291980743408, Discriminator loss: 1.133805274963379\n",
      "\tGenerator loss: 1.0872535705566406, Discriminator loss: 1.1570043563842773\n",
      "\tGenerator loss: 1.0567162036895752, Discriminator loss: 1.2169573307037354\n",
      "\tGenerator loss: 1.0461018085479736, Discriminator loss: 1.228646993637085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0762417316436768, Discriminator loss: 1.3350787162780762\n",
      "\tGenerator loss: 1.0246920585632324, Discriminator loss: 1.3531726598739624\n",
      "\tGenerator loss: 1.0206539630889893, Discriminator loss: 1.2493255138397217\n",
      "\tGenerator loss: 1.025327444076538, Discriminator loss: 1.2340598106384277\n",
      "\tGenerator loss: 1.0370185375213623, Discriminator loss: 1.227089285850525\n",
      "\tGenerator loss: 1.0827440023422241, Discriminator loss: 1.246295690536499\n",
      "\tGenerator loss: 1.0350041389465332, Discriminator loss: 1.201341152191162\n",
      "\tGenerator loss: 0.976830780506134, Discriminator loss: 1.3286056518554688\n",
      "\tGenerator loss: 0.9573395252227783, Discriminator loss: 1.3468108177185059\n",
      "\tGenerator loss: 0.9525881409645081, Discriminator loss: 1.4080603122711182\n",
      "\tGenerator loss: 0.9743521213531494, Discriminator loss: 1.5097558498382568\n",
      "\tGenerator loss: 0.978288471698761, Discriminator loss: 1.413181185722351\n",
      "\tGenerator loss: 0.9588255882263184, Discriminator loss: 1.3380428552627563\n",
      "\tGenerator loss: 0.9629553556442261, Discriminator loss: 1.3683671951293945\n",
      "\tGenerator loss: 0.9624060988426208, Discriminator loss: 1.2623053789138794\n",
      "\tGenerator loss: 1.0361448526382446, Discriminator loss: 1.2785661220550537\n",
      "\tGenerator loss: 1.0559228658676147, Discriminator loss: 1.3479113578796387\n",
      "\tGenerator loss: 1.0225714445114136, Discriminator loss: 1.444356918334961\n",
      "\tGenerator loss: 0.9413752555847168, Discriminator loss: 1.4481631517410278\n",
      "\tGenerator loss: 0.9057902097702026, Discriminator loss: 1.4438161849975586\n",
      "\tGenerator loss: 0.9043761491775513, Discriminator loss: 1.404913306236267\n",
      "\tGenerator loss: 0.9078090190887451, Discriminator loss: 1.415348768234253\n",
      "\tGenerator loss: 0.9286324977874756, Discriminator loss: 1.460540533065796\n",
      "\tGenerator loss: 0.9261838793754578, Discriminator loss: 1.4510407447814941\n",
      "\tGenerator loss: 0.9280239343643188, Discriminator loss: 1.4419324398040771\n",
      "\tGenerator loss: 0.8893765211105347, Discriminator loss: 1.4370670318603516\n",
      "\tGenerator loss: 0.9049100279808044, Discriminator loss: 1.3968698978424072\n",
      "\tGenerator loss: 0.9406951665878296, Discriminator loss: 1.4540809392929077\n",
      "\tGenerator loss: 0.9725942015647888, Discriminator loss: 1.4578137397766113\n",
      "\tGenerator loss: 0.9724845886230469, Discriminator loss: 1.378983974456787\n",
      "\tGenerator loss: 0.9746676683425903, Discriminator loss: 1.371842622756958\n",
      "\tGenerator loss: 0.9616742134094238, Discriminator loss: 1.379740595817566\n",
      "\tGenerator loss: 0.9244011640548706, Discriminator loss: 1.3729356527328491\n",
      "\tGenerator loss: 0.9003909826278687, Discriminator loss: 1.4077844619750977\n",
      "\tGenerator loss: 0.9420357942581177, Discriminator loss: 1.309442162513733\n",
      "\tGenerator loss: 0.9966897368431091, Discriminator loss: 1.360016107559204\n",
      "\tGenerator loss: 1.0169625282287598, Discriminator loss: 1.3713419437408447\n",
      "\tGenerator loss: 1.0159884691238403, Discriminator loss: 1.3456226587295532\n",
      "\tGenerator loss: 0.9126102924346924, Discriminator loss: 1.319199562072754\n",
      "\tGenerator loss: 0.8489500284194946, Discriminator loss: 1.3727500438690186\n",
      "\tGenerator loss: 0.8980305194854736, Discriminator loss: 1.333136796951294\n",
      "\tGenerator loss: 1.0131614208221436, Discriminator loss: 1.302308440208435\n",
      "\tGenerator loss: 1.1000914573669434, Discriminator loss: 1.3011691570281982\n",
      "\tGenerator loss: 1.0697555541992188, Discriminator loss: 1.2996550798416138\n",
      "\tGenerator loss: 0.9798492193222046, Discriminator loss: 1.2472589015960693\n",
      "\tGenerator loss: 0.9290731549263, Discriminator loss: 1.2375435829162598\n",
      "\tGenerator loss: 0.884152889251709, Discriminator loss: 1.2456200122833252\n",
      "\tGenerator loss: 0.9445075988769531, Discriminator loss: 1.1892201900482178\n",
      "\tGenerator loss: 1.070204496383667, Discriminator loss: 1.2018601894378662\n",
      "\tGenerator loss: 1.1027127504348755, Discriminator loss: 1.1616166830062866\n",
      "\tGenerator loss: 1.109285593032837, Discriminator loss: 1.1305022239685059\n",
      "\tGenerator loss: 1.0711437463760376, Discriminator loss: 1.1469273567199707\n",
      "\tGenerator loss: 1.0354082584381104, Discriminator loss: 1.1137397289276123\n",
      "\tGenerator loss: 1.0411689281463623, Discriminator loss: 1.124746322631836\n",
      "\tGenerator loss: 1.0291997194290161, Discriminator loss: 1.0684070587158203\n",
      "\tGenerator loss: 1.105672836303711, Discriminator loss: 1.0252912044525146\n",
      "\tGenerator loss: 1.2239245176315308, Discriminator loss: 1.0315073728561401\n",
      "\tGenerator loss: 1.2621742486953735, Discriminator loss: 1.023451805114746\n",
      "\tGenerator loss: 1.208132266998291, Discriminator loss: 1.0137319564819336\n",
      "\tGenerator loss: 1.1065303087234497, Discriminator loss: 1.0125328302383423\n",
      "\tGenerator loss: 1.055868148803711, Discriminator loss: 1.0129015445709229\n",
      "\tGenerator loss: 1.0601907968521118, Discriminator loss: 1.0110119581222534\n",
      "\tGenerator loss: 1.0838896036148071, Discriminator loss: 1.0291180610656738\n",
      "\tGenerator loss: 1.1549038887023926, Discriminator loss: 0.9604352712631226\n",
      "\tGenerator loss: 1.2747313976287842, Discriminator loss: 0.9627547264099121\n",
      "\tGenerator loss: 1.2718809843063354, Discriminator loss: 1.0029635429382324\n",
      "\tGenerator loss: 1.2213778495788574, Discriminator loss: 1.0346356630325317\n",
      "\tGenerator loss: 1.1647429466247559, Discriminator loss: 1.0161751508712769\n",
      "\tGenerator loss: 1.0883737802505493, Discriminator loss: 0.9846317172050476\n",
      "\tGenerator loss: 1.0790256261825562, Discriminator loss: 0.9712913036346436\n",
      "\tGenerator loss: 1.1216531991958618, Discriminator loss: 0.97771155834198\n",
      "\tGenerator loss: 1.1856215000152588, Discriminator loss: 1.0190484523773193\n",
      "\tGenerator loss: 1.2524276971817017, Discriminator loss: 0.9699970483779907\n",
      "\tGenerator loss: 1.2627930641174316, Discriminator loss: 0.997342050075531\n",
      "\tGenerator loss: 1.1954679489135742, Discriminator loss: 1.0110079050064087\n",
      "\tGenerator loss: 1.1192905902862549, Discriminator loss: 0.9900041818618774\n",
      "\tGenerator loss: 1.0741477012634277, Discriminator loss: 1.0126886367797852\n",
      "\tGenerator loss: 1.0763142108917236, Discriminator loss: 1.0199778079986572\n",
      "\tGenerator loss: 1.0930020809173584, Discriminator loss: 1.0500214099884033\n",
      "\tGenerator loss: 1.1058552265167236, Discriminator loss: 1.0757625102996826\n",
      "\tGenerator loss: 1.1670626401901245, Discriminator loss: 1.0382091999053955\n",
      "\tGenerator loss: 1.1428465843200684, Discriminator loss: 1.0562434196472168\n",
      "\tGenerator loss: 1.0876837968826294, Discriminator loss: 1.0436275005340576\n",
      "\tGenerator loss: 1.0452075004577637, Discriminator loss: 1.056634545326233\n",
      "\tGenerator loss: 1.0857312679290771, Discriminator loss: 1.0063320398330688\n",
      "\tGenerator loss: 1.154447078704834, Discriminator loss: 0.9818270206451416\n",
      "\tGenerator loss: 1.189117193222046, Discriminator loss: 1.0739576816558838\n",
      "\tGenerator loss: 1.1897023916244507, Discriminator loss: 1.1257396936416626\n",
      "\tGenerator loss: 1.1116621494293213, Discriminator loss: 1.1127792596817017\n",
      "\tGenerator loss: 1.0756667852401733, Discriminator loss: 1.0767793655395508\n",
      "\tGenerator loss: 1.0856797695159912, Discriminator loss: 1.0265737771987915\n",
      "\tGenerator loss: 1.1249862909317017, Discriminator loss: 1.0802016258239746\n",
      "\tGenerator loss: 1.1484401226043701, Discriminator loss: 1.0931566953659058\n",
      "\tGenerator loss: 1.1855034828186035, Discriminator loss: 1.0644755363464355\n",
      "\tGenerator loss: 1.1789201498031616, Discriminator loss: 1.0365138053894043\n",
      "\tGenerator loss: 1.1190829277038574, Discriminator loss: 1.0426287651062012\n",
      "\tGenerator loss: 1.093446969985962, Discriminator loss: 1.0143855810165405\n",
      "\tGenerator loss: 1.1187143325805664, Discriminator loss: 1.0608360767364502\n",
      "\tGenerator loss: 1.1040281057357788, Discriminator loss: 1.0735150575637817\n",
      "\tGenerator loss: 1.118739128112793, Discriminator loss: 1.0455601215362549\n",
      "\tGenerator loss: 1.1487549543380737, Discriminator loss: 1.0312402248382568\n",
      "\tGenerator loss: 1.1477112770080566, Discriminator loss: 1.0905195474624634\n",
      "\tGenerator loss: 1.1354272365570068, Discriminator loss: 1.1569087505340576\n",
      "\tGenerator loss: 1.1669330596923828, Discriminator loss: 1.2026007175445557\n",
      "\tGenerator loss: 1.117617130279541, Discriminator loss: 1.1580005884170532\n",
      "\tGenerator loss: 1.0482292175292969, Discriminator loss: 1.16518235206604\n",
      "\tGenerator loss: 1.0308191776275635, Discriminator loss: 1.1311943531036377\n",
      "\tGenerator loss: 1.0810227394104004, Discriminator loss: 1.0670676231384277\n",
      "\tGenerator loss: 1.1465485095977783, Discriminator loss: 1.1467565298080444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1982176303863525, Discriminator loss: 1.2154300212860107\n",
      "\tGenerator loss: 1.1534208059310913, Discriminator loss: 1.139519453048706\n",
      "\tGenerator loss: 1.076390266418457, Discriminator loss: 1.1664339303970337\n",
      "\tGenerator loss: 1.01414155960083, Discriminator loss: 1.1660412549972534\n",
      "\tGenerator loss: 1.0494563579559326, Discriminator loss: 1.1958034038543701\n",
      "\tGenerator loss: 1.0843250751495361, Discriminator loss: 1.1544711589813232\n",
      "\tGenerator loss: 1.142775058746338, Discriminator loss: 1.110068678855896\n",
      "\tGenerator loss: 1.177924633026123, Discriminator loss: 1.1226418018341064\n",
      "\tGenerator loss: 1.1455535888671875, Discriminator loss: 1.1369224786758423\n",
      "\tGenerator loss: 1.1028649806976318, Discriminator loss: 1.1846251487731934\n",
      "\tGenerator loss: 1.0678260326385498, Discriminator loss: 1.1653831005096436\n",
      "\tGenerator loss: 1.0763270854949951, Discriminator loss: 1.255115032196045\n",
      "\tGenerator loss: 1.1087093353271484, Discriminator loss: 1.2258005142211914\n",
      "\tGenerator loss: 1.120236873626709, Discriminator loss: 1.2535182237625122\n",
      "\tGenerator loss: 1.1018751859664917, Discriminator loss: 1.2298851013183594\n",
      "\tGenerator loss: 1.0529165267944336, Discriminator loss: 1.1621999740600586\n",
      "\tGenerator loss: 1.0531704425811768, Discriminator loss: 1.1757839918136597\n",
      "\tGenerator loss: 1.0970559120178223, Discriminator loss: 1.1974453926086426\n",
      "\tGenerator loss: 1.16995370388031, Discriminator loss: 1.1245172023773193\n",
      "\tGenerator loss: 1.1668884754180908, Discriminator loss: 1.116859793663025\n",
      "\tGenerator loss: 1.1253080368041992, Discriminator loss: 1.1352511644363403\n",
      "\tGenerator loss: 1.0947253704071045, Discriminator loss: 1.161830186843872\n",
      "\tGenerator loss: 1.0770115852355957, Discriminator loss: 1.206512689590454\n",
      "\tGenerator loss: 1.0742566585540771, Discriminator loss: 1.1281338930130005\n",
      "\tGenerator loss: 1.0924516916275024, Discriminator loss: 1.133662462234497\n",
      "\tGenerator loss: 1.1209716796875, Discriminator loss: 1.0253863334655762\n",
      "\tGenerator loss: 1.2243940830230713, Discriminator loss: 1.0113303661346436\n",
      "\tGenerator loss: 1.3150625228881836, Discriminator loss: 1.0204005241394043\n",
      "\tGenerator loss: 1.3091062307357788, Discriminator loss: 1.0100452899932861\n",
      "\tGenerator loss: 1.226837158203125, Discriminator loss: 0.9571253061294556\n",
      "\tGenerator loss: 1.161405324935913, Discriminator loss: 1.002861499786377\n",
      "\tGenerator loss: 1.148163080215454, Discriminator loss: 1.0175366401672363\n",
      "\tGenerator loss: 1.1300702095031738, Discriminator loss: 1.0210843086242676\n",
      "\tGenerator loss: 1.1392446756362915, Discriminator loss: 0.996166467666626\n",
      "\tGenerator loss: 1.2621114253997803, Discriminator loss: 0.9796730279922485\n",
      "\tGenerator loss: 1.3738150596618652, Discriminator loss: 0.929663360118866\n",
      "\tGenerator loss: 1.3868972063064575, Discriminator loss: 0.935333251953125\n",
      "\tGenerator loss: 1.3040891885757446, Discriminator loss: 0.9078353047370911\n",
      "\tGenerator loss: 1.2376201152801514, Discriminator loss: 0.919129490852356\n",
      "\tGenerator loss: 1.2294950485229492, Discriminator loss: 0.9050973057746887\n",
      "\tGenerator loss: 1.2266182899475098, Discriminator loss: 0.8521511554718018\n",
      "\tGenerator loss: 1.2615771293640137, Discriminator loss: 0.8787282705307007\n",
      "\tGenerator loss: 1.3332483768463135, Discriminator loss: 0.909446656703949\n",
      "\tGenerator loss: 1.3561291694641113, Discriminator loss: 0.9419327974319458\n",
      "\tGenerator loss: 1.29990816116333, Discriminator loss: 0.8968290686607361\n",
      "\tGenerator loss: 1.218559980392456, Discriminator loss: 0.9072620272636414\n",
      "\tGenerator loss: 1.196937918663025, Discriminator loss: 0.9162970781326294\n",
      "\tGenerator loss: 1.2397024631500244, Discriminator loss: 0.9653081297874451\n",
      "\tGenerator loss: 1.2546064853668213, Discriminator loss: 0.9077786207199097\n",
      "\tGenerator loss: 1.2299113273620605, Discriminator loss: 0.8997021913528442\n",
      "\tGenerator loss: 1.2201579809188843, Discriminator loss: 0.9040833711624146\n",
      "\tGenerator loss: 1.298126459121704, Discriminator loss: 0.8969103097915649\n",
      "\tGenerator loss: 1.335085391998291, Discriminator loss: 0.9291876554489136\n",
      "\tGenerator loss: 1.355384111404419, Discriminator loss: 0.8826725482940674\n",
      "\tGenerator loss: 1.30387544631958, Discriminator loss: 0.8677582740783691\n",
      "\tGenerator loss: 1.2628846168518066, Discriminator loss: 0.9134552478790283\n",
      "\tGenerator loss: 1.2704601287841797, Discriminator loss: 0.8904612064361572\n",
      "\tGenerator loss: 1.2726600170135498, Discriminator loss: 0.8959591388702393\n",
      "\tGenerator loss: 1.288688063621521, Discriminator loss: 0.8918178677558899\n",
      "\tGenerator loss: 1.313589334487915, Discriminator loss: 0.9120391607284546\n",
      "\tGenerator loss: 1.2989466190338135, Discriminator loss: 0.8715053200721741\n",
      "\tGenerator loss: 1.3063006401062012, Discriminator loss: 0.8483190536499023\n",
      "\tGenerator loss: 1.2751080989837646, Discriminator loss: 0.8724682331085205\n",
      "\tGenerator loss: 1.2866544723510742, Discriminator loss: 0.912895679473877\n",
      "\tGenerator loss: 1.271082878112793, Discriminator loss: 0.9104411602020264\n",
      "\tGenerator loss: 1.2506799697875977, Discriminator loss: 0.9068876504898071\n",
      "\tGenerator loss: 1.2444820404052734, Discriminator loss: 0.9366161823272705\n",
      "\tGenerator loss: 1.2147672176361084, Discriminator loss: 0.9249513149261475\n",
      "\tGenerator loss: 1.216581106185913, Discriminator loss: 0.9142593741416931\n",
      "\tGenerator loss: 1.258078932762146, Discriminator loss: 0.8810379505157471\n",
      "\tGenerator loss: 1.323319911956787, Discriminator loss: 0.9023314118385315\n",
      "\tGenerator loss: 1.3269121646881104, Discriminator loss: 0.9153976440429688\n",
      "\tGenerator loss: 1.315455675125122, Discriminator loss: 0.9451678991317749\n",
      "\tGenerator loss: 1.2509195804595947, Discriminator loss: 0.9263463020324707\n",
      "\tGenerator loss: 1.2369465827941895, Discriminator loss: 0.9500153064727783\n",
      "\tGenerator loss: 1.2099223136901855, Discriminator loss: 0.9628639221191406\n",
      "\tGenerator loss: 1.2149428129196167, Discriminator loss: 0.9383299350738525\n",
      "\tGenerator loss: 1.2111313343048096, Discriminator loss: 0.9649986624717712\n",
      "\tGenerator loss: 1.2785553932189941, Discriminator loss: 0.9394069314002991\n",
      "\tGenerator loss: 1.3211445808410645, Discriminator loss: 0.9975012540817261\n",
      "\tGenerator loss: 1.3600332736968994, Discriminator loss: 1.0223917961120605\n",
      "\tGenerator loss: 1.279187560081482, Discriminator loss: 1.073591947555542\n",
      "\tGenerator loss: 1.1710476875305176, Discriminator loss: 1.0618650913238525\n",
      "\tGenerator loss: 1.0611095428466797, Discriminator loss: 1.0823230743408203\n",
      "\tGenerator loss: 1.0441703796386719, Discriminator loss: 1.1189587116241455\n",
      "\tGenerator loss: 1.112099528312683, Discriminator loss: 1.185328722000122\n",
      "\tGenerator loss: 1.1603660583496094, Discriminator loss: 1.1698758602142334\n",
      "\tGenerator loss: 1.1733448505401611, Discriminator loss: 1.2192573547363281\n",
      "\tGenerator loss: 1.1626396179199219, Discriminator loss: 1.2043778896331787\n",
      "\tGenerator loss: 1.088661789894104, Discriminator loss: 1.2221745252609253\n",
      "\tGenerator loss: 1.0679877996444702, Discriminator loss: 1.1799510717391968\n",
      "\tGenerator loss: 1.0442605018615723, Discriminator loss: 1.1809723377227783\n",
      "\tGenerator loss: 1.0711641311645508, Discriminator loss: 1.1630595922470093\n",
      "\tGenerator loss: 1.1007490158081055, Discriminator loss: 1.175624132156372\n",
      "\tGenerator loss: 1.1191450357437134, Discriminator loss: 1.2265205383300781\n",
      "\tGenerator loss: 1.0631206035614014, Discriminator loss: 1.2007508277893066\n",
      "\tGenerator loss: 1.0502859354019165, Discriminator loss: 1.22361159324646\n",
      "\tGenerator loss: 1.0064148902893066, Discriminator loss: 1.2101247310638428\n",
      "\tGenerator loss: 1.007043480873108, Discriminator loss: 1.156250238418579\n",
      "\tGenerator loss: 1.0672109127044678, Discriminator loss: 1.3317402601242065\n",
      "\tGenerator loss: 1.0992443561553955, Discriminator loss: 1.4101125001907349\n",
      "\tGenerator loss: 1.1119779348373413, Discriminator loss: 1.3958218097686768\n",
      "\tGenerator loss: 1.0613330602645874, Discriminator loss: 1.2607618570327759\n",
      "Time for epoch 24 is 249.4068784713745 sec\n",
      "\tGenerator loss: 1.0126619338989258, Discriminator loss: 1.2859971523284912\n",
      "\tGenerator loss: 0.9592025876045227, Discriminator loss: 1.283193588256836\n",
      "\tGenerator loss: 0.970777690410614, Discriminator loss: 1.2870069742202759\n",
      "\tGenerator loss: 1.0030608177185059, Discriminator loss: 1.2742772102355957\n",
      "\tGenerator loss: 1.0654520988464355, Discriminator loss: 1.3969643115997314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0545070171356201, Discriminator loss: 1.4266598224639893\n",
      "\tGenerator loss: 1.009015679359436, Discriminator loss: 1.3239858150482178\n",
      "\tGenerator loss: 0.9639013409614563, Discriminator loss: 1.3630236387252808\n",
      "\tGenerator loss: 0.9415798187255859, Discriminator loss: 1.33876633644104\n",
      "\tGenerator loss: 0.9696952700614929, Discriminator loss: 1.2836573123931885\n",
      "\tGenerator loss: 1.047346830368042, Discriminator loss: 1.2779978513717651\n",
      "\tGenerator loss: 1.1260066032409668, Discriminator loss: 1.261645793914795\n",
      "\tGenerator loss: 1.1969188451766968, Discriminator loss: 1.222112774848938\n",
      "\tGenerator loss: 1.1140269041061401, Discriminator loss: 1.185633659362793\n",
      "\tGenerator loss: 1.0441120862960815, Discriminator loss: 1.1448404788970947\n",
      "\tGenerator loss: 1.0278682708740234, Discriminator loss: 1.1210148334503174\n",
      "\tGenerator loss: 1.0907530784606934, Discriminator loss: 1.1030000448226929\n",
      "\tGenerator loss: 1.2190111875534058, Discriminator loss: 1.07186758518219\n",
      "\tGenerator loss: 1.3115758895874023, Discriminator loss: 1.0966179370880127\n",
      "\tGenerator loss: 1.2949117422103882, Discriminator loss: 1.025173544883728\n",
      "\tGenerator loss: 1.2446893453598022, Discriminator loss: 0.9907728433609009\n",
      "\tGenerator loss: 1.2075600624084473, Discriminator loss: 0.9817216396331787\n",
      "\tGenerator loss: 1.2116827964782715, Discriminator loss: 0.9677211046218872\n",
      "\tGenerator loss: 1.2714112997055054, Discriminator loss: 0.9504277110099792\n",
      "\tGenerator loss: 1.308884859085083, Discriminator loss: 0.9219950437545776\n",
      "\tGenerator loss: 1.3663989305496216, Discriminator loss: 0.8731778860092163\n",
      "\tGenerator loss: 1.384727954864502, Discriminator loss: 0.9309661388397217\n",
      "\tGenerator loss: 1.368404507637024, Discriminator loss: 0.8950728178024292\n",
      "\tGenerator loss: 1.3139164447784424, Discriminator loss: 0.9578172564506531\n",
      "\tGenerator loss: 1.192757487297058, Discriminator loss: 0.922543466091156\n",
      "\tGenerator loss: 1.1612541675567627, Discriminator loss: 0.9074307084083557\n",
      "\tGenerator loss: 1.2416765689849854, Discriminator loss: 0.8433786630630493\n",
      "\tGenerator loss: 1.4431252479553223, Discriminator loss: 0.7910892367362976\n",
      "\tGenerator loss: 1.5465010404586792, Discriminator loss: 0.7921799421310425\n",
      "\tGenerator loss: 1.634534478187561, Discriminator loss: 0.78087317943573\n",
      "\tGenerator loss: 1.6651637554168701, Discriminator loss: 0.7794682383537292\n",
      "\tGenerator loss: 1.5237213373184204, Discriminator loss: 0.7921123504638672\n",
      "\tGenerator loss: 1.3583061695098877, Discriminator loss: 0.828438401222229\n",
      "\tGenerator loss: 1.2562583684921265, Discriminator loss: 0.8406659364700317\n",
      "\tGenerator loss: 1.2500120401382446, Discriminator loss: 0.8002184629440308\n",
      "\tGenerator loss: 1.3583316802978516, Discriminator loss: 0.7890282273292542\n",
      "\tGenerator loss: 1.6043819189071655, Discriminator loss: 0.7954579591751099\n",
      "\tGenerator loss: 1.7485932111740112, Discriminator loss: 0.8057918548583984\n",
      "\tGenerator loss: 1.7293143272399902, Discriminator loss: 0.7904358506202698\n",
      "\tGenerator loss: 1.5647077560424805, Discriminator loss: 0.7986245155334473\n",
      "\tGenerator loss: 1.345059871673584, Discriminator loss: 0.8315444588661194\n",
      "\tGenerator loss: 1.2594777345657349, Discriminator loss: 0.8225525617599487\n",
      "\tGenerator loss: 1.2328654527664185, Discriminator loss: 0.8318027257919312\n",
      "\tGenerator loss: 1.3282561302185059, Discriminator loss: 0.8463622331619263\n",
      "\tGenerator loss: 1.5206046104431152, Discriminator loss: 0.8676170110702515\n",
      "\tGenerator loss: 1.5986251831054688, Discriminator loss: 0.912256121635437\n",
      "\tGenerator loss: 1.5432183742523193, Discriminator loss: 0.8844037055969238\n",
      "\tGenerator loss: 1.4291056394577026, Discriminator loss: 0.880483865737915\n",
      "\tGenerator loss: 1.3120431900024414, Discriminator loss: 0.9695931673049927\n",
      "\tGenerator loss: 1.2606865167617798, Discriminator loss: 0.9627687335014343\n",
      "\tGenerator loss: 1.2225050926208496, Discriminator loss: 0.9438721537590027\n",
      "\tGenerator loss: 1.171303391456604, Discriminator loss: 1.0155084133148193\n",
      "\tGenerator loss: 1.2018516063690186, Discriminator loss: 1.0446605682373047\n",
      "\tGenerator loss: 1.2054071426391602, Discriminator loss: 1.0136005878448486\n",
      "\tGenerator loss: 1.210860252380371, Discriminator loss: 1.059190273284912\n",
      "\tGenerator loss: 1.2562236785888672, Discriminator loss: 1.064204454421997\n",
      "\tGenerator loss: 1.241151213645935, Discriminator loss: 1.1058564186096191\n",
      "\tGenerator loss: 1.1677038669586182, Discriminator loss: 1.0714898109436035\n",
      "\tGenerator loss: 1.1214219331741333, Discriminator loss: 1.0340594053268433\n",
      "\tGenerator loss: 1.1469850540161133, Discriminator loss: 1.0258787870407104\n",
      "\tGenerator loss: 1.1680456399917603, Discriminator loss: 1.1028988361358643\n",
      "\tGenerator loss: 1.255441427230835, Discriminator loss: 1.0837175846099854\n",
      "\tGenerator loss: 1.2405483722686768, Discriminator loss: 1.1140046119689941\n",
      "\tGenerator loss: 1.2196969985961914, Discriminator loss: 1.175572156906128\n",
      "\tGenerator loss: 1.1508944034576416, Discriminator loss: 1.1056315898895264\n",
      "\tGenerator loss: 1.0983078479766846, Discriminator loss: 1.064497947692871\n",
      "\tGenerator loss: 1.130711317062378, Discriminator loss: 1.0084328651428223\n",
      "\tGenerator loss: 1.2132622003555298, Discriminator loss: 1.044670581817627\n",
      "\tGenerator loss: 1.217393159866333, Discriminator loss: 1.0717995166778564\n",
      "\tGenerator loss: 1.302323579788208, Discriminator loss: 1.0459188222885132\n",
      "\tGenerator loss: 1.3146944046020508, Discriminator loss: 1.0793232917785645\n",
      "\tGenerator loss: 1.282612681388855, Discriminator loss: 1.0783607959747314\n",
      "\tGenerator loss: 1.2349755764007568, Discriminator loss: 1.0577807426452637\n",
      "\tGenerator loss: 1.203993558883667, Discriminator loss: 1.0776680707931519\n",
      "\tGenerator loss: 1.1801029443740845, Discriminator loss: 1.0501174926757812\n",
      "\tGenerator loss: 1.1703965663909912, Discriminator loss: 1.063737154006958\n",
      "\tGenerator loss: 1.222771406173706, Discriminator loss: 1.0806422233581543\n",
      "\tGenerator loss: 1.2797043323516846, Discriminator loss: 1.0343456268310547\n",
      "\tGenerator loss: 1.3315627574920654, Discriminator loss: 1.0457476377487183\n",
      "\tGenerator loss: 1.265110731124878, Discriminator loss: 1.0348799228668213\n",
      "\tGenerator loss: 1.284494400024414, Discriminator loss: 1.1310946941375732\n",
      "\tGenerator loss: 1.2472949028015137, Discriminator loss: 1.0595180988311768\n",
      "\tGenerator loss: 1.207259178161621, Discriminator loss: 1.0567073822021484\n",
      "\tGenerator loss: 1.1589609384536743, Discriminator loss: 1.1874353885650635\n",
      "\tGenerator loss: 1.1565165519714355, Discriminator loss: 1.2547324895858765\n",
      "\tGenerator loss: 1.189100742340088, Discriminator loss: 1.1830898523330688\n",
      "\tGenerator loss: 1.1886303424835205, Discriminator loss: 1.108433723449707\n",
      "\tGenerator loss: 1.1885948181152344, Discriminator loss: 1.051792025566101\n",
      "\tGenerator loss: 1.2018909454345703, Discriminator loss: 1.0469794273376465\n",
      "\tGenerator loss: 1.1788612604141235, Discriminator loss: 1.0615800619125366\n",
      "\tGenerator loss: 1.2172224521636963, Discriminator loss: 1.0341789722442627\n",
      "\tGenerator loss: 1.1930088996887207, Discriminator loss: 1.0736103057861328\n",
      "\tGenerator loss: 1.1543512344360352, Discriminator loss: 1.0338220596313477\n",
      "\tGenerator loss: 1.1426159143447876, Discriminator loss: 1.058506727218628\n",
      "\tGenerator loss: 1.1793060302734375, Discriminator loss: 1.096099853515625\n",
      "\tGenerator loss: 1.2098766565322876, Discriminator loss: 1.0342481136322021\n",
      "\tGenerator loss: 1.214194655418396, Discriminator loss: 1.006352186203003\n",
      "\tGenerator loss: 1.184600591659546, Discriminator loss: 1.013024926185608\n",
      "\tGenerator loss: 1.1910946369171143, Discriminator loss: 0.9853464365005493\n",
      "\tGenerator loss: 1.219671607017517, Discriminator loss: 1.0053048133850098\n",
      "\tGenerator loss: 1.2353568077087402, Discriminator loss: 0.9886167645454407\n",
      "\tGenerator loss: 1.1976611614227295, Discriminator loss: 1.0485467910766602\n",
      "\tGenerator loss: 1.162717580795288, Discriminator loss: 0.9994628429412842\n",
      "\tGenerator loss: 1.1866025924682617, Discriminator loss: 0.9635865092277527\n",
      "\tGenerator loss: 1.2056710720062256, Discriminator loss: 1.032136082649231\n",
      "\tGenerator loss: 1.1913560628890991, Discriminator loss: 1.1193965673446655\n",
      "\tGenerator loss: 1.1664690971374512, Discriminator loss: 1.139225721359253\n",
      "\tGenerator loss: 1.113673210144043, Discriminator loss: 1.1097040176391602\n",
      "\tGenerator loss: 1.0985426902770996, Discriminator loss: 1.0692756175994873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0924016237258911, Discriminator loss: 1.123516321182251\n",
      "\tGenerator loss: 1.1482961177825928, Discriminator loss: 1.020931601524353\n",
      "\tGenerator loss: 1.2346361875534058, Discriminator loss: 1.015036702156067\n",
      "\tGenerator loss: 1.2466979026794434, Discriminator loss: 1.0454270839691162\n",
      "\tGenerator loss: 1.2029118537902832, Discriminator loss: 0.962978720664978\n",
      "\tGenerator loss: 1.1403553485870361, Discriminator loss: 0.9671099781990051\n",
      "\tGenerator loss: 1.1111260652542114, Discriminator loss: 0.9520121812820435\n",
      "\tGenerator loss: 1.2090637683868408, Discriminator loss: 0.933318555355072\n",
      "\tGenerator loss: 1.303625464439392, Discriminator loss: 0.9755797386169434\n",
      "\tGenerator loss: 1.3220241069793701, Discriminator loss: 0.944676399230957\n",
      "\tGenerator loss: 1.2686678171157837, Discriminator loss: 0.8871195912361145\n",
      "\tGenerator loss: 1.2247042655944824, Discriminator loss: 0.9532898664474487\n",
      "\tGenerator loss: 1.2019894123077393, Discriminator loss: 1.069155216217041\n",
      "\tGenerator loss: 1.121985673904419, Discriminator loss: 0.9826319217681885\n",
      "\tGenerator loss: 1.123652458190918, Discriminator loss: 0.9123790264129639\n",
      "\tGenerator loss: 1.2390682697296143, Discriminator loss: 0.9924741983413696\n",
      "\tGenerator loss: 1.3670384883880615, Discriminator loss: 0.961181640625\n",
      "\tGenerator loss: 1.3719487190246582, Discriminator loss: 0.9078284502029419\n",
      "\tGenerator loss: 1.324537754058838, Discriminator loss: 0.9036921858787537\n",
      "\tGenerator loss: 1.233109951019287, Discriminator loss: 0.8936814069747925\n",
      "\tGenerator loss: 1.1844896078109741, Discriminator loss: 0.872012734413147\n",
      "\tGenerator loss: 1.2808198928833008, Discriminator loss: 0.9104912877082825\n",
      "\tGenerator loss: 1.3880759477615356, Discriminator loss: 0.9376294612884521\n",
      "\tGenerator loss: 1.3713276386260986, Discriminator loss: 0.9643721580505371\n",
      "\tGenerator loss: 1.3160345554351807, Discriminator loss: 0.9585847854614258\n",
      "\tGenerator loss: 1.2256052494049072, Discriminator loss: 0.9190295338630676\n",
      "\tGenerator loss: 1.149874210357666, Discriminator loss: 0.9140841960906982\n",
      "\tGenerator loss: 1.186687707901001, Discriminator loss: 0.8720163106918335\n",
      "\tGenerator loss: 1.3626842498779297, Discriminator loss: 0.9057921171188354\n",
      "\tGenerator loss: 1.4780921936035156, Discriminator loss: 0.9004331827163696\n",
      "\tGenerator loss: 1.5123908519744873, Discriminator loss: 0.8992043733596802\n",
      "\tGenerator loss: 1.460221529006958, Discriminator loss: 0.89983069896698\n",
      "\tGenerator loss: 1.3296394348144531, Discriminator loss: 0.8863062858581543\n",
      "\tGenerator loss: 1.2195708751678467, Discriminator loss: 0.9288455247879028\n",
      "\tGenerator loss: 1.2010242938995361, Discriminator loss: 0.9189465045928955\n",
      "\tGenerator loss: 1.2559126615524292, Discriminator loss: 0.9375038146972656\n",
      "\tGenerator loss: 1.3548009395599365, Discriminator loss: 0.9300597906112671\n",
      "\tGenerator loss: 1.3779915571212769, Discriminator loss: 0.9076530933380127\n",
      "\tGenerator loss: 1.3944028615951538, Discriminator loss: 0.8796329498291016\n",
      "\tGenerator loss: 1.3395447731018066, Discriminator loss: 0.954619824886322\n",
      "\tGenerator loss: 1.263183832168579, Discriminator loss: 0.9548564553260803\n",
      "\tGenerator loss: 1.221852421760559, Discriminator loss: 1.0190976858139038\n",
      "\tGenerator loss: 1.1616735458374023, Discriminator loss: 1.004723072052002\n",
      "\tGenerator loss: 1.1780669689178467, Discriminator loss: 0.9834221601486206\n",
      "\tGenerator loss: 1.2328686714172363, Discriminator loss: 0.9923698306083679\n",
      "\tGenerator loss: 1.2792036533355713, Discriminator loss: 0.9695125818252563\n",
      "\tGenerator loss: 1.2911877632141113, Discriminator loss: 0.9618148803710938\n",
      "\tGenerator loss: 1.3047428131103516, Discriminator loss: 1.0397467613220215\n",
      "\tGenerator loss: 1.2427587509155273, Discriminator loss: 1.1335604190826416\n",
      "\tGenerator loss: 1.1046496629714966, Discriminator loss: 1.1287257671356201\n",
      "\tGenerator loss: 1.0066773891448975, Discriminator loss: 1.0799189805984497\n",
      "\tGenerator loss: 1.0452171564102173, Discriminator loss: 1.0555644035339355\n",
      "\tGenerator loss: 1.2223241329193115, Discriminator loss: 1.0178247690200806\n",
      "\tGenerator loss: 1.3927111625671387, Discriminator loss: 1.0124894380569458\n",
      "\tGenerator loss: 1.4850733280181885, Discriminator loss: 1.0024131536483765\n",
      "\tGenerator loss: 1.3522776365280151, Discriminator loss: 1.0044713020324707\n",
      "\tGenerator loss: 1.1494873762130737, Discriminator loss: 1.026238203048706\n",
      "\tGenerator loss: 1.0547668933868408, Discriminator loss: 1.028958797454834\n",
      "\tGenerator loss: 1.039871335029602, Discriminator loss: 1.0615755319595337\n",
      "\tGenerator loss: 1.106627106666565, Discriminator loss: 1.0655690431594849\n",
      "\tGenerator loss: 1.2691004276275635, Discriminator loss: 1.0114398002624512\n",
      "\tGenerator loss: 1.3220640420913696, Discriminator loss: 1.030894160270691\n",
      "\tGenerator loss: 1.2855879068374634, Discriminator loss: 0.9872681498527527\n",
      "\tGenerator loss: 1.2283473014831543, Discriminator loss: 1.032779335975647\n",
      "\tGenerator loss: 1.122378945350647, Discriminator loss: 1.047628402709961\n",
      "\tGenerator loss: 1.1156508922576904, Discriminator loss: 1.134829044342041\n",
      "\tGenerator loss: 1.0584571361541748, Discriminator loss: 1.1193885803222656\n",
      "\tGenerator loss: 1.0434491634368896, Discriminator loss: 1.0542373657226562\n",
      "\tGenerator loss: 1.1284313201904297, Discriminator loss: 0.9755662679672241\n",
      "\tGenerator loss: 1.2269296646118164, Discriminator loss: 0.9995593428611755\n",
      "\tGenerator loss: 1.3331669569015503, Discriminator loss: 1.0191731452941895\n",
      "\tGenerator loss: 1.3220548629760742, Discriminator loss: 1.0594031810760498\n",
      "\tGenerator loss: 1.1903414726257324, Discriminator loss: 0.9988980889320374\n",
      "\tGenerator loss: 1.1339712142944336, Discriminator loss: 1.0049315690994263\n",
      "\tGenerator loss: 1.1536656618118286, Discriminator loss: 1.0037367343902588\n",
      "\tGenerator loss: 1.1806135177612305, Discriminator loss: 0.9800043106079102\n",
      "\tGenerator loss: 1.2474405765533447, Discriminator loss: 0.977912425994873\n",
      "\tGenerator loss: 1.3054008483886719, Discriminator loss: 1.0642890930175781\n",
      "\tGenerator loss: 1.2559075355529785, Discriminator loss: 1.0479662418365479\n",
      "\tGenerator loss: 1.1512538194656372, Discriminator loss: 1.0634264945983887\n",
      "\tGenerator loss: 1.033828616142273, Discriminator loss: 1.0227771997451782\n",
      "\tGenerator loss: 1.0661723613739014, Discriminator loss: 0.9935320615768433\n",
      "\tGenerator loss: 1.1826560497283936, Discriminator loss: 0.9910649061203003\n",
      "\tGenerator loss: 1.3219950199127197, Discriminator loss: 0.9720190167427063\n",
      "\tGenerator loss: 1.3061012029647827, Discriminator loss: 0.9595112800598145\n",
      "\tGenerator loss: 1.3338043689727783, Discriminator loss: 0.93952876329422\n",
      "\tGenerator loss: 1.3057806491851807, Discriminator loss: 0.9648241996765137\n",
      "\tGenerator loss: 1.2365230321884155, Discriminator loss: 0.9280536770820618\n",
      "\tGenerator loss: 1.212733268737793, Discriminator loss: 0.9359526038169861\n",
      "\tGenerator loss: 1.1924371719360352, Discriminator loss: 0.9739763736724854\n",
      "\tGenerator loss: 1.1667635440826416, Discriminator loss: 0.9937065243721008\n",
      "\tGenerator loss: 1.2052819728851318, Discriminator loss: 0.9075441360473633\n",
      "\tGenerator loss: 1.231037974357605, Discriminator loss: 0.9049888849258423\n",
      "\tGenerator loss: 1.289825201034546, Discriminator loss: 0.9390877485275269\n",
      "\tGenerator loss: 1.268375039100647, Discriminator loss: 0.9170073866844177\n",
      "\tGenerator loss: 1.26865816116333, Discriminator loss: 0.8893020153045654\n",
      "\tGenerator loss: 1.2501753568649292, Discriminator loss: 0.8781851530075073\n",
      "\tGenerator loss: 1.2531535625457764, Discriminator loss: 0.8481242656707764\n",
      "\tGenerator loss: 1.2897001504898071, Discriminator loss: 0.8552237749099731\n",
      "\tGenerator loss: 1.3277246952056885, Discriminator loss: 0.8648404479026794\n",
      "\tGenerator loss: 1.378225564956665, Discriminator loss: 0.8668265342712402\n",
      "\tGenerator loss: 1.3427976369857788, Discriminator loss: 0.909346342086792\n",
      "\tGenerator loss: 1.2727768421173096, Discriminator loss: 0.9123782515525818\n",
      "\tGenerator loss: 1.2160929441452026, Discriminator loss: 0.9674850702285767\n",
      "\tGenerator loss: 1.1707496643066406, Discriminator loss: 0.901890218257904\n",
      "\tGenerator loss: 1.1663813591003418, Discriminator loss: 0.9130707383155823\n",
      "\tGenerator loss: 1.2812817096710205, Discriminator loss: 0.8521586656570435\n",
      "\tGenerator loss: 1.3564519882202148, Discriminator loss: 0.8726076483726501\n",
      "\tGenerator loss: 1.396457552909851, Discriminator loss: 0.8375821113586426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.3775714635849, Discriminator loss: 0.8323174715042114\n",
      "\tGenerator loss: 1.3489036560058594, Discriminator loss: 0.8748922348022461\n",
      "\tGenerator loss: 1.3049105405807495, Discriminator loss: 0.8201422095298767\n",
      "\tGenerator loss: 1.3109889030456543, Discriminator loss: 0.8227438926696777\n",
      "\tGenerator loss: 1.2948222160339355, Discriminator loss: 0.8112189769744873\n",
      "\tGenerator loss: 1.308605670928955, Discriminator loss: 0.840595006942749\n",
      "\tGenerator loss: 1.3450350761413574, Discriminator loss: 0.7773882150650024\n",
      "\tGenerator loss: 1.3530293703079224, Discriminator loss: 0.7759379148483276\n",
      "\tGenerator loss: 1.426628589630127, Discriminator loss: 0.9457960724830627\n",
      "\tGenerator loss: 1.4062416553497314, Discriminator loss: 1.1270101070404053\n",
      "\tGenerator loss: 1.2943874597549438, Discriminator loss: 1.1468700170516968\n",
      "\tGenerator loss: 1.2066872119903564, Discriminator loss: 1.0393437147140503\n",
      "Time for epoch 25 is 255.88675689697266 sec\n",
      "\tGenerator loss: 1.070759892463684, Discriminator loss: 1.0238749980926514\n",
      "\tGenerator loss: 1.083470106124878, Discriminator loss: 0.9812222719192505\n",
      "\tGenerator loss: 1.1467658281326294, Discriminator loss: 1.0248494148254395\n",
      "\tGenerator loss: 1.2760486602783203, Discriminator loss: 1.0303910970687866\n",
      "\tGenerator loss: 1.3075571060180664, Discriminator loss: 1.195689082145691\n",
      "\tGenerator loss: 1.294455647468567, Discriminator loss: 1.3133854866027832\n",
      "\tGenerator loss: 1.1925630569458008, Discriminator loss: 1.123303771018982\n",
      "\tGenerator loss: 1.1217560768127441, Discriminator loss: 1.2110085487365723\n",
      "\tGenerator loss: 1.0636844635009766, Discriminator loss: 1.1227624416351318\n",
      "\tGenerator loss: 1.0796092748641968, Discriminator loss: 1.100632667541504\n",
      "\tGenerator loss: 1.1522140502929688, Discriminator loss: 1.0676898956298828\n",
      "\tGenerator loss: 1.2734849452972412, Discriminator loss: 1.0533148050308228\n",
      "\tGenerator loss: 1.324294090270996, Discriminator loss: 1.0527775287628174\n",
      "\tGenerator loss: 1.256072998046875, Discriminator loss: 1.0211951732635498\n",
      "\tGenerator loss: 1.2148993015289307, Discriminator loss: 1.0260058641433716\n",
      "\tGenerator loss: 1.1739248037338257, Discriminator loss: 1.0154647827148438\n",
      "\tGenerator loss: 1.1644361019134521, Discriminator loss: 1.0290381908416748\n",
      "\tGenerator loss: 1.148665189743042, Discriminator loss: 1.0453250408172607\n",
      "\tGenerator loss: 1.1662567853927612, Discriminator loss: 1.085179090499878\n",
      "\tGenerator loss: 1.2104166746139526, Discriminator loss: 1.0448739528656006\n",
      "\tGenerator loss: 1.241662621498108, Discriminator loss: 1.0876803398132324\n",
      "\tGenerator loss: 1.2231736183166504, Discriminator loss: 1.162943720817566\n",
      "\tGenerator loss: 1.1732100248336792, Discriminator loss: 1.1540443897247314\n",
      "\tGenerator loss: 1.1129460334777832, Discriminator loss: 1.2693779468536377\n",
      "\tGenerator loss: 1.0511850118637085, Discriminator loss: 1.3053724765777588\n",
      "\tGenerator loss: 1.0166748762130737, Discriminator loss: 1.1783267259597778\n",
      "\tGenerator loss: 1.0486557483673096, Discriminator loss: 1.1304662227630615\n",
      "\tGenerator loss: 1.1440171003341675, Discriminator loss: 1.123233437538147\n",
      "\tGenerator loss: 1.2484431266784668, Discriminator loss: 1.1924965381622314\n",
      "\tGenerator loss: 1.2236504554748535, Discriminator loss: 1.0898762941360474\n",
      "\tGenerator loss: 1.1752939224243164, Discriminator loss: 1.1054236888885498\n",
      "\tGenerator loss: 1.1153236627578735, Discriminator loss: 1.1280577182769775\n",
      "\tGenerator loss: 1.0698435306549072, Discriminator loss: 1.1499261856079102\n",
      "\tGenerator loss: 1.057024359703064, Discriminator loss: 1.258453607559204\n",
      "\tGenerator loss: 1.1183407306671143, Discriminator loss: 1.1719419956207275\n",
      "\tGenerator loss: 1.1573786735534668, Discriminator loss: 1.1140432357788086\n",
      "\tGenerator loss: 1.176975131034851, Discriminator loss: 1.1302372217178345\n",
      "\tGenerator loss: 1.1779147386550903, Discriminator loss: 1.118234395980835\n",
      "\tGenerator loss: 1.1972570419311523, Discriminator loss: 1.0891308784484863\n",
      "\tGenerator loss: 1.192846655845642, Discriminator loss: 1.0907799005508423\n",
      "\tGenerator loss: 1.156402349472046, Discriminator loss: 1.1126821041107178\n",
      "\tGenerator loss: 1.1562544107437134, Discriminator loss: 1.0798425674438477\n",
      "\tGenerator loss: 1.1633920669555664, Discriminator loss: 1.0963411331176758\n",
      "\tGenerator loss: 1.1680853366851807, Discriminator loss: 1.1032428741455078\n",
      "\tGenerator loss: 1.2167723178863525, Discriminator loss: 1.0778919458389282\n",
      "\tGenerator loss: 1.2119323015213013, Discriminator loss: 1.1125340461730957\n",
      "\tGenerator loss: 1.1674578189849854, Discriminator loss: 1.0842444896697998\n",
      "\tGenerator loss: 1.1332367658615112, Discriminator loss: 1.0379021167755127\n",
      "\tGenerator loss: 1.0913095474243164, Discriminator loss: 1.0623955726623535\n",
      "\tGenerator loss: 1.1733198165893555, Discriminator loss: 0.9924542307853699\n",
      "\tGenerator loss: 1.2587978839874268, Discriminator loss: 1.0400707721710205\n",
      "\tGenerator loss: 1.3157744407653809, Discriminator loss: 1.029150128364563\n",
      "\tGenerator loss: 1.2861907482147217, Discriminator loss: 0.9772694110870361\n",
      "\tGenerator loss: 1.2147446870803833, Discriminator loss: 1.0634045600891113\n",
      "\tGenerator loss: 1.126659870147705, Discriminator loss: 1.0744788646697998\n",
      "\tGenerator loss: 1.0767710208892822, Discriminator loss: 1.0897860527038574\n",
      "\tGenerator loss: 1.1166354417800903, Discriminator loss: 1.0650358200073242\n",
      "\tGenerator loss: 1.1689667701721191, Discriminator loss: 1.0919959545135498\n",
      "\tGenerator loss: 1.1714942455291748, Discriminator loss: 1.0359621047973633\n",
      "\tGenerator loss: 1.1971776485443115, Discriminator loss: 1.0043041706085205\n",
      "\tGenerator loss: 1.1901609897613525, Discriminator loss: 0.9942306876182556\n",
      "\tGenerator loss: 1.2028024196624756, Discriminator loss: 0.9539179801940918\n",
      "\tGenerator loss: 1.2145321369171143, Discriminator loss: 0.970550000667572\n",
      "\tGenerator loss: 1.1950531005859375, Discriminator loss: 0.9358036518096924\n",
      "\tGenerator loss: 1.2146594524383545, Discriminator loss: 0.9021462202072144\n",
      "\tGenerator loss: 1.3254411220550537, Discriminator loss: 0.9038305878639221\n",
      "\tGenerator loss: 1.3659136295318604, Discriminator loss: 0.902147650718689\n",
      "\tGenerator loss: 1.2802815437316895, Discriminator loss: 0.8748273253440857\n",
      "\tGenerator loss: 1.254152536392212, Discriminator loss: 0.9257676601409912\n",
      "\tGenerator loss: 1.2393758296966553, Discriminator loss: 0.919921875\n",
      "\tGenerator loss: 1.2082853317260742, Discriminator loss: 0.8760367631912231\n",
      "\tGenerator loss: 1.2537232637405396, Discriminator loss: 0.8778829574584961\n",
      "\tGenerator loss: 1.304241418838501, Discriminator loss: 0.8205952644348145\n",
      "\tGenerator loss: 1.345674991607666, Discriminator loss: 0.8232938051223755\n",
      "\tGenerator loss: 1.4206759929656982, Discriminator loss: 0.7935808897018433\n",
      "\tGenerator loss: 1.4411252737045288, Discriminator loss: 0.8030129671096802\n",
      "\tGenerator loss: 1.4586939811706543, Discriminator loss: 0.8415430784225464\n",
      "\tGenerator loss: 1.4350439310073853, Discriminator loss: 0.8081363439559937\n",
      "\tGenerator loss: 1.395444631576538, Discriminator loss: 0.8284046649932861\n",
      "\tGenerator loss: 1.3761669397354126, Discriminator loss: 0.8164297342300415\n",
      "\tGenerator loss: 1.384850263595581, Discriminator loss: 0.8035833239555359\n",
      "\tGenerator loss: 1.4012595415115356, Discriminator loss: 0.7817306518554688\n",
      "\tGenerator loss: 1.466904878616333, Discriminator loss: 0.7709485292434692\n",
      "\tGenerator loss: 1.5076628923416138, Discriminator loss: 0.7242200374603271\n",
      "\tGenerator loss: 1.5063896179199219, Discriminator loss: 0.6874551773071289\n",
      "\tGenerator loss: 1.5338304042816162, Discriminator loss: 0.7763800024986267\n",
      "\tGenerator loss: 1.5016043186187744, Discriminator loss: 0.7334593534469604\n",
      "\tGenerator loss: 1.5094215869903564, Discriminator loss: 0.7082869410514832\n",
      "\tGenerator loss: 1.451095461845398, Discriminator loss: 0.8026440739631653\n",
      "\tGenerator loss: 1.40912663936615, Discriminator loss: 0.8149703741073608\n",
      "\tGenerator loss: 1.4426984786987305, Discriminator loss: 0.8180792927742004\n",
      "\tGenerator loss: 1.436391830444336, Discriminator loss: 0.8132062554359436\n",
      "\tGenerator loss: 1.3917474746704102, Discriminator loss: 0.7726266384124756\n",
      "\tGenerator loss: 1.433767557144165, Discriminator loss: 0.7757505178451538\n",
      "\tGenerator loss: 1.469140648841858, Discriminator loss: 0.7996185421943665\n",
      "\tGenerator loss: 1.452085018157959, Discriminator loss: 0.7678287029266357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.443969488143921, Discriminator loss: 0.7565509676933289\n",
      "\tGenerator loss: 1.402146816253662, Discriminator loss: 0.7657580375671387\n",
      "\tGenerator loss: 1.433772325515747, Discriminator loss: 0.7932901382446289\n",
      "\tGenerator loss: 1.5144587755203247, Discriminator loss: 0.8490250706672668\n",
      "\tGenerator loss: 1.4679672718048096, Discriminator loss: 0.8461980819702148\n",
      "\tGenerator loss: 1.4104260206222534, Discriminator loss: 0.8623795509338379\n",
      "\tGenerator loss: 1.326096773147583, Discriminator loss: 0.8640671968460083\n",
      "\tGenerator loss: 1.2723581790924072, Discriminator loss: 0.8680047988891602\n",
      "\tGenerator loss: 1.331224799156189, Discriminator loss: 0.9249669313430786\n",
      "\tGenerator loss: 1.2865321636199951, Discriminator loss: 0.8914679288864136\n",
      "\tGenerator loss: 1.3239264488220215, Discriminator loss: 0.9269917011260986\n",
      "\tGenerator loss: 1.3805787563323975, Discriminator loss: 0.8841310143470764\n",
      "\tGenerator loss: 1.3460800647735596, Discriminator loss: 0.8564056158065796\n",
      "\tGenerator loss: 1.4057905673980713, Discriminator loss: 0.9584138989448547\n",
      "\tGenerator loss: 1.3371737003326416, Discriminator loss: 1.0170211791992188\n",
      "\tGenerator loss: 1.2480294704437256, Discriminator loss: 1.0580039024353027\n",
      "\tGenerator loss: 1.2023463249206543, Discriminator loss: 1.0009371042251587\n",
      "\tGenerator loss: 1.1550060510635376, Discriminator loss: 0.9924222230911255\n",
      "\tGenerator loss: 1.216055154800415, Discriminator loss: 1.0430426597595215\n",
      "\tGenerator loss: 1.2819916009902954, Discriminator loss: 1.0112297534942627\n",
      "\tGenerator loss: 1.3498799800872803, Discriminator loss: 0.9967591166496277\n",
      "\tGenerator loss: 1.3611176013946533, Discriminator loss: 0.9831016063690186\n",
      "\tGenerator loss: 1.2585285902023315, Discriminator loss: 1.043399453163147\n",
      "\tGenerator loss: 1.1517679691314697, Discriminator loss: 1.0412603616714478\n",
      "\tGenerator loss: 1.1231651306152344, Discriminator loss: 1.0508310794830322\n",
      "\tGenerator loss: 1.1591341495513916, Discriminator loss: 1.0359364748001099\n",
      "\tGenerator loss: 1.2288841009140015, Discriminator loss: 1.046811819076538\n",
      "\tGenerator loss: 1.2741241455078125, Discriminator loss: 1.022725224494934\n",
      "\tGenerator loss: 1.3109744787216187, Discriminator loss: 1.0221669673919678\n",
      "\tGenerator loss: 1.2123773097991943, Discriminator loss: 1.1293976306915283\n",
      "\tGenerator loss: 1.1685495376586914, Discriminator loss: 1.216591477394104\n",
      "\tGenerator loss: 1.076485514640808, Discriminator loss: 1.1921188831329346\n",
      "\tGenerator loss: 1.0706291198730469, Discriminator loss: 1.12031888961792\n",
      "\tGenerator loss: 1.0874674320220947, Discriminator loss: 1.1519569158554077\n",
      "\tGenerator loss: 1.1887198686599731, Discriminator loss: 1.0684928894042969\n",
      "\tGenerator loss: 1.2560913562774658, Discriminator loss: 1.1677929162979126\n",
      "\tGenerator loss: 1.2558140754699707, Discriminator loss: 1.2189226150512695\n",
      "\tGenerator loss: 1.1869611740112305, Discriminator loss: 1.1681714057922363\n",
      "\tGenerator loss: 1.0768373012542725, Discriminator loss: 1.149135708808899\n",
      "\tGenerator loss: 1.0455347299575806, Discriminator loss: 1.2011886835098267\n",
      "\tGenerator loss: 1.0830566883087158, Discriminator loss: 1.1741411685943604\n",
      "\tGenerator loss: 1.1319234371185303, Discriminator loss: 1.14565908908844\n",
      "\tGenerator loss: 1.2026492357254028, Discriminator loss: 1.191584587097168\n",
      "\tGenerator loss: 1.2035672664642334, Discriminator loss: 1.193143367767334\n",
      "\tGenerator loss: 1.1589670181274414, Discriminator loss: 1.160752534866333\n",
      "\tGenerator loss: 1.148634672164917, Discriminator loss: 1.166373372077942\n",
      "\tGenerator loss: 1.1115765571594238, Discriminator loss: 1.133771538734436\n",
      "\tGenerator loss: 1.0829548835754395, Discriminator loss: 1.2602267265319824\n",
      "\tGenerator loss: 1.1488192081451416, Discriminator loss: 1.226588249206543\n",
      "\tGenerator loss: 1.1280057430267334, Discriminator loss: 1.2588165998458862\n",
      "\tGenerator loss: 1.1526799201965332, Discriminator loss: 1.2514138221740723\n",
      "\tGenerator loss: 1.1308406591415405, Discriminator loss: 1.2006561756134033\n",
      "\tGenerator loss: 1.1002838611602783, Discriminator loss: 1.1544510126113892\n",
      "\tGenerator loss: 1.119292974472046, Discriminator loss: 1.1619465351104736\n",
      "\tGenerator loss: 1.0896316766738892, Discriminator loss: 1.1525477170944214\n",
      "\tGenerator loss: 1.1011834144592285, Discriminator loss: 1.16585111618042\n",
      "\tGenerator loss: 1.1146178245544434, Discriminator loss: 1.1521323919296265\n",
      "\tGenerator loss: 1.1212751865386963, Discriminator loss: 1.2229199409484863\n",
      "\tGenerator loss: 1.170270323753357, Discriminator loss: 1.2579889297485352\n",
      "\tGenerator loss: 1.1239759922027588, Discriminator loss: 1.230046033859253\n",
      "\tGenerator loss: 1.0684289932250977, Discriminator loss: 1.1708779335021973\n",
      "\tGenerator loss: 1.0189929008483887, Discriminator loss: 1.1469827890396118\n",
      "\tGenerator loss: 1.0452756881713867, Discriminator loss: 1.2155473232269287\n",
      "\tGenerator loss: 1.1447936296463013, Discriminator loss: 1.1800585985183716\n",
      "\tGenerator loss: 1.221200704574585, Discriminator loss: 1.1349644660949707\n",
      "\tGenerator loss: 1.183053970336914, Discriminator loss: 1.137103796005249\n",
      "\tGenerator loss: 1.1038570404052734, Discriminator loss: 1.1999187469482422\n",
      "\tGenerator loss: 1.0395586490631104, Discriminator loss: 1.1926829814910889\n",
      "\tGenerator loss: 0.9939901232719421, Discriminator loss: 1.1957653760910034\n",
      "\tGenerator loss: 1.0388132333755493, Discriminator loss: 1.1623446941375732\n",
      "\tGenerator loss: 1.094764232635498, Discriminator loss: 1.180765151977539\n",
      "\tGenerator loss: 1.2197225093841553, Discriminator loss: 1.1291637420654297\n",
      "\tGenerator loss: 1.2218071222305298, Discriminator loss: 1.155245304107666\n",
      "\tGenerator loss: 1.1780146360397339, Discriminator loss: 1.1003365516662598\n",
      "\tGenerator loss: 1.1172537803649902, Discriminator loss: 1.0881521701812744\n",
      "\tGenerator loss: 1.0994057655334473, Discriminator loss: 1.0682811737060547\n",
      "\tGenerator loss: 1.1056290864944458, Discriminator loss: 1.0591095685958862\n",
      "\tGenerator loss: 1.1448167562484741, Discriminator loss: 1.0155627727508545\n",
      "\tGenerator loss: 1.175438404083252, Discriminator loss: 1.0151718854904175\n",
      "\tGenerator loss: 1.163532018661499, Discriminator loss: 1.0726357698440552\n",
      "\tGenerator loss: 1.1951699256896973, Discriminator loss: 1.0441913604736328\n",
      "\tGenerator loss: 1.1638803482055664, Discriminator loss: 1.0543031692504883\n",
      "\tGenerator loss: 1.1226762533187866, Discriminator loss: 1.072764277458191\n",
      "\tGenerator loss: 1.1113147735595703, Discriminator loss: 1.1592507362365723\n",
      "\tGenerator loss: 1.0963903665542603, Discriminator loss: 1.0964393615722656\n",
      "\tGenerator loss: 1.0914092063903809, Discriminator loss: 1.0495216846466064\n",
      "\tGenerator loss: 1.10737943649292, Discriminator loss: 1.0250557661056519\n",
      "\tGenerator loss: 1.1586570739746094, Discriminator loss: 1.0241010189056396\n",
      "\tGenerator loss: 1.2523167133331299, Discriminator loss: 1.0607380867004395\n",
      "\tGenerator loss: 1.2707819938659668, Discriminator loss: 1.0932137966156006\n",
      "\tGenerator loss: 1.2035859823226929, Discriminator loss: 1.0510311126708984\n",
      "\tGenerator loss: 1.1323647499084473, Discriminator loss: 1.0949424505233765\n",
      "\tGenerator loss: 1.0841760635375977, Discriminator loss: 1.0869662761688232\n",
      "\tGenerator loss: 1.1138906478881836, Discriminator loss: 1.0507574081420898\n",
      "\tGenerator loss: 1.21537446975708, Discriminator loss: 1.0594425201416016\n",
      "\tGenerator loss: 1.3000314235687256, Discriminator loss: 1.087410569190979\n",
      "\tGenerator loss: 1.2392330169677734, Discriminator loss: 1.0936784744262695\n",
      "\tGenerator loss: 1.177081823348999, Discriminator loss: 1.0663466453552246\n",
      "\tGenerator loss: 1.0928012132644653, Discriminator loss: 1.0423033237457275\n",
      "\tGenerator loss: 1.0685434341430664, Discriminator loss: 1.0389701128005981\n",
      "\tGenerator loss: 1.122411847114563, Discriminator loss: 1.0367711782455444\n",
      "\tGenerator loss: 1.2564213275909424, Discriminator loss: 0.9818363189697266\n",
      "\tGenerator loss: 1.293632984161377, Discriminator loss: 0.9952581524848938\n",
      "\tGenerator loss: 1.3000906705856323, Discriminator loss: 1.0021754503250122\n",
      "\tGenerator loss: 1.2236285209655762, Discriminator loss: 1.0359764099121094\n",
      "\tGenerator loss: 1.1578242778778076, Discriminator loss: 0.9787598848342896\n",
      "\tGenerator loss: 1.1664297580718994, Discriminator loss: 0.9714781045913696\n",
      "\tGenerator loss: 1.1871161460876465, Discriminator loss: 0.9739887714385986\n",
      "\tGenerator loss: 1.1984437704086304, Discriminator loss: 0.9842491149902344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2309191226959229, Discriminator loss: 0.9305953979492188\n",
      "\tGenerator loss: 1.2190582752227783, Discriminator loss: 0.9541032314300537\n",
      "\tGenerator loss: 1.2187960147857666, Discriminator loss: 0.9608275890350342\n",
      "\tGenerator loss: 1.2484426498413086, Discriminator loss: 0.935695469379425\n",
      "\tGenerator loss: 1.2303798198699951, Discriminator loss: 0.9006861448287964\n",
      "\tGenerator loss: 1.2528514862060547, Discriminator loss: 0.9310342073440552\n",
      "\tGenerator loss: 1.220110535621643, Discriminator loss: 0.9405823945999146\n",
      "\tGenerator loss: 1.2416884899139404, Discriminator loss: 0.9590534567832947\n",
      "\tGenerator loss: 1.2778210639953613, Discriminator loss: 0.9663833975791931\n",
      "\tGenerator loss: 1.2825927734375, Discriminator loss: 0.964186429977417\n",
      "\tGenerator loss: 1.2335755825042725, Discriminator loss: 1.0157687664031982\n",
      "\tGenerator loss: 1.1785430908203125, Discriminator loss: 0.980544924736023\n",
      "\tGenerator loss: 1.1425600051879883, Discriminator loss: 1.0231339931488037\n",
      "\tGenerator loss: 1.1311780214309692, Discriminator loss: 0.9810800552368164\n",
      "\tGenerator loss: 1.2042040824890137, Discriminator loss: 0.9800909757614136\n",
      "\tGenerator loss: 1.326366901397705, Discriminator loss: 0.9772107005119324\n",
      "\tGenerator loss: 1.3126013278961182, Discriminator loss: 0.9761366844177246\n",
      "\tGenerator loss: 1.2462563514709473, Discriminator loss: 0.9843423366546631\n",
      "\tGenerator loss: 1.1629765033721924, Discriminator loss: 0.984264612197876\n",
      "\tGenerator loss: 1.111122727394104, Discriminator loss: 0.9839668273925781\n",
      "\tGenerator loss: 1.0814900398254395, Discriminator loss: 0.9616643190383911\n",
      "\tGenerator loss: 1.1516196727752686, Discriminator loss: 0.9531837701797485\n",
      "\tGenerator loss: 1.2552940845489502, Discriminator loss: 0.9604905843734741\n",
      "\tGenerator loss: 1.3058640956878662, Discriminator loss: 1.023653268814087\n",
      "\tGenerator loss: 1.2949249744415283, Discriminator loss: 0.978904128074646\n",
      "\tGenerator loss: 1.2108491659164429, Discriminator loss: 0.9671978950500488\n",
      "\tGenerator loss: 1.12847900390625, Discriminator loss: 1.0181248188018799\n",
      "\tGenerator loss: 1.1111156940460205, Discriminator loss: 1.054735541343689\n",
      "\tGenerator loss: 1.123203992843628, Discriminator loss: 1.0887320041656494\n",
      "\tGenerator loss: 1.168416142463684, Discriminator loss: 1.1271501779556274\n",
      "Time for epoch 26 is 251.03928804397583 sec\n",
      "\tGenerator loss: 1.1462088823318481, Discriminator loss: 1.0747030973434448\n",
      "\tGenerator loss: 1.0969774723052979, Discriminator loss: 1.0472898483276367\n",
      "\tGenerator loss: 1.0368895530700684, Discriminator loss: 1.1018460988998413\n",
      "\tGenerator loss: 1.0147712230682373, Discriminator loss: 1.1046860218048096\n",
      "\tGenerator loss: 1.0939526557922363, Discriminator loss: 1.1150555610656738\n",
      "\tGenerator loss: 1.1412931680679321, Discriminator loss: 1.1495956182479858\n",
      "\tGenerator loss: 1.1689221858978271, Discriminator loss: 1.0587096214294434\n",
      "\tGenerator loss: 1.1362684965133667, Discriminator loss: 1.0894700288772583\n",
      "\tGenerator loss: 1.1080188751220703, Discriminator loss: 1.0246332883834839\n",
      "\tGenerator loss: 1.1394253969192505, Discriminator loss: 1.0268213748931885\n",
      "\tGenerator loss: 1.1612900495529175, Discriminator loss: 1.0477540493011475\n",
      "\tGenerator loss: 1.1924779415130615, Discriminator loss: 1.0535907745361328\n",
      "\tGenerator loss: 1.186769723892212, Discriminator loss: 1.0150552988052368\n",
      "\tGenerator loss: 1.1409934759140015, Discriminator loss: 0.9964192509651184\n",
      "\tGenerator loss: 1.1484262943267822, Discriminator loss: 0.99106365442276\n",
      "\tGenerator loss: 1.1630187034606934, Discriminator loss: 0.986046552658081\n",
      "\tGenerator loss: 1.1802258491516113, Discriminator loss: 1.0443143844604492\n",
      "\tGenerator loss: 1.1749919652938843, Discriminator loss: 1.0382448434829712\n",
      "\tGenerator loss: 1.1329081058502197, Discriminator loss: 1.0423181056976318\n",
      "\tGenerator loss: 1.1241546869277954, Discriminator loss: 1.0217325687408447\n",
      "\tGenerator loss: 1.1484336853027344, Discriminator loss: 1.0666179656982422\n",
      "\tGenerator loss: 1.1242952346801758, Discriminator loss: 1.0870721340179443\n",
      "\tGenerator loss: 1.1377077102661133, Discriminator loss: 1.0826804637908936\n",
      "\tGenerator loss: 1.167867660522461, Discriminator loss: 1.1332279443740845\n",
      "\tGenerator loss: 1.1327763795852661, Discriminator loss: 1.157564640045166\n",
      "\tGenerator loss: 1.1058049201965332, Discriminator loss: 1.0638419389724731\n",
      "\tGenerator loss: 1.1163721084594727, Discriminator loss: 1.0465295314788818\n",
      "\tGenerator loss: 1.1787173748016357, Discriminator loss: 1.050936222076416\n",
      "\tGenerator loss: 1.251136064529419, Discriminator loss: 1.0658165216445923\n",
      "\tGenerator loss: 1.135952353477478, Discriminator loss: 1.0122926235198975\n",
      "\tGenerator loss: 1.1144907474517822, Discriminator loss: 1.0243818759918213\n",
      "\tGenerator loss: 1.1088348627090454, Discriminator loss: 1.0413868427276611\n",
      "\tGenerator loss: 1.1720376014709473, Discriminator loss: 1.0486860275268555\n",
      "\tGenerator loss: 1.1648705005645752, Discriminator loss: 1.133338451385498\n",
      "\tGenerator loss: 1.1609992980957031, Discriminator loss: 1.084048867225647\n",
      "\tGenerator loss: 1.1624300479888916, Discriminator loss: 1.028587818145752\n",
      "\tGenerator loss: 1.1597447395324707, Discriminator loss: 1.0183449983596802\n",
      "\tGenerator loss: 1.1958131790161133, Discriminator loss: 0.9937387704849243\n",
      "\tGenerator loss: 1.2126448154449463, Discriminator loss: 0.9490264654159546\n",
      "\tGenerator loss: 1.2400776147842407, Discriminator loss: 0.9846207499504089\n",
      "\tGenerator loss: 1.2674472332000732, Discriminator loss: 1.0200107097625732\n",
      "\tGenerator loss: 1.263864278793335, Discriminator loss: 0.9802340269088745\n",
      "\tGenerator loss: 1.2488610744476318, Discriminator loss: 0.9981876611709595\n",
      "\tGenerator loss: 1.243842601776123, Discriminator loss: 0.9750469923019409\n",
      "\tGenerator loss: 1.187926173210144, Discriminator loss: 0.9782055616378784\n",
      "\tGenerator loss: 1.2192490100860596, Discriminator loss: 0.9659449458122253\n",
      "\tGenerator loss: 1.2225815057754517, Discriminator loss: 0.9813050031661987\n",
      "\tGenerator loss: 1.2133171558380127, Discriminator loss: 0.991330623626709\n",
      "\tGenerator loss: 1.263627290725708, Discriminator loss: 0.9691846370697021\n",
      "\tGenerator loss: 1.2453819513320923, Discriminator loss: 0.9344306588172913\n",
      "\tGenerator loss: 1.2888760566711426, Discriminator loss: 0.9633534550666809\n",
      "\tGenerator loss: 1.2861106395721436, Discriminator loss: 0.9840350151062012\n",
      "\tGenerator loss: 1.2356284856796265, Discriminator loss: 0.9689049124717712\n",
      "\tGenerator loss: 1.2068595886230469, Discriminator loss: 1.0201419591903687\n",
      "\tGenerator loss: 1.2143149375915527, Discriminator loss: 0.998855471611023\n",
      "\tGenerator loss: 1.1980862617492676, Discriminator loss: 1.0441615581512451\n",
      "\tGenerator loss: 1.164903998374939, Discriminator loss: 1.0384232997894287\n",
      "\tGenerator loss: 1.1978983879089355, Discriminator loss: 0.9956991672515869\n",
      "\tGenerator loss: 1.1966547966003418, Discriminator loss: 0.9916277527809143\n",
      "\tGenerator loss: 1.270633578300476, Discriminator loss: 0.9613069891929626\n",
      "\tGenerator loss: 1.2490260601043701, Discriminator loss: 0.9900071620941162\n",
      "\tGenerator loss: 1.203091025352478, Discriminator loss: 0.9938098788261414\n",
      "\tGenerator loss: 1.1857733726501465, Discriminator loss: 1.0313537120819092\n",
      "\tGenerator loss: 1.1621639728546143, Discriminator loss: 1.037109136581421\n",
      "\tGenerator loss: 1.2042917013168335, Discriminator loss: 0.9931354522705078\n",
      "\tGenerator loss: 1.2205078601837158, Discriminator loss: 0.9903321266174316\n",
      "\tGenerator loss: 1.2364695072174072, Discriminator loss: 1.0428245067596436\n",
      "\tGenerator loss: 1.180858850479126, Discriminator loss: 1.0578222274780273\n",
      "\tGenerator loss: 1.0981802940368652, Discriminator loss: 1.1374688148498535\n",
      "\tGenerator loss: 1.0929689407348633, Discriminator loss: 1.1306591033935547\n",
      "\tGenerator loss: 1.0859920978546143, Discriminator loss: 1.0867705345153809\n",
      "\tGenerator loss: 1.1224581003189087, Discriminator loss: 1.1108040809631348\n",
      "\tGenerator loss: 1.1322739124298096, Discriminator loss: 1.0787551403045654\n",
      "\tGenerator loss: 1.1522949934005737, Discriminator loss: 1.0652592182159424\n",
      "\tGenerator loss: 1.1431641578674316, Discriminator loss: 1.0675336122512817\n",
      "\tGenerator loss: 1.1261920928955078, Discriminator loss: 1.1202808618545532\n",
      "\tGenerator loss: 1.1225067377090454, Discriminator loss: 1.1290028095245361\n",
      "\tGenerator loss: 1.0692873001098633, Discriminator loss: 1.1559836864471436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0255162715911865, Discriminator loss: 1.1633840799331665\n",
      "\tGenerator loss: 1.099839210510254, Discriminator loss: 1.1450603008270264\n",
      "\tGenerator loss: 1.1408535242080688, Discriminator loss: 1.1699097156524658\n",
      "\tGenerator loss: 1.1426141262054443, Discriminator loss: 1.1690783500671387\n",
      "\tGenerator loss: 1.0875872373580933, Discriminator loss: 1.0836141109466553\n",
      "\tGenerator loss: 1.0939736366271973, Discriminator loss: 1.0919833183288574\n",
      "\tGenerator loss: 1.11295747756958, Discriminator loss: 1.0567771196365356\n",
      "\tGenerator loss: 1.1476746797561646, Discriminator loss: 1.1627864837646484\n",
      "\tGenerator loss: 1.1183526515960693, Discriminator loss: 1.1240123510360718\n",
      "\tGenerator loss: 1.097995638847351, Discriminator loss: 1.1193469762802124\n",
      "\tGenerator loss: 1.1070048809051514, Discriminator loss: 1.234995722770691\n",
      "\tGenerator loss: 1.0903892517089844, Discriminator loss: 1.269057035446167\n",
      "\tGenerator loss: 1.0099107027053833, Discriminator loss: 1.2917333841323853\n",
      "\tGenerator loss: 1.0338778495788574, Discriminator loss: 1.2270798683166504\n",
      "\tGenerator loss: 1.052687406539917, Discriminator loss: 1.1579285860061646\n",
      "\tGenerator loss: 1.121032953262329, Discriminator loss: 1.168980360031128\n",
      "\tGenerator loss: 1.1390784978866577, Discriminator loss: 1.1931471824645996\n",
      "\tGenerator loss: 1.030410647392273, Discriminator loss: 1.2009730339050293\n",
      "\tGenerator loss: 1.0298134088516235, Discriminator loss: 1.2047579288482666\n",
      "\tGenerator loss: 1.0482664108276367, Discriminator loss: 1.1496808528900146\n",
      "\tGenerator loss: 1.0968002080917358, Discriminator loss: 1.169808030128479\n",
      "\tGenerator loss: 1.1262247562408447, Discriminator loss: 1.2863057851791382\n",
      "\tGenerator loss: 1.159085988998413, Discriminator loss: 1.2028130292892456\n",
      "\tGenerator loss: 1.0725712776184082, Discriminator loss: 1.2013475894927979\n",
      "\tGenerator loss: 1.0343725681304932, Discriminator loss: 1.199955701828003\n",
      "\tGenerator loss: 1.0415682792663574, Discriminator loss: 1.184087872505188\n",
      "\tGenerator loss: 1.0773054361343384, Discriminator loss: 1.212892770767212\n",
      "\tGenerator loss: 1.036073923110962, Discriminator loss: 1.2186651229858398\n",
      "\tGenerator loss: 1.093163013458252, Discriminator loss: 1.2602044343948364\n",
      "\tGenerator loss: 1.14021897315979, Discriminator loss: 1.166884422302246\n",
      "\tGenerator loss: 1.111555814743042, Discriminator loss: 1.1368041038513184\n",
      "\tGenerator loss: 1.1285443305969238, Discriminator loss: 1.2503392696380615\n",
      "\tGenerator loss: 1.1197071075439453, Discriminator loss: 1.3550775051116943\n",
      "\tGenerator loss: 1.0427497625350952, Discriminator loss: 1.3572840690612793\n",
      "\tGenerator loss: 1.0311530828475952, Discriminator loss: 1.2695841789245605\n",
      "\tGenerator loss: 1.0080548524856567, Discriminator loss: 1.235379934310913\n",
      "\tGenerator loss: 1.0571856498718262, Discriminator loss: 1.3215417861938477\n",
      "\tGenerator loss: 1.1073051691055298, Discriminator loss: 1.2082107067108154\n",
      "\tGenerator loss: 1.127835750579834, Discriminator loss: 1.176277995109558\n",
      "\tGenerator loss: 1.1249412298202515, Discriminator loss: 1.1385324001312256\n",
      "\tGenerator loss: 1.0604784488677979, Discriminator loss: 1.1540570259094238\n",
      "\tGenerator loss: 1.0442442893981934, Discriminator loss: 1.147694706916809\n",
      "\tGenerator loss: 1.0888454914093018, Discriminator loss: 1.135796070098877\n",
      "\tGenerator loss: 1.096454381942749, Discriminator loss: 1.0891324281692505\n",
      "\tGenerator loss: 1.1114448308944702, Discriminator loss: 1.119717001914978\n",
      "\tGenerator loss: 1.1435039043426514, Discriminator loss: 1.1067432165145874\n",
      "\tGenerator loss: 1.1657347679138184, Discriminator loss: 1.1214210987091064\n",
      "\tGenerator loss: 1.124276876449585, Discriminator loss: 1.1570450067520142\n",
      "\tGenerator loss: 1.0761635303497314, Discriminator loss: 1.2927082777023315\n",
      "\tGenerator loss: 1.0851263999938965, Discriminator loss: 1.1815176010131836\n",
      "\tGenerator loss: 1.0830838680267334, Discriminator loss: 1.1362786293029785\n",
      "\tGenerator loss: 1.1438751220703125, Discriminator loss: 1.138263463973999\n",
      "\tGenerator loss: 1.1688952445983887, Discriminator loss: 1.1089611053466797\n",
      "\tGenerator loss: 1.2113951444625854, Discriminator loss: 1.1467032432556152\n",
      "\tGenerator loss: 1.1359302997589111, Discriminator loss: 1.2059385776519775\n",
      "\tGenerator loss: 1.0801470279693604, Discriminator loss: 1.1280732154846191\n",
      "\tGenerator loss: 1.0526044368743896, Discriminator loss: 1.1192739009857178\n",
      "\tGenerator loss: 1.1427903175354004, Discriminator loss: 1.104689121246338\n",
      "\tGenerator loss: 1.2292704582214355, Discriminator loss: 1.102332353591919\n",
      "\tGenerator loss: 1.2623380422592163, Discriminator loss: 1.0561347007751465\n",
      "\tGenerator loss: 1.2190227508544922, Discriminator loss: 1.083925485610962\n",
      "\tGenerator loss: 1.2508516311645508, Discriminator loss: 1.0377631187438965\n",
      "\tGenerator loss: 1.206331491470337, Discriminator loss: 1.0443121194839478\n",
      "\tGenerator loss: 1.1878107786178589, Discriminator loss: 1.0615544319152832\n",
      "\tGenerator loss: 1.1321864128112793, Discriminator loss: 1.059840440750122\n",
      "\tGenerator loss: 1.2275733947753906, Discriminator loss: 1.0528323650360107\n",
      "\tGenerator loss: 1.2892807722091675, Discriminator loss: 1.0401123762130737\n",
      "\tGenerator loss: 1.281497597694397, Discriminator loss: 1.0557701587677002\n",
      "\tGenerator loss: 1.2323001623153687, Discriminator loss: 1.0382063388824463\n",
      "\tGenerator loss: 1.2123098373413086, Discriminator loss: 1.006013035774231\n",
      "\tGenerator loss: 1.2055684328079224, Discriminator loss: 0.9951928853988647\n",
      "\tGenerator loss: 1.2223801612854004, Discriminator loss: 0.9723215699195862\n",
      "\tGenerator loss: 1.2746198177337646, Discriminator loss: 0.9530460834503174\n",
      "\tGenerator loss: 1.318838357925415, Discriminator loss: 0.959812343120575\n",
      "\tGenerator loss: 1.3326101303100586, Discriminator loss: 0.9578051567077637\n",
      "\tGenerator loss: 1.293947696685791, Discriminator loss: 0.9844070672988892\n",
      "\tGenerator loss: 1.2193095684051514, Discriminator loss: 1.0268044471740723\n",
      "\tGenerator loss: 1.2543506622314453, Discriminator loss: 1.0043809413909912\n",
      "\tGenerator loss: 1.240913987159729, Discriminator loss: 0.9921875\n",
      "\tGenerator loss: 1.2426252365112305, Discriminator loss: 0.9511109590530396\n",
      "\tGenerator loss: 1.2801679372787476, Discriminator loss: 0.9495969414710999\n",
      "\tGenerator loss: 1.2920610904693604, Discriminator loss: 0.9332135319709778\n",
      "\tGenerator loss: 1.3354049921035767, Discriminator loss: 0.958357572555542\n",
      "\tGenerator loss: 1.3402392864227295, Discriminator loss: 0.9214673042297363\n",
      "\tGenerator loss: 1.284112811088562, Discriminator loss: 0.98894202709198\n",
      "\tGenerator loss: 1.188966989517212, Discriminator loss: 1.0512566566467285\n",
      "\tGenerator loss: 1.0973669290542603, Discriminator loss: 1.048209309577942\n",
      "\tGenerator loss: 1.1360580921173096, Discriminator loss: 1.0186758041381836\n",
      "\tGenerator loss: 1.1898722648620605, Discriminator loss: 1.0494604110717773\n",
      "\tGenerator loss: 1.2582902908325195, Discriminator loss: 1.025592565536499\n",
      "\tGenerator loss: 1.2876534461975098, Discriminator loss: 1.048677921295166\n",
      "\tGenerator loss: 1.2722446918487549, Discriminator loss: 0.9983161687850952\n",
      "\tGenerator loss: 1.2045414447784424, Discriminator loss: 1.0323539972305298\n",
      "\tGenerator loss: 1.2040969133377075, Discriminator loss: 1.0133228302001953\n",
      "\tGenerator loss: 1.1562862396240234, Discriminator loss: 1.0009958744049072\n",
      "\tGenerator loss: 1.1473966836929321, Discriminator loss: 0.9962582588195801\n",
      "\tGenerator loss: 1.1916954517364502, Discriminator loss: 1.0570244789123535\n",
      "\tGenerator loss: 1.204682469367981, Discriminator loss: 1.1184093952178955\n",
      "\tGenerator loss: 1.1774241924285889, Discriminator loss: 1.08164644241333\n",
      "\tGenerator loss: 1.111811876296997, Discriminator loss: 1.1172471046447754\n",
      "\tGenerator loss: 1.1242258548736572, Discriminator loss: 1.089883804321289\n",
      "\tGenerator loss: 1.1117150783538818, Discriminator loss: 1.1852023601531982\n",
      "\tGenerator loss: 1.0822701454162598, Discriminator loss: 1.1140007972717285\n",
      "\tGenerator loss: 1.0606873035430908, Discriminator loss: 1.1044538021087646\n",
      "\tGenerator loss: 1.0329439640045166, Discriminator loss: 1.1089696884155273\n",
      "\tGenerator loss: 1.0765503644943237, Discriminator loss: 1.1027017831802368\n",
      "\tGenerator loss: 1.1655688285827637, Discriminator loss: 1.1422780752182007\n",
      "\tGenerator loss: 1.2184021472930908, Discriminator loss: 1.1322176456451416\n",
      "\tGenerator loss: 1.192281723022461, Discriminator loss: 1.1220567226409912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.10746169090271, Discriminator loss: 1.1370131969451904\n",
      "\tGenerator loss: 1.0190740823745728, Discriminator loss: 1.215593695640564\n",
      "\tGenerator loss: 0.9906681776046753, Discriminator loss: 1.203629970550537\n",
      "\tGenerator loss: 0.9970712065696716, Discriminator loss: 1.2218713760375977\n",
      "\tGenerator loss: 1.07259202003479, Discriminator loss: 1.229049563407898\n",
      "\tGenerator loss: 1.0872774124145508, Discriminator loss: 1.246459722518921\n",
      "\tGenerator loss: 1.091736078262329, Discriminator loss: 1.2177737951278687\n",
      "\tGenerator loss: 1.0720573663711548, Discriminator loss: 1.174330234527588\n",
      "\tGenerator loss: 1.0368573665618896, Discriminator loss: 1.1753334999084473\n",
      "\tGenerator loss: 1.001387119293213, Discriminator loss: 1.2145251035690308\n",
      "\tGenerator loss: 1.0193867683410645, Discriminator loss: 1.1856331825256348\n",
      "\tGenerator loss: 1.0717558860778809, Discriminator loss: 1.2054760456085205\n",
      "\tGenerator loss: 1.093745231628418, Discriminator loss: 1.2141600847244263\n",
      "\tGenerator loss: 1.0991134643554688, Discriminator loss: 1.242647409439087\n",
      "\tGenerator loss: 1.090923547744751, Discriminator loss: 1.1600511074066162\n",
      "\tGenerator loss: 1.0580241680145264, Discriminator loss: 1.164342999458313\n",
      "\tGenerator loss: 1.0510250329971313, Discriminator loss: 1.135786533355713\n",
      "\tGenerator loss: 1.024543046951294, Discriminator loss: 1.1976513862609863\n",
      "\tGenerator loss: 1.056902289390564, Discriminator loss: 1.1625590324401855\n",
      "\tGenerator loss: 1.067978858947754, Discriminator loss: 1.1905364990234375\n",
      "\tGenerator loss: 1.0550501346588135, Discriminator loss: 1.2412663698196411\n",
      "\tGenerator loss: 1.0145825147628784, Discriminator loss: 1.2203106880187988\n",
      "\tGenerator loss: 1.0344676971435547, Discriminator loss: 1.1530756950378418\n",
      "\tGenerator loss: 1.0608620643615723, Discriminator loss: 1.1739304065704346\n",
      "\tGenerator loss: 1.0656976699829102, Discriminator loss: 1.1678197383880615\n",
      "\tGenerator loss: 1.1076613664627075, Discriminator loss: 1.1819779872894287\n",
      "\tGenerator loss: 1.0833439826965332, Discriminator loss: 1.219407558441162\n",
      "\tGenerator loss: 1.0416098833084106, Discriminator loss: 1.1888248920440674\n",
      "\tGenerator loss: 1.020721197128296, Discriminator loss: 1.2152495384216309\n",
      "\tGenerator loss: 0.9930577874183655, Discriminator loss: 1.2209808826446533\n",
      "\tGenerator loss: 1.0402847528457642, Discriminator loss: 1.2811850309371948\n",
      "\tGenerator loss: 1.0938150882720947, Discriminator loss: 1.185241937637329\n",
      "\tGenerator loss: 1.0960010290145874, Discriminator loss: 1.1774604320526123\n",
      "\tGenerator loss: 1.0538175106048584, Discriminator loss: 1.139095664024353\n",
      "\tGenerator loss: 1.0919215679168701, Discriminator loss: 1.1407198905944824\n",
      "\tGenerator loss: 1.0905038118362427, Discriminator loss: 1.1222676038742065\n",
      "\tGenerator loss: 1.0994129180908203, Discriminator loss: 1.1249163150787354\n",
      "\tGenerator loss: 1.0881760120391846, Discriminator loss: 1.1458439826965332\n",
      "\tGenerator loss: 1.0447046756744385, Discriminator loss: 1.1034104824066162\n",
      "\tGenerator loss: 1.054537296295166, Discriminator loss: 1.0981369018554688\n",
      "\tGenerator loss: 1.107143521308899, Discriminator loss: 1.075308918952942\n",
      "\tGenerator loss: 1.1210901737213135, Discriminator loss: 1.125820517539978\n",
      "\tGenerator loss: 1.1164023876190186, Discriminator loss: 1.0504964590072632\n",
      "\tGenerator loss: 1.1089473962783813, Discriminator loss: 1.0576412677764893\n",
      "\tGenerator loss: 1.130988597869873, Discriminator loss: 1.1225651502609253\n",
      "\tGenerator loss: 1.1626213788986206, Discriminator loss: 1.1876351833343506\n",
      "\tGenerator loss: 1.134948492050171, Discriminator loss: 1.2301902770996094\n",
      "\tGenerator loss: 1.0721626281738281, Discriminator loss: 1.1578090190887451\n",
      "Time for epoch 27 is 246.3054723739624 sec\n",
      "\tGenerator loss: 1.080607533454895, Discriminator loss: 1.115734577178955\n",
      "\tGenerator loss: 1.0762097835540771, Discriminator loss: 1.1000828742980957\n",
      "\tGenerator loss: 1.0826915502548218, Discriminator loss: 1.153265118598938\n",
      "\tGenerator loss: 1.135239601135254, Discriminator loss: 1.111565351486206\n",
      "\tGenerator loss: 1.110026240348816, Discriminator loss: 1.1682199239730835\n",
      "\tGenerator loss: 1.1063368320465088, Discriminator loss: 1.1707005500793457\n",
      "\tGenerator loss: 1.095874309539795, Discriminator loss: 1.0539878606796265\n",
      "\tGenerator loss: 1.1087698936462402, Discriminator loss: 1.0601556301116943\n",
      "\tGenerator loss: 1.1633003950119019, Discriminator loss: 1.0245267152786255\n",
      "\tGenerator loss: 1.2479698657989502, Discriminator loss: 1.0327060222625732\n",
      "\tGenerator loss: 1.2835291624069214, Discriminator loss: 0.9922766089439392\n",
      "\tGenerator loss: 1.2311046123504639, Discriminator loss: 0.9862023591995239\n",
      "\tGenerator loss: 1.1640243530273438, Discriminator loss: 0.9897484183311462\n",
      "\tGenerator loss: 1.0981240272521973, Discriminator loss: 1.0072969198226929\n",
      "\tGenerator loss: 1.1030994653701782, Discriminator loss: 0.9911965131759644\n",
      "\tGenerator loss: 1.216076374053955, Discriminator loss: 0.9418386220932007\n",
      "\tGenerator loss: 1.3274027109146118, Discriminator loss: 0.9376180171966553\n",
      "\tGenerator loss: 1.3534526824951172, Discriminator loss: 0.9432400465011597\n",
      "\tGenerator loss: 1.2912585735321045, Discriminator loss: 0.9365620017051697\n",
      "\tGenerator loss: 1.240900993347168, Discriminator loss: 0.9271026849746704\n",
      "\tGenerator loss: 1.2281782627105713, Discriminator loss: 0.9115777611732483\n",
      "\tGenerator loss: 1.2610902786254883, Discriminator loss: 0.9355765581130981\n",
      "\tGenerator loss: 1.308931827545166, Discriminator loss: 0.9262186288833618\n",
      "\tGenerator loss: 1.3403048515319824, Discriminator loss: 0.9328882098197937\n",
      "\tGenerator loss: 1.3286770582199097, Discriminator loss: 0.9214299917221069\n",
      "\tGenerator loss: 1.2756853103637695, Discriminator loss: 0.9180833697319031\n",
      "\tGenerator loss: 1.2617416381835938, Discriminator loss: 0.9485410451889038\n",
      "\tGenerator loss: 1.2306268215179443, Discriminator loss: 0.9248290061950684\n",
      "\tGenerator loss: 1.2152953147888184, Discriminator loss: 1.0279529094696045\n",
      "\tGenerator loss: 1.2152020931243896, Discriminator loss: 0.9340113997459412\n",
      "\tGenerator loss: 1.1955989599227905, Discriminator loss: 0.952650785446167\n",
      "\tGenerator loss: 1.2643933296203613, Discriminator loss: 0.9295918941497803\n",
      "\tGenerator loss: 1.3049439191818237, Discriminator loss: 0.9528501033782959\n",
      "\tGenerator loss: 1.3302841186523438, Discriminator loss: 0.9456606507301331\n",
      "\tGenerator loss: 1.287572979927063, Discriminator loss: 0.9591771960258484\n",
      "\tGenerator loss: 1.2581982612609863, Discriminator loss: 0.9655575156211853\n",
      "\tGenerator loss: 1.229698896408081, Discriminator loss: 0.9666879177093506\n",
      "\tGenerator loss: 1.198061466217041, Discriminator loss: 0.9486810564994812\n",
      "\tGenerator loss: 1.2578072547912598, Discriminator loss: 0.9119396209716797\n",
      "\tGenerator loss: 1.2543072700500488, Discriminator loss: 0.9395594000816345\n",
      "\tGenerator loss: 1.2861933708190918, Discriminator loss: 0.9390408992767334\n",
      "\tGenerator loss: 1.3125911951065063, Discriminator loss: 0.9461864233016968\n",
      "\tGenerator loss: 1.3289639949798584, Discriminator loss: 0.9737558960914612\n",
      "\tGenerator loss: 1.2783960103988647, Discriminator loss: 0.9786968231201172\n",
      "\tGenerator loss: 1.1950242519378662, Discriminator loss: 1.0056848526000977\n",
      "\tGenerator loss: 1.138923168182373, Discriminator loss: 1.018998622894287\n",
      "\tGenerator loss: 1.054826021194458, Discriminator loss: 1.0850279331207275\n",
      "\tGenerator loss: 1.0596661567687988, Discriminator loss: 1.1222580671310425\n",
      "\tGenerator loss: 1.1508729457855225, Discriminator loss: 1.100907802581787\n",
      "\tGenerator loss: 1.164006233215332, Discriminator loss: 1.058864712715149\n",
      "\tGenerator loss: 1.1662967205047607, Discriminator loss: 1.0776054859161377\n",
      "\tGenerator loss: 1.1756839752197266, Discriminator loss: 1.0656747817993164\n",
      "\tGenerator loss: 1.111061692237854, Discriminator loss: 1.0624974966049194\n",
      "\tGenerator loss: 1.0784883499145508, Discriminator loss: 1.1109845638275146\n",
      "\tGenerator loss: 1.0768747329711914, Discriminator loss: 1.0809657573699951\n",
      "\tGenerator loss: 1.0564086437225342, Discriminator loss: 1.1114457845687866\n",
      "\tGenerator loss: 1.079636573791504, Discriminator loss: 1.1162333488464355\n",
      "\tGenerator loss: 1.071732997894287, Discriminator loss: 1.097153902053833\n",
      "\tGenerator loss: 1.1036094427108765, Discriminator loss: 1.0900638103485107\n",
      "\tGenerator loss: 1.1067044734954834, Discriminator loss: 1.078432321548462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.064835786819458, Discriminator loss: 1.0998135805130005\n",
      "\tGenerator loss: 1.0215327739715576, Discriminator loss: 1.0588446855545044\n",
      "\tGenerator loss: 0.995607852935791, Discriminator loss: 1.1610243320465088\n",
      "\tGenerator loss: 1.0249344110488892, Discriminator loss: 1.1404807567596436\n",
      "\tGenerator loss: 1.0231921672821045, Discriminator loss: 1.1083869934082031\n",
      "\tGenerator loss: 1.0961174964904785, Discriminator loss: 1.0820304155349731\n",
      "\tGenerator loss: 1.1745781898498535, Discriminator loss: 1.1243884563446045\n",
      "\tGenerator loss: 1.183990716934204, Discriminator loss: 1.0863401889801025\n",
      "\tGenerator loss: 1.0629081726074219, Discriminator loss: 1.1366932392120361\n",
      "\tGenerator loss: 0.9788073301315308, Discriminator loss: 1.1220011711120605\n",
      "\tGenerator loss: 0.9649994969367981, Discriminator loss: 1.095651626586914\n",
      "\tGenerator loss: 1.032537579536438, Discriminator loss: 1.1394261121749878\n",
      "\tGenerator loss: 1.1155083179473877, Discriminator loss: 1.101630449295044\n",
      "\tGenerator loss: 1.1466422080993652, Discriminator loss: 1.1176135540008545\n",
      "\tGenerator loss: 1.1880980730056763, Discriminator loss: 1.0537774562835693\n",
      "\tGenerator loss: 1.165578842163086, Discriminator loss: 1.197058916091919\n",
      "\tGenerator loss: 1.0539697408676147, Discriminator loss: 1.316431999206543\n",
      "\tGenerator loss: 1.007747769355774, Discriminator loss: 1.2597088813781738\n",
      "\tGenerator loss: 1.0185956954956055, Discriminator loss: 1.1857184171676636\n",
      "\tGenerator loss: 1.0967388153076172, Discriminator loss: 1.1489931344985962\n",
      "\tGenerator loss: 1.1487854719161987, Discriminator loss: 1.2060999870300293\n",
      "\tGenerator loss: 1.1771326065063477, Discriminator loss: 1.2279871702194214\n",
      "\tGenerator loss: 1.188018798828125, Discriminator loss: 1.0926439762115479\n",
      "\tGenerator loss: 1.1208888292312622, Discriminator loss: 1.1079318523406982\n",
      "\tGenerator loss: 1.0689117908477783, Discriminator loss: 1.0737056732177734\n",
      "\tGenerator loss: 1.1289687156677246, Discriminator loss: 1.265834093093872\n",
      "\tGenerator loss: 1.1332697868347168, Discriminator loss: 1.1404842138290405\n",
      "\tGenerator loss: 1.146091341972351, Discriminator loss: 1.1907531023025513\n",
      "\tGenerator loss: 1.1587402820587158, Discriminator loss: 1.394113540649414\n",
      "\tGenerator loss: 1.0617396831512451, Discriminator loss: 1.4292802810668945\n",
      "\tGenerator loss: 0.956821858882904, Discriminator loss: 1.4120168685913086\n",
      "\tGenerator loss: 0.8927990198135376, Discriminator loss: 1.3437377214431763\n",
      "\tGenerator loss: 0.9515772461891174, Discriminator loss: 1.2157820463180542\n",
      "\tGenerator loss: 1.0754358768463135, Discriminator loss: 1.2695622444152832\n",
      "\tGenerator loss: 1.1922633647918701, Discriminator loss: 1.3729839324951172\n",
      "\tGenerator loss: 1.1104786396026611, Discriminator loss: 1.3164936304092407\n",
      "\tGenerator loss: 1.0024874210357666, Discriminator loss: 1.4094233512878418\n",
      "\tGenerator loss: 0.8896329998970032, Discriminator loss: 1.3289730548858643\n",
      "\tGenerator loss: 0.8548954725265503, Discriminator loss: 1.293361783027649\n",
      "\tGenerator loss: 0.9843698143959045, Discriminator loss: 1.3038406372070312\n",
      "\tGenerator loss: 1.1757149696350098, Discriminator loss: 1.2391183376312256\n",
      "\tGenerator loss: 1.25230073928833, Discriminator loss: 1.2317991256713867\n",
      "\tGenerator loss: 1.151046872138977, Discriminator loss: 1.2146143913269043\n",
      "\tGenerator loss: 1.0343103408813477, Discriminator loss: 1.1945271492004395\n",
      "\tGenerator loss: 0.9419759511947632, Discriminator loss: 1.2520997524261475\n",
      "\tGenerator loss: 0.9386593103408813, Discriminator loss: 1.195516586303711\n",
      "\tGenerator loss: 1.0830144882202148, Discriminator loss: 1.1118322610855103\n",
      "\tGenerator loss: 1.2181156873703003, Discriminator loss: 1.0982789993286133\n",
      "\tGenerator loss: 1.36479914188385, Discriminator loss: 1.1127694845199585\n",
      "\tGenerator loss: 1.3087847232818604, Discriminator loss: 1.1988394260406494\n",
      "\tGenerator loss: 1.1351405382156372, Discriminator loss: 1.239145278930664\n",
      "\tGenerator loss: 1.0054539442062378, Discriminator loss: 1.2560665607452393\n",
      "\tGenerator loss: 0.9508432149887085, Discriminator loss: 1.1814309358596802\n",
      "\tGenerator loss: 1.0095796585083008, Discriminator loss: 1.1506086587905884\n",
      "\tGenerator loss: 1.1818610429763794, Discriminator loss: 1.1757690906524658\n",
      "\tGenerator loss: 1.3357751369476318, Discriminator loss: 1.0700137615203857\n",
      "\tGenerator loss: 1.35121750831604, Discriminator loss: 1.1267733573913574\n",
      "\tGenerator loss: 1.2515027523040771, Discriminator loss: 1.1151052713394165\n",
      "\tGenerator loss: 1.0533370971679688, Discriminator loss: 1.0902986526489258\n",
      "\tGenerator loss: 0.997360110282898, Discriminator loss: 1.1124337911605835\n",
      "\tGenerator loss: 1.018855094909668, Discriminator loss: 1.1098823547363281\n",
      "\tGenerator loss: 1.143646478652954, Discriminator loss: 1.0452361106872559\n",
      "\tGenerator loss: 1.3106647729873657, Discriminator loss: 1.0609322786331177\n",
      "\tGenerator loss: 1.3847014904022217, Discriminator loss: 1.0668737888336182\n",
      "\tGenerator loss: 1.277017593383789, Discriminator loss: 1.029808759689331\n",
      "\tGenerator loss: 1.1567096710205078, Discriminator loss: 1.0391004085540771\n",
      "\tGenerator loss: 1.0959206819534302, Discriminator loss: 1.0891543626785278\n",
      "\tGenerator loss: 1.075415849685669, Discriminator loss: 1.0420845746994019\n",
      "\tGenerator loss: 1.1864725351333618, Discriminator loss: 0.9695731401443481\n",
      "\tGenerator loss: 1.3446035385131836, Discriminator loss: 1.0151028633117676\n",
      "\tGenerator loss: 1.4221322536468506, Discriminator loss: 0.9957218170166016\n",
      "\tGenerator loss: 1.3926230669021606, Discriminator loss: 1.0352871417999268\n",
      "\tGenerator loss: 1.2865551710128784, Discriminator loss: 1.0441296100616455\n",
      "\tGenerator loss: 1.1322400569915771, Discriminator loss: 1.015952706336975\n",
      "\tGenerator loss: 1.0382355451583862, Discriminator loss: 1.0389032363891602\n",
      "\tGenerator loss: 1.0356762409210205, Discriminator loss: 1.1000877618789673\n",
      "\tGenerator loss: 1.1527448892593384, Discriminator loss: 1.0858982801437378\n",
      "\tGenerator loss: 1.3221601247787476, Discriminator loss: 1.073195457458496\n",
      "\tGenerator loss: 1.3616821765899658, Discriminator loss: 1.0363943576812744\n",
      "\tGenerator loss: 1.2893288135528564, Discriminator loss: 1.008082628250122\n",
      "\tGenerator loss: 1.2053701877593994, Discriminator loss: 1.0936685800552368\n",
      "\tGenerator loss: 1.0900527238845825, Discriminator loss: 1.070712924003601\n",
      "\tGenerator loss: 1.0503532886505127, Discriminator loss: 1.0575875043869019\n",
      "\tGenerator loss: 1.0991848707199097, Discriminator loss: 1.0626912117004395\n",
      "\tGenerator loss: 1.185078501701355, Discriminator loss: 1.0789375305175781\n",
      "\tGenerator loss: 1.319425106048584, Discriminator loss: 1.0624336004257202\n",
      "\tGenerator loss: 1.3163193464279175, Discriminator loss: 1.0524578094482422\n",
      "\tGenerator loss: 1.2877752780914307, Discriminator loss: 1.0472095012664795\n",
      "\tGenerator loss: 1.1659115552902222, Discriminator loss: 1.0793267488479614\n",
      "\tGenerator loss: 1.0852959156036377, Discriminator loss: 1.0716382265090942\n",
      "\tGenerator loss: 1.025108814239502, Discriminator loss: 1.0905778408050537\n",
      "\tGenerator loss: 1.0582633018493652, Discriminator loss: 1.036206841468811\n",
      "\tGenerator loss: 1.0956461429595947, Discriminator loss: 1.0523487329483032\n",
      "\tGenerator loss: 1.1885451078414917, Discriminator loss: 1.1211658716201782\n",
      "\tGenerator loss: 1.2669758796691895, Discriminator loss: 1.1196246147155762\n",
      "\tGenerator loss: 1.2365707159042358, Discriminator loss: 1.1294268369674683\n",
      "\tGenerator loss: 1.158074140548706, Discriminator loss: 1.116706132888794\n",
      "\tGenerator loss: 1.0704500675201416, Discriminator loss: 1.0649291276931763\n",
      "\tGenerator loss: 1.0321505069732666, Discriminator loss: 1.1044747829437256\n",
      "\tGenerator loss: 1.035933494567871, Discriminator loss: 1.063058853149414\n",
      "\tGenerator loss: 1.1123149394989014, Discriminator loss: 1.0604006052017212\n",
      "\tGenerator loss: 1.1468350887298584, Discriminator loss: 1.0797340869903564\n",
      "\tGenerator loss: 1.255118489265442, Discriminator loss: 1.1119184494018555\n",
      "\tGenerator loss: 1.268169641494751, Discriminator loss: 1.1235144138336182\n",
      "\tGenerator loss: 1.1980724334716797, Discriminator loss: 1.1354364156723022\n",
      "\tGenerator loss: 1.071675419807434, Discriminator loss: 1.121497392654419\n",
      "\tGenerator loss: 1.004112958908081, Discriminator loss: 1.1442497968673706\n",
      "\tGenerator loss: 1.014019250869751, Discriminator loss: 1.1279137134552002\n",
      "\tGenerator loss: 1.0966062545776367, Discriminator loss: 1.0730328559875488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1811764240264893, Discriminator loss: 1.0628929138183594\n",
      "\tGenerator loss: 1.2771177291870117, Discriminator loss: 1.1289809942245483\n",
      "\tGenerator loss: 1.3174538612365723, Discriminator loss: 1.091071367263794\n",
      "\tGenerator loss: 1.2427338361740112, Discriminator loss: 1.0578763484954834\n",
      "\tGenerator loss: 1.1865153312683105, Discriminator loss: 1.0280953645706177\n",
      "\tGenerator loss: 1.120314121246338, Discriminator loss: 1.0413289070129395\n",
      "\tGenerator loss: 1.1209791898727417, Discriminator loss: 1.068224310874939\n",
      "\tGenerator loss: 1.138899564743042, Discriminator loss: 1.01749849319458\n",
      "\tGenerator loss: 1.1531428098678589, Discriminator loss: 1.05501389503479\n",
      "\tGenerator loss: 1.2030553817749023, Discriminator loss: 1.086639642715454\n",
      "\tGenerator loss: 1.230579137802124, Discriminator loss: 1.1179600954055786\n",
      "\tGenerator loss: 1.2003521919250488, Discriminator loss: 1.0812690258026123\n",
      "\tGenerator loss: 1.179525375366211, Discriminator loss: 1.0962011814117432\n",
      "\tGenerator loss: 1.176957130432129, Discriminator loss: 1.0951099395751953\n",
      "\tGenerator loss: 1.162558913230896, Discriminator loss: 1.1040878295898438\n",
      "\tGenerator loss: 1.162427306175232, Discriminator loss: 1.1137455701828003\n",
      "\tGenerator loss: 1.1757633686065674, Discriminator loss: 1.1496477127075195\n",
      "\tGenerator loss: 1.1537649631500244, Discriminator loss: 1.2026870250701904\n",
      "\tGenerator loss: 1.1445810794830322, Discriminator loss: 1.2646007537841797\n",
      "\tGenerator loss: 1.1283884048461914, Discriminator loss: 1.3332748413085938\n",
      "\tGenerator loss: 1.0793449878692627, Discriminator loss: 1.2834885120391846\n",
      "\tGenerator loss: 1.0622780323028564, Discriminator loss: 1.2654157876968384\n",
      "\tGenerator loss: 1.1328930854797363, Discriminator loss: 1.1665184497833252\n",
      "\tGenerator loss: 1.156297206878662, Discriminator loss: 1.122054934501648\n",
      "\tGenerator loss: 1.2327094078063965, Discriminator loss: 1.0604053735733032\n",
      "\tGenerator loss: 1.2395018339157104, Discriminator loss: 1.0681383609771729\n",
      "\tGenerator loss: 1.2231335639953613, Discriminator loss: 1.1092394590377808\n",
      "\tGenerator loss: 1.1457403898239136, Discriminator loss: 1.1088612079620361\n",
      "\tGenerator loss: 1.0628643035888672, Discriminator loss: 1.094599723815918\n",
      "\tGenerator loss: 1.0707751512527466, Discriminator loss: 1.2188726663589478\n",
      "\tGenerator loss: 1.1184215545654297, Discriminator loss: 1.171142339706421\n",
      "\tGenerator loss: 1.1905395984649658, Discriminator loss: 1.1389272212982178\n",
      "\tGenerator loss: 1.228959560394287, Discriminator loss: 1.0560117959976196\n",
      "\tGenerator loss: 1.2007954120635986, Discriminator loss: 1.0590155124664307\n",
      "\tGenerator loss: 1.1916762590408325, Discriminator loss: 1.038463830947876\n",
      "\tGenerator loss: 1.1719036102294922, Discriminator loss: 1.0856311321258545\n",
      "\tGenerator loss: 1.128854513168335, Discriminator loss: 1.0488845109939575\n",
      "\tGenerator loss: 1.14035165309906, Discriminator loss: 1.0486364364624023\n",
      "\tGenerator loss: 1.159142017364502, Discriminator loss: 1.0753259658813477\n",
      "\tGenerator loss: 1.1793129444122314, Discriminator loss: 1.0615546703338623\n",
      "\tGenerator loss: 1.2878029346466064, Discriminator loss: 0.9909846782684326\n",
      "\tGenerator loss: 1.2896475791931152, Discriminator loss: 0.9790658950805664\n",
      "\tGenerator loss: 1.2664390802383423, Discriminator loss: 0.9852074980735779\n",
      "\tGenerator loss: 1.2181763648986816, Discriminator loss: 1.0583592653274536\n",
      "\tGenerator loss: 1.2006863355636597, Discriminator loss: 1.066462755203247\n",
      "\tGenerator loss: 1.1309411525726318, Discriminator loss: 1.0309114456176758\n",
      "\tGenerator loss: 1.1491212844848633, Discriminator loss: 1.0409982204437256\n",
      "\tGenerator loss: 1.1914128065109253, Discriminator loss: 1.0686008930206299\n",
      "\tGenerator loss: 1.221781611442566, Discriminator loss: 1.0877618789672852\n",
      "\tGenerator loss: 1.2575366497039795, Discriminator loss: 1.058624505996704\n",
      "\tGenerator loss: 1.2460741996765137, Discriminator loss: 1.052152395248413\n",
      "\tGenerator loss: 1.2110753059387207, Discriminator loss: 1.0791046619415283\n",
      "\tGenerator loss: 1.1109521389007568, Discriminator loss: 1.0906016826629639\n",
      "\tGenerator loss: 1.1249055862426758, Discriminator loss: 1.077574372291565\n",
      "\tGenerator loss: 1.163840413093567, Discriminator loss: 1.0736658573150635\n",
      "\tGenerator loss: 1.191595196723938, Discriminator loss: 1.0033295154571533\n",
      "\tGenerator loss: 1.2403883934020996, Discriminator loss: 1.0506747961044312\n",
      "\tGenerator loss: 1.2060034275054932, Discriminator loss: 1.1154019832611084\n",
      "\tGenerator loss: 1.129537582397461, Discriminator loss: 1.0575679540634155\n",
      "\tGenerator loss: 1.1033151149749756, Discriminator loss: 1.0572230815887451\n",
      "\tGenerator loss: 1.1602044105529785, Discriminator loss: 1.0506805181503296\n",
      "\tGenerator loss: 1.2029603719711304, Discriminator loss: 0.9931396245956421\n",
      "\tGenerator loss: 1.2429487705230713, Discriminator loss: 0.9858771562576294\n",
      "\tGenerator loss: 1.2532250881195068, Discriminator loss: 1.011920690536499\n",
      "\tGenerator loss: 1.292446494102478, Discriminator loss: 1.0381990671157837\n",
      "\tGenerator loss: 1.276913046836853, Discriminator loss: 1.1032867431640625\n",
      "Time for epoch 28 is 225.27778816223145 sec\n",
      "\tGenerator loss: 1.1558204889297485, Discriminator loss: 1.1282646656036377\n",
      "\tGenerator loss: 1.0269145965576172, Discriminator loss: 1.1452341079711914\n",
      "\tGenerator loss: 0.9674215316772461, Discriminator loss: 1.1264749765396118\n",
      "\tGenerator loss: 1.011470079421997, Discriminator loss: 1.1190998554229736\n",
      "\tGenerator loss: 1.1100226640701294, Discriminator loss: 1.1709885597229004\n",
      "\tGenerator loss: 1.1786627769470215, Discriminator loss: 1.1230697631835938\n",
      "\tGenerator loss: 1.2329225540161133, Discriminator loss: 1.1328027248382568\n",
      "\tGenerator loss: 1.208707332611084, Discriminator loss: 1.1310069561004639\n",
      "\tGenerator loss: 1.123220443725586, Discriminator loss: 1.1462790966033936\n",
      "\tGenerator loss: 1.0335628986358643, Discriminator loss: 1.1118268966674805\n",
      "\tGenerator loss: 1.0055501461029053, Discriminator loss: 1.1122748851776123\n",
      "\tGenerator loss: 1.0617436170578003, Discriminator loss: 1.135586142539978\n",
      "\tGenerator loss: 1.1541428565979004, Discriminator loss: 1.1642587184906006\n",
      "\tGenerator loss: 1.1600240468978882, Discriminator loss: 1.126676321029663\n",
      "\tGenerator loss: 1.1397266387939453, Discriminator loss: 1.1152771711349487\n",
      "\tGenerator loss: 1.1193492412567139, Discriminator loss: 1.1496717929840088\n",
      "\tGenerator loss: 1.0776991844177246, Discriminator loss: 1.1479108333587646\n",
      "\tGenerator loss: 1.0366458892822266, Discriminator loss: 1.1541465520858765\n",
      "\tGenerator loss: 1.0556756258010864, Discriminator loss: 1.1200933456420898\n",
      "\tGenerator loss: 1.1033153533935547, Discriminator loss: 1.1080350875854492\n",
      "\tGenerator loss: 1.1463589668273926, Discriminator loss: 1.0843361616134644\n",
      "\tGenerator loss: 1.1329618692398071, Discriminator loss: 1.162585735321045\n",
      "\tGenerator loss: 1.1177951097488403, Discriminator loss: 1.1414306163787842\n",
      "\tGenerator loss: 1.0982675552368164, Discriminator loss: 1.1590921878814697\n",
      "\tGenerator loss: 1.105205774307251, Discriminator loss: 1.1349101066589355\n",
      "\tGenerator loss: 1.092756986618042, Discriminator loss: 1.156445026397705\n",
      "\tGenerator loss: 1.0848889350891113, Discriminator loss: 1.1755667924880981\n",
      "\tGenerator loss: 1.0846563577651978, Discriminator loss: 1.1275790929794312\n",
      "\tGenerator loss: 1.063516616821289, Discriminator loss: 1.1845107078552246\n",
      "\tGenerator loss: 1.0380024909973145, Discriminator loss: 1.1471552848815918\n",
      "\tGenerator loss: 1.070993185043335, Discriminator loss: 1.1214817762374878\n",
      "\tGenerator loss: 1.0420315265655518, Discriminator loss: 1.1444427967071533\n",
      "\tGenerator loss: 1.0749852657318115, Discriminator loss: 1.1027274131774902\n",
      "\tGenerator loss: 1.0851893424987793, Discriminator loss: 1.155660629272461\n",
      "\tGenerator loss: 1.1365966796875, Discriminator loss: 1.1434270143508911\n",
      "\tGenerator loss: 1.1660550832748413, Discriminator loss: 1.1226005554199219\n",
      "\tGenerator loss: 1.1760880947113037, Discriminator loss: 1.1308236122131348\n",
      "\tGenerator loss: 1.1038432121276855, Discriminator loss: 1.1070505380630493\n",
      "\tGenerator loss: 1.1191794872283936, Discriminator loss: 1.0372061729431152\n",
      "\tGenerator loss: 1.0920405387878418, Discriminator loss: 1.1029447317123413\n",
      "\tGenerator loss: 1.122799038887024, Discriminator loss: 1.1409186124801636\n",
      "\tGenerator loss: 1.1952028274536133, Discriminator loss: 1.0937614440917969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2046610116958618, Discriminator loss: 1.147467017173767\n",
      "\tGenerator loss: 1.2068634033203125, Discriminator loss: 1.1489064693450928\n",
      "\tGenerator loss: 1.1715153455734253, Discriminator loss: 1.129153847694397\n",
      "\tGenerator loss: 1.1093316078186035, Discriminator loss: 1.1369755268096924\n",
      "\tGenerator loss: 1.0755982398986816, Discriminator loss: 1.144437313079834\n",
      "\tGenerator loss: 1.0638015270233154, Discriminator loss: 1.1821895837783813\n",
      "\tGenerator loss: 1.0541012287139893, Discriminator loss: 1.1615264415740967\n",
      "\tGenerator loss: 1.0901763439178467, Discriminator loss: 1.1223117113113403\n",
      "\tGenerator loss: 1.1657482385635376, Discriminator loss: 1.1252613067626953\n",
      "\tGenerator loss: 1.2333588600158691, Discriminator loss: 1.156781792640686\n",
      "\tGenerator loss: 1.1990149021148682, Discriminator loss: 1.1179463863372803\n",
      "\tGenerator loss: 1.1896679401397705, Discriminator loss: 1.1067426204681396\n",
      "\tGenerator loss: 1.1457576751708984, Discriminator loss: 1.0690661668777466\n",
      "\tGenerator loss: 1.1321258544921875, Discriminator loss: 1.1127533912658691\n",
      "\tGenerator loss: 1.0919837951660156, Discriminator loss: 1.1158784627914429\n",
      "\tGenerator loss: 1.0890514850616455, Discriminator loss: 1.0603290796279907\n",
      "\tGenerator loss: 1.135850429534912, Discriminator loss: 1.0373973846435547\n",
      "\tGenerator loss: 1.1968518495559692, Discriminator loss: 1.0230653285980225\n",
      "\tGenerator loss: 1.2497835159301758, Discriminator loss: 1.0176204442977905\n",
      "\tGenerator loss: 1.2113522291183472, Discriminator loss: 0.988564670085907\n",
      "\tGenerator loss: 1.1411033868789673, Discriminator loss: 1.1387256383895874\n",
      "\tGenerator loss: 1.0685083866119385, Discriminator loss: 1.1791048049926758\n",
      "\tGenerator loss: 1.040656328201294, Discriminator loss: 1.1176135540008545\n",
      "\tGenerator loss: 1.0447274446487427, Discriminator loss: 1.0717902183532715\n",
      "\tGenerator loss: 1.07735276222229, Discriminator loss: 1.1628847122192383\n",
      "\tGenerator loss: 1.175962209701538, Discriminator loss: 1.1291530132293701\n",
      "\tGenerator loss: 1.188058614730835, Discriminator loss: 1.151850700378418\n",
      "\tGenerator loss: 1.1576594114303589, Discriminator loss: 1.118730068206787\n",
      "\tGenerator loss: 1.1025269031524658, Discriminator loss: 1.1300379037857056\n",
      "\tGenerator loss: 1.093340277671814, Discriminator loss: 1.1504051685333252\n",
      "\tGenerator loss: 1.0311992168426514, Discriminator loss: 1.1282234191894531\n",
      "\tGenerator loss: 1.0295300483703613, Discriminator loss: 1.1300379037857056\n",
      "\tGenerator loss: 1.1070445775985718, Discriminator loss: 1.0980448722839355\n",
      "\tGenerator loss: 1.1578328609466553, Discriminator loss: 1.160075306892395\n",
      "\tGenerator loss: 1.1749833822250366, Discriminator loss: 1.2713768482208252\n",
      "\tGenerator loss: 1.1673378944396973, Discriminator loss: 1.1784069538116455\n",
      "\tGenerator loss: 1.1119906902313232, Discriminator loss: 1.1350551843643188\n",
      "\tGenerator loss: 1.0950311422348022, Discriminator loss: 1.1381680965423584\n",
      "\tGenerator loss: 1.0932343006134033, Discriminator loss: 1.1502273082733154\n",
      "\tGenerator loss: 1.0940637588500977, Discriminator loss: 1.141956090927124\n",
      "\tGenerator loss: 1.115123987197876, Discriminator loss: 1.0861870050430298\n",
      "\tGenerator loss: 1.1659890413284302, Discriminator loss: 1.08329439163208\n",
      "\tGenerator loss: 1.1774263381958008, Discriminator loss: 1.0460397005081177\n",
      "\tGenerator loss: 1.1597621440887451, Discriminator loss: 1.1314337253570557\n",
      "\tGenerator loss: 1.1429364681243896, Discriminator loss: 1.0241492986679077\n",
      "\tGenerator loss: 1.1729239225387573, Discriminator loss: 1.0791425704956055\n",
      "\tGenerator loss: 1.1559377908706665, Discriminator loss: 1.133765459060669\n",
      "\tGenerator loss: 1.1095421314239502, Discriminator loss: 1.1425689458847046\n",
      "\tGenerator loss: 1.1126930713653564, Discriminator loss: 1.1237497329711914\n",
      "\tGenerator loss: 1.1257508993148804, Discriminator loss: 1.048839807510376\n",
      "\tGenerator loss: 1.164602279663086, Discriminator loss: 1.015402913093567\n",
      "\tGenerator loss: 1.2547798156738281, Discriminator loss: 1.045039415359497\n",
      "\tGenerator loss: 1.2294814586639404, Discriminator loss: 1.0698347091674805\n",
      "\tGenerator loss: 1.1787797212600708, Discriminator loss: 1.0419654846191406\n",
      "\tGenerator loss: 1.1606085300445557, Discriminator loss: 1.0497870445251465\n",
      "\tGenerator loss: 1.1058473587036133, Discriminator loss: 1.03230881690979\n",
      "\tGenerator loss: 1.1040887832641602, Discriminator loss: 1.0156338214874268\n",
      "\tGenerator loss: 1.1681251525878906, Discriminator loss: 1.000000238418579\n",
      "\tGenerator loss: 1.2833216190338135, Discriminator loss: 0.982383131980896\n",
      "\tGenerator loss: 1.3776261806488037, Discriminator loss: 0.97843337059021\n",
      "\tGenerator loss: 1.3111364841461182, Discriminator loss: 0.9850928783416748\n",
      "\tGenerator loss: 1.1913821697235107, Discriminator loss: 1.0036866664886475\n",
      "\tGenerator loss: 1.080898642539978, Discriminator loss: 1.0029354095458984\n",
      "\tGenerator loss: 1.068436622619629, Discriminator loss: 0.9815319180488586\n",
      "\tGenerator loss: 1.148059606552124, Discriminator loss: 0.9430863857269287\n",
      "\tGenerator loss: 1.2931392192840576, Discriminator loss: 0.9460339546203613\n",
      "\tGenerator loss: 1.4224753379821777, Discriminator loss: 0.9858784675598145\n",
      "\tGenerator loss: 1.3486045598983765, Discriminator loss: 0.961344301700592\n",
      "\tGenerator loss: 1.2457101345062256, Discriminator loss: 0.9987461566925049\n",
      "\tGenerator loss: 1.1513760089874268, Discriminator loss: 1.0148199796676636\n",
      "\tGenerator loss: 1.136347770690918, Discriminator loss: 0.9771205186843872\n",
      "\tGenerator loss: 1.1540032625198364, Discriminator loss: 1.0012447834014893\n",
      "\tGenerator loss: 1.162743091583252, Discriminator loss: 1.015448808670044\n",
      "\tGenerator loss: 1.187560796737671, Discriminator loss: 0.9632493257522583\n",
      "\tGenerator loss: 1.234300136566162, Discriminator loss: 1.0336143970489502\n",
      "\tGenerator loss: 1.190028190612793, Discriminator loss: 1.0415527820587158\n",
      "\tGenerator loss: 1.123124599456787, Discriminator loss: 0.9877405762672424\n",
      "\tGenerator loss: 1.066565752029419, Discriminator loss: 1.0317682027816772\n",
      "\tGenerator loss: 1.073817253112793, Discriminator loss: 0.9764012098312378\n",
      "\tGenerator loss: 1.1293816566467285, Discriminator loss: 0.9374483823776245\n",
      "\tGenerator loss: 1.1572896242141724, Discriminator loss: 0.9764828681945801\n",
      "\tGenerator loss: 1.219691276550293, Discriminator loss: 0.9936668276786804\n",
      "\tGenerator loss: 1.2323731184005737, Discriminator loss: 0.9560873508453369\n",
      "\tGenerator loss: 1.2754480838775635, Discriminator loss: 0.9770216941833496\n",
      "\tGenerator loss: 1.1857757568359375, Discriminator loss: 1.0355337858200073\n",
      "\tGenerator loss: 1.1544760465621948, Discriminator loss: 0.9856796860694885\n",
      "\tGenerator loss: 1.0986716747283936, Discriminator loss: 0.944990873336792\n",
      "\tGenerator loss: 1.0914649963378906, Discriminator loss: 1.000412940979004\n",
      "\tGenerator loss: 1.132676124572754, Discriminator loss: 0.9806861877441406\n",
      "\tGenerator loss: 1.2420791387557983, Discriminator loss: 0.9754663705825806\n",
      "\tGenerator loss: 1.246779203414917, Discriminator loss: 0.9937404990196228\n",
      "\tGenerator loss: 1.2600786685943604, Discriminator loss: 0.9543197154998779\n",
      "\tGenerator loss: 1.2000937461853027, Discriminator loss: 0.9641983509063721\n",
      "\tGenerator loss: 1.1352992057800293, Discriminator loss: 1.0368874073028564\n",
      "\tGenerator loss: 1.1122725009918213, Discriminator loss: 1.0173869132995605\n",
      "\tGenerator loss: 1.121555209159851, Discriminator loss: 0.978011965751648\n",
      "\tGenerator loss: 1.1486358642578125, Discriminator loss: 0.9978453516960144\n",
      "\tGenerator loss: 1.2138363122940063, Discriminator loss: 0.974969744682312\n",
      "\tGenerator loss: 1.2474274635314941, Discriminator loss: 0.9700618982315063\n",
      "\tGenerator loss: 1.218851089477539, Discriminator loss: 1.046152114868164\n",
      "\tGenerator loss: 1.1517741680145264, Discriminator loss: 1.0620441436767578\n",
      "\tGenerator loss: 1.1562891006469727, Discriminator loss: 1.108454704284668\n",
      "\tGenerator loss: 1.1287760734558105, Discriminator loss: 1.1060097217559814\n",
      "\tGenerator loss: 1.1178209781646729, Discriminator loss: 1.1521389484405518\n",
      "\tGenerator loss: 1.111919641494751, Discriminator loss: 1.0975236892700195\n",
      "\tGenerator loss: 1.1243083477020264, Discriminator loss: 1.0673420429229736\n",
      "\tGenerator loss: 1.166406273841858, Discriminator loss: 1.0500189065933228\n",
      "\tGenerator loss: 1.1697683334350586, Discriminator loss: 1.0413755178451538\n",
      "\tGenerator loss: 1.177134394645691, Discriminator loss: 1.0557093620300293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1745001077651978, Discriminator loss: 1.0329010486602783\n",
      "\tGenerator loss: 1.1585783958435059, Discriminator loss: 1.0401968955993652\n",
      "\tGenerator loss: 1.1815615892410278, Discriminator loss: 1.1278581619262695\n",
      "\tGenerator loss: 1.101337194442749, Discriminator loss: 1.203019380569458\n",
      "\tGenerator loss: 1.049466848373413, Discriminator loss: 1.1519356966018677\n",
      "\tGenerator loss: 0.9830770492553711, Discriminator loss: 1.1981675624847412\n",
      "\tGenerator loss: 1.0235058069229126, Discriminator loss: 1.151309609413147\n",
      "\tGenerator loss: 1.092403531074524, Discriminator loss: 1.2067558765411377\n",
      "\tGenerator loss: 1.151705265045166, Discriminator loss: 1.1426852941513062\n",
      "\tGenerator loss: 1.1620686054229736, Discriminator loss: 1.1396416425704956\n",
      "\tGenerator loss: 1.1373648643493652, Discriminator loss: 1.1714603900909424\n",
      "\tGenerator loss: 1.0848783254623413, Discriminator loss: 1.2101935148239136\n",
      "\tGenerator loss: 1.000113844871521, Discriminator loss: 1.262451410293579\n",
      "\tGenerator loss: 0.9262853860855103, Discriminator loss: 1.359614610671997\n",
      "\tGenerator loss: 0.9698992967605591, Discriminator loss: 1.2712074518203735\n",
      "\tGenerator loss: 0.9953171610832214, Discriminator loss: 1.3256945610046387\n",
      "\tGenerator loss: 1.0089468955993652, Discriminator loss: 1.2841784954071045\n",
      "\tGenerator loss: 1.0465768575668335, Discriminator loss: 1.2906314134597778\n",
      "\tGenerator loss: 1.1115388870239258, Discriminator loss: 1.2327985763549805\n",
      "\tGenerator loss: 1.0733546018600464, Discriminator loss: 1.2865736484527588\n",
      "\tGenerator loss: 0.983840823173523, Discriminator loss: 1.2383142709732056\n",
      "\tGenerator loss: 0.9189834594726562, Discriminator loss: 1.2234246730804443\n",
      "\tGenerator loss: 0.9602938890457153, Discriminator loss: 1.2149968147277832\n",
      "\tGenerator loss: 1.026195764541626, Discriminator loss: 1.2137529850006104\n",
      "\tGenerator loss: 1.1256071329116821, Discriminator loss: 1.2478703260421753\n",
      "\tGenerator loss: 1.1387174129486084, Discriminator loss: 1.2077763080596924\n",
      "\tGenerator loss: 1.0695500373840332, Discriminator loss: 1.2009588479995728\n",
      "\tGenerator loss: 1.018885850906372, Discriminator loss: 1.2361071109771729\n",
      "\tGenerator loss: 0.965191125869751, Discriminator loss: 1.2862673997879028\n",
      "\tGenerator loss: 0.9646586179733276, Discriminator loss: 1.238608717918396\n",
      "\tGenerator loss: 0.9855882525444031, Discriminator loss: 1.2285960912704468\n",
      "\tGenerator loss: 1.019150733947754, Discriminator loss: 1.249889850616455\n",
      "\tGenerator loss: 1.0861687660217285, Discriminator loss: 1.209037184715271\n",
      "\tGenerator loss: 1.0787482261657715, Discriminator loss: 1.2841911315917969\n",
      "\tGenerator loss: 1.0406571626663208, Discriminator loss: 1.2964965105056763\n",
      "\tGenerator loss: 0.9768991470336914, Discriminator loss: 1.3204004764556885\n",
      "\tGenerator loss: 0.9634994864463806, Discriminator loss: 1.3450562953948975\n",
      "\tGenerator loss: 0.9509586095809937, Discriminator loss: 1.4089843034744263\n",
      "\tGenerator loss: 0.9944429993629456, Discriminator loss: 1.3696919679641724\n",
      "\tGenerator loss: 1.0421456098556519, Discriminator loss: 1.322204828262329\n",
      "\tGenerator loss: 1.0272564888000488, Discriminator loss: 1.3224506378173828\n",
      "\tGenerator loss: 1.0161725282669067, Discriminator loss: 1.245567798614502\n",
      "\tGenerator loss: 1.0150591135025024, Discriminator loss: 1.200911283493042\n",
      "\tGenerator loss: 1.0367989540100098, Discriminator loss: 1.191645622253418\n",
      "\tGenerator loss: 1.055774450302124, Discriminator loss: 1.217520833015442\n",
      "\tGenerator loss: 1.0649266242980957, Discriminator loss: 1.1874141693115234\n",
      "\tGenerator loss: 1.063310146331787, Discriminator loss: 1.1465816497802734\n",
      "\tGenerator loss: 1.0443775653839111, Discriminator loss: 1.1943626403808594\n",
      "\tGenerator loss: 1.031768798828125, Discriminator loss: 1.1750702857971191\n",
      "\tGenerator loss: 1.0743426084518433, Discriminator loss: 1.1669766902923584\n",
      "\tGenerator loss: 1.1165013313293457, Discriminator loss: 1.1070191860198975\n",
      "\tGenerator loss: 1.1516573429107666, Discriminator loss: 1.1322814226150513\n",
      "\tGenerator loss: 1.1398855447769165, Discriminator loss: 1.1911773681640625\n",
      "\tGenerator loss: 1.051943302154541, Discriminator loss: 1.1694903373718262\n",
      "\tGenerator loss: 0.9793398380279541, Discriminator loss: 1.1402385234832764\n",
      "\tGenerator loss: 0.985634446144104, Discriminator loss: 1.1199378967285156\n",
      "\tGenerator loss: 1.0233910083770752, Discriminator loss: 1.1293411254882812\n",
      "\tGenerator loss: 1.1771526336669922, Discriminator loss: 1.0951998233795166\n",
      "\tGenerator loss: 1.2675292491912842, Discriminator loss: 1.1070806980133057\n",
      "\tGenerator loss: 1.2623262405395508, Discriminator loss: 1.079310417175293\n",
      "\tGenerator loss: 1.1469227075576782, Discriminator loss: 1.0920206308364868\n",
      "\tGenerator loss: 1.0149660110473633, Discriminator loss: 1.130448341369629\n",
      "\tGenerator loss: 0.9895493984222412, Discriminator loss: 1.111039638519287\n",
      "\tGenerator loss: 1.039722204208374, Discriminator loss: 1.0977833271026611\n",
      "\tGenerator loss: 1.1435115337371826, Discriminator loss: 1.0810611248016357\n",
      "\tGenerator loss: 1.1895365715026855, Discriminator loss: 1.1039735078811646\n",
      "\tGenerator loss: 1.183408498764038, Discriminator loss: 1.1167654991149902\n",
      "\tGenerator loss: 1.1466559171676636, Discriminator loss: 1.1018445491790771\n",
      "\tGenerator loss: 1.1402432918548584, Discriminator loss: 1.0762922763824463\n",
      "\tGenerator loss: 1.0677653551101685, Discriminator loss: 1.1240744590759277\n",
      "\tGenerator loss: 1.0149948596954346, Discriminator loss: 1.1321035623550415\n",
      "\tGenerator loss: 1.054222583770752, Discriminator loss: 1.118985652923584\n",
      "\tGenerator loss: 1.0487592220306396, Discriminator loss: 1.1317903995513916\n",
      "\tGenerator loss: 1.160512924194336, Discriminator loss: 1.0775642395019531\n",
      "\tGenerator loss: 1.182582139968872, Discriminator loss: 1.0921120643615723\n",
      "\tGenerator loss: 1.1633415222167969, Discriminator loss: 1.1121556758880615\n",
      "\tGenerator loss: 1.1291837692260742, Discriminator loss: 1.0523924827575684\n",
      "\tGenerator loss: 1.0822045803070068, Discriminator loss: 1.0662792921066284\n",
      "\tGenerator loss: 1.0913889408111572, Discriminator loss: 1.0395841598510742\n",
      "\tGenerator loss: 1.1194247007369995, Discriminator loss: 0.96087646484375\n",
      "\tGenerator loss: 1.2001049518585205, Discriminator loss: 1.0567197799682617\n",
      "\tGenerator loss: 1.2708450555801392, Discriminator loss: 1.0983963012695312\n",
      "\tGenerator loss: 1.2556452751159668, Discriminator loss: 1.106522798538208\n",
      "\tGenerator loss: 1.202683687210083, Discriminator loss: 1.1053612232208252\n",
      "Time for epoch 29 is 219.80702543258667 sec\n",
      "\tGenerator loss: 1.112271785736084, Discriminator loss: 1.0950443744659424\n",
      "\tGenerator loss: 1.0487560033798218, Discriminator loss: 1.087360143661499\n",
      "\tGenerator loss: 1.0253257751464844, Discriminator loss: 1.079576015472412\n",
      "\tGenerator loss: 1.047423243522644, Discriminator loss: 1.073500156402588\n",
      "\tGenerator loss: 1.1742527484893799, Discriminator loss: 1.1724486351013184\n",
      "\tGenerator loss: 1.222249984741211, Discriminator loss: 1.2032089233398438\n",
      "\tGenerator loss: 1.2192384004592896, Discriminator loss: 1.1316205263137817\n",
      "\tGenerator loss: 1.116544246673584, Discriminator loss: 1.2093291282653809\n",
      "\tGenerator loss: 1.008288860321045, Discriminator loss: 1.179168462753296\n",
      "\tGenerator loss: 0.9965511560440063, Discriminator loss: 1.1405775547027588\n",
      "\tGenerator loss: 1.052441120147705, Discriminator loss: 1.109349012374878\n",
      "\tGenerator loss: 1.1527687311172485, Discriminator loss: 1.1321663856506348\n",
      "\tGenerator loss: 1.2026982307434082, Discriminator loss: 1.146272897720337\n",
      "\tGenerator loss: 1.2010612487792969, Discriminator loss: 1.0827245712280273\n",
      "\tGenerator loss: 1.1346285343170166, Discriminator loss: 1.0996291637420654\n",
      "\tGenerator loss: 1.1045186519622803, Discriminator loss: 1.0946218967437744\n",
      "\tGenerator loss: 1.0404281616210938, Discriminator loss: 1.1117807626724243\n",
      "\tGenerator loss: 1.0391120910644531, Discriminator loss: 1.1084973812103271\n",
      "\tGenerator loss: 1.1480809450149536, Discriminator loss: 1.1337906122207642\n",
      "\tGenerator loss: 1.204770803451538, Discriminator loss: 1.1378523111343384\n",
      "\tGenerator loss: 1.1435983180999756, Discriminator loss: 1.1646853685379028\n",
      "\tGenerator loss: 1.0898025035858154, Discriminator loss: 1.2336149215698242\n",
      "\tGenerator loss: 1.019324541091919, Discriminator loss: 1.2434484958648682\n",
      "\tGenerator loss: 0.9971572160720825, Discriminator loss: 1.3001563549041748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0351696014404297, Discriminator loss: 1.280912160873413\n",
      "\tGenerator loss: 1.0861932039260864, Discriminator loss: 1.201977014541626\n",
      "\tGenerator loss: 1.0888830423355103, Discriminator loss: 1.1830427646636963\n",
      "\tGenerator loss: 1.058038353919983, Discriminator loss: 1.1644338369369507\n",
      "\tGenerator loss: 1.0506255626678467, Discriminator loss: 1.2090950012207031\n",
      "\tGenerator loss: 1.031538963317871, Discriminator loss: 1.1934289932250977\n",
      "\tGenerator loss: 1.0250213146209717, Discriminator loss: 1.2136039733886719\n",
      "\tGenerator loss: 1.0102282762527466, Discriminator loss: 1.2513437271118164\n",
      "\tGenerator loss: 1.0276103019714355, Discriminator loss: 1.2448424100875854\n",
      "\tGenerator loss: 1.0577439069747925, Discriminator loss: 1.3451213836669922\n",
      "\tGenerator loss: 1.0028221607208252, Discriminator loss: 1.3600530624389648\n",
      "\tGenerator loss: 0.9761422872543335, Discriminator loss: 1.3087987899780273\n",
      "\tGenerator loss: 0.9855836629867554, Discriminator loss: 1.286716341972351\n",
      "\tGenerator loss: 1.0050621032714844, Discriminator loss: 1.2633981704711914\n",
      "\tGenerator loss: 1.0550692081451416, Discriminator loss: 1.1967148780822754\n",
      "\tGenerator loss: 1.0612304210662842, Discriminator loss: 1.2385915517807007\n",
      "\tGenerator loss: 1.0525197982788086, Discriminator loss: 1.2903459072113037\n",
      "\tGenerator loss: 1.0408952236175537, Discriminator loss: 1.2596830129623413\n",
      "\tGenerator loss: 1.0621323585510254, Discriminator loss: 1.2684791088104248\n",
      "\tGenerator loss: 1.0462520122528076, Discriminator loss: 1.2610299587249756\n",
      "\tGenerator loss: 1.0212717056274414, Discriminator loss: 1.2505829334259033\n",
      "\tGenerator loss: 0.9922988414764404, Discriminator loss: 1.2697430849075317\n",
      "\tGenerator loss: 0.9855620265007019, Discriminator loss: 1.2753517627716064\n",
      "\tGenerator loss: 1.0092393159866333, Discriminator loss: 1.2778608798980713\n",
      "\tGenerator loss: 1.0152311325073242, Discriminator loss: 1.2436944246292114\n",
      "\tGenerator loss: 1.0393399000167847, Discriminator loss: 1.2025611400604248\n",
      "\tGenerator loss: 1.0884366035461426, Discriminator loss: 1.2156939506530762\n",
      "\tGenerator loss: 1.142492413520813, Discriminator loss: 1.1680903434753418\n",
      "\tGenerator loss: 1.1371641159057617, Discriminator loss: 1.1192212104797363\n",
      "\tGenerator loss: 1.051459550857544, Discriminator loss: 1.199042797088623\n",
      "\tGenerator loss: 1.0192995071411133, Discriminator loss: 1.176161289215088\n",
      "\tGenerator loss: 1.0607051849365234, Discriminator loss: 1.1391096115112305\n",
      "\tGenerator loss: 1.0907431840896606, Discriminator loss: 1.123747706413269\n",
      "\tGenerator loss: 1.1361956596374512, Discriminator loss: 1.0938003063201904\n",
      "\tGenerator loss: 1.1712939739227295, Discriminator loss: 1.0954935550689697\n",
      "\tGenerator loss: 1.1192915439605713, Discriminator loss: 1.1076492071151733\n",
      "\tGenerator loss: 1.0639225244522095, Discriminator loss: 1.1029127836227417\n",
      "\tGenerator loss: 1.0295841693878174, Discriminator loss: 1.0809524059295654\n",
      "\tGenerator loss: 1.0564532279968262, Discriminator loss: 1.111684799194336\n",
      "\tGenerator loss: 1.08311927318573, Discriminator loss: 1.0958178043365479\n",
      "\tGenerator loss: 1.1287565231323242, Discriminator loss: 1.0872646570205688\n",
      "\tGenerator loss: 1.1981019973754883, Discriminator loss: 1.0585647821426392\n",
      "\tGenerator loss: 1.161508321762085, Discriminator loss: 1.0831046104431152\n",
      "\tGenerator loss: 1.1145389080047607, Discriminator loss: 1.0431158542633057\n",
      "\tGenerator loss: 1.0595847368240356, Discriminator loss: 1.0693856477737427\n",
      "\tGenerator loss: 1.0576987266540527, Discriminator loss: 1.0734632015228271\n",
      "\tGenerator loss: 1.0469416379928589, Discriminator loss: 1.070066213607788\n",
      "\tGenerator loss: 1.0624723434448242, Discriminator loss: 1.1206319332122803\n",
      "\tGenerator loss: 1.1071269512176514, Discriminator loss: 1.0941717624664307\n",
      "\tGenerator loss: 1.1464505195617676, Discriminator loss: 1.094420313835144\n",
      "\tGenerator loss: 1.1403752565383911, Discriminator loss: 1.0676651000976562\n",
      "\tGenerator loss: 1.1071975231170654, Discriminator loss: 1.0465149879455566\n",
      "\tGenerator loss: 1.0691179037094116, Discriminator loss: 1.1002326011657715\n",
      "\tGenerator loss: 1.0709285736083984, Discriminator loss: 1.0728245973587036\n",
      "\tGenerator loss: 1.1384356021881104, Discriminator loss: 1.0603407621383667\n",
      "\tGenerator loss: 1.188659429550171, Discriminator loss: 1.0983521938323975\n",
      "\tGenerator loss: 1.2360756397247314, Discriminator loss: 1.0839000940322876\n",
      "\tGenerator loss: 1.1403207778930664, Discriminator loss: 1.0917942523956299\n",
      "\tGenerator loss: 1.0487151145935059, Discriminator loss: 1.1005370616912842\n",
      "\tGenerator loss: 0.9750939607620239, Discriminator loss: 1.1071157455444336\n",
      "\tGenerator loss: 0.9848381876945496, Discriminator loss: 1.1437755823135376\n",
      "\tGenerator loss: 1.0181432962417603, Discriminator loss: 1.1274256706237793\n",
      "\tGenerator loss: 1.1021479368209839, Discriminator loss: 1.0447715520858765\n",
      "\tGenerator loss: 1.1676275730133057, Discriminator loss: 1.0889019966125488\n",
      "\tGenerator loss: 1.1650779247283936, Discriminator loss: 1.1186244487762451\n",
      "\tGenerator loss: 1.149853229522705, Discriminator loss: 1.0854973793029785\n",
      "\tGenerator loss: 1.0609055757522583, Discriminator loss: 1.1250990629196167\n",
      "\tGenerator loss: 1.0018821954727173, Discriminator loss: 1.106172800064087\n",
      "\tGenerator loss: 1.00151789188385, Discriminator loss: 1.1128679513931274\n",
      "\tGenerator loss: 1.002631664276123, Discriminator loss: 1.1573498249053955\n",
      "\tGenerator loss: 1.0148742198944092, Discriminator loss: 1.1760021448135376\n",
      "\tGenerator loss: 1.0556024312973022, Discriminator loss: 1.0997226238250732\n",
      "\tGenerator loss: 1.0793652534484863, Discriminator loss: 1.1197787523269653\n",
      "\tGenerator loss: 1.0941717624664307, Discriminator loss: 1.0882089138031006\n",
      "\tGenerator loss: 1.0819950103759766, Discriminator loss: 1.0837551355361938\n",
      "\tGenerator loss: 1.0208617448806763, Discriminator loss: 1.1536571979522705\n",
      "\tGenerator loss: 1.0378658771514893, Discriminator loss: 1.1142734289169312\n",
      "\tGenerator loss: 1.0561635494232178, Discriminator loss: 1.1257545948028564\n",
      "\tGenerator loss: 1.0658526420593262, Discriminator loss: 1.1207019090652466\n",
      "\tGenerator loss: 1.077770709991455, Discriminator loss: 1.100640892982483\n",
      "\tGenerator loss: 1.0780272483825684, Discriminator loss: 1.1636390686035156\n",
      "\tGenerator loss: 1.0472776889801025, Discriminator loss: 1.1587669849395752\n",
      "\tGenerator loss: 1.057058572769165, Discriminator loss: 1.1324467658996582\n",
      "\tGenerator loss: 1.0607134103775024, Discriminator loss: 1.124798059463501\n",
      "\tGenerator loss: 1.114612102508545, Discriminator loss: 1.111018419265747\n",
      "\tGenerator loss: 1.1280990839004517, Discriminator loss: 1.1502712965011597\n",
      "\tGenerator loss: 1.1243562698364258, Discriminator loss: 1.1979775428771973\n",
      "\tGenerator loss: 1.1390299797058105, Discriminator loss: 1.1719378232955933\n",
      "\tGenerator loss: 1.0929745435714722, Discriminator loss: 1.13893723487854\n",
      "\tGenerator loss: 1.0396982431411743, Discriminator loss: 1.130414605140686\n",
      "\tGenerator loss: 1.046140432357788, Discriminator loss: 1.1953270435333252\n",
      "\tGenerator loss: 1.0506882667541504, Discriminator loss: 1.1624574661254883\n",
      "\tGenerator loss: 1.1056915521621704, Discriminator loss: 1.1326117515563965\n",
      "\tGenerator loss: 1.13771390914917, Discriminator loss: 1.1066547632217407\n",
      "\tGenerator loss: 1.1057028770446777, Discriminator loss: 1.1083698272705078\n",
      "\tGenerator loss: 1.137614130973816, Discriminator loss: 1.0695874691009521\n",
      "\tGenerator loss: 1.1168475151062012, Discriminator loss: 1.1126288175582886\n",
      "\tGenerator loss: 1.0814683437347412, Discriminator loss: 1.0938788652420044\n",
      "\tGenerator loss: 1.0282697677612305, Discriminator loss: 1.1277053356170654\n",
      "\tGenerator loss: 1.0718190670013428, Discriminator loss: 1.0731178522109985\n",
      "\tGenerator loss: 1.134467363357544, Discriminator loss: 1.0488848686218262\n",
      "\tGenerator loss: 1.1644541025161743, Discriminator loss: 1.2141807079315186\n",
      "\tGenerator loss: 1.1314094066619873, Discriminator loss: 1.3405765295028687\n",
      "\tGenerator loss: 0.9986134767532349, Discriminator loss: 1.2433204650878906\n",
      "\tGenerator loss: 0.9525123834609985, Discriminator loss: 1.2195912599563599\n",
      "\tGenerator loss: 0.9812787175178528, Discriminator loss: 1.2537071704864502\n",
      "\tGenerator loss: 1.0682450532913208, Discriminator loss: 1.1605418920516968\n",
      "\tGenerator loss: 1.1618032455444336, Discriminator loss: 1.1943929195404053\n",
      "\tGenerator loss: 1.201202392578125, Discriminator loss: 1.250810146331787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0833991765975952, Discriminator loss: 1.2122302055358887\n",
      "\tGenerator loss: 0.967558741569519, Discriminator loss: 1.1948268413543701\n",
      "\tGenerator loss: 0.9363921284675598, Discriminator loss: 1.2572190761566162\n",
      "\tGenerator loss: 0.9770431518554688, Discriminator loss: 1.2760589122772217\n",
      "\tGenerator loss: 1.0942682027816772, Discriminator loss: 1.1809662580490112\n",
      "\tGenerator loss: 1.127016305923462, Discriminator loss: 1.208678960800171\n",
      "\tGenerator loss: 1.173793077468872, Discriminator loss: 1.146734356880188\n",
      "\tGenerator loss: 1.126051664352417, Discriminator loss: 1.1128878593444824\n",
      "\tGenerator loss: 1.0754783153533936, Discriminator loss: 1.1718995571136475\n",
      "\tGenerator loss: 1.0300004482269287, Discriminator loss: 1.1987985372543335\n",
      "\tGenerator loss: 1.0623722076416016, Discriminator loss: 1.2582612037658691\n",
      "\tGenerator loss: 1.1240873336791992, Discriminator loss: 1.2397311925888062\n",
      "\tGenerator loss: 1.1824239492416382, Discriminator loss: 1.1764769554138184\n",
      "\tGenerator loss: 1.1222374439239502, Discriminator loss: 1.1098048686981201\n",
      "\tGenerator loss: 1.1136682033538818, Discriminator loss: 1.0576987266540527\n",
      "\tGenerator loss: 1.1371723413467407, Discriminator loss: 1.0810000896453857\n",
      "\tGenerator loss: 1.2066583633422852, Discriminator loss: 1.0506433248519897\n",
      "\tGenerator loss: 1.2237563133239746, Discriminator loss: 1.0377354621887207\n",
      "\tGenerator loss: 1.2470108270645142, Discriminator loss: 1.011838674545288\n",
      "\tGenerator loss: 1.218881607055664, Discriminator loss: 1.0034921169281006\n",
      "\tGenerator loss: 1.1871418952941895, Discriminator loss: 1.0261410474777222\n",
      "\tGenerator loss: 1.1919059753417969, Discriminator loss: 1.0402004718780518\n",
      "\tGenerator loss: 1.2070845365524292, Discriminator loss: 1.0104774236679077\n",
      "\tGenerator loss: 1.2245948314666748, Discriminator loss: 1.0277180671691895\n",
      "\tGenerator loss: 1.2117148637771606, Discriminator loss: 0.9767642021179199\n",
      "\tGenerator loss: 1.2319107055664062, Discriminator loss: 0.9821630120277405\n",
      "\tGenerator loss: 1.2597382068634033, Discriminator loss: 0.9862092137336731\n",
      "\tGenerator loss: 1.3031277656555176, Discriminator loss: 0.9556291103363037\n",
      "\tGenerator loss: 1.2945748567581177, Discriminator loss: 0.9182882905006409\n",
      "\tGenerator loss: 1.2925550937652588, Discriminator loss: 0.9735450744628906\n",
      "\tGenerator loss: 1.2265434265136719, Discriminator loss: 1.035768985748291\n",
      "\tGenerator loss: 1.164457082748413, Discriminator loss: 1.0091814994812012\n",
      "\tGenerator loss: 1.1208168268203735, Discriminator loss: 1.008102297782898\n",
      "\tGenerator loss: 1.1589012145996094, Discriminator loss: 1.015942096710205\n",
      "\tGenerator loss: 1.2683466672897339, Discriminator loss: 1.0096479654312134\n",
      "\tGenerator loss: 1.3388698101043701, Discriminator loss: 1.0440711975097656\n",
      "\tGenerator loss: 1.2850452661514282, Discriminator loss: 1.0031107664108276\n",
      "\tGenerator loss: 1.2349541187286377, Discriminator loss: 1.028393268585205\n",
      "\tGenerator loss: 1.1532102823257446, Discriminator loss: 1.0441889762878418\n",
      "\tGenerator loss: 1.0489625930786133, Discriminator loss: 1.0203688144683838\n",
      "\tGenerator loss: 1.0510010719299316, Discriminator loss: 1.019034504890442\n",
      "\tGenerator loss: 1.113720178604126, Discriminator loss: 1.053017497062683\n",
      "\tGenerator loss: 1.1635931730270386, Discriminator loss: 1.1134836673736572\n",
      "\tGenerator loss: 1.178887128829956, Discriminator loss: 1.0975687503814697\n",
      "\tGenerator loss: 1.1716439723968506, Discriminator loss: 1.100624680519104\n",
      "\tGenerator loss: 1.1044902801513672, Discriminator loss: 1.1554303169250488\n",
      "\tGenerator loss: 1.0404762029647827, Discriminator loss: 1.206906795501709\n",
      "\tGenerator loss: 0.948134183883667, Discriminator loss: 1.177966833114624\n",
      "\tGenerator loss: 0.9097791910171509, Discriminator loss: 1.1552433967590332\n",
      "\tGenerator loss: 0.9421297311782837, Discriminator loss: 1.166447401046753\n",
      "\tGenerator loss: 1.002588152885437, Discriminator loss: 1.153531551361084\n",
      "\tGenerator loss: 1.112216591835022, Discriminator loss: 1.1704812049865723\n",
      "\tGenerator loss: 1.140271782875061, Discriminator loss: 1.1536056995391846\n",
      "\tGenerator loss: 1.074967861175537, Discriminator loss: 1.1373875141143799\n",
      "\tGenerator loss: 1.0004229545593262, Discriminator loss: 1.2048120498657227\n",
      "\tGenerator loss: 0.9569132924079895, Discriminator loss: 1.1978543996810913\n",
      "\tGenerator loss: 0.9331930875778198, Discriminator loss: 1.2076714038848877\n",
      "\tGenerator loss: 0.9646743535995483, Discriminator loss: 1.2090730667114258\n",
      "\tGenerator loss: 1.004305124282837, Discriminator loss: 1.193076729774475\n",
      "\tGenerator loss: 1.0191309452056885, Discriminator loss: 1.1789488792419434\n",
      "\tGenerator loss: 1.0254101753234863, Discriminator loss: 1.120105504989624\n",
      "\tGenerator loss: 1.0718162059783936, Discriminator loss: 1.0706372261047363\n",
      "\tGenerator loss: 1.0529048442840576, Discriminator loss: 1.1104012727737427\n",
      "\tGenerator loss: 1.0653531551361084, Discriminator loss: 1.1121925115585327\n",
      "\tGenerator loss: 1.076958417892456, Discriminator loss: 1.0691444873809814\n",
      "\tGenerator loss: 1.0803731679916382, Discriminator loss: 1.1211657524108887\n",
      "\tGenerator loss: 1.0484929084777832, Discriminator loss: 1.114020824432373\n",
      "\tGenerator loss: 1.051737904548645, Discriminator loss: 1.1240915060043335\n",
      "\tGenerator loss: 1.0914008617401123, Discriminator loss: 1.0326597690582275\n",
      "\tGenerator loss: 1.1406726837158203, Discriminator loss: 1.0515507459640503\n",
      "\tGenerator loss: 1.1412204504013062, Discriminator loss: 1.0364875793457031\n",
      "\tGenerator loss: 1.2057647705078125, Discriminator loss: 1.081287145614624\n",
      "\tGenerator loss: 1.2263712882995605, Discriminator loss: 1.0465047359466553\n",
      "\tGenerator loss: 1.1895084381103516, Discriminator loss: 1.0730786323547363\n",
      "\tGenerator loss: 1.1819790601730347, Discriminator loss: 1.1091598272323608\n",
      "\tGenerator loss: 1.1536924839019775, Discriminator loss: 1.0300779342651367\n",
      "\tGenerator loss: 1.1355540752410889, Discriminator loss: 1.0040979385375977\n",
      "\tGenerator loss: 1.1505508422851562, Discriminator loss: 1.009098768234253\n",
      "\tGenerator loss: 1.1981399059295654, Discriminator loss: 1.0561046600341797\n",
      "\tGenerator loss: 1.2797715663909912, Discriminator loss: 1.1043024063110352\n",
      "\tGenerator loss: 1.3439112901687622, Discriminator loss: 1.192533254623413\n",
      "\tGenerator loss: 1.2674365043640137, Discriminator loss: 1.1824393272399902\n",
      "\tGenerator loss: 1.1721973419189453, Discriminator loss: 1.1825053691864014\n",
      "\tGenerator loss: 1.0477423667907715, Discriminator loss: 1.2420282363891602\n",
      "\tGenerator loss: 0.9922268390655518, Discriminator loss: 1.3926807641983032\n",
      "\tGenerator loss: 1.0000218152999878, Discriminator loss: 1.312443733215332\n",
      "\tGenerator loss: 1.024562120437622, Discriminator loss: 1.3057260513305664\n",
      "\tGenerator loss: 1.0601521730422974, Discriminator loss: 1.2577300071716309\n",
      "\tGenerator loss: 1.1418235301971436, Discriminator loss: 1.2563081979751587\n",
      "\tGenerator loss: 1.1646826267242432, Discriminator loss: 1.2280611991882324\n",
      "\tGenerator loss: 1.1331290006637573, Discriminator loss: 1.233698844909668\n",
      "\tGenerator loss: 1.0936311483383179, Discriminator loss: 1.2408474683761597\n",
      "\tGenerator loss: 1.0452663898468018, Discriminator loss: 1.1637194156646729\n",
      "\tGenerator loss: 0.9738171100616455, Discriminator loss: 1.2299938201904297\n",
      "\tGenerator loss: 1.0096403360366821, Discriminator loss: 1.2164944410324097\n",
      "\tGenerator loss: 1.0978410243988037, Discriminator loss: 1.2498695850372314\n",
      "\tGenerator loss: 1.1093380451202393, Discriminator loss: 1.1520782709121704\n",
      "\tGenerator loss: 1.0934298038482666, Discriminator loss: 1.1721620559692383\n",
      "\tGenerator loss: 1.1170514822006226, Discriminator loss: 1.358789324760437\n",
      "\tGenerator loss: 1.0662388801574707, Discriminator loss: 1.5234375\n",
      "\tGenerator loss: 1.0099537372589111, Discriminator loss: 1.528306484222412\n",
      "\tGenerator loss: 0.9738597869873047, Discriminator loss: 1.3581231832504272\n",
      "Time for epoch 30 is 257.6275203227997 sec\n",
      "\tGenerator loss: 1.0116075277328491, Discriminator loss: 1.3178668022155762\n",
      "\tGenerator loss: 1.0287671089172363, Discriminator loss: 1.2871620655059814\n",
      "\tGenerator loss: 1.0487332344055176, Discriminator loss: 1.2603408098220825\n",
      "\tGenerator loss: 1.0432381629943848, Discriminator loss: 1.2710161209106445\n",
      "\tGenerator loss: 1.062227725982666, Discriminator loss: 1.3802026510238647\n",
      "\tGenerator loss: 1.0526061058044434, Discriminator loss: 1.4051073789596558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.032820224761963, Discriminator loss: 1.293350100517273\n",
      "\tGenerator loss: 1.1018133163452148, Discriminator loss: 1.3077964782714844\n",
      "\tGenerator loss: 1.1125211715698242, Discriminator loss: 1.2065931558609009\n",
      "\tGenerator loss: 1.1100788116455078, Discriminator loss: 1.1735801696777344\n",
      "\tGenerator loss: 1.1358692646026611, Discriminator loss: 1.1422525644302368\n",
      "\tGenerator loss: 1.2050774097442627, Discriminator loss: 1.1282641887664795\n",
      "\tGenerator loss: 1.2004549503326416, Discriminator loss: 1.1480255126953125\n",
      "\tGenerator loss: 1.1581312417984009, Discriminator loss: 1.1077934503555298\n",
      "\tGenerator loss: 1.113642930984497, Discriminator loss: 1.1071007251739502\n",
      "\tGenerator loss: 1.1401021480560303, Discriminator loss: 1.0733962059020996\n",
      "\tGenerator loss: 1.1829298734664917, Discriminator loss: 1.0773801803588867\n",
      "\tGenerator loss: 1.2536802291870117, Discriminator loss: 1.0761336088180542\n",
      "\tGenerator loss: 1.292886734008789, Discriminator loss: 1.0901422500610352\n",
      "\tGenerator loss: 1.278921365737915, Discriminator loss: 1.0611170530319214\n",
      "\tGenerator loss: 1.2227448225021362, Discriminator loss: 1.0644066333770752\n",
      "\tGenerator loss: 1.1818764209747314, Discriminator loss: 1.0759479999542236\n",
      "\tGenerator loss: 1.1959809064865112, Discriminator loss: 1.0880334377288818\n",
      "\tGenerator loss: 1.169835090637207, Discriminator loss: 1.107677936553955\n",
      "\tGenerator loss: 1.2084919214248657, Discriminator loss: 1.0926812887191772\n",
      "\tGenerator loss: 1.2850310802459717, Discriminator loss: 1.073108196258545\n",
      "\tGenerator loss: 1.2776046991348267, Discriminator loss: 1.1874053478240967\n",
      "\tGenerator loss: 1.1528265476226807, Discriminator loss: 1.1661667823791504\n",
      "\tGenerator loss: 1.1191898584365845, Discriminator loss: 1.2640421390533447\n",
      "\tGenerator loss: 1.0041851997375488, Discriminator loss: 1.223892331123352\n",
      "\tGenerator loss: 0.9614590406417847, Discriminator loss: 1.1966373920440674\n",
      "\tGenerator loss: 1.0113812685012817, Discriminator loss: 1.1507713794708252\n",
      "\tGenerator loss: 1.1628718376159668, Discriminator loss: 1.1477892398834229\n",
      "\tGenerator loss: 1.3026018142700195, Discriminator loss: 1.0987207889556885\n",
      "\tGenerator loss: 1.3278238773345947, Discriminator loss: 1.12834894657135\n",
      "\tGenerator loss: 1.2583839893341064, Discriminator loss: 1.1663044691085815\n",
      "\tGenerator loss: 1.1049184799194336, Discriminator loss: 1.1830339431762695\n",
      "\tGenerator loss: 0.9712053537368774, Discriminator loss: 1.1812723875045776\n",
      "\tGenerator loss: 0.9138362407684326, Discriminator loss: 1.1979191303253174\n",
      "\tGenerator loss: 0.9970022439956665, Discriminator loss: 1.1318063735961914\n",
      "\tGenerator loss: 1.1189720630645752, Discriminator loss: 1.143545150756836\n",
      "\tGenerator loss: 1.2767376899719238, Discriminator loss: 1.2071926593780518\n",
      "\tGenerator loss: 1.2727203369140625, Discriminator loss: 1.2162789106369019\n",
      "\tGenerator loss: 1.2002012729644775, Discriminator loss: 1.1607441902160645\n",
      "\tGenerator loss: 1.0698039531707764, Discriminator loss: 1.1616127490997314\n",
      "\tGenerator loss: 1.0183295011520386, Discriminator loss: 1.15428626537323\n",
      "\tGenerator loss: 0.9818062782287598, Discriminator loss: 1.184559941291809\n",
      "\tGenerator loss: 0.9598738551139832, Discriminator loss: 1.1904263496398926\n",
      "\tGenerator loss: 1.060516595840454, Discriminator loss: 1.1824122667312622\n",
      "\tGenerator loss: 1.179762601852417, Discriminator loss: 1.1848127841949463\n",
      "\tGenerator loss: 1.2533413171768188, Discriminator loss: 1.1817408800125122\n",
      "\tGenerator loss: 1.213219165802002, Discriminator loss: 1.1705143451690674\n",
      "\tGenerator loss: 1.1723765134811401, Discriminator loss: 1.1194067001342773\n",
      "\tGenerator loss: 1.0886554718017578, Discriminator loss: 1.15401029586792\n",
      "\tGenerator loss: 1.0205252170562744, Discriminator loss: 1.1555992364883423\n",
      "\tGenerator loss: 1.0004411935806274, Discriminator loss: 1.1653285026550293\n",
      "\tGenerator loss: 1.0619826316833496, Discriminator loss: 1.1614208221435547\n",
      "\tGenerator loss: 1.1530059576034546, Discriminator loss: 1.102927803993225\n",
      "\tGenerator loss: 1.254967212677002, Discriminator loss: 1.075390100479126\n",
      "\tGenerator loss: 1.3152217864990234, Discriminator loss: 1.048787236213684\n",
      "\tGenerator loss: 1.255814790725708, Discriminator loss: 1.0584759712219238\n",
      "\tGenerator loss: 1.1960861682891846, Discriminator loss: 1.0736163854599\n",
      "\tGenerator loss: 1.1498444080352783, Discriminator loss: 1.068925380706787\n",
      "\tGenerator loss: 1.1286687850952148, Discriminator loss: 1.0609807968139648\n",
      "\tGenerator loss: 1.1576218605041504, Discriminator loss: 1.0105435848236084\n",
      "\tGenerator loss: 1.228632926940918, Discriminator loss: 0.9634408950805664\n",
      "\tGenerator loss: 1.3221700191497803, Discriminator loss: 0.9877482652664185\n",
      "\tGenerator loss: 1.4289135932922363, Discriminator loss: 0.970962405204773\n",
      "\tGenerator loss: 1.4370449781417847, Discriminator loss: 0.9740631580352783\n",
      "\tGenerator loss: 1.3856884241104126, Discriminator loss: 0.9406258463859558\n",
      "\tGenerator loss: 1.3524622917175293, Discriminator loss: 0.9239003658294678\n",
      "\tGenerator loss: 1.331281304359436, Discriminator loss: 0.9441397190093994\n",
      "\tGenerator loss: 1.2684597969055176, Discriminator loss: 0.9288944005966187\n",
      "\tGenerator loss: 1.2858428955078125, Discriminator loss: 0.9061660170555115\n",
      "\tGenerator loss: 1.3266594409942627, Discriminator loss: 0.8741428852081299\n",
      "\tGenerator loss: 1.3835482597351074, Discriminator loss: 0.9932689070701599\n",
      "\tGenerator loss: 1.407545804977417, Discriminator loss: 1.1136434078216553\n",
      "\tGenerator loss: 1.3980367183685303, Discriminator loss: 1.0839040279388428\n",
      "\tGenerator loss: 1.3357009887695312, Discriminator loss: 1.032651662826538\n",
      "\tGenerator loss: 1.2790777683258057, Discriminator loss: 0.9628984928131104\n",
      "\tGenerator loss: 1.2305755615234375, Discriminator loss: 1.0210771560668945\n",
      "\tGenerator loss: 1.221836805343628, Discriminator loss: 1.0228067636489868\n",
      "\tGenerator loss: 1.2523562908172607, Discriminator loss: 0.9624910354614258\n",
      "\tGenerator loss: 1.2790788412094116, Discriminator loss: 0.9299534559249878\n",
      "\tGenerator loss: 1.3500572443008423, Discriminator loss: 0.8986402750015259\n",
      "\tGenerator loss: 1.3727331161499023, Discriminator loss: 1.1316709518432617\n",
      "\tGenerator loss: 1.3503695726394653, Discriminator loss: 1.0220081806182861\n",
      "\tGenerator loss: 1.325117588043213, Discriminator loss: 1.0174282789230347\n",
      "\tGenerator loss: 1.2794482707977295, Discriminator loss: 1.1665079593658447\n",
      "\tGenerator loss: 1.1883318424224854, Discriminator loss: 1.2398099899291992\n",
      "\tGenerator loss: 1.0847930908203125, Discriminator loss: 1.2525672912597656\n",
      "\tGenerator loss: 1.04246187210083, Discriminator loss: 1.1821844577789307\n",
      "\tGenerator loss: 1.0263158082962036, Discriminator loss: 1.0966039896011353\n",
      "\tGenerator loss: 1.0898146629333496, Discriminator loss: 1.1267759799957275\n",
      "\tGenerator loss: 1.1933763027191162, Discriminator loss: 1.2007737159729004\n",
      "\tGenerator loss: 1.2363266944885254, Discriminator loss: 1.141714334487915\n",
      "\tGenerator loss: 1.2177623510360718, Discriminator loss: 1.211242914199829\n",
      "\tGenerator loss: 1.1381263732910156, Discriminator loss: 1.1661491394042969\n",
      "\tGenerator loss: 1.0297319889068604, Discriminator loss: 1.1994130611419678\n",
      "\tGenerator loss: 0.9921400547027588, Discriminator loss: 1.2738651037216187\n",
      "\tGenerator loss: 1.0041558742523193, Discriminator loss: 1.2001993656158447\n",
      "\tGenerator loss: 1.0547308921813965, Discriminator loss: 1.1927521228790283\n",
      "\tGenerator loss: 1.1281577348709106, Discriminator loss: 1.1899144649505615\n",
      "\tGenerator loss: 1.1159117221832275, Discriminator loss: 1.183187484741211\n",
      "\tGenerator loss: 1.129748821258545, Discriminator loss: 1.287047028541565\n",
      "\tGenerator loss: 1.0719479322433472, Discriminator loss: 1.2167117595672607\n",
      "\tGenerator loss: 0.9866297245025635, Discriminator loss: 1.2285058498382568\n",
      "\tGenerator loss: 0.9724098443984985, Discriminator loss: 1.169675588607788\n",
      "\tGenerator loss: 1.0056333541870117, Discriminator loss: 1.158860683441162\n",
      "\tGenerator loss: 1.1138052940368652, Discriminator loss: 1.2449440956115723\n",
      "\tGenerator loss: 1.1178137063980103, Discriminator loss: 1.340082049369812\n",
      "\tGenerator loss: 1.0911486148834229, Discriminator loss: 1.300400733947754\n",
      "\tGenerator loss: 1.0208340883255005, Discriminator loss: 1.2704945802688599\n",
      "\tGenerator loss: 0.9810115098953247, Discriminator loss: 1.218106746673584\n",
      "\tGenerator loss: 0.9664912223815918, Discriminator loss: 1.2804336547851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9964731931686401, Discriminator loss: 1.2091630697250366\n",
      "\tGenerator loss: 1.0655609369277954, Discriminator loss: 1.1933023929595947\n",
      "\tGenerator loss: 1.0917046070098877, Discriminator loss: 1.1740566492080688\n",
      "\tGenerator loss: 1.0618400573730469, Discriminator loss: 1.1674890518188477\n",
      "\tGenerator loss: 1.0535368919372559, Discriminator loss: 1.1644424200057983\n",
      "\tGenerator loss: 1.0889699459075928, Discriminator loss: 1.1271072626113892\n",
      "\tGenerator loss: 1.0464694499969482, Discriminator loss: 1.1187934875488281\n",
      "\tGenerator loss: 1.0161128044128418, Discriminator loss: 1.1199285984039307\n",
      "\tGenerator loss: 1.0181801319122314, Discriminator loss: 1.1157656908035278\n",
      "\tGenerator loss: 1.0730555057525635, Discriminator loss: 1.0871624946594238\n",
      "\tGenerator loss: 1.1206499338150024, Discriminator loss: 1.1663765907287598\n",
      "\tGenerator loss: 1.1220483779907227, Discriminator loss: 1.220670223236084\n",
      "\tGenerator loss: 1.0934228897094727, Discriminator loss: 1.1497688293457031\n",
      "\tGenerator loss: 1.0348109006881714, Discriminator loss: 1.1206586360931396\n",
      "\tGenerator loss: 1.0723307132720947, Discriminator loss: 1.132589340209961\n",
      "\tGenerator loss: 1.0810701847076416, Discriminator loss: 1.08290433883667\n",
      "\tGenerator loss: 1.1156237125396729, Discriminator loss: 1.0974721908569336\n",
      "\tGenerator loss: 1.1259208917617798, Discriminator loss: 1.1092185974121094\n",
      "\tGenerator loss: 1.0842163562774658, Discriminator loss: 1.110987663269043\n",
      "\tGenerator loss: 1.0576791763305664, Discriminator loss: 1.0703659057617188\n",
      "\tGenerator loss: 1.087674617767334, Discriminator loss: 1.1053271293640137\n",
      "\tGenerator loss: 1.1127697229385376, Discriminator loss: 1.0893925428390503\n",
      "\tGenerator loss: 1.1475293636322021, Discriminator loss: 1.0858373641967773\n",
      "\tGenerator loss: 1.1406302452087402, Discriminator loss: 1.060375690460205\n",
      "\tGenerator loss: 1.1107971668243408, Discriminator loss: 1.088648796081543\n",
      "\tGenerator loss: 1.1046347618103027, Discriminator loss: 1.1382133960723877\n",
      "\tGenerator loss: 1.074953556060791, Discriminator loss: 1.0965137481689453\n",
      "\tGenerator loss: 1.0703672170639038, Discriminator loss: 1.0845122337341309\n",
      "\tGenerator loss: 1.0940052270889282, Discriminator loss: 1.0833076238632202\n",
      "\tGenerator loss: 1.1251320838928223, Discriminator loss: 1.0905630588531494\n",
      "\tGenerator loss: 1.1409093141555786, Discriminator loss: 1.0686686038970947\n",
      "\tGenerator loss: 1.2103586196899414, Discriminator loss: 1.1019471883773804\n",
      "\tGenerator loss: 1.156400442123413, Discriminator loss: 1.1255149841308594\n",
      "\tGenerator loss: 1.135536789894104, Discriminator loss: 1.1209263801574707\n",
      "\tGenerator loss: 1.0936143398284912, Discriminator loss: 1.1175761222839355\n",
      "\tGenerator loss: 1.0298354625701904, Discriminator loss: 1.1342729330062866\n",
      "\tGenerator loss: 0.9865649938583374, Discriminator loss: 1.161696195602417\n",
      "\tGenerator loss: 1.004277229309082, Discriminator loss: 1.1178195476531982\n",
      "\tGenerator loss: 1.026228904724121, Discriminator loss: 1.1543704271316528\n",
      "\tGenerator loss: 1.056840181350708, Discriminator loss: 1.1792337894439697\n",
      "\tGenerator loss: 1.112210750579834, Discriminator loss: 1.2209224700927734\n",
      "\tGenerator loss: 1.0901567935943604, Discriminator loss: 1.196856141090393\n",
      "\tGenerator loss: 1.0143400430679321, Discriminator loss: 1.1733434200286865\n",
      "\tGenerator loss: 0.9923985004425049, Discriminator loss: 1.1640019416809082\n",
      "\tGenerator loss: 0.9708238840103149, Discriminator loss: 1.1560062170028687\n",
      "\tGenerator loss: 0.9752440452575684, Discriminator loss: 1.1197009086608887\n",
      "\tGenerator loss: 1.0442314147949219, Discriminator loss: 1.0945357084274292\n",
      "\tGenerator loss: 1.102096438407898, Discriminator loss: 1.1478384733200073\n",
      "\tGenerator loss: 1.1015546321868896, Discriminator loss: 1.1400249004364014\n",
      "\tGenerator loss: 1.0300207138061523, Discriminator loss: 1.147784948348999\n",
      "\tGenerator loss: 0.9927147626876831, Discriminator loss: 1.1259584426879883\n",
      "\tGenerator loss: 0.958334743976593, Discriminator loss: 1.1537896394729614\n",
      "\tGenerator loss: 0.9780148863792419, Discriminator loss: 1.1526646614074707\n",
      "\tGenerator loss: 1.0550941228866577, Discriminator loss: 1.1165944337844849\n",
      "\tGenerator loss: 1.100165605545044, Discriminator loss: 1.0905964374542236\n",
      "\tGenerator loss: 1.0989457368850708, Discriminator loss: 1.0998754501342773\n",
      "\tGenerator loss: 1.0791192054748535, Discriminator loss: 1.0686841011047363\n",
      "\tGenerator loss: 1.0458385944366455, Discriminator loss: 1.04473876953125\n",
      "\tGenerator loss: 1.0541517734527588, Discriminator loss: 1.0129694938659668\n",
      "\tGenerator loss: 1.0942786931991577, Discriminator loss: 1.0248451232910156\n",
      "\tGenerator loss: 1.0934679508209229, Discriminator loss: 1.0912355184555054\n",
      "\tGenerator loss: 1.1400671005249023, Discriminator loss: 1.0653059482574463\n",
      "\tGenerator loss: 1.1317839622497559, Discriminator loss: 1.040313959121704\n",
      "\tGenerator loss: 1.1701443195343018, Discriminator loss: 1.0157651901245117\n",
      "\tGenerator loss: 1.1486952304840088, Discriminator loss: 1.0245282649993896\n",
      "\tGenerator loss: 1.1251300573349, Discriminator loss: 0.9838162660598755\n",
      "\tGenerator loss: 1.10821533203125, Discriminator loss: 0.973842203617096\n",
      "\tGenerator loss: 1.132367730140686, Discriminator loss: 1.0096114873886108\n",
      "\tGenerator loss: 1.2029541730880737, Discriminator loss: 1.010211706161499\n",
      "\tGenerator loss: 1.2600493431091309, Discriminator loss: 0.9860057234764099\n",
      "\tGenerator loss: 1.2675431966781616, Discriminator loss: 1.0232073068618774\n",
      "\tGenerator loss: 1.224403738975525, Discriminator loss: 1.024078130722046\n",
      "\tGenerator loss: 1.1834222078323364, Discriminator loss: 1.080540657043457\n",
      "\tGenerator loss: 1.1209217309951782, Discriminator loss: 1.1491868495941162\n",
      "\tGenerator loss: 1.0528817176818848, Discriminator loss: 1.1493464708328247\n",
      "\tGenerator loss: 1.080716848373413, Discriminator loss: 1.1138052940368652\n",
      "\tGenerator loss: 1.106902003288269, Discriminator loss: 1.0572617053985596\n",
      "\tGenerator loss: 1.1585760116577148, Discriminator loss: 1.0465736389160156\n",
      "\tGenerator loss: 1.2550048828125, Discriminator loss: 1.0126235485076904\n",
      "\tGenerator loss: 1.2560657262802124, Discriminator loss: 0.9823449850082397\n",
      "\tGenerator loss: 1.2497918605804443, Discriminator loss: 0.9974706768989563\n",
      "\tGenerator loss: 1.2163927555084229, Discriminator loss: 1.0124708414077759\n",
      "\tGenerator loss: 1.103774070739746, Discriminator loss: 1.0341062545776367\n",
      "\tGenerator loss: 1.0972856283187866, Discriminator loss: 1.0932998657226562\n",
      "\tGenerator loss: 1.065004825592041, Discriminator loss: 1.0923973321914673\n",
      "\tGenerator loss: 1.0637261867523193, Discriminator loss: 1.1450846195220947\n",
      "\tGenerator loss: 1.0745964050292969, Discriminator loss: 1.0907446146011353\n",
      "\tGenerator loss: 1.1608330011367798, Discriminator loss: 1.0691473484039307\n",
      "\tGenerator loss: 1.1580636501312256, Discriminator loss: 1.0640547275543213\n",
      "\tGenerator loss: 1.1761069297790527, Discriminator loss: 1.0711086988449097\n",
      "\tGenerator loss: 1.1258149147033691, Discriminator loss: 1.0369367599487305\n",
      "\tGenerator loss: 1.0377006530761719, Discriminator loss: 1.098512887954712\n",
      "\tGenerator loss: 1.0724613666534424, Discriminator loss: 1.1143685579299927\n",
      "\tGenerator loss: 1.0923854112625122, Discriminator loss: 1.090052604675293\n",
      "\tGenerator loss: 1.107659935951233, Discriminator loss: 1.0741312503814697\n",
      "\tGenerator loss: 1.1367113590240479, Discriminator loss: 1.0508886575698853\n",
      "\tGenerator loss: 1.1435763835906982, Discriminator loss: 1.1043856143951416\n",
      "\tGenerator loss: 1.1412513256072998, Discriminator loss: 1.1955013275146484\n",
      "\tGenerator loss: 1.0956369638442993, Discriminator loss: 1.246932029724121\n",
      "\tGenerator loss: 1.021428108215332, Discriminator loss: 1.2103030681610107\n",
      "\tGenerator loss: 0.9683055281639099, Discriminator loss: 1.2026879787445068\n",
      "\tGenerator loss: 0.967699408531189, Discriminator loss: 1.2310734987258911\n",
      "\tGenerator loss: 0.9734519720077515, Discriminator loss: 1.359938144683838\n",
      "\tGenerator loss: 1.010972499847412, Discriminator loss: 1.2753970623016357\n",
      "\tGenerator loss: 1.0407841205596924, Discriminator loss: 1.2565628290176392\n",
      "\tGenerator loss: 1.0395193099975586, Discriminator loss: 1.2392377853393555\n",
      "\tGenerator loss: 1.0406999588012695, Discriminator loss: 1.2368836402893066\n",
      "\tGenerator loss: 1.033684492111206, Discriminator loss: 1.1914775371551514\n",
      "\tGenerator loss: 0.9711086750030518, Discriminator loss: 1.1916933059692383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9619631767272949, Discriminator loss: 1.2147245407104492\n",
      "\tGenerator loss: 0.9907183647155762, Discriminator loss: 1.162520170211792\n",
      "\tGenerator loss: 1.0753062963485718, Discriminator loss: 1.1640701293945312\n",
      "\tGenerator loss: 1.1265225410461426, Discriminator loss: 1.1322638988494873\n",
      "\tGenerator loss: 1.121526837348938, Discriminator loss: 1.158804178237915\n",
      "\tGenerator loss: 1.0664024353027344, Discriminator loss: 1.1124727725982666\n",
      "\tGenerator loss: 1.0563002824783325, Discriminator loss: 1.0767256021499634\n",
      "\tGenerator loss: 1.0682861804962158, Discriminator loss: 1.1378899812698364\n",
      "\tGenerator loss: 1.0939662456512451, Discriminator loss: 1.2228963375091553\n",
      "\tGenerator loss: 1.1138113737106323, Discriminator loss: 1.260214924812317\n",
      "\tGenerator loss: 1.1373841762542725, Discriminator loss: 1.1978113651275635\n",
      "Time for epoch 31 is 256.2013909816742 sec\n",
      "\tGenerator loss: 1.1184264421463013, Discriminator loss: 1.1592291593551636\n",
      "\tGenerator loss: 1.0444504022598267, Discriminator loss: 1.163187861442566\n",
      "\tGenerator loss: 0.9407289624214172, Discriminator loss: 1.2004581689834595\n",
      "\tGenerator loss: 0.9788463115692139, Discriminator loss: 1.174360990524292\n",
      "\tGenerator loss: 1.0793169736862183, Discriminator loss: 1.2288830280303955\n",
      "\tGenerator loss: 1.1427454948425293, Discriminator loss: 1.2618672847747803\n",
      "\tGenerator loss: 1.107208490371704, Discriminator loss: 1.2125155925750732\n",
      "\tGenerator loss: 1.0540623664855957, Discriminator loss: 1.2355387210845947\n",
      "\tGenerator loss: 1.0375308990478516, Discriminator loss: 1.1934595108032227\n",
      "\tGenerator loss: 1.0286493301391602, Discriminator loss: 1.1606013774871826\n",
      "\tGenerator loss: 1.036623239517212, Discriminator loss: 1.1276963949203491\n",
      "\tGenerator loss: 1.0927207469940186, Discriminator loss: 1.1440324783325195\n",
      "\tGenerator loss: 1.1277475357055664, Discriminator loss: 1.1681722402572632\n",
      "\tGenerator loss: 1.1233078241348267, Discriminator loss: 1.1468110084533691\n",
      "\tGenerator loss: 1.080918550491333, Discriminator loss: 1.1743135452270508\n",
      "\tGenerator loss: 1.045792818069458, Discriminator loss: 1.1632007360458374\n",
      "\tGenerator loss: 1.0453338623046875, Discriminator loss: 1.1533606052398682\n",
      "\tGenerator loss: 1.0730711221694946, Discriminator loss: 1.1486096382141113\n",
      "\tGenerator loss: 1.0659788846969604, Discriminator loss: 1.1959433555603027\n",
      "\tGenerator loss: 1.0508370399475098, Discriminator loss: 1.1669400930404663\n",
      "\tGenerator loss: 1.0567976236343384, Discriminator loss: 1.1622223854064941\n",
      "\tGenerator loss: 1.1048777103424072, Discriminator loss: 1.1994493007659912\n",
      "\tGenerator loss: 1.12166428565979, Discriminator loss: 1.2214173078536987\n",
      "\tGenerator loss: 1.077260971069336, Discriminator loss: 1.2234609127044678\n",
      "\tGenerator loss: 1.0270416736602783, Discriminator loss: 1.2090739011764526\n",
      "\tGenerator loss: 0.9921392202377319, Discriminator loss: 1.1889631748199463\n",
      "\tGenerator loss: 1.0313379764556885, Discriminator loss: 1.1943392753601074\n",
      "\tGenerator loss: 1.0401440858840942, Discriminator loss: 1.1613065004348755\n",
      "\tGenerator loss: 1.0431735515594482, Discriminator loss: 1.285098910331726\n",
      "\tGenerator loss: 0.968005895614624, Discriminator loss: 1.2425987720489502\n",
      "\tGenerator loss: 0.9045110940933228, Discriminator loss: 1.2425568103790283\n",
      "\tGenerator loss: 0.9254814386367798, Discriminator loss: 1.214756965637207\n",
      "\tGenerator loss: 0.9534654021263123, Discriminator loss: 1.2339321374893188\n",
      "\tGenerator loss: 1.0160185098648071, Discriminator loss: 1.2307758331298828\n",
      "\tGenerator loss: 1.0764570236206055, Discriminator loss: 1.222556233406067\n",
      "\tGenerator loss: 1.0976271629333496, Discriminator loss: 1.2241103649139404\n",
      "\tGenerator loss: 1.0641183853149414, Discriminator loss: 1.2323273420333862\n",
      "\tGenerator loss: 0.976681649684906, Discriminator loss: 1.2100541591644287\n",
      "\tGenerator loss: 0.9463059902191162, Discriminator loss: 1.1463050842285156\n",
      "\tGenerator loss: 0.933745801448822, Discriminator loss: 1.16995108127594\n",
      "\tGenerator loss: 0.983005166053772, Discriminator loss: 1.192866325378418\n",
      "\tGenerator loss: 1.0775818824768066, Discriminator loss: 1.182816505432129\n",
      "\tGenerator loss: 1.1463253498077393, Discriminator loss: 1.1850463151931763\n",
      "\tGenerator loss: 1.135213851928711, Discriminator loss: 1.1937178373336792\n",
      "\tGenerator loss: 1.1028587818145752, Discriminator loss: 1.1416925191879272\n",
      "\tGenerator loss: 1.019765019416809, Discriminator loss: 1.1784801483154297\n",
      "\tGenerator loss: 0.9699777960777283, Discriminator loss: 1.1764363050460815\n",
      "\tGenerator loss: 0.9278546571731567, Discriminator loss: 1.202200174331665\n",
      "\tGenerator loss: 0.966955840587616, Discriminator loss: 1.160871982574463\n",
      "\tGenerator loss: 1.0767396688461304, Discriminator loss: 1.1211838722229004\n",
      "\tGenerator loss: 1.1656869649887085, Discriminator loss: 1.2097960710525513\n",
      "\tGenerator loss: 1.1796804666519165, Discriminator loss: 1.2116235494613647\n",
      "\tGenerator loss: 1.1149733066558838, Discriminator loss: 1.1583278179168701\n",
      "\tGenerator loss: 1.0740405321121216, Discriminator loss: 1.1587802171707153\n",
      "\tGenerator loss: 1.0162913799285889, Discriminator loss: 1.135227084159851\n",
      "\tGenerator loss: 0.9577691555023193, Discriminator loss: 1.1698698997497559\n",
      "\tGenerator loss: 0.9848604202270508, Discriminator loss: 1.1491923332214355\n",
      "\tGenerator loss: 1.032529354095459, Discriminator loss: 1.1228924989700317\n",
      "\tGenerator loss: 1.1020441055297852, Discriminator loss: 1.086794376373291\n",
      "\tGenerator loss: 1.1745729446411133, Discriminator loss: 1.0611114501953125\n",
      "\tGenerator loss: 1.263429880142212, Discriminator loss: 1.0409696102142334\n",
      "\tGenerator loss: 1.16975998878479, Discriminator loss: 1.0443603992462158\n",
      "\tGenerator loss: 1.0867743492126465, Discriminator loss: 1.1147780418395996\n",
      "\tGenerator loss: 1.0538315773010254, Discriminator loss: 1.088626503944397\n",
      "\tGenerator loss: 1.0261943340301514, Discriminator loss: 1.070410966873169\n",
      "\tGenerator loss: 1.0499119758605957, Discriminator loss: 1.0540891885757446\n",
      "\tGenerator loss: 1.107068419456482, Discriminator loss: 1.0811541080474854\n",
      "\tGenerator loss: 1.193408727645874, Discriminator loss: 1.067265510559082\n",
      "\tGenerator loss: 1.2171475887298584, Discriminator loss: 1.1111801862716675\n",
      "\tGenerator loss: 1.1363383531570435, Discriminator loss: 1.098712682723999\n",
      "\tGenerator loss: 1.0777393579483032, Discriminator loss: 1.1085176467895508\n",
      "\tGenerator loss: 1.03013014793396, Discriminator loss: 1.1381258964538574\n",
      "\tGenerator loss: 1.0547301769256592, Discriminator loss: 1.0789909362792969\n",
      "\tGenerator loss: 1.0762311220169067, Discriminator loss: 1.0654960870742798\n",
      "\tGenerator loss: 1.1289706230163574, Discriminator loss: 1.036546230316162\n",
      "\tGenerator loss: 1.209845781326294, Discriminator loss: 1.1553370952606201\n",
      "\tGenerator loss: 1.2078983783721924, Discriminator loss: 1.2636078596115112\n",
      "\tGenerator loss: 1.191321849822998, Discriminator loss: 1.209954023361206\n",
      "\tGenerator loss: 1.1008117198944092, Discriminator loss: 1.1457927227020264\n",
      "\tGenerator loss: 1.0342613458633423, Discriminator loss: 1.201412558555603\n",
      "\tGenerator loss: 1.0169588327407837, Discriminator loss: 1.2522711753845215\n",
      "\tGenerator loss: 0.9903146028518677, Discriminator loss: 1.2591452598571777\n",
      "\tGenerator loss: 1.0548162460327148, Discriminator loss: 1.2035927772521973\n",
      "\tGenerator loss: 1.1282912492752075, Discriminator loss: 1.1571143865585327\n",
      "\tGenerator loss: 1.1155840158462524, Discriminator loss: 1.1299207210540771\n",
      "\tGenerator loss: 1.1577093601226807, Discriminator loss: 1.2299507856369019\n",
      "\tGenerator loss: 1.0939995050430298, Discriminator loss: 1.1683661937713623\n",
      "\tGenerator loss: 1.0755698680877686, Discriminator loss: 1.181490421295166\n",
      "\tGenerator loss: 1.071407437324524, Discriminator loss: 1.281886339187622\n",
      "\tGenerator loss: 1.0198112726211548, Discriminator loss: 1.2902023792266846\n",
      "\tGenerator loss: 1.030646800994873, Discriminator loss: 1.2978789806365967\n",
      "\tGenerator loss: 1.0001893043518066, Discriminator loss: 1.2535099983215332\n",
      "\tGenerator loss: 1.0387561321258545, Discriminator loss: 1.1672443151474\n",
      "\tGenerator loss: 1.0384644269943237, Discriminator loss: 1.2304468154907227\n",
      "\tGenerator loss: 1.0443224906921387, Discriminator loss: 1.2747445106506348\n",
      "\tGenerator loss: 1.055633306503296, Discriminator loss: 1.2027796506881714\n",
      "\tGenerator loss: 1.0089271068572998, Discriminator loss: 1.2303290367126465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.040920615196228, Discriminator loss: 1.2313364744186401\n",
      "\tGenerator loss: 1.0256500244140625, Discriminator loss: 1.2223236560821533\n",
      "\tGenerator loss: 1.0233879089355469, Discriminator loss: 1.2467143535614014\n",
      "\tGenerator loss: 1.0371578931808472, Discriminator loss: 1.2255953550338745\n",
      "\tGenerator loss: 1.0426790714263916, Discriminator loss: 1.218498945236206\n",
      "\tGenerator loss: 1.0037097930908203, Discriminator loss: 1.2575676441192627\n",
      "\tGenerator loss: 0.9983178377151489, Discriminator loss: 1.2450010776519775\n",
      "\tGenerator loss: 0.9582189321517944, Discriminator loss: 1.243422269821167\n",
      "\tGenerator loss: 0.9600189328193665, Discriminator loss: 1.194749355316162\n",
      "\tGenerator loss: 0.9978200197219849, Discriminator loss: 1.1902813911437988\n",
      "\tGenerator loss: 1.0946686267852783, Discriminator loss: 1.1779719591140747\n",
      "\tGenerator loss: 1.1565903425216675, Discriminator loss: 1.2172715663909912\n",
      "\tGenerator loss: 1.0913240909576416, Discriminator loss: 1.2249040603637695\n",
      "\tGenerator loss: 1.0322959423065186, Discriminator loss: 1.2148512601852417\n",
      "\tGenerator loss: 0.9693474173545837, Discriminator loss: 1.206491470336914\n",
      "\tGenerator loss: 1.0020911693572998, Discriminator loss: 1.1780033111572266\n",
      "\tGenerator loss: 1.039521336555481, Discriminator loss: 1.2136083841323853\n",
      "\tGenerator loss: 1.056239366531372, Discriminator loss: 1.2201249599456787\n",
      "\tGenerator loss: 1.0823755264282227, Discriminator loss: 1.1922402381896973\n",
      "\tGenerator loss: 1.048821210861206, Discriminator loss: 1.2457249164581299\n",
      "\tGenerator loss: 0.9681628346443176, Discriminator loss: 1.2716848850250244\n",
      "\tGenerator loss: 0.9097386002540588, Discriminator loss: 1.252258539199829\n",
      "\tGenerator loss: 0.894912838935852, Discriminator loss: 1.2638750076293945\n",
      "\tGenerator loss: 0.9271087646484375, Discriminator loss: 1.2768172025680542\n",
      "\tGenerator loss: 0.948555588722229, Discriminator loss: 1.2447983026504517\n",
      "\tGenerator loss: 0.9730892777442932, Discriminator loss: 1.2210114002227783\n",
      "\tGenerator loss: 1.0557419061660767, Discriminator loss: 1.2244184017181396\n",
      "\tGenerator loss: 1.0051921606063843, Discriminator loss: 1.1813030242919922\n",
      "\tGenerator loss: 0.9549981951713562, Discriminator loss: 1.2053401470184326\n",
      "\tGenerator loss: 0.9414358735084534, Discriminator loss: 1.2215627431869507\n",
      "\tGenerator loss: 0.9295140504837036, Discriminator loss: 1.2531073093414307\n",
      "\tGenerator loss: 0.9600550532341003, Discriminator loss: 1.198072910308838\n",
      "\tGenerator loss: 0.9907209873199463, Discriminator loss: 1.2111390829086304\n",
      "\tGenerator loss: 1.0215389728546143, Discriminator loss: 1.1680536270141602\n",
      "\tGenerator loss: 1.0360082387924194, Discriminator loss: 1.2036585807800293\n",
      "\tGenerator loss: 1.0197330713272095, Discriminator loss: 1.2047239542007446\n",
      "\tGenerator loss: 0.979037880897522, Discriminator loss: 1.1586241722106934\n",
      "\tGenerator loss: 0.9763883352279663, Discriminator loss: 1.1350719928741455\n",
      "\tGenerator loss: 0.9772661924362183, Discriminator loss: 1.1738239526748657\n",
      "\tGenerator loss: 1.0151772499084473, Discriminator loss: 1.1470673084259033\n",
      "\tGenerator loss: 1.0390452146530151, Discriminator loss: 1.146446704864502\n",
      "\tGenerator loss: 1.093754768371582, Discriminator loss: 1.0882189273834229\n",
      "\tGenerator loss: 1.1020987033843994, Discriminator loss: 1.0933552980422974\n",
      "\tGenerator loss: 1.0734772682189941, Discriminator loss: 1.078153371810913\n",
      "\tGenerator loss: 1.0559786558151245, Discriminator loss: 1.1080145835876465\n",
      "\tGenerator loss: 1.0129261016845703, Discriminator loss: 1.100654125213623\n",
      "\tGenerator loss: 1.0344724655151367, Discriminator loss: 1.1286091804504395\n",
      "\tGenerator loss: 1.075798511505127, Discriminator loss: 1.138352870941162\n",
      "\tGenerator loss: 1.076398253440857, Discriminator loss: 1.1146128177642822\n",
      "\tGenerator loss: 1.089332103729248, Discriminator loss: 1.084764003753662\n",
      "\tGenerator loss: 1.1333122253417969, Discriminator loss: 1.0442523956298828\n",
      "\tGenerator loss: 1.1189641952514648, Discriminator loss: 1.0320584774017334\n",
      "\tGenerator loss: 1.1134388446807861, Discriminator loss: 1.0546658039093018\n",
      "\tGenerator loss: 1.1070778369903564, Discriminator loss: 1.0360554456710815\n",
      "\tGenerator loss: 1.0792981386184692, Discriminator loss: 1.0198462009429932\n",
      "\tGenerator loss: 1.1470983028411865, Discriminator loss: 0.9901112914085388\n",
      "\tGenerator loss: 1.178916335105896, Discriminator loss: 1.0513670444488525\n",
      "\tGenerator loss: 1.1744885444641113, Discriminator loss: 1.1055290699005127\n",
      "\tGenerator loss: 1.1277120113372803, Discriminator loss: 1.0353933572769165\n",
      "\tGenerator loss: 1.0991199016571045, Discriminator loss: 1.0670034885406494\n",
      "\tGenerator loss: 1.1340042352676392, Discriminator loss: 1.0001049041748047\n",
      "\tGenerator loss: 1.138723611831665, Discriminator loss: 1.015254020690918\n",
      "\tGenerator loss: 1.1991722583770752, Discriminator loss: 0.9678774476051331\n",
      "\tGenerator loss: 1.196373701095581, Discriminator loss: 0.982373833656311\n",
      "\tGenerator loss: 1.2237024307250977, Discriminator loss: 0.9543161392211914\n",
      "\tGenerator loss: 1.2450454235076904, Discriminator loss: 1.0014070272445679\n",
      "\tGenerator loss: 1.232096552848816, Discriminator loss: 1.0356019735336304\n",
      "\tGenerator loss: 1.1787497997283936, Discriminator loss: 1.05869460105896\n",
      "\tGenerator loss: 1.1154060363769531, Discriminator loss: 1.0404610633850098\n",
      "\tGenerator loss: 1.0715879201889038, Discriminator loss: 1.0910775661468506\n",
      "\tGenerator loss: 1.107038974761963, Discriminator loss: 1.0717953443527222\n",
      "\tGenerator loss: 1.1583725214004517, Discriminator loss: 1.0873346328735352\n",
      "\tGenerator loss: 1.2068438529968262, Discriminator loss: 1.0582311153411865\n",
      "\tGenerator loss: 1.2168246507644653, Discriminator loss: 1.0835051536560059\n",
      "\tGenerator loss: 1.1735687255859375, Discriminator loss: 1.036696195602417\n",
      "\tGenerator loss: 1.1292202472686768, Discriminator loss: 0.9973158836364746\n",
      "\tGenerator loss: 1.1359977722167969, Discriminator loss: 0.9825814366340637\n",
      "\tGenerator loss: 1.1749074459075928, Discriminator loss: 1.0131347179412842\n",
      "\tGenerator loss: 1.2016453742980957, Discriminator loss: 1.0829037427902222\n",
      "\tGenerator loss: 1.1706130504608154, Discriminator loss: 1.0699279308319092\n",
      "\tGenerator loss: 1.169072151184082, Discriminator loss: 1.0566017627716064\n",
      "\tGenerator loss: 1.1912221908569336, Discriminator loss: 1.0759750604629517\n",
      "\tGenerator loss: 1.1562191247940063, Discriminator loss: 1.065397024154663\n",
      "\tGenerator loss: 1.095456838607788, Discriminator loss: 1.0857954025268555\n",
      "\tGenerator loss: 1.0496662855148315, Discriminator loss: 1.0709593296051025\n",
      "\tGenerator loss: 1.0513637065887451, Discriminator loss: 1.102346420288086\n",
      "\tGenerator loss: 1.13433039188385, Discriminator loss: 1.1068878173828125\n",
      "\tGenerator loss: 1.1512386798858643, Discriminator loss: 1.1228632926940918\n",
      "\tGenerator loss: 1.1101627349853516, Discriminator loss: 1.197199821472168\n",
      "\tGenerator loss: 1.0859147310256958, Discriminator loss: 1.2284420728683472\n",
      "\tGenerator loss: 1.0471436977386475, Discriminator loss: 1.264998197555542\n",
      "\tGenerator loss: 1.0272088050842285, Discriminator loss: 1.2804474830627441\n",
      "\tGenerator loss: 0.9843473434448242, Discriminator loss: 1.2737064361572266\n",
      "\tGenerator loss: 0.9562211036682129, Discriminator loss: 1.2979665994644165\n",
      "\tGenerator loss: 1.0203675031661987, Discriminator loss: 1.2645878791809082\n",
      "\tGenerator loss: 1.0583999156951904, Discriminator loss: 1.23974609375\n",
      "\tGenerator loss: 1.082582712173462, Discriminator loss: 1.2344757318496704\n",
      "\tGenerator loss: 1.0794334411621094, Discriminator loss: 1.2108089923858643\n",
      "\tGenerator loss: 1.0409693717956543, Discriminator loss: 1.2193235158920288\n",
      "\tGenerator loss: 1.0060627460479736, Discriminator loss: 1.2333149909973145\n",
      "\tGenerator loss: 0.9421086311340332, Discriminator loss: 1.2555899620056152\n",
      "\tGenerator loss: 0.9443392753601074, Discriminator loss: 1.311744213104248\n",
      "\tGenerator loss: 0.9689801931381226, Discriminator loss: 1.3007526397705078\n",
      "\tGenerator loss: 1.0383198261260986, Discriminator loss: 1.3039495944976807\n",
      "\tGenerator loss: 1.0569779872894287, Discriminator loss: 1.2237803936004639\n",
      "\tGenerator loss: 1.061020016670227, Discriminator loss: 1.2625707387924194\n",
      "\tGenerator loss: 1.0403308868408203, Discriminator loss: 1.2750709056854248\n",
      "\tGenerator loss: 0.9479066729545593, Discriminator loss: 1.3140074014663696\n",
      "\tGenerator loss: 0.8846840262413025, Discriminator loss: 1.2766075134277344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.899018406867981, Discriminator loss: 1.3162704706192017\n",
      "\tGenerator loss: 0.958550214767456, Discriminator loss: 1.3217283487319946\n",
      "\tGenerator loss: 1.001129388809204, Discriminator loss: 1.2950401306152344\n",
      "\tGenerator loss: 1.0440707206726074, Discriminator loss: 1.264575481414795\n",
      "\tGenerator loss: 1.0354615449905396, Discriminator loss: 1.271407127380371\n",
      "\tGenerator loss: 1.00117826461792, Discriminator loss: 1.3038256168365479\n",
      "\tGenerator loss: 0.9499505758285522, Discriminator loss: 1.27686607837677\n",
      "\tGenerator loss: 0.8970239758491516, Discriminator loss: 1.342268705368042\n",
      "\tGenerator loss: 0.9020742177963257, Discriminator loss: 1.3423585891723633\n",
      "\tGenerator loss: 0.9525582194328308, Discriminator loss: 1.293914556503296\n",
      "\tGenerator loss: 0.945458173751831, Discriminator loss: 1.332620620727539\n",
      "\tGenerator loss: 0.9468550086021423, Discriminator loss: 1.341468095779419\n",
      "\tGenerator loss: 0.9477027654647827, Discriminator loss: 1.3306891918182373\n",
      "\tGenerator loss: 0.9369219541549683, Discriminator loss: 1.3432776927947998\n",
      "\tGenerator loss: 0.9289054870605469, Discriminator loss: 1.3463289737701416\n",
      "\tGenerator loss: 0.9382975101470947, Discriminator loss: 1.3002417087554932\n",
      "\tGenerator loss: 0.9282787442207336, Discriminator loss: 1.308000087738037\n",
      "\tGenerator loss: 0.93764328956604, Discriminator loss: 1.2848353385925293\n",
      "\tGenerator loss: 0.9032474756240845, Discriminator loss: 1.2952454090118408\n",
      "\tGenerator loss: 0.9305479526519775, Discriminator loss: 1.252780556678772\n",
      "\tGenerator loss: 0.9376871585845947, Discriminator loss: 1.2652541399002075\n",
      "\tGenerator loss: 0.9299834966659546, Discriminator loss: 1.2776763439178467\n",
      "\tGenerator loss: 0.9577077627182007, Discriminator loss: 1.2818766832351685\n",
      "\tGenerator loss: 0.9673141241073608, Discriminator loss: 1.259346842765808\n",
      "\tGenerator loss: 0.9275973439216614, Discriminator loss: 1.244185209274292\n",
      "\tGenerator loss: 0.9290771484375, Discriminator loss: 1.2378027439117432\n",
      "\tGenerator loss: 0.9503928422927856, Discriminator loss: 1.2798596620559692\n",
      "\tGenerator loss: 1.0216631889343262, Discriminator loss: 1.2864272594451904\n",
      "\tGenerator loss: 1.0483603477478027, Discriminator loss: 1.3231265544891357\n",
      "Time for epoch 32 is 249.98582315444946 sec\n",
      "\tGenerator loss: 0.9688506126403809, Discriminator loss: 1.3066322803497314\n",
      "\tGenerator loss: 0.8710383772850037, Discriminator loss: 1.2708607912063599\n",
      "\tGenerator loss: 0.8356742858886719, Discriminator loss: 1.2640206813812256\n",
      "\tGenerator loss: 0.8581150770187378, Discriminator loss: 1.2530624866485596\n",
      "\tGenerator loss: 0.9377660155296326, Discriminator loss: 1.2719327211380005\n",
      "\tGenerator loss: 1.0117243528366089, Discriminator loss: 1.2562227249145508\n",
      "\tGenerator loss: 1.0784056186676025, Discriminator loss: 1.196671485900879\n",
      "\tGenerator loss: 1.0506213903427124, Discriminator loss: 1.246747374534607\n",
      "\tGenerator loss: 0.9931252002716064, Discriminator loss: 1.2175781726837158\n",
      "\tGenerator loss: 0.9462239742279053, Discriminator loss: 1.1783465147018433\n",
      "\tGenerator loss: 0.9636729955673218, Discriminator loss: 1.1619305610656738\n",
      "\tGenerator loss: 0.9918285012245178, Discriminator loss: 1.157151460647583\n",
      "\tGenerator loss: 1.0389684438705444, Discriminator loss: 1.1547062397003174\n",
      "\tGenerator loss: 1.0516910552978516, Discriminator loss: 1.1265608072280884\n",
      "\tGenerator loss: 1.0553172826766968, Discriminator loss: 1.1513032913208008\n",
      "\tGenerator loss: 1.007974624633789, Discriminator loss: 1.1290113925933838\n",
      "\tGenerator loss: 1.0126001834869385, Discriminator loss: 1.110656976699829\n",
      "\tGenerator loss: 1.0249360799789429, Discriminator loss: 1.0991816520690918\n",
      "\tGenerator loss: 1.0339992046356201, Discriminator loss: 1.1435480117797852\n",
      "\tGenerator loss: 1.0649436712265015, Discriminator loss: 1.121814489364624\n",
      "\tGenerator loss: 1.0817947387695312, Discriminator loss: 1.1069309711456299\n",
      "\tGenerator loss: 1.0756882429122925, Discriminator loss: 1.144134283065796\n",
      "\tGenerator loss: 1.0894399881362915, Discriminator loss: 1.1098213195800781\n",
      "\tGenerator loss: 1.0772733688354492, Discriminator loss: 1.1403727531433105\n",
      "\tGenerator loss: 1.0669479370117188, Discriminator loss: 1.1342945098876953\n",
      "\tGenerator loss: 1.0194977521896362, Discriminator loss: 1.1068930625915527\n",
      "\tGenerator loss: 1.0231132507324219, Discriminator loss: 1.0937166213989258\n",
      "\tGenerator loss: 1.063389539718628, Discriminator loss: 1.075709342956543\n",
      "\tGenerator loss: 1.1047104597091675, Discriminator loss: 1.1045799255371094\n",
      "\tGenerator loss: 1.113196849822998, Discriminator loss: 1.044234275817871\n",
      "\tGenerator loss: 1.0944947004318237, Discriminator loss: 1.0568122863769531\n",
      "\tGenerator loss: 1.0517752170562744, Discriminator loss: 1.0759882926940918\n",
      "\tGenerator loss: 1.0226590633392334, Discriminator loss: 1.0930843353271484\n",
      "\tGenerator loss: 1.0089844465255737, Discriminator loss: 1.1790993213653564\n",
      "\tGenerator loss: 1.03616201877594, Discriminator loss: 1.1502265930175781\n",
      "\tGenerator loss: 1.0919370651245117, Discriminator loss: 1.0993456840515137\n",
      "\tGenerator loss: 1.0999255180358887, Discriminator loss: 1.1123058795928955\n",
      "\tGenerator loss: 1.078563928604126, Discriminator loss: 1.1182231903076172\n",
      "\tGenerator loss: 1.0470741987228394, Discriminator loss: 1.080930233001709\n",
      "\tGenerator loss: 1.007734775543213, Discriminator loss: 1.0989598035812378\n",
      "\tGenerator loss: 1.0387259721755981, Discriminator loss: 1.1552929878234863\n",
      "\tGenerator loss: 1.1007251739501953, Discriminator loss: 1.1247045993804932\n",
      "\tGenerator loss: 1.100287675857544, Discriminator loss: 1.1583598852157593\n",
      "\tGenerator loss: 1.0320525169372559, Discriminator loss: 1.182161569595337\n",
      "\tGenerator loss: 1.020336389541626, Discriminator loss: 1.1664478778839111\n",
      "\tGenerator loss: 1.020470380783081, Discriminator loss: 1.1858185529708862\n",
      "\tGenerator loss: 1.0164265632629395, Discriminator loss: 1.173588514328003\n",
      "\tGenerator loss: 0.982272207736969, Discriminator loss: 1.1996716260910034\n",
      "\tGenerator loss: 0.9598071575164795, Discriminator loss: 1.1974375247955322\n",
      "\tGenerator loss: 0.9555940628051758, Discriminator loss: 1.1873304843902588\n",
      "\tGenerator loss: 1.0205837488174438, Discriminator loss: 1.2108510732650757\n",
      "\tGenerator loss: 1.0541144609451294, Discriminator loss: 1.2357709407806396\n",
      "\tGenerator loss: 1.0307092666625977, Discriminator loss: 1.2373749017715454\n",
      "\tGenerator loss: 0.9751617908477783, Discriminator loss: 1.2655935287475586\n",
      "\tGenerator loss: 0.9091391563415527, Discriminator loss: 1.2350353002548218\n",
      "\tGenerator loss: 0.9067015647888184, Discriminator loss: 1.2750979661941528\n",
      "\tGenerator loss: 0.9169763922691345, Discriminator loss: 1.2636829614639282\n",
      "\tGenerator loss: 0.9913018941879272, Discriminator loss: 1.246577262878418\n",
      "\tGenerator loss: 0.993502676486969, Discriminator loss: 1.235652208328247\n",
      "\tGenerator loss: 0.9982305765151978, Discriminator loss: 1.190213680267334\n",
      "\tGenerator loss: 0.9546258449554443, Discriminator loss: 1.1877588033676147\n",
      "\tGenerator loss: 0.9646746516227722, Discriminator loss: 1.1617183685302734\n",
      "\tGenerator loss: 0.9462975263595581, Discriminator loss: 1.2414239645004272\n",
      "\tGenerator loss: 0.9782612919807434, Discriminator loss: 1.224440336227417\n",
      "\tGenerator loss: 0.9818307161331177, Discriminator loss: 1.1985903978347778\n",
      "\tGenerator loss: 0.9759011268615723, Discriminator loss: 1.2236862182617188\n",
      "\tGenerator loss: 0.9745544791221619, Discriminator loss: 1.2654142379760742\n",
      "\tGenerator loss: 0.9351061582565308, Discriminator loss: 1.2317728996276855\n",
      "\tGenerator loss: 0.9421012997627258, Discriminator loss: 1.2574431896209717\n",
      "\tGenerator loss: 0.9240642786026001, Discriminator loss: 1.249216914176941\n",
      "\tGenerator loss: 0.9362795948982239, Discriminator loss: 1.2182822227478027\n",
      "\tGenerator loss: 0.9666173458099365, Discriminator loss: 1.2425345182418823\n",
      "\tGenerator loss: 0.973071277141571, Discriminator loss: 1.2281181812286377\n",
      "\tGenerator loss: 0.9704670906066895, Discriminator loss: 1.2310290336608887\n",
      "\tGenerator loss: 0.9597477912902832, Discriminator loss: 1.1984816789627075\n",
      "\tGenerator loss: 0.9732580184936523, Discriminator loss: 1.227818489074707\n",
      "\tGenerator loss: 1.0016276836395264, Discriminator loss: 1.2926489114761353\n",
      "\tGenerator loss: 0.9862118363380432, Discriminator loss: 1.3238136768341064\n",
      "\tGenerator loss: 0.971295952796936, Discriminator loss: 1.2909634113311768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9476532340049744, Discriminator loss: 1.3022613525390625\n",
      "\tGenerator loss: 0.943489670753479, Discriminator loss: 1.315237283706665\n",
      "\tGenerator loss: 0.9497644901275635, Discriminator loss: 1.2861756086349487\n",
      "\tGenerator loss: 0.908678412437439, Discriminator loss: 1.2634713649749756\n",
      "\tGenerator loss: 0.9266657829284668, Discriminator loss: 1.2327851057052612\n",
      "\tGenerator loss: 0.9763212203979492, Discriminator loss: 1.205885410308838\n",
      "\tGenerator loss: 1.0461207628250122, Discriminator loss: 1.2765589952468872\n",
      "\tGenerator loss: 1.0569201707839966, Discriminator loss: 1.2261087894439697\n",
      "\tGenerator loss: 1.0310733318328857, Discriminator loss: 1.2006382942199707\n",
      "\tGenerator loss: 0.9928187131881714, Discriminator loss: 1.267900824546814\n",
      "\tGenerator loss: 0.9380955100059509, Discriminator loss: 1.2546288967132568\n",
      "\tGenerator loss: 0.9365386962890625, Discriminator loss: 1.2550472021102905\n",
      "\tGenerator loss: 0.9713440537452698, Discriminator loss: 1.2163543701171875\n",
      "\tGenerator loss: 1.0291656255722046, Discriminator loss: 1.1632356643676758\n",
      "\tGenerator loss: 1.0524400472640991, Discriminator loss: 1.1667811870574951\n",
      "\tGenerator loss: 1.0343559980392456, Discriminator loss: 1.1940934658050537\n",
      "\tGenerator loss: 1.0028467178344727, Discriminator loss: 1.1419963836669922\n",
      "\tGenerator loss: 0.9627095460891724, Discriminator loss: 1.162144422531128\n",
      "\tGenerator loss: 0.9667831659317017, Discriminator loss: 1.1779651641845703\n",
      "\tGenerator loss: 0.9904194474220276, Discriminator loss: 1.1519749164581299\n",
      "\tGenerator loss: 1.0307393074035645, Discriminator loss: 1.2017319202423096\n",
      "\tGenerator loss: 1.0537230968475342, Discriminator loss: 1.208054542541504\n",
      "\tGenerator loss: 1.0287866592407227, Discriminator loss: 1.1992789506912231\n",
      "\tGenerator loss: 0.9599259495735168, Discriminator loss: 1.2200751304626465\n",
      "\tGenerator loss: 0.9228967428207397, Discriminator loss: 1.2021417617797852\n",
      "\tGenerator loss: 0.9374551773071289, Discriminator loss: 1.223340630531311\n",
      "\tGenerator loss: 0.939537763595581, Discriminator loss: 1.184959888458252\n",
      "\tGenerator loss: 0.9909619688987732, Discriminator loss: 1.1934332847595215\n",
      "\tGenerator loss: 1.0315399169921875, Discriminator loss: 1.1622384786605835\n",
      "\tGenerator loss: 1.088746190071106, Discriminator loss: 1.1492382287979126\n",
      "\tGenerator loss: 1.0635838508605957, Discriminator loss: 1.180248498916626\n",
      "\tGenerator loss: 1.021688461303711, Discriminator loss: 1.1901211738586426\n",
      "\tGenerator loss: 0.9706546068191528, Discriminator loss: 1.173966884613037\n",
      "\tGenerator loss: 0.9624788165092468, Discriminator loss: 1.1562212705612183\n",
      "\tGenerator loss: 1.039048671722412, Discriminator loss: 1.1494240760803223\n",
      "\tGenerator loss: 1.077796220779419, Discriminator loss: 1.158324956893921\n",
      "\tGenerator loss: 1.0892441272735596, Discriminator loss: 1.0951730012893677\n",
      "\tGenerator loss: 1.0951478481292725, Discriminator loss: 1.1109215021133423\n",
      "\tGenerator loss: 1.0040706396102905, Discriminator loss: 1.120816946029663\n",
      "\tGenerator loss: 0.9610901474952698, Discriminator loss: 1.1100983619689941\n",
      "\tGenerator loss: 0.9854865074157715, Discriminator loss: 1.1115689277648926\n",
      "\tGenerator loss: 1.0236623287200928, Discriminator loss: 1.1129311323165894\n",
      "\tGenerator loss: 1.0561193227767944, Discriminator loss: 1.1025879383087158\n",
      "\tGenerator loss: 1.1033374071121216, Discriminator loss: 1.0788331031799316\n",
      "\tGenerator loss: 1.1065844297409058, Discriminator loss: 1.0494025945663452\n",
      "\tGenerator loss: 1.0808589458465576, Discriminator loss: 1.0374140739440918\n",
      "\tGenerator loss: 1.068350076675415, Discriminator loss: 1.0700358152389526\n",
      "\tGenerator loss: 1.0799182653427124, Discriminator loss: 1.0939953327178955\n",
      "\tGenerator loss: 1.084932565689087, Discriminator loss: 1.0816423892974854\n",
      "\tGenerator loss: 1.0729033946990967, Discriminator loss: 1.0741357803344727\n",
      "\tGenerator loss: 1.084963321685791, Discriminator loss: 1.101506233215332\n",
      "\tGenerator loss: 1.0910747051239014, Discriminator loss: 1.0527434349060059\n",
      "\tGenerator loss: 1.078052282333374, Discriminator loss: 1.1219931840896606\n",
      "\tGenerator loss: 1.114617109298706, Discriminator loss: 1.1313612461090088\n",
      "\tGenerator loss: 1.0879400968551636, Discriminator loss: 1.0767701864242554\n",
      "\tGenerator loss: 1.0777778625488281, Discriminator loss: 1.0847373008728027\n",
      "\tGenerator loss: 1.0566353797912598, Discriminator loss: 1.1012901067733765\n",
      "\tGenerator loss: 1.107175588607788, Discriminator loss: 1.091219186782837\n",
      "\tGenerator loss: 1.1702628135681152, Discriminator loss: 1.0531554222106934\n",
      "\tGenerator loss: 1.1521878242492676, Discriminator loss: 1.0857959985733032\n",
      "\tGenerator loss: 1.169497013092041, Discriminator loss: 1.0546513795852661\n",
      "\tGenerator loss: 1.136266827583313, Discriminator loss: 1.0422921180725098\n",
      "\tGenerator loss: 1.0682121515274048, Discriminator loss: 1.1213200092315674\n",
      "\tGenerator loss: 1.1029250621795654, Discriminator loss: 1.112928867340088\n",
      "\tGenerator loss: 1.120331048965454, Discriminator loss: 1.187462329864502\n",
      "\tGenerator loss: 1.109815001487732, Discriminator loss: 1.1771279573440552\n",
      "\tGenerator loss: 1.0858033895492554, Discriminator loss: 1.16824209690094\n",
      "\tGenerator loss: 1.0709378719329834, Discriminator loss: 1.132416009902954\n",
      "\tGenerator loss: 1.078286051750183, Discriminator loss: 1.1200473308563232\n",
      "\tGenerator loss: 1.0573222637176514, Discriminator loss: 1.1253814697265625\n",
      "\tGenerator loss: 1.0901700258255005, Discriminator loss: 1.1448326110839844\n",
      "\tGenerator loss: 1.1192350387573242, Discriminator loss: 1.1248314380645752\n",
      "\tGenerator loss: 1.0927114486694336, Discriminator loss: 1.1327239274978638\n",
      "\tGenerator loss: 1.0220630168914795, Discriminator loss: 1.1650837659835815\n",
      "\tGenerator loss: 1.0076011419296265, Discriminator loss: 1.2353034019470215\n",
      "\tGenerator loss: 1.0084025859832764, Discriminator loss: 1.268915057182312\n",
      "\tGenerator loss: 1.0274505615234375, Discriminator loss: 1.2244188785552979\n",
      "\tGenerator loss: 1.0354626178741455, Discriminator loss: 1.225518822669983\n",
      "\tGenerator loss: 0.9907140731811523, Discriminator loss: 1.188619613647461\n",
      "\tGenerator loss: 1.0379724502563477, Discriminator loss: 1.1850377321243286\n",
      "\tGenerator loss: 1.1029199361801147, Discriminator loss: 1.1690376996994019\n",
      "\tGenerator loss: 1.072460651397705, Discriminator loss: 1.1824743747711182\n",
      "\tGenerator loss: 1.079856276512146, Discriminator loss: 1.133683681488037\n",
      "\tGenerator loss: 1.0557057857513428, Discriminator loss: 1.1819448471069336\n",
      "\tGenerator loss: 0.984663188457489, Discriminator loss: 1.2308242321014404\n",
      "\tGenerator loss: 0.9615610837936401, Discriminator loss: 1.2525993585586548\n",
      "\tGenerator loss: 0.9815462827682495, Discriminator loss: 1.240248680114746\n",
      "\tGenerator loss: 1.0152864456176758, Discriminator loss: 1.2501399517059326\n",
      "\tGenerator loss: 1.0419758558273315, Discriminator loss: 1.2546470165252686\n",
      "\tGenerator loss: 1.1036970615386963, Discriminator loss: 1.214949607849121\n",
      "\tGenerator loss: 1.0692479610443115, Discriminator loss: 1.171091914176941\n",
      "\tGenerator loss: 1.0174278020858765, Discriminator loss: 1.2485365867614746\n",
      "\tGenerator loss: 0.9979912042617798, Discriminator loss: 1.2353259325027466\n",
      "\tGenerator loss: 0.9943389892578125, Discriminator loss: 1.170830488204956\n",
      "\tGenerator loss: 1.0340615510940552, Discriminator loss: 1.138883352279663\n",
      "\tGenerator loss: 1.0451282262802124, Discriminator loss: 1.1981265544891357\n",
      "\tGenerator loss: 1.0453622341156006, Discriminator loss: 1.2490673065185547\n",
      "\tGenerator loss: 1.023078203201294, Discriminator loss: 1.2266663312911987\n",
      "\tGenerator loss: 0.9846460223197937, Discriminator loss: 1.205028772354126\n",
      "\tGenerator loss: 0.9754069447517395, Discriminator loss: 1.2447057962417603\n",
      "\tGenerator loss: 0.9547457695007324, Discriminator loss: 1.2980402708053589\n",
      "\tGenerator loss: 0.9813550710678101, Discriminator loss: 1.2448689937591553\n",
      "\tGenerator loss: 0.9532605409622192, Discriminator loss: 1.1903386116027832\n",
      "\tGenerator loss: 0.9697251319885254, Discriminator loss: 1.192423701286316\n",
      "\tGenerator loss: 0.9963111877441406, Discriminator loss: 1.231414794921875\n",
      "\tGenerator loss: 1.0788748264312744, Discriminator loss: 1.2591474056243896\n",
      "\tGenerator loss: 1.060695767402649, Discriminator loss: 1.2419006824493408\n",
      "\tGenerator loss: 0.9959180355072021, Discriminator loss: 1.191576361656189\n",
      "\tGenerator loss: 0.991733729839325, Discriminator loss: 1.2175065279006958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9736806154251099, Discriminator loss: 1.2126691341400146\n",
      "\tGenerator loss: 0.9721947908401489, Discriminator loss: 1.201149582862854\n",
      "\tGenerator loss: 1.0235381126403809, Discriminator loss: 1.226640224456787\n",
      "\tGenerator loss: 1.079498529434204, Discriminator loss: 1.2799357175827026\n",
      "\tGenerator loss: 1.0124021768569946, Discriminator loss: 1.280745029449463\n",
      "\tGenerator loss: 0.9545189738273621, Discriminator loss: 1.2592151165008545\n",
      "\tGenerator loss: 0.9405170679092407, Discriminator loss: 1.225376844406128\n",
      "\tGenerator loss: 0.918009877204895, Discriminator loss: 1.2175334692001343\n",
      "\tGenerator loss: 0.9549208879470825, Discriminator loss: 1.2295396327972412\n",
      "\tGenerator loss: 0.9624263644218445, Discriminator loss: 1.2558307647705078\n",
      "\tGenerator loss: 0.9520416259765625, Discriminator loss: 1.2586143016815186\n",
      "\tGenerator loss: 0.9644430875778198, Discriminator loss: 1.2371697425842285\n",
      "\tGenerator loss: 0.9828597903251648, Discriminator loss: 1.2332005500793457\n",
      "\tGenerator loss: 0.9910504817962646, Discriminator loss: 1.1791794300079346\n",
      "\tGenerator loss: 0.9879250526428223, Discriminator loss: 1.226141095161438\n",
      "\tGenerator loss: 0.963365912437439, Discriminator loss: 1.2316176891326904\n",
      "\tGenerator loss: 0.9656452536582947, Discriminator loss: 1.22084379196167\n",
      "\tGenerator loss: 0.9174672365188599, Discriminator loss: 1.200404167175293\n",
      "\tGenerator loss: 0.9387296438217163, Discriminator loss: 1.1981511116027832\n",
      "\tGenerator loss: 0.9234108924865723, Discriminator loss: 1.2218942642211914\n",
      "\tGenerator loss: 0.9686301350593567, Discriminator loss: 1.2093193531036377\n",
      "\tGenerator loss: 0.9959893226623535, Discriminator loss: 1.1804015636444092\n",
      "\tGenerator loss: 1.0110968351364136, Discriminator loss: 1.1922626495361328\n",
      "\tGenerator loss: 0.9932697415351868, Discriminator loss: 1.1846305131912231\n",
      "\tGenerator loss: 0.987144947052002, Discriminator loss: 1.2056409120559692\n",
      "\tGenerator loss: 0.9768633842468262, Discriminator loss: 1.247856855392456\n",
      "\tGenerator loss: 0.9620931148529053, Discriminator loss: 1.217348575592041\n",
      "\tGenerator loss: 0.9526249170303345, Discriminator loss: 1.2520129680633545\n",
      "\tGenerator loss: 0.9740933179855347, Discriminator loss: 1.223770260810852\n",
      "\tGenerator loss: 0.9978933334350586, Discriminator loss: 1.2687201499938965\n",
      "\tGenerator loss: 0.99905925989151, Discriminator loss: 1.2179970741271973\n",
      "\tGenerator loss: 1.0303670167922974, Discriminator loss: 1.209022879600525\n",
      "\tGenerator loss: 1.0165064334869385, Discriminator loss: 1.1822580099105835\n",
      "\tGenerator loss: 0.9749751687049866, Discriminator loss: 1.2084057331085205\n",
      "\tGenerator loss: 0.9887833595275879, Discriminator loss: 1.176339030265808\n",
      "\tGenerator loss: 1.0159868001937866, Discriminator loss: 1.1598351001739502\n",
      "\tGenerator loss: 1.036827564239502, Discriminator loss: 1.1677266359329224\n",
      "\tGenerator loss: 1.0186817646026611, Discriminator loss: 1.1374437808990479\n",
      "\tGenerator loss: 0.9896856546401978, Discriminator loss: 1.1381220817565918\n",
      "\tGenerator loss: 1.0121033191680908, Discriminator loss: 1.133849024772644\n",
      "\tGenerator loss: 1.0541621446609497, Discriminator loss: 1.164102554321289\n",
      "\tGenerator loss: 1.0517737865447998, Discriminator loss: 1.0898301601409912\n",
      "\tGenerator loss: 1.0313950777053833, Discriminator loss: 1.0912067890167236\n",
      "\tGenerator loss: 1.045701265335083, Discriminator loss: 1.1402451992034912\n",
      "\tGenerator loss: 1.0459651947021484, Discriminator loss: 1.2554290294647217\n",
      "\tGenerator loss: 1.0772031545639038, Discriminator loss: 1.3030428886413574\n",
      "\tGenerator loss: 1.0177812576293945, Discriminator loss: 1.1905381679534912\n",
      "Time for epoch 33 is 254.58809900283813 sec\n",
      "\tGenerator loss: 0.9728875756263733, Discriminator loss: 1.209716796875\n",
      "\tGenerator loss: 1.0238080024719238, Discriminator loss: 1.1387608051300049\n",
      "\tGenerator loss: 1.0138622522354126, Discriminator loss: 1.1764979362487793\n",
      "\tGenerator loss: 1.0367274284362793, Discriminator loss: 1.1896089315414429\n",
      "\tGenerator loss: 1.0323355197906494, Discriminator loss: 1.2437224388122559\n",
      "\tGenerator loss: 0.9967600107192993, Discriminator loss: 1.2823545932769775\n",
      "\tGenerator loss: 0.9533171653747559, Discriminator loss: 1.2296181917190552\n",
      "\tGenerator loss: 0.9965035319328308, Discriminator loss: 1.2962923049926758\n",
      "\tGenerator loss: 0.9990643262863159, Discriminator loss: 1.2446448802947998\n",
      "\tGenerator loss: 1.0262041091918945, Discriminator loss: 1.2020509243011475\n",
      "\tGenerator loss: 1.042536973953247, Discriminator loss: 1.2119202613830566\n",
      "\tGenerator loss: 1.027267575263977, Discriminator loss: 1.1891497373580933\n",
      "\tGenerator loss: 1.0306167602539062, Discriminator loss: 1.1928184032440186\n",
      "\tGenerator loss: 1.0053024291992188, Discriminator loss: 1.1935007572174072\n",
      "\tGenerator loss: 0.9806681871414185, Discriminator loss: 1.1768860816955566\n",
      "\tGenerator loss: 0.9965906739234924, Discriminator loss: 1.16386079788208\n",
      "\tGenerator loss: 1.0079214572906494, Discriminator loss: 1.1711969375610352\n",
      "\tGenerator loss: 1.0023196935653687, Discriminator loss: 1.1979466676712036\n",
      "\tGenerator loss: 1.0098388195037842, Discriminator loss: 1.2327275276184082\n",
      "\tGenerator loss: 1.0108755826950073, Discriminator loss: 1.1975078582763672\n",
      "\tGenerator loss: 1.0352575778961182, Discriminator loss: 1.1931113004684448\n",
      "\tGenerator loss: 1.078277587890625, Discriminator loss: 1.2197835445404053\n",
      "\tGenerator loss: 1.0520581007003784, Discriminator loss: 1.2062785625457764\n",
      "\tGenerator loss: 1.021191120147705, Discriminator loss: 1.2130295038223267\n",
      "\tGenerator loss: 0.9885038733482361, Discriminator loss: 1.242401123046875\n",
      "\tGenerator loss: 0.9894578456878662, Discriminator loss: 1.1692005395889282\n",
      "\tGenerator loss: 1.0287259817123413, Discriminator loss: 1.1778464317321777\n",
      "\tGenerator loss: 1.0606017112731934, Discriminator loss: 1.1362624168395996\n",
      "\tGenerator loss: 1.0617703199386597, Discriminator loss: 1.1821138858795166\n",
      "\tGenerator loss: 1.034754753112793, Discriminator loss: 1.1349248886108398\n",
      "\tGenerator loss: 0.9986132383346558, Discriminator loss: 1.133714199066162\n",
      "\tGenerator loss: 0.9780939817428589, Discriminator loss: 1.142996072769165\n",
      "\tGenerator loss: 1.0438027381896973, Discriminator loss: 1.1460165977478027\n",
      "\tGenerator loss: 1.0686019659042358, Discriminator loss: 1.176511287689209\n",
      "\tGenerator loss: 1.1275722980499268, Discriminator loss: 1.1646060943603516\n",
      "\tGenerator loss: 1.0572718381881714, Discriminator loss: 1.177534580230713\n",
      "\tGenerator loss: 1.0432957410812378, Discriminator loss: 1.165584921836853\n",
      "\tGenerator loss: 0.9956274628639221, Discriminator loss: 1.1924924850463867\n",
      "\tGenerator loss: 0.9748150110244751, Discriminator loss: 1.1338551044464111\n",
      "\tGenerator loss: 0.9899432063102722, Discriminator loss: 1.1213209629058838\n",
      "\tGenerator loss: 1.0593243837356567, Discriminator loss: 1.1158791780471802\n",
      "\tGenerator loss: 1.1731877326965332, Discriminator loss: 1.1331582069396973\n",
      "\tGenerator loss: 1.1903858184814453, Discriminator loss: 1.1087212562561035\n",
      "\tGenerator loss: 1.141014575958252, Discriminator loss: 1.111670732498169\n",
      "\tGenerator loss: 1.09958016872406, Discriminator loss: 1.094315528869629\n",
      "\tGenerator loss: 1.0204944610595703, Discriminator loss: 1.1376489400863647\n",
      "\tGenerator loss: 0.9629784822463989, Discriminator loss: 1.1576435565948486\n",
      "\tGenerator loss: 1.0057482719421387, Discriminator loss: 1.1116087436676025\n",
      "\tGenerator loss: 1.0730233192443848, Discriminator loss: 1.1029443740844727\n",
      "\tGenerator loss: 1.1110284328460693, Discriminator loss: 1.1033804416656494\n",
      "\tGenerator loss: 1.0903522968292236, Discriminator loss: 1.1481866836547852\n",
      "\tGenerator loss: 1.0594632625579834, Discriminator loss: 1.1120235919952393\n",
      "\tGenerator loss: 1.0360994338989258, Discriminator loss: 1.1029876470565796\n",
      "\tGenerator loss: 1.0033848285675049, Discriminator loss: 1.2022117376327515\n",
      "\tGenerator loss: 1.003049612045288, Discriminator loss: 1.1980326175689697\n",
      "\tGenerator loss: 1.0130438804626465, Discriminator loss: 1.2038872241973877\n",
      "\tGenerator loss: 1.026734709739685, Discriminator loss: 1.2077794075012207\n",
      "\tGenerator loss: 1.0007410049438477, Discriminator loss: 1.192643642425537\n",
      "\tGenerator loss: 0.9674562811851501, Discriminator loss: 1.1860421895980835\n",
      "\tGenerator loss: 0.9949545860290527, Discriminator loss: 1.1630067825317383\n",
      "\tGenerator loss: 0.9586701393127441, Discriminator loss: 1.2076016664505005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9620407819747925, Discriminator loss: 1.1766417026519775\n",
      "\tGenerator loss: 0.9532623291015625, Discriminator loss: 1.2078943252563477\n",
      "\tGenerator loss: 0.9610263705253601, Discriminator loss: 1.2079360485076904\n",
      "\tGenerator loss: 1.0045229196548462, Discriminator loss: 1.1837611198425293\n",
      "\tGenerator loss: 0.9892320036888123, Discriminator loss: 1.1793875694274902\n",
      "\tGenerator loss: 0.995755672454834, Discriminator loss: 1.1962127685546875\n",
      "\tGenerator loss: 0.9656816720962524, Discriminator loss: 1.1816160678863525\n",
      "\tGenerator loss: 0.9386523962020874, Discriminator loss: 1.2121763229370117\n",
      "\tGenerator loss: 0.9646264314651489, Discriminator loss: 1.1748342514038086\n",
      "\tGenerator loss: 0.9464698433876038, Discriminator loss: 1.173133134841919\n",
      "\tGenerator loss: 0.9709432721138, Discriminator loss: 1.1834685802459717\n",
      "\tGenerator loss: 1.0404613018035889, Discriminator loss: 1.1371763944625854\n",
      "\tGenerator loss: 1.0264461040496826, Discriminator loss: 1.157848596572876\n",
      "\tGenerator loss: 1.0393332242965698, Discriminator loss: 1.1132121086120605\n",
      "\tGenerator loss: 1.0233633518218994, Discriminator loss: 1.1808884143829346\n",
      "\tGenerator loss: 1.0076417922973633, Discriminator loss: 1.2581278085708618\n",
      "\tGenerator loss: 0.9543232321739197, Discriminator loss: 1.268610954284668\n",
      "\tGenerator loss: 0.9518128633499146, Discriminator loss: 1.2326874732971191\n",
      "\tGenerator loss: 0.9818621277809143, Discriminator loss: 1.2066988945007324\n",
      "\tGenerator loss: 0.9975148439407349, Discriminator loss: 1.2631993293762207\n",
      "\tGenerator loss: 1.0132124423980713, Discriminator loss: 1.2256183624267578\n",
      "\tGenerator loss: 1.0093433856964111, Discriminator loss: 1.1620521545410156\n",
      "\tGenerator loss: 1.0448957681655884, Discriminator loss: 1.1442468166351318\n",
      "\tGenerator loss: 1.0258121490478516, Discriminator loss: 1.1106586456298828\n",
      "\tGenerator loss: 1.0549101829528809, Discriminator loss: 1.2453341484069824\n",
      "\tGenerator loss: 1.0246574878692627, Discriminator loss: 1.144855260848999\n",
      "\tGenerator loss: 1.0190095901489258, Discriminator loss: 1.1707004308700562\n",
      "\tGenerator loss: 1.056383728981018, Discriminator loss: 1.3036712408065796\n",
      "\tGenerator loss: 1.036353349685669, Discriminator loss: 1.3306427001953125\n",
      "\tGenerator loss: 0.9761552214622498, Discriminator loss: 1.3417766094207764\n",
      "\tGenerator loss: 0.9055335521697998, Discriminator loss: 1.3147212266921997\n",
      "\tGenerator loss: 0.9522445201873779, Discriminator loss: 1.1871449947357178\n",
      "\tGenerator loss: 0.9807320237159729, Discriminator loss: 1.2254242897033691\n",
      "\tGenerator loss: 1.0481109619140625, Discriminator loss: 1.2655538320541382\n",
      "\tGenerator loss: 1.009801983833313, Discriminator loss: 1.2513964176177979\n",
      "\tGenerator loss: 1.0298223495483398, Discriminator loss: 1.2581639289855957\n",
      "\tGenerator loss: 0.9970864653587341, Discriminator loss: 1.2222073078155518\n",
      "\tGenerator loss: 0.9638354778289795, Discriminator loss: 1.247727394104004\n",
      "\tGenerator loss: 0.9581183791160583, Discriminator loss: 1.3186885118484497\n",
      "\tGenerator loss: 0.9787566661834717, Discriminator loss: 1.283388376235962\n",
      "\tGenerator loss: 0.9638420343399048, Discriminator loss: 1.2656183242797852\n",
      "\tGenerator loss: 0.957706868648529, Discriminator loss: 1.2687526941299438\n",
      "\tGenerator loss: 0.9586905241012573, Discriminator loss: 1.2113842964172363\n",
      "\tGenerator loss: 0.9549139738082886, Discriminator loss: 1.3068852424621582\n",
      "\tGenerator loss: 0.9485325813293457, Discriminator loss: 1.281418800354004\n",
      "\tGenerator loss: 0.9771788120269775, Discriminator loss: 1.3224314451217651\n",
      "\tGenerator loss: 0.9949742555618286, Discriminator loss: 1.2565605640411377\n",
      "\tGenerator loss: 1.0035675764083862, Discriminator loss: 1.2047215700149536\n",
      "\tGenerator loss: 0.9977490901947021, Discriminator loss: 1.3022429943084717\n",
      "\tGenerator loss: 1.0001245737075806, Discriminator loss: 1.3690201044082642\n",
      "\tGenerator loss: 0.959716796875, Discriminator loss: 1.3871469497680664\n",
      "\tGenerator loss: 0.9047166705131531, Discriminator loss: 1.3325318098068237\n",
      "\tGenerator loss: 0.8940523862838745, Discriminator loss: 1.2965457439422607\n",
      "\tGenerator loss: 0.9766579270362854, Discriminator loss: 1.3690412044525146\n",
      "\tGenerator loss: 1.04107666015625, Discriminator loss: 1.299511432647705\n",
      "\tGenerator loss: 1.0554736852645874, Discriminator loss: 1.2633576393127441\n",
      "\tGenerator loss: 1.0079046487808228, Discriminator loss: 1.2437543869018555\n",
      "\tGenerator loss: 0.9532681107521057, Discriminator loss: 1.2306698560714722\n",
      "\tGenerator loss: 0.9284946918487549, Discriminator loss: 1.214233160018921\n",
      "\tGenerator loss: 0.9513742327690125, Discriminator loss: 1.2244617938995361\n",
      "\tGenerator loss: 0.9794248342514038, Discriminator loss: 1.2090823650360107\n",
      "\tGenerator loss: 1.0056394338607788, Discriminator loss: 1.2159662246704102\n",
      "\tGenerator loss: 1.0290427207946777, Discriminator loss: 1.169190526008606\n",
      "\tGenerator loss: 1.0193082094192505, Discriminator loss: 1.1572093963623047\n",
      "\tGenerator loss: 1.0393083095550537, Discriminator loss: 1.1921414136886597\n",
      "\tGenerator loss: 1.006962776184082, Discriminator loss: 1.2657041549682617\n",
      "\tGenerator loss: 0.9839246273040771, Discriminator loss: 1.2614574432373047\n",
      "\tGenerator loss: 0.9835603833198547, Discriminator loss: 1.1744630336761475\n",
      "\tGenerator loss: 0.9992349147796631, Discriminator loss: 1.2075302600860596\n",
      "\tGenerator loss: 1.0417933464050293, Discriminator loss: 1.151778221130371\n",
      "\tGenerator loss: 1.0442042350769043, Discriminator loss: 1.215685248374939\n",
      "\tGenerator loss: 1.0278923511505127, Discriminator loss: 1.2140079736709595\n",
      "\tGenerator loss: 0.9960184097290039, Discriminator loss: 1.18471097946167\n",
      "\tGenerator loss: 1.0111408233642578, Discriminator loss: 1.1558085680007935\n",
      "\tGenerator loss: 1.0390788316726685, Discriminator loss: 1.197862148284912\n",
      "\tGenerator loss: 1.044043779373169, Discriminator loss: 1.2064870595932007\n",
      "\tGenerator loss: 1.0536208152770996, Discriminator loss: 1.1899230480194092\n",
      "\tGenerator loss: 1.0547916889190674, Discriminator loss: 1.1686904430389404\n",
      "\tGenerator loss: 1.0461502075195312, Discriminator loss: 1.186798334121704\n",
      "\tGenerator loss: 1.0207138061523438, Discriminator loss: 1.2142003774642944\n",
      "\tGenerator loss: 1.0201619863510132, Discriminator loss: 1.1722090244293213\n",
      "\tGenerator loss: 1.0287539958953857, Discriminator loss: 1.1484373807907104\n",
      "\tGenerator loss: 1.0948359966278076, Discriminator loss: 1.1407670974731445\n",
      "\tGenerator loss: 1.0960079431533813, Discriminator loss: 1.1503158807754517\n",
      "\tGenerator loss: 1.1087210178375244, Discriminator loss: 1.1391351222991943\n",
      "\tGenerator loss: 1.107715368270874, Discriminator loss: 1.1884827613830566\n",
      "\tGenerator loss: 1.0723700523376465, Discriminator loss: 1.1733165979385376\n",
      "\tGenerator loss: 1.0313847064971924, Discriminator loss: 1.1325873136520386\n",
      "\tGenerator loss: 0.9962155222892761, Discriminator loss: 1.1622943878173828\n",
      "\tGenerator loss: 1.009056568145752, Discriminator loss: 1.1318409442901611\n",
      "\tGenerator loss: 1.0338759422302246, Discriminator loss: 1.1293705701828003\n",
      "\tGenerator loss: 1.083282470703125, Discriminator loss: 1.1480275392532349\n",
      "\tGenerator loss: 1.0969126224517822, Discriminator loss: 1.1618746519088745\n",
      "\tGenerator loss: 1.0891189575195312, Discriminator loss: 1.161181926727295\n",
      "\tGenerator loss: 1.0765831470489502, Discriminator loss: 1.162283182144165\n",
      "\tGenerator loss: 1.0141297578811646, Discriminator loss: 1.1661646366119385\n",
      "\tGenerator loss: 0.9744229316711426, Discriminator loss: 1.120369791984558\n",
      "\tGenerator loss: 0.9968854188919067, Discriminator loss: 1.141343593597412\n",
      "\tGenerator loss: 1.089207410812378, Discriminator loss: 1.1436115503311157\n",
      "\tGenerator loss: 1.1239410638809204, Discriminator loss: 1.1394588947296143\n",
      "\tGenerator loss: 1.106536865234375, Discriminator loss: 1.0941985845565796\n",
      "\tGenerator loss: 1.0837938785552979, Discriminator loss: 1.1491341590881348\n",
      "\tGenerator loss: 1.0011019706726074, Discriminator loss: 1.161428451538086\n",
      "\tGenerator loss: 0.9533371925354004, Discriminator loss: 1.1138945817947388\n",
      "\tGenerator loss: 0.9529064297676086, Discriminator loss: 1.104419231414795\n",
      "\tGenerator loss: 1.0548732280731201, Discriminator loss: 1.1010254621505737\n",
      "\tGenerator loss: 1.1679335832595825, Discriminator loss: 1.0795016288757324\n",
      "\tGenerator loss: 1.219951868057251, Discriminator loss: 1.0697534084320068\n",
      "\tGenerator loss: 1.1759073734283447, Discriminator loss: 1.0596004724502563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.110440731048584, Discriminator loss: 1.0715241432189941\n",
      "\tGenerator loss: 1.0632885694503784, Discriminator loss: 1.058121681213379\n",
      "\tGenerator loss: 1.0444283485412598, Discriminator loss: 1.0323073863983154\n",
      "\tGenerator loss: 1.051140546798706, Discriminator loss: 1.0704259872436523\n",
      "\tGenerator loss: 1.1172051429748535, Discriminator loss: 1.0945022106170654\n",
      "\tGenerator loss: 1.1417348384857178, Discriminator loss: 1.0791810750961304\n",
      "\tGenerator loss: 1.122100830078125, Discriminator loss: 1.1007981300354004\n",
      "\tGenerator loss: 1.09341299533844, Discriminator loss: 1.0893102884292603\n",
      "\tGenerator loss: 1.073603868484497, Discriminator loss: 1.093599557876587\n",
      "\tGenerator loss: 1.0542181730270386, Discriminator loss: 1.1155855655670166\n",
      "\tGenerator loss: 1.044995665550232, Discriminator loss: 1.078857183456421\n",
      "\tGenerator loss: 0.9905861020088196, Discriminator loss: 1.0785850286483765\n",
      "\tGenerator loss: 1.0349476337432861, Discriminator loss: 1.1062811613082886\n",
      "\tGenerator loss: 1.1404129266738892, Discriminator loss: 1.0810816287994385\n",
      "\tGenerator loss: 1.2183177471160889, Discriminator loss: 1.1098647117614746\n",
      "\tGenerator loss: 1.2055975198745728, Discriminator loss: 1.0633909702301025\n",
      "\tGenerator loss: 1.1287665367126465, Discriminator loss: 1.0830473899841309\n",
      "\tGenerator loss: 1.0684118270874023, Discriminator loss: 1.1154215335845947\n",
      "\tGenerator loss: 1.0097649097442627, Discriminator loss: 1.1595664024353027\n",
      "\tGenerator loss: 1.039703130722046, Discriminator loss: 1.1168264150619507\n",
      "\tGenerator loss: 1.0394591093063354, Discriminator loss: 1.1643874645233154\n",
      "\tGenerator loss: 1.0900828838348389, Discriminator loss: 1.1293153762817383\n",
      "\tGenerator loss: 1.103032112121582, Discriminator loss: 1.1389168500900269\n",
      "\tGenerator loss: 1.1130387783050537, Discriminator loss: 1.0953333377838135\n",
      "\tGenerator loss: 1.045103669166565, Discriminator loss: 1.0870068073272705\n",
      "\tGenerator loss: 1.0196545124053955, Discriminator loss: 1.101369857788086\n",
      "\tGenerator loss: 1.0339794158935547, Discriminator loss: 1.1495792865753174\n",
      "\tGenerator loss: 1.044475793838501, Discriminator loss: 1.1359093189239502\n",
      "\tGenerator loss: 1.0354408025741577, Discriminator loss: 1.1944465637207031\n",
      "\tGenerator loss: 0.9840616583824158, Discriminator loss: 1.183218002319336\n",
      "\tGenerator loss: 0.9848668575286865, Discriminator loss: 1.1909712553024292\n",
      "\tGenerator loss: 1.004690170288086, Discriminator loss: 1.158468246459961\n",
      "\tGenerator loss: 1.0324575901031494, Discriminator loss: 1.15093994140625\n",
      "\tGenerator loss: 1.0513198375701904, Discriminator loss: 1.1531239748001099\n",
      "\tGenerator loss: 1.0329362154006958, Discriminator loss: 1.20179283618927\n",
      "\tGenerator loss: 0.9655256271362305, Discriminator loss: 1.1657367944717407\n",
      "\tGenerator loss: 0.9541109800338745, Discriminator loss: 1.198653221130371\n",
      "\tGenerator loss: 0.9887506365776062, Discriminator loss: 1.198537826538086\n",
      "\tGenerator loss: 1.0194430351257324, Discriminator loss: 1.2012999057769775\n",
      "\tGenerator loss: 1.0408848524093628, Discriminator loss: 1.1889715194702148\n",
      "\tGenerator loss: 1.0256898403167725, Discriminator loss: 1.1778534650802612\n",
      "\tGenerator loss: 0.9639761447906494, Discriminator loss: 1.2239294052124023\n",
      "\tGenerator loss: 0.9417804479598999, Discriminator loss: 1.293632984161377\n",
      "\tGenerator loss: 0.9676310420036316, Discriminator loss: 1.3024243116378784\n",
      "\tGenerator loss: 0.911058783531189, Discriminator loss: 1.2813692092895508\n",
      "\tGenerator loss: 0.899821400642395, Discriminator loss: 1.3178811073303223\n",
      "\tGenerator loss: 0.9229363203048706, Discriminator loss: 1.345585584640503\n",
      "\tGenerator loss: 0.9546304941177368, Discriminator loss: 1.4009318351745605\n",
      "\tGenerator loss: 0.9576106071472168, Discriminator loss: 1.3656527996063232\n",
      "\tGenerator loss: 0.9331329464912415, Discriminator loss: 1.3482544422149658\n",
      "\tGenerator loss: 0.907172679901123, Discriminator loss: 1.319377064704895\n",
      "\tGenerator loss: 0.8633534908294678, Discriminator loss: 1.3206145763397217\n",
      "\tGenerator loss: 0.8513368964195251, Discriminator loss: 1.340893268585205\n",
      "\tGenerator loss: 0.9034140110015869, Discriminator loss: 1.3337857723236084\n",
      "\tGenerator loss: 0.945897102355957, Discriminator loss: 1.2945665121078491\n",
      "\tGenerator loss: 0.9508552551269531, Discriminator loss: 1.2911224365234375\n",
      "\tGenerator loss: 0.9495359659194946, Discriminator loss: 1.2996704578399658\n",
      "\tGenerator loss: 0.9066958427429199, Discriminator loss: 1.2732651233673096\n",
      "\tGenerator loss: 0.8891329765319824, Discriminator loss: 1.3280034065246582\n",
      "\tGenerator loss: 0.8992850184440613, Discriminator loss: 1.2852087020874023\n",
      "\tGenerator loss: 0.9074618816375732, Discriminator loss: 1.2558039426803589\n",
      "\tGenerator loss: 0.9322830438613892, Discriminator loss: 1.257194995880127\n",
      "\tGenerator loss: 0.9952834844589233, Discriminator loss: 1.313581943511963\n",
      "\tGenerator loss: 1.0474553108215332, Discriminator loss: 1.3581217527389526\n",
      "\tGenerator loss: 1.0115952491760254, Discriminator loss: 1.3152258396148682\n",
      "Time for epoch 34 is 251.92864298820496 sec\n",
      "\tGenerator loss: 0.8869830965995789, Discriminator loss: 1.3439924716949463\n",
      "\tGenerator loss: 0.8006215691566467, Discriminator loss: 1.346092939376831\n",
      "\tGenerator loss: 0.7922738194465637, Discriminator loss: 1.3423494100570679\n",
      "\tGenerator loss: 0.8478115200996399, Discriminator loss: 1.3194231986999512\n",
      "\tGenerator loss: 0.9621149301528931, Discriminator loss: 1.3600537776947021\n",
      "\tGenerator loss: 1.045717477798462, Discriminator loss: 1.3367068767547607\n",
      "\tGenerator loss: 1.039946436882019, Discriminator loss: 1.3056766986846924\n",
      "\tGenerator loss: 0.9525383114814758, Discriminator loss: 1.3161399364471436\n",
      "\tGenerator loss: 0.858251690864563, Discriminator loss: 1.3069037199020386\n",
      "\tGenerator loss: 0.8116108179092407, Discriminator loss: 1.2920154333114624\n",
      "\tGenerator loss: 0.8778002262115479, Discriminator loss: 1.2804194688796997\n",
      "\tGenerator loss: 0.9805850982666016, Discriminator loss: 1.2785656452178955\n",
      "\tGenerator loss: 1.0662329196929932, Discriminator loss: 1.29886794090271\n",
      "\tGenerator loss: 1.0206146240234375, Discriminator loss: 1.273483157157898\n",
      "\tGenerator loss: 0.9429688453674316, Discriminator loss: 1.2807917594909668\n",
      "\tGenerator loss: 0.8713250160217285, Discriminator loss: 1.2509613037109375\n",
      "\tGenerator loss: 0.8408366441726685, Discriminator loss: 1.2485628128051758\n",
      "\tGenerator loss: 0.8763599395751953, Discriminator loss: 1.2060827016830444\n",
      "\tGenerator loss: 0.9374982118606567, Discriminator loss: 1.235999584197998\n",
      "\tGenerator loss: 1.032710313796997, Discriminator loss: 1.2454228401184082\n",
      "\tGenerator loss: 1.0849454402923584, Discriminator loss: 1.210556983947754\n",
      "\tGenerator loss: 1.0888608694076538, Discriminator loss: 1.2004863023757935\n",
      "\tGenerator loss: 1.026864767074585, Discriminator loss: 1.190385341644287\n",
      "\tGenerator loss: 0.9331837892532349, Discriminator loss: 1.2131125926971436\n",
      "\tGenerator loss: 0.8953766226768494, Discriminator loss: 1.223292350769043\n",
      "\tGenerator loss: 0.9229193329811096, Discriminator loss: 1.1785277128219604\n",
      "\tGenerator loss: 0.9956992864608765, Discriminator loss: 1.195205807685852\n",
      "\tGenerator loss: 1.0393500328063965, Discriminator loss: 1.164613962173462\n",
      "\tGenerator loss: 1.042385458946228, Discriminator loss: 1.2382006645202637\n",
      "\tGenerator loss: 0.9588748216629028, Discriminator loss: 1.1751682758331299\n",
      "\tGenerator loss: 0.90830397605896, Discriminator loss: 1.1558696031570435\n",
      "\tGenerator loss: 0.8959448337554932, Discriminator loss: 1.1552784442901611\n",
      "\tGenerator loss: 0.9469891786575317, Discriminator loss: 1.1436913013458252\n",
      "\tGenerator loss: 1.0528478622436523, Discriminator loss: 1.1472346782684326\n",
      "\tGenerator loss: 1.1143581867218018, Discriminator loss: 1.175440788269043\n",
      "\tGenerator loss: 1.149448275566101, Discriminator loss: 1.155350685119629\n",
      "\tGenerator loss: 1.1158936023712158, Discriminator loss: 1.138495922088623\n",
      "\tGenerator loss: 1.0317747592926025, Discriminator loss: 1.1309762001037598\n",
      "\tGenerator loss: 0.9280838966369629, Discriminator loss: 1.096533179283142\n",
      "\tGenerator loss: 0.9065048098564148, Discriminator loss: 1.0947898626327515\n",
      "\tGenerator loss: 0.9743530750274658, Discriminator loss: 1.112945556640625\n",
      "\tGenerator loss: 1.1259135007858276, Discriminator loss: 1.0895323753356934\n",
      "\tGenerator loss: 1.2364232540130615, Discriminator loss: 1.0794923305511475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.2318874597549438, Discriminator loss: 1.0867983102798462\n",
      "\tGenerator loss: 1.1822744607925415, Discriminator loss: 1.0573452711105347\n",
      "\tGenerator loss: 1.0548818111419678, Discriminator loss: 1.0874426364898682\n",
      "\tGenerator loss: 0.9617608785629272, Discriminator loss: 1.1109287738800049\n",
      "\tGenerator loss: 0.9337549209594727, Discriminator loss: 1.109908103942871\n",
      "\tGenerator loss: 0.9637293815612793, Discriminator loss: 1.0819127559661865\n",
      "\tGenerator loss: 1.013261318206787, Discriminator loss: 1.0686156749725342\n",
      "\tGenerator loss: 1.1288142204284668, Discriminator loss: 1.0920428037643433\n",
      "\tGenerator loss: 1.1999430656433105, Discriminator loss: 1.0753705501556396\n",
      "\tGenerator loss: 1.1915379762649536, Discriminator loss: 1.0668758153915405\n",
      "\tGenerator loss: 1.1214385032653809, Discriminator loss: 1.0852564573287964\n",
      "\tGenerator loss: 1.0908946990966797, Discriminator loss: 1.0431599617004395\n",
      "\tGenerator loss: 1.0028347969055176, Discriminator loss: 1.0993622541427612\n",
      "\tGenerator loss: 0.9684014320373535, Discriminator loss: 1.078535795211792\n",
      "\tGenerator loss: 1.0173535346984863, Discriminator loss: 1.0470536947250366\n",
      "\tGenerator loss: 1.0342628955841064, Discriminator loss: 1.0466830730438232\n",
      "\tGenerator loss: 1.100447654724121, Discriminator loss: 1.0364887714385986\n",
      "\tGenerator loss: 1.167399525642395, Discriminator loss: 1.034529209136963\n",
      "\tGenerator loss: 1.126021385192871, Discriminator loss: 1.023275375366211\n",
      "\tGenerator loss: 1.066574215888977, Discriminator loss: 1.0781586170196533\n",
      "\tGenerator loss: 1.0413627624511719, Discriminator loss: 1.0801267623901367\n",
      "\tGenerator loss: 1.0047626495361328, Discriminator loss: 1.0781522989273071\n",
      "\tGenerator loss: 1.0014712810516357, Discriminator loss: 1.0538063049316406\n",
      "\tGenerator loss: 1.0327509641647339, Discriminator loss: 1.112837553024292\n",
      "\tGenerator loss: 1.0227450132369995, Discriminator loss: 1.1104981899261475\n",
      "\tGenerator loss: 1.0451295375823975, Discriminator loss: 1.1165032386779785\n",
      "\tGenerator loss: 1.0821752548217773, Discriminator loss: 1.0900105237960815\n",
      "\tGenerator loss: 1.0555574893951416, Discriminator loss: 1.0916759967803955\n",
      "\tGenerator loss: 1.0067470073699951, Discriminator loss: 1.131701946258545\n",
      "\tGenerator loss: 0.9521610140800476, Discriminator loss: 1.1266485452651978\n",
      "\tGenerator loss: 0.949283242225647, Discriminator loss: 1.1475505828857422\n",
      "\tGenerator loss: 0.9630879163742065, Discriminator loss: 1.1148210763931274\n",
      "\tGenerator loss: 1.059139370918274, Discriminator loss: 1.185521125793457\n",
      "\tGenerator loss: 1.0874850749969482, Discriminator loss: 1.2691912651062012\n",
      "\tGenerator loss: 1.0731197595596313, Discriminator loss: 1.2661375999450684\n",
      "\tGenerator loss: 1.0106244087219238, Discriminator loss: 1.2299456596374512\n",
      "\tGenerator loss: 0.9715909957885742, Discriminator loss: 1.2234021425247192\n",
      "\tGenerator loss: 0.8847216963768005, Discriminator loss: 1.3182330131530762\n",
      "\tGenerator loss: 0.8985735177993774, Discriminator loss: 1.2828235626220703\n",
      "\tGenerator loss: 0.9167469143867493, Discriminator loss: 1.2420933246612549\n",
      "\tGenerator loss: 0.9662564992904663, Discriminator loss: 1.2593297958374023\n",
      "\tGenerator loss: 1.0053104162216187, Discriminator loss: 1.2533373832702637\n",
      "\tGenerator loss: 0.9849530458450317, Discriminator loss: 1.362412929534912\n",
      "\tGenerator loss: 0.9526905417442322, Discriminator loss: 1.3047709465026855\n",
      "\tGenerator loss: 0.9514384269714355, Discriminator loss: 1.3156602382659912\n",
      "\tGenerator loss: 0.9216369390487671, Discriminator loss: 1.4066832065582275\n",
      "\tGenerator loss: 0.9023955464363098, Discriminator loss: 1.4011799097061157\n",
      "\tGenerator loss: 0.9066599607467651, Discriminator loss: 1.3600578308105469\n",
      "\tGenerator loss: 0.885787308216095, Discriminator loss: 1.3476338386535645\n",
      "\tGenerator loss: 0.8931354284286499, Discriminator loss: 1.317788004875183\n",
      "\tGenerator loss: 0.9380370378494263, Discriminator loss: 1.3591289520263672\n",
      "\tGenerator loss: 0.9317218661308289, Discriminator loss: 1.3995102643966675\n",
      "\tGenerator loss: 0.9393504858016968, Discriminator loss: 1.3482372760772705\n",
      "\tGenerator loss: 0.9122327566146851, Discriminator loss: 1.3593056201934814\n",
      "\tGenerator loss: 0.8594359755516052, Discriminator loss: 1.4009625911712646\n",
      "\tGenerator loss: 0.8415220975875854, Discriminator loss: 1.3590106964111328\n",
      "\tGenerator loss: 0.8562705516815186, Discriminator loss: 1.3947588205337524\n",
      "\tGenerator loss: 0.8840345740318298, Discriminator loss: 1.3949320316314697\n",
      "\tGenerator loss: 0.8996872901916504, Discriminator loss: 1.3997304439544678\n",
      "\tGenerator loss: 0.8808490633964539, Discriminator loss: 1.4214454889297485\n",
      "\tGenerator loss: 0.8387665748596191, Discriminator loss: 1.4391558170318604\n",
      "\tGenerator loss: 0.7828526496887207, Discriminator loss: 1.4379630088806152\n",
      "\tGenerator loss: 0.7872962355613708, Discriminator loss: 1.3843121528625488\n",
      "\tGenerator loss: 0.8440258502960205, Discriminator loss: 1.3855677843093872\n",
      "\tGenerator loss: 0.8995101451873779, Discriminator loss: 1.3418264389038086\n",
      "\tGenerator loss: 0.9320996999740601, Discriminator loss: 1.3940180540084839\n",
      "\tGenerator loss: 0.9073630571365356, Discriminator loss: 1.3990659713745117\n",
      "\tGenerator loss: 0.8683360815048218, Discriminator loss: 1.3788412809371948\n",
      "\tGenerator loss: 0.794053316116333, Discriminator loss: 1.410158395767212\n",
      "\tGenerator loss: 0.7893962264060974, Discriminator loss: 1.3759530782699585\n",
      "\tGenerator loss: 0.8468441963195801, Discriminator loss: 1.386601448059082\n",
      "\tGenerator loss: 0.8900927305221558, Discriminator loss: 1.4217166900634766\n",
      "\tGenerator loss: 0.9198242425918579, Discriminator loss: 1.3763980865478516\n",
      "\tGenerator loss: 0.8854891061782837, Discriminator loss: 1.388422966003418\n",
      "\tGenerator loss: 0.8093081116676331, Discriminator loss: 1.371103048324585\n",
      "\tGenerator loss: 0.7633709907531738, Discriminator loss: 1.3473098278045654\n",
      "\tGenerator loss: 0.7602014541625977, Discriminator loss: 1.3389960527420044\n",
      "\tGenerator loss: 0.8094691038131714, Discriminator loss: 1.336838960647583\n",
      "\tGenerator loss: 0.865597665309906, Discriminator loss: 1.3073327541351318\n",
      "\tGenerator loss: 0.9239237308502197, Discriminator loss: 1.2661375999450684\n",
      "\tGenerator loss: 0.9440057277679443, Discriminator loss: 1.2593966722488403\n",
      "\tGenerator loss: 0.8955475091934204, Discriminator loss: 1.2533146142959595\n",
      "\tGenerator loss: 0.8848282098770142, Discriminator loss: 1.2548346519470215\n",
      "\tGenerator loss: 0.8838964700698853, Discriminator loss: 1.263819932937622\n",
      "\tGenerator loss: 0.8724671006202698, Discriminator loss: 1.2720445394515991\n",
      "\tGenerator loss: 0.8795719146728516, Discriminator loss: 1.2590458393096924\n",
      "\tGenerator loss: 0.9621601104736328, Discriminator loss: 1.2230134010314941\n",
      "\tGenerator loss: 1.008135199546814, Discriminator loss: 1.1580820083618164\n",
      "\tGenerator loss: 1.0156939029693604, Discriminator loss: 1.1596177816390991\n",
      "\tGenerator loss: 0.9850437045097351, Discriminator loss: 1.1798818111419678\n",
      "\tGenerator loss: 0.9446041584014893, Discriminator loss: 1.1570758819580078\n",
      "\tGenerator loss: 0.9584901928901672, Discriminator loss: 1.1428247690200806\n",
      "\tGenerator loss: 0.9578655958175659, Discriminator loss: 1.170145869255066\n",
      "\tGenerator loss: 0.9473016262054443, Discriminator loss: 1.1864187717437744\n",
      "\tGenerator loss: 0.993858814239502, Discriminator loss: 1.1386032104492188\n",
      "\tGenerator loss: 1.0705658197402954, Discriminator loss: 1.1039924621582031\n",
      "\tGenerator loss: 1.0958389043807983, Discriminator loss: 1.1201919317245483\n",
      "\tGenerator loss: 1.0723376274108887, Discriminator loss: 1.0718907117843628\n",
      "\tGenerator loss: 1.0299500226974487, Discriminator loss: 1.1434578895568848\n",
      "\tGenerator loss: 1.018622636795044, Discriminator loss: 1.1275218725204468\n",
      "\tGenerator loss: 1.0396658182144165, Discriminator loss: 1.1755201816558838\n",
      "\tGenerator loss: 1.048530101776123, Discriminator loss: 1.1522083282470703\n",
      "\tGenerator loss: 1.0580968856811523, Discriminator loss: 1.159057378768921\n",
      "\tGenerator loss: 1.0611672401428223, Discriminator loss: 1.1090304851531982\n",
      "\tGenerator loss: 1.0456113815307617, Discriminator loss: 1.0912847518920898\n",
      "\tGenerator loss: 1.0505847930908203, Discriminator loss: 1.1018890142440796\n",
      "\tGenerator loss: 1.080561876296997, Discriminator loss: 1.0940940380096436\n",
      "\tGenerator loss: 1.0925049781799316, Discriminator loss: 1.065455675125122\n",
      "\tGenerator loss: 1.0667062997817993, Discriminator loss: 1.0798192024230957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0746548175811768, Discriminator loss: 1.0617998838424683\n",
      "\tGenerator loss: 1.0801740884780884, Discriminator loss: 1.1056013107299805\n",
      "\tGenerator loss: 1.0513575077056885, Discriminator loss: 1.131824016571045\n",
      "\tGenerator loss: 1.074379801750183, Discriminator loss: 1.0602271556854248\n",
      "\tGenerator loss: 1.0926282405853271, Discriminator loss: 1.0854065418243408\n",
      "\tGenerator loss: 1.0642361640930176, Discriminator loss: 1.0486297607421875\n",
      "\tGenerator loss: 1.0325310230255127, Discriminator loss: 1.088634729385376\n",
      "\tGenerator loss: 1.064610481262207, Discriminator loss: 1.0784838199615479\n",
      "\tGenerator loss: 1.1123483180999756, Discriminator loss: 1.0562353134155273\n",
      "\tGenerator loss: 1.1346265077590942, Discriminator loss: 1.023099660873413\n",
      "\tGenerator loss: 1.129995346069336, Discriminator loss: 1.0754899978637695\n",
      "\tGenerator loss: 1.0796130895614624, Discriminator loss: 1.1407620906829834\n",
      "\tGenerator loss: 1.0201659202575684, Discriminator loss: 1.1491752862930298\n",
      "\tGenerator loss: 0.9993435144424438, Discriminator loss: 1.1256768703460693\n",
      "\tGenerator loss: 0.9996312856674194, Discriminator loss: 1.1471612453460693\n",
      "\tGenerator loss: 1.0112824440002441, Discriminator loss: 1.1453185081481934\n",
      "\tGenerator loss: 1.0760258436203003, Discriminator loss: 1.1413841247558594\n",
      "\tGenerator loss: 1.0862020254135132, Discriminator loss: 1.130204677581787\n",
      "\tGenerator loss: 1.0721619129180908, Discriminator loss: 1.1439108848571777\n",
      "\tGenerator loss: 1.0310916900634766, Discriminator loss: 1.1422046422958374\n",
      "\tGenerator loss: 0.9866349697113037, Discriminator loss: 1.1004830598831177\n",
      "\tGenerator loss: 0.9977251887321472, Discriminator loss: 1.1174564361572266\n",
      "\tGenerator loss: 1.0471160411834717, Discriminator loss: 1.157598614692688\n",
      "\tGenerator loss: 1.0716392993927002, Discriminator loss: 1.191698431968689\n",
      "\tGenerator loss: 1.0519719123840332, Discriminator loss: 1.1462790966033936\n",
      "\tGenerator loss: 1.016319751739502, Discriminator loss: 1.1548408269882202\n",
      "\tGenerator loss: 0.9847680330276489, Discriminator loss: 1.198803424835205\n",
      "\tGenerator loss: 0.9722428321838379, Discriminator loss: 1.2375136613845825\n",
      "\tGenerator loss: 0.9497796297073364, Discriminator loss: 1.2228541374206543\n",
      "\tGenerator loss: 0.9320566654205322, Discriminator loss: 1.2428655624389648\n",
      "\tGenerator loss: 0.9417935609817505, Discriminator loss: 1.2464262247085571\n",
      "\tGenerator loss: 1.0018463134765625, Discriminator loss: 1.2216789722442627\n",
      "\tGenerator loss: 1.034475564956665, Discriminator loss: 1.2817238569259644\n",
      "\tGenerator loss: 1.0186036825180054, Discriminator loss: 1.2555099725723267\n",
      "\tGenerator loss: 0.9445623159408569, Discriminator loss: 1.2415807247161865\n",
      "\tGenerator loss: 0.910815954208374, Discriminator loss: 1.2758140563964844\n",
      "\tGenerator loss: 0.9055798649787903, Discriminator loss: 1.327562928199768\n",
      "\tGenerator loss: 0.9345659017562866, Discriminator loss: 1.3444327116012573\n",
      "\tGenerator loss: 0.9723065495491028, Discriminator loss: 1.3469874858856201\n",
      "\tGenerator loss: 0.9879369735717773, Discriminator loss: 1.3524272441864014\n",
      "\tGenerator loss: 0.9823020696640015, Discriminator loss: 1.3105368614196777\n",
      "\tGenerator loss: 0.8951679468154907, Discriminator loss: 1.3049720525741577\n",
      "\tGenerator loss: 0.8851755857467651, Discriminator loss: 1.2629618644714355\n",
      "\tGenerator loss: 0.8594954609870911, Discriminator loss: 1.296994686126709\n",
      "\tGenerator loss: 0.879267692565918, Discriminator loss: 1.3333710432052612\n",
      "\tGenerator loss: 0.9178378582000732, Discriminator loss: 1.3140754699707031\n",
      "\tGenerator loss: 0.9171240329742432, Discriminator loss: 1.3473165035247803\n",
      "\tGenerator loss: 0.9072872996330261, Discriminator loss: 1.3309950828552246\n",
      "\tGenerator loss: 0.9145267009735107, Discriminator loss: 1.330215334892273\n",
      "\tGenerator loss: 0.911030650138855, Discriminator loss: 1.3237345218658447\n",
      "\tGenerator loss: 0.9103038311004639, Discriminator loss: 1.321630597114563\n",
      "\tGenerator loss: 0.8915911912918091, Discriminator loss: 1.3771743774414062\n",
      "\tGenerator loss: 0.8548470735549927, Discriminator loss: 1.3808777332305908\n",
      "\tGenerator loss: 0.8272238969802856, Discriminator loss: 1.3423559665679932\n",
      "\tGenerator loss: 0.8107333183288574, Discriminator loss: 1.361799716949463\n",
      "\tGenerator loss: 0.8149787187576294, Discriminator loss: 1.3930389881134033\n",
      "\tGenerator loss: 0.8706656694412231, Discriminator loss: 1.3615093231201172\n",
      "\tGenerator loss: 0.9248536229133606, Discriminator loss: 1.3169405460357666\n",
      "\tGenerator loss: 0.9164752960205078, Discriminator loss: 1.3407506942749023\n",
      "\tGenerator loss: 0.9181479811668396, Discriminator loss: 1.3056015968322754\n",
      "\tGenerator loss: 0.8719974756240845, Discriminator loss: 1.3223291635513306\n",
      "\tGenerator loss: 0.8423938751220703, Discriminator loss: 1.3333958387374878\n",
      "\tGenerator loss: 0.8439992070198059, Discriminator loss: 1.2949116230010986\n",
      "\tGenerator loss: 0.892528772354126, Discriminator loss: 1.3120851516723633\n",
      "\tGenerator loss: 0.9126139879226685, Discriminator loss: 1.316482424736023\n",
      "\tGenerator loss: 0.9276227951049805, Discriminator loss: 1.33699631690979\n",
      "\tGenerator loss: 0.9326519966125488, Discriminator loss: 1.3024137020111084\n",
      "\tGenerator loss: 0.9420106410980225, Discriminator loss: 1.3167963027954102\n",
      "\tGenerator loss: 0.9409386515617371, Discriminator loss: 1.2936923503875732\n",
      "\tGenerator loss: 0.8800276517868042, Discriminator loss: 1.2953259944915771\n",
      "\tGenerator loss: 0.8815832138061523, Discriminator loss: 1.2774144411087036\n",
      "\tGenerator loss: 0.9068982601165771, Discriminator loss: 1.2470567226409912\n",
      "\tGenerator loss: 0.9042057991027832, Discriminator loss: 1.224663496017456\n",
      "\tGenerator loss: 0.9605761766433716, Discriminator loss: 1.2185384035110474\n",
      "\tGenerator loss: 0.9681438207626343, Discriminator loss: 1.2170902490615845\n",
      "\tGenerator loss: 0.9864311814308167, Discriminator loss: 1.1793508529663086\n",
      "\tGenerator loss: 0.9932776689529419, Discriminator loss: 1.2135480642318726\n",
      "\tGenerator loss: 0.9571570754051208, Discriminator loss: 1.1756157875061035\n",
      "\tGenerator loss: 0.9365420341491699, Discriminator loss: 1.1585794687271118\n",
      "\tGenerator loss: 0.9860355257987976, Discriminator loss: 1.1538714170455933\n",
      "\tGenerator loss: 1.0294619798660278, Discriminator loss: 1.1773892641067505\n",
      "\tGenerator loss: 1.0861306190490723, Discriminator loss: 1.1869173049926758\n",
      "\tGenerator loss: 1.0963525772094727, Discriminator loss: 1.161244511604309\n",
      "Time for epoch 35 is 251.25840854644775 sec\n",
      "\tGenerator loss: 1.0233076810836792, Discriminator loss: 1.1775000095367432\n",
      "\tGenerator loss: 0.9337947964668274, Discriminator loss: 1.1883970499038696\n",
      "\tGenerator loss: 0.9176253080368042, Discriminator loss: 1.1741282939910889\n",
      "\tGenerator loss: 0.9689021110534668, Discriminator loss: 1.1349077224731445\n",
      "\tGenerator loss: 1.0465856790542603, Discriminator loss: 1.1713405847549438\n",
      "\tGenerator loss: 1.0959744453430176, Discriminator loss: 1.170161247253418\n",
      "\tGenerator loss: 1.0892384052276611, Discriminator loss: 1.113606333732605\n",
      "\tGenerator loss: 1.0519721508026123, Discriminator loss: 1.1539061069488525\n",
      "\tGenerator loss: 1.025853157043457, Discriminator loss: 1.128080129623413\n",
      "\tGenerator loss: 1.0181324481964111, Discriminator loss: 1.0899513959884644\n",
      "\tGenerator loss: 1.0059007406234741, Discriminator loss: 1.1209654808044434\n",
      "\tGenerator loss: 1.0469787120819092, Discriminator loss: 1.117405891418457\n",
      "\tGenerator loss: 1.0779045820236206, Discriminator loss: 1.1163690090179443\n",
      "\tGenerator loss: 1.107532024383545, Discriminator loss: 1.0823339223861694\n",
      "\tGenerator loss: 1.0620784759521484, Discriminator loss: 1.0898323059082031\n",
      "\tGenerator loss: 1.0150338411331177, Discriminator loss: 1.0943522453308105\n",
      "\tGenerator loss: 0.9919536113739014, Discriminator loss: 1.0847972631454468\n",
      "\tGenerator loss: 1.0351743698120117, Discriminator loss: 1.0616755485534668\n",
      "\tGenerator loss: 1.0757133960723877, Discriminator loss: 1.1249966621398926\n",
      "\tGenerator loss: 1.0949149131774902, Discriminator loss: 1.116715669631958\n",
      "\tGenerator loss: 1.1225866079330444, Discriminator loss: 1.0960729122161865\n",
      "\tGenerator loss: 1.1112918853759766, Discriminator loss: 1.0745075941085815\n",
      "\tGenerator loss: 1.0336432456970215, Discriminator loss: 1.0956854820251465\n",
      "\tGenerator loss: 1.041801929473877, Discriminator loss: 1.0906203985214233\n",
      "\tGenerator loss: 1.0661303997039795, Discriminator loss: 1.1102981567382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.092576265335083, Discriminator loss: 1.0839486122131348\n",
      "\tGenerator loss: 1.1161372661590576, Discriminator loss: 1.1097923517227173\n",
      "\tGenerator loss: 1.0575639009475708, Discriminator loss: 1.1202211380004883\n",
      "\tGenerator loss: 1.0267421007156372, Discriminator loss: 1.1690583229064941\n",
      "\tGenerator loss: 0.9605976343154907, Discriminator loss: 1.1352894306182861\n",
      "\tGenerator loss: 0.9632948637008667, Discriminator loss: 1.1256000995635986\n",
      "\tGenerator loss: 0.9878731369972229, Discriminator loss: 1.1527907848358154\n",
      "\tGenerator loss: 1.070322036743164, Discriminator loss: 1.1161878108978271\n",
      "\tGenerator loss: 1.1114870309829712, Discriminator loss: 1.1569271087646484\n",
      "\tGenerator loss: 1.1069841384887695, Discriminator loss: 1.1531703472137451\n",
      "\tGenerator loss: 1.0620969533920288, Discriminator loss: 1.1640137434005737\n",
      "\tGenerator loss: 0.9945883750915527, Discriminator loss: 1.1680593490600586\n",
      "\tGenerator loss: 0.9240939617156982, Discriminator loss: 1.1990567445755005\n",
      "\tGenerator loss: 0.8829379677772522, Discriminator loss: 1.1781435012817383\n",
      "\tGenerator loss: 0.9390149116516113, Discriminator loss: 1.1547918319702148\n",
      "\tGenerator loss: 1.0584853887557983, Discriminator loss: 1.1443756818771362\n",
      "\tGenerator loss: 1.1244648694992065, Discriminator loss: 1.1915292739868164\n",
      "\tGenerator loss: 1.1582868099212646, Discriminator loss: 1.1753315925598145\n",
      "\tGenerator loss: 1.0680723190307617, Discriminator loss: 1.1898293495178223\n",
      "\tGenerator loss: 0.9711697697639465, Discriminator loss: 1.2116886377334595\n",
      "\tGenerator loss: 0.9123785495758057, Discriminator loss: 1.2255027294158936\n",
      "\tGenerator loss: 0.8688951730728149, Discriminator loss: 1.2355719804763794\n",
      "\tGenerator loss: 0.9018362164497375, Discriminator loss: 1.2205482721328735\n",
      "\tGenerator loss: 0.9557156562805176, Discriminator loss: 1.2276792526245117\n",
      "\tGenerator loss: 1.03748619556427, Discriminator loss: 1.2462528944015503\n",
      "\tGenerator loss: 1.0907223224639893, Discriminator loss: 1.264041543006897\n",
      "\tGenerator loss: 1.0334312915802002, Discriminator loss: 1.2364522218704224\n",
      "\tGenerator loss: 0.9873858094215393, Discriminator loss: 1.2288931608200073\n",
      "\tGenerator loss: 0.9030201435089111, Discriminator loss: 1.3095462322235107\n",
      "\tGenerator loss: 0.88997483253479, Discriminator loss: 1.2837474346160889\n",
      "\tGenerator loss: 0.8860873579978943, Discriminator loss: 1.3097361326217651\n",
      "\tGenerator loss: 0.9104650020599365, Discriminator loss: 1.3068745136260986\n",
      "\tGenerator loss: 0.9667248725891113, Discriminator loss: 1.2946357727050781\n",
      "\tGenerator loss: 0.9613199234008789, Discriminator loss: 1.2872250080108643\n",
      "\tGenerator loss: 0.92097008228302, Discriminator loss: 1.292861819267273\n",
      "\tGenerator loss: 0.8907569646835327, Discriminator loss: 1.3006737232208252\n",
      "\tGenerator loss: 0.8554866313934326, Discriminator loss: 1.2918424606323242\n",
      "\tGenerator loss: 0.8673158884048462, Discriminator loss: 1.3063642978668213\n",
      "\tGenerator loss: 0.8883714079856873, Discriminator loss: 1.3161287307739258\n",
      "\tGenerator loss: 0.9442379474639893, Discriminator loss: 1.3235499858856201\n",
      "\tGenerator loss: 0.957004725933075, Discriminator loss: 1.2981425523757935\n",
      "\tGenerator loss: 0.9550879001617432, Discriminator loss: 1.3028323650360107\n",
      "\tGenerator loss: 0.9063888788223267, Discriminator loss: 1.251870036125183\n",
      "\tGenerator loss: 0.8904848098754883, Discriminator loss: 1.2625207901000977\n",
      "\tGenerator loss: 0.8873482346534729, Discriminator loss: 1.277337908744812\n",
      "\tGenerator loss: 0.9064735174179077, Discriminator loss: 1.228546142578125\n",
      "\tGenerator loss: 0.8919299244880676, Discriminator loss: 1.282149314880371\n",
      "\tGenerator loss: 0.931289553642273, Discriminator loss: 1.2691236734390259\n",
      "\tGenerator loss: 0.9763359427452087, Discriminator loss: 1.2476134300231934\n",
      "\tGenerator loss: 0.9849538207054138, Discriminator loss: 1.1847738027572632\n",
      "\tGenerator loss: 0.9584280252456665, Discriminator loss: 1.251168966293335\n",
      "\tGenerator loss: 0.9436326622962952, Discriminator loss: 1.2858208417892456\n",
      "\tGenerator loss: 0.9707491397857666, Discriminator loss: 1.2590513229370117\n",
      "\tGenerator loss: 0.9706546068191528, Discriminator loss: 1.2586084604263306\n",
      "\tGenerator loss: 0.9740772247314453, Discriminator loss: 1.2461326122283936\n",
      "\tGenerator loss: 0.965894877910614, Discriminator loss: 1.2561959028244019\n",
      "\tGenerator loss: 0.9549518823623657, Discriminator loss: 1.236948847770691\n",
      "\tGenerator loss: 0.9555559158325195, Discriminator loss: 1.210059642791748\n",
      "\tGenerator loss: 1.006375789642334, Discriminator loss: 1.208333134651184\n",
      "\tGenerator loss: 1.0179839134216309, Discriminator loss: 1.167907953262329\n",
      "\tGenerator loss: 1.0016429424285889, Discriminator loss: 1.2901641130447388\n",
      "\tGenerator loss: 1.004504919052124, Discriminator loss: 1.181990623474121\n",
      "\tGenerator loss: 1.023941993713379, Discriminator loss: 1.1597168445587158\n",
      "\tGenerator loss: 1.0018032789230347, Discriminator loss: 1.2125608921051025\n",
      "\tGenerator loss: 0.9825968742370605, Discriminator loss: 1.213137149810791\n",
      "\tGenerator loss: 0.9723188281059265, Discriminator loss: 1.2362605333328247\n",
      "\tGenerator loss: 0.9812620878219604, Discriminator loss: 1.2044594287872314\n",
      "\tGenerator loss: 1.0074543952941895, Discriminator loss: 1.1544725894927979\n",
      "\tGenerator loss: 1.0683845281600952, Discriminator loss: 1.1825523376464844\n",
      "\tGenerator loss: 1.0602834224700928, Discriminator loss: 1.187437891960144\n",
      "\tGenerator loss: 0.9924560785293579, Discriminator loss: 1.1557738780975342\n",
      "\tGenerator loss: 0.9602833986282349, Discriminator loss: 1.1576423645019531\n",
      "\tGenerator loss: 0.9470030069351196, Discriminator loss: 1.1714690923690796\n",
      "\tGenerator loss: 0.9599202871322632, Discriminator loss: 1.1844515800476074\n",
      "\tGenerator loss: 1.0184566974639893, Discriminator loss: 1.2101049423217773\n",
      "\tGenerator loss: 1.049540400505066, Discriminator loss: 1.209754467010498\n",
      "\tGenerator loss: 1.0602469444274902, Discriminator loss: 1.1923081874847412\n",
      "\tGenerator loss: 1.0120632648468018, Discriminator loss: 1.176847219467163\n",
      "\tGenerator loss: 0.9372339248657227, Discriminator loss: 1.1879297494888306\n",
      "\tGenerator loss: 0.8921279907226562, Discriminator loss: 1.2097933292388916\n",
      "\tGenerator loss: 0.9107030630111694, Discriminator loss: 1.184149980545044\n",
      "\tGenerator loss: 0.9547916650772095, Discriminator loss: 1.2121727466583252\n",
      "\tGenerator loss: 1.0213727951049805, Discriminator loss: 1.1954050064086914\n",
      "\tGenerator loss: 1.1012427806854248, Discriminator loss: 1.156282901763916\n",
      "\tGenerator loss: 1.0460314750671387, Discriminator loss: 1.166327714920044\n",
      "\tGenerator loss: 0.9755024909973145, Discriminator loss: 1.2100791931152344\n",
      "\tGenerator loss: 0.91058349609375, Discriminator loss: 1.228362798690796\n",
      "\tGenerator loss: 0.912904679775238, Discriminator loss: 1.1930663585662842\n",
      "\tGenerator loss: 0.9804835319519043, Discriminator loss: 1.2134732007980347\n",
      "\tGenerator loss: 1.020115852355957, Discriminator loss: 1.256538987159729\n",
      "\tGenerator loss: 0.998265266418457, Discriminator loss: 1.216456413269043\n",
      "\tGenerator loss: 0.9593499302864075, Discriminator loss: 1.2343113422393799\n",
      "\tGenerator loss: 0.9254146218299866, Discriminator loss: 1.2144638299942017\n",
      "\tGenerator loss: 0.8818131685256958, Discriminator loss: 1.2110929489135742\n",
      "\tGenerator loss: 0.9195281267166138, Discriminator loss: 1.1883885860443115\n",
      "\tGenerator loss: 0.9307803511619568, Discriminator loss: 1.2204513549804688\n",
      "\tGenerator loss: 0.9788497686386108, Discriminator loss: 1.2030268907546997\n",
      "\tGenerator loss: 1.025118112564087, Discriminator loss: 1.1781671047210693\n",
      "\tGenerator loss: 1.0148966312408447, Discriminator loss: 1.1327308416366577\n",
      "\tGenerator loss: 0.950300931930542, Discriminator loss: 1.1323468685150146\n",
      "\tGenerator loss: 0.9396531581878662, Discriminator loss: 1.2013672590255737\n",
      "\tGenerator loss: 0.9772630929946899, Discriminator loss: 1.2471020221710205\n",
      "\tGenerator loss: 0.9871929287910461, Discriminator loss: 1.2117836475372314\n",
      "\tGenerator loss: 0.992445707321167, Discriminator loss: 1.1821320056915283\n",
      "\tGenerator loss: 0.9814081192016602, Discriminator loss: 1.2219769954681396\n",
      "\tGenerator loss: 0.9812610149383545, Discriminator loss: 1.1749626398086548\n",
      "\tGenerator loss: 0.9971267580986023, Discriminator loss: 1.1875014305114746\n",
      "\tGenerator loss: 0.999292254447937, Discriminator loss: 1.2307419776916504\n",
      "\tGenerator loss: 0.9739968180656433, Discriminator loss: 1.1905626058578491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.968707799911499, Discriminator loss: 1.159761667251587\n",
      "\tGenerator loss: 0.9677718877792358, Discriminator loss: 1.2327824831008911\n",
      "\tGenerator loss: 0.9928072094917297, Discriminator loss: 1.2252190113067627\n",
      "\tGenerator loss: 1.009213924407959, Discriminator loss: 1.1821198463439941\n",
      "\tGenerator loss: 1.045400857925415, Discriminator loss: 1.179382085800171\n",
      "\tGenerator loss: 1.0277756452560425, Discriminator loss: 1.1468387842178345\n",
      "\tGenerator loss: 0.9857073426246643, Discriminator loss: 1.1231470108032227\n",
      "\tGenerator loss: 0.9592080116271973, Discriminator loss: 1.2014684677124023\n",
      "\tGenerator loss: 1.010827660560608, Discriminator loss: 1.187409520149231\n",
      "\tGenerator loss: 1.0469311475753784, Discriminator loss: 1.2275655269622803\n",
      "\tGenerator loss: 1.0634679794311523, Discriminator loss: 1.2149062156677246\n",
      "\tGenerator loss: 1.0110177993774414, Discriminator loss: 1.2226099967956543\n",
      "\tGenerator loss: 0.9942184686660767, Discriminator loss: 1.168894648551941\n",
      "\tGenerator loss: 0.9643694162368774, Discriminator loss: 1.1651484966278076\n",
      "\tGenerator loss: 0.9884733557701111, Discriminator loss: 1.173802137374878\n",
      "\tGenerator loss: 1.0370762348175049, Discriminator loss: 1.1828250885009766\n",
      "\tGenerator loss: 1.0288163423538208, Discriminator loss: 1.171058177947998\n",
      "\tGenerator loss: 1.0089489221572876, Discriminator loss: 1.1407188177108765\n",
      "\tGenerator loss: 0.9806785583496094, Discriminator loss: 1.1632969379425049\n",
      "\tGenerator loss: 0.9678729176521301, Discriminator loss: 1.2415708303451538\n",
      "\tGenerator loss: 0.9655605554580688, Discriminator loss: 1.239170789718628\n",
      "\tGenerator loss: 1.0055341720581055, Discriminator loss: 1.1882349252700806\n",
      "\tGenerator loss: 1.005707025527954, Discriminator loss: 1.208421230316162\n",
      "\tGenerator loss: 0.9835433959960938, Discriminator loss: 1.1796616315841675\n",
      "\tGenerator loss: 0.992810070514679, Discriminator loss: 1.1933420896530151\n",
      "\tGenerator loss: 1.03045654296875, Discriminator loss: 1.1453914642333984\n",
      "\tGenerator loss: 1.0826016664505005, Discriminator loss: 1.1097722053527832\n",
      "\tGenerator loss: 1.047111988067627, Discriminator loss: 1.118450403213501\n",
      "\tGenerator loss: 1.034956455230713, Discriminator loss: 1.189435601234436\n",
      "\tGenerator loss: 0.9916634559631348, Discriminator loss: 1.2145662307739258\n",
      "\tGenerator loss: 0.9430891275405884, Discriminator loss: 1.2425771951675415\n",
      "\tGenerator loss: 0.9164184927940369, Discriminator loss: 1.2199547290802002\n",
      "\tGenerator loss: 0.9407434463500977, Discriminator loss: 1.232871413230896\n",
      "\tGenerator loss: 1.059845209121704, Discriminator loss: 1.202369213104248\n",
      "\tGenerator loss: 1.106801986694336, Discriminator loss: 1.2219287157058716\n",
      "\tGenerator loss: 1.073935627937317, Discriminator loss: 1.193683385848999\n",
      "\tGenerator loss: 0.994976282119751, Discriminator loss: 1.2263928651809692\n",
      "\tGenerator loss: 0.9704417586326599, Discriminator loss: 1.1794066429138184\n",
      "\tGenerator loss: 0.9409336447715759, Discriminator loss: 1.1481804847717285\n",
      "\tGenerator loss: 0.9737849235534668, Discriminator loss: 1.1689338684082031\n",
      "\tGenerator loss: 1.0515780448913574, Discriminator loss: 1.181258201599121\n",
      "\tGenerator loss: 1.0766849517822266, Discriminator loss: 1.212953805923462\n",
      "\tGenerator loss: 1.0227383375167847, Discriminator loss: 1.2050981521606445\n",
      "\tGenerator loss: 0.9877815246582031, Discriminator loss: 1.1870187520980835\n",
      "\tGenerator loss: 0.9842844605445862, Discriminator loss: 1.1902556419372559\n",
      "\tGenerator loss: 1.000191330909729, Discriminator loss: 1.2244958877563477\n",
      "\tGenerator loss: 0.9674988985061646, Discriminator loss: 1.1901689767837524\n",
      "\tGenerator loss: 0.9473183155059814, Discriminator loss: 1.1937546730041504\n",
      "\tGenerator loss: 0.9556198120117188, Discriminator loss: 1.196985125541687\n",
      "\tGenerator loss: 1.042054533958435, Discriminator loss: 1.2004165649414062\n",
      "\tGenerator loss: 1.0930352210998535, Discriminator loss: 1.2214932441711426\n",
      "\tGenerator loss: 1.0665431022644043, Discriminator loss: 1.2578730583190918\n",
      "\tGenerator loss: 0.9830775260925293, Discriminator loss: 1.277457594871521\n",
      "\tGenerator loss: 0.9569058418273926, Discriminator loss: 1.2663216590881348\n",
      "\tGenerator loss: 0.9490234851837158, Discriminator loss: 1.2680294513702393\n",
      "\tGenerator loss: 0.9533987045288086, Discriminator loss: 1.2958719730377197\n",
      "\tGenerator loss: 0.9815502166748047, Discriminator loss: 1.3267579078674316\n",
      "\tGenerator loss: 1.039804220199585, Discriminator loss: 1.3074023723602295\n",
      "\tGenerator loss: 1.021430253982544, Discriminator loss: 1.2857619524002075\n",
      "\tGenerator loss: 0.9536648392677307, Discriminator loss: 1.2509652376174927\n",
      "\tGenerator loss: 0.9332079887390137, Discriminator loss: 1.2144134044647217\n",
      "\tGenerator loss: 0.928466796875, Discriminator loss: 1.1940176486968994\n",
      "\tGenerator loss: 0.9923970699310303, Discriminator loss: 1.2132617235183716\n",
      "\tGenerator loss: 1.0148741006851196, Discriminator loss: 1.223007321357727\n",
      "\tGenerator loss: 1.0582702159881592, Discriminator loss: 1.2259492874145508\n",
      "\tGenerator loss: 1.0463544130325317, Discriminator loss: 1.2028303146362305\n",
      "\tGenerator loss: 0.9968817234039307, Discriminator loss: 1.2458398342132568\n",
      "\tGenerator loss: 0.9465489387512207, Discriminator loss: 1.2029718160629272\n",
      "\tGenerator loss: 0.9506123065948486, Discriminator loss: 1.2075086832046509\n",
      "\tGenerator loss: 1.0039032697677612, Discriminator loss: 1.216738224029541\n",
      "\tGenerator loss: 1.0135786533355713, Discriminator loss: 1.2392683029174805\n",
      "\tGenerator loss: 1.005388855934143, Discriminator loss: 1.1856993436813354\n",
      "\tGenerator loss: 0.9927621483802795, Discriminator loss: 1.2178711891174316\n",
      "\tGenerator loss: 0.9939419031143188, Discriminator loss: 1.2139233350753784\n",
      "\tGenerator loss: 0.969395101070404, Discriminator loss: 1.2130637168884277\n",
      "\tGenerator loss: 1.025694489479065, Discriminator loss: 1.1395738124847412\n",
      "\tGenerator loss: 1.053633689880371, Discriminator loss: 1.1668603420257568\n",
      "\tGenerator loss: 1.065194845199585, Discriminator loss: 1.1484947204589844\n",
      "\tGenerator loss: 1.0299808979034424, Discriminator loss: 1.171624779701233\n",
      "\tGenerator loss: 1.009286880493164, Discriminator loss: 1.183496356010437\n",
      "\tGenerator loss: 1.0175485610961914, Discriminator loss: 1.179520606994629\n",
      "\tGenerator loss: 0.9855474233627319, Discriminator loss: 1.2324578762054443\n",
      "\tGenerator loss: 0.9919085502624512, Discriminator loss: 1.2310199737548828\n",
      "\tGenerator loss: 0.9764935374259949, Discriminator loss: 1.2602401971817017\n",
      "\tGenerator loss: 0.9907951354980469, Discriminator loss: 1.2509527206420898\n",
      "\tGenerator loss: 1.025158405303955, Discriminator loss: 1.2425769567489624\n",
      "\tGenerator loss: 1.021906852722168, Discriminator loss: 1.2475483417510986\n",
      "\tGenerator loss: 1.0100789070129395, Discriminator loss: 1.226522445678711\n",
      "\tGenerator loss: 0.9630885720252991, Discriminator loss: 1.2325385808944702\n",
      "\tGenerator loss: 0.9525684118270874, Discriminator loss: 1.203643560409546\n",
      "\tGenerator loss: 0.9461215734481812, Discriminator loss: 1.2019901275634766\n",
      "\tGenerator loss: 0.9959669709205627, Discriminator loss: 1.169936180114746\n",
      "\tGenerator loss: 1.024152159690857, Discriminator loss: 1.2083115577697754\n",
      "\tGenerator loss: 1.0432970523834229, Discriminator loss: 1.140594244003296\n",
      "\tGenerator loss: 1.0317676067352295, Discriminator loss: 1.189263939857483\n",
      "\tGenerator loss: 0.9945071339607239, Discriminator loss: 1.1605374813079834\n",
      "\tGenerator loss: 0.963821291923523, Discriminator loss: 1.1461619138717651\n",
      "\tGenerator loss: 0.9787478446960449, Discriminator loss: 1.150829792022705\n",
      "\tGenerator loss: 1.0619069337844849, Discriminator loss: 1.175012230873108\n",
      "\tGenerator loss: 1.101332664489746, Discriminator loss: 1.1764755249023438\n",
      "\tGenerator loss: 1.0994266271591187, Discriminator loss: 1.2251288890838623\n",
      "Time for epoch 36 is 255.4455165863037 sec\n",
      "\tGenerator loss: 1.0455553531646729, Discriminator loss: 1.1936269998550415\n",
      "\tGenerator loss: 0.9587543606758118, Discriminator loss: 1.2104988098144531\n",
      "\tGenerator loss: 0.9050582647323608, Discriminator loss: 1.1961801052093506\n",
      "\tGenerator loss: 0.899071991443634, Discriminator loss: 1.1723549365997314\n",
      "\tGenerator loss: 1.0037678480148315, Discriminator loss: 1.2076120376586914\n",
      "\tGenerator loss: 1.0601756572723389, Discriminator loss: 1.1922587156295776\n",
      "\tGenerator loss: 1.1098824739456177, Discriminator loss: 1.1810553073883057\n",
      "\tGenerator loss: 1.0818672180175781, Discriminator loss: 1.2231470346450806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0254861116409302, Discriminator loss: 1.1985162496566772\n",
      "\tGenerator loss: 0.9260721206665039, Discriminator loss: 1.1846415996551514\n",
      "\tGenerator loss: 0.9127886295318604, Discriminator loss: 1.1748905181884766\n",
      "\tGenerator loss: 0.9739812612533569, Discriminator loss: 1.1968262195587158\n",
      "\tGenerator loss: 1.0188541412353516, Discriminator loss: 1.2135305404663086\n",
      "\tGenerator loss: 1.0513203144073486, Discriminator loss: 1.2144919633865356\n",
      "\tGenerator loss: 1.0640594959259033, Discriminator loss: 1.206312656402588\n",
      "\tGenerator loss: 1.0125460624694824, Discriminator loss: 1.1788465976715088\n",
      "\tGenerator loss: 0.9855383634567261, Discriminator loss: 1.1551008224487305\n",
      "\tGenerator loss: 0.9644261598587036, Discriminator loss: 1.1646003723144531\n",
      "\tGenerator loss: 0.9588298797607422, Discriminator loss: 1.245526671409607\n",
      "\tGenerator loss: 1.0118149518966675, Discriminator loss: 1.193053960800171\n",
      "\tGenerator loss: 1.053783893585205, Discriminator loss: 1.1740336418151855\n",
      "\tGenerator loss: 1.1320462226867676, Discriminator loss: 1.1577712297439575\n",
      "\tGenerator loss: 1.1135218143463135, Discriminator loss: 1.150809645652771\n",
      "\tGenerator loss: 1.0261495113372803, Discriminator loss: 1.1876137256622314\n",
      "\tGenerator loss: 0.9948275089263916, Discriminator loss: 1.212288737297058\n",
      "\tGenerator loss: 1.0139949321746826, Discriminator loss: 1.1449291706085205\n",
      "\tGenerator loss: 1.0127122402191162, Discriminator loss: 1.1938084363937378\n",
      "\tGenerator loss: 0.9882667064666748, Discriminator loss: 1.1966097354888916\n",
      "\tGenerator loss: 0.995648205280304, Discriminator loss: 1.2532401084899902\n",
      "\tGenerator loss: 0.9526088237762451, Discriminator loss: 1.2400528192520142\n",
      "\tGenerator loss: 0.9253199696540833, Discriminator loss: 1.2024283409118652\n",
      "\tGenerator loss: 0.9302462339401245, Discriminator loss: 1.213975191116333\n",
      "\tGenerator loss: 0.9941854476928711, Discriminator loss: 1.1879160404205322\n",
      "\tGenerator loss: 1.0547354221343994, Discriminator loss: 1.206345796585083\n",
      "\tGenerator loss: 1.117633581161499, Discriminator loss: 1.1967353820800781\n",
      "\tGenerator loss: 1.0931109189987183, Discriminator loss: 1.2293128967285156\n",
      "\tGenerator loss: 1.0342955589294434, Discriminator loss: 1.2294812202453613\n",
      "\tGenerator loss: 0.9174017906188965, Discriminator loss: 1.2624531984329224\n",
      "\tGenerator loss: 0.8885942697525024, Discriminator loss: 1.2150895595550537\n",
      "\tGenerator loss: 0.9494933485984802, Discriminator loss: 1.1772420406341553\n",
      "\tGenerator loss: 1.0672812461853027, Discriminator loss: 1.2125792503356934\n",
      "\tGenerator loss: 1.126858115196228, Discriminator loss: 1.2339580059051514\n",
      "\tGenerator loss: 1.1551860570907593, Discriminator loss: 1.2241497039794922\n",
      "\tGenerator loss: 1.0980355739593506, Discriminator loss: 1.2219946384429932\n",
      "\tGenerator loss: 1.0101792812347412, Discriminator loss: 1.2047863006591797\n",
      "\tGenerator loss: 0.9450943470001221, Discriminator loss: 1.1832776069641113\n",
      "\tGenerator loss: 0.9312043786048889, Discriminator loss: 1.1821064949035645\n",
      "\tGenerator loss: 0.9780569076538086, Discriminator loss: 1.167014479637146\n",
      "\tGenerator loss: 1.0786895751953125, Discriminator loss: 1.142406940460205\n",
      "\tGenerator loss: 1.1481618881225586, Discriminator loss: 1.1820194721221924\n",
      "\tGenerator loss: 1.1376246213912964, Discriminator loss: 1.2120590209960938\n",
      "\tGenerator loss: 1.1249030828475952, Discriminator loss: 1.1468474864959717\n",
      "\tGenerator loss: 1.060455322265625, Discriminator loss: 1.1441069841384888\n",
      "\tGenerator loss: 1.001412034034729, Discriminator loss: 1.1715095043182373\n",
      "\tGenerator loss: 0.9560049772262573, Discriminator loss: 1.1743760108947754\n",
      "\tGenerator loss: 0.9938096404075623, Discriminator loss: 1.1985334157943726\n",
      "\tGenerator loss: 1.0396276712417603, Discriminator loss: 1.2099372148513794\n",
      "\tGenerator loss: 1.1094017028808594, Discriminator loss: 1.192704439163208\n",
      "\tGenerator loss: 1.093229055404663, Discriminator loss: 1.2130379676818848\n",
      "\tGenerator loss: 1.036651849746704, Discriminator loss: 1.2018342018127441\n",
      "\tGenerator loss: 0.9839720726013184, Discriminator loss: 1.1882603168487549\n",
      "\tGenerator loss: 0.964691698551178, Discriminator loss: 1.1615526676177979\n",
      "\tGenerator loss: 0.9466477632522583, Discriminator loss: 1.184037685394287\n",
      "\tGenerator loss: 0.9970739483833313, Discriminator loss: 1.1941429376602173\n",
      "\tGenerator loss: 1.0454894304275513, Discriminator loss: 1.202253818511963\n",
      "\tGenerator loss: 1.0675082206726074, Discriminator loss: 1.167993426322937\n",
      "\tGenerator loss: 1.0782259702682495, Discriminator loss: 1.1993705034255981\n",
      "\tGenerator loss: 1.02010178565979, Discriminator loss: 1.1827857494354248\n",
      "\tGenerator loss: 0.9774065613746643, Discriminator loss: 1.1863845586776733\n",
      "\tGenerator loss: 0.9344356060028076, Discriminator loss: 1.205177903175354\n",
      "\tGenerator loss: 0.9456315040588379, Discriminator loss: 1.195776343345642\n",
      "\tGenerator loss: 0.9851024746894836, Discriminator loss: 1.237408995628357\n",
      "\tGenerator loss: 1.0412975549697876, Discriminator loss: 1.2038342952728271\n",
      "\tGenerator loss: 1.0491337776184082, Discriminator loss: 1.2101938724517822\n",
      "\tGenerator loss: 1.0141624212265015, Discriminator loss: 1.1866511106491089\n",
      "\tGenerator loss: 0.9847902655601501, Discriminator loss: 1.242262840270996\n",
      "\tGenerator loss: 0.9865586757659912, Discriminator loss: 1.3110679388046265\n",
      "\tGenerator loss: 0.9473264813423157, Discriminator loss: 1.3409626483917236\n",
      "\tGenerator loss: 0.9795742034912109, Discriminator loss: 1.3289903402328491\n",
      "\tGenerator loss: 1.0082941055297852, Discriminator loss: 1.2621166706085205\n",
      "\tGenerator loss: 0.9724162220954895, Discriminator loss: 1.2952854633331299\n",
      "\tGenerator loss: 0.973818302154541, Discriminator loss: 1.27496337890625\n",
      "\tGenerator loss: 1.0036529302597046, Discriminator loss: 1.2200508117675781\n",
      "\tGenerator loss: 0.9767988920211792, Discriminator loss: 1.261035442352295\n",
      "\tGenerator loss: 0.9798906445503235, Discriminator loss: 1.2126892805099487\n",
      "\tGenerator loss: 0.9819271564483643, Discriminator loss: 1.307302474975586\n",
      "\tGenerator loss: 0.9594905972480774, Discriminator loss: 1.2573661804199219\n",
      "\tGenerator loss: 0.9908449649810791, Discriminator loss: 1.231640338897705\n",
      "\tGenerator loss: 1.0344542264938354, Discriminator loss: 1.2744094133377075\n",
      "\tGenerator loss: 1.0177271366119385, Discriminator loss: 1.3001165390014648\n",
      "\tGenerator loss: 0.985876202583313, Discriminator loss: 1.289852499961853\n",
      "\tGenerator loss: 0.9683411121368408, Discriminator loss: 1.2484897375106812\n",
      "\tGenerator loss: 0.9750721454620361, Discriminator loss: 1.1901586055755615\n",
      "\tGenerator loss: 0.9848613739013672, Discriminator loss: 1.2084052562713623\n",
      "\tGenerator loss: 1.0006638765335083, Discriminator loss: 1.2158844470977783\n",
      "\tGenerator loss: 1.0040924549102783, Discriminator loss: 1.1996217966079712\n",
      "\tGenerator loss: 0.9976735711097717, Discriminator loss: 1.2110278606414795\n",
      "\tGenerator loss: 1.0139069557189941, Discriminator loss: 1.1928963661193848\n",
      "\tGenerator loss: 1.0196096897125244, Discriminator loss: 1.1636073589324951\n",
      "\tGenerator loss: 1.0121135711669922, Discriminator loss: 1.2002114057540894\n",
      "\tGenerator loss: 0.9663918614387512, Discriminator loss: 1.1863434314727783\n",
      "\tGenerator loss: 0.9419798851013184, Discriminator loss: 1.2127879858016968\n",
      "\tGenerator loss: 0.9566115736961365, Discriminator loss: 1.2197041511535645\n",
      "\tGenerator loss: 0.9963712692260742, Discriminator loss: 1.1917906999588013\n",
      "\tGenerator loss: 0.982203483581543, Discriminator loss: 1.196756362915039\n",
      "\tGenerator loss: 0.9679003953933716, Discriminator loss: 1.1543015241622925\n",
      "\tGenerator loss: 0.9936487078666687, Discriminator loss: 1.1969821453094482\n",
      "\tGenerator loss: 0.9958001375198364, Discriminator loss: 1.1855393648147583\n",
      "\tGenerator loss: 1.0081756114959717, Discriminator loss: 1.1584290266036987\n",
      "\tGenerator loss: 1.0114518404006958, Discriminator loss: 1.1766291856765747\n",
      "\tGenerator loss: 1.025433897972107, Discriminator loss: 1.2309837341308594\n",
      "\tGenerator loss: 0.9986374378204346, Discriminator loss: 1.2271925210952759\n",
      "\tGenerator loss: 1.0148072242736816, Discriminator loss: 1.1775965690612793\n",
      "\tGenerator loss: 1.0162609815597534, Discriminator loss: 1.171371579170227\n",
      "\tGenerator loss: 1.0080106258392334, Discriminator loss: 1.2034037113189697\n",
      "\tGenerator loss: 0.987525463104248, Discriminator loss: 1.180317759513855\n",
      "\tGenerator loss: 0.9950368404388428, Discriminator loss: 1.1980807781219482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9727474451065063, Discriminator loss: 1.2188594341278076\n",
      "\tGenerator loss: 0.9215905666351318, Discriminator loss: 1.195205807685852\n",
      "\tGenerator loss: 0.9205117225646973, Discriminator loss: 1.1902797222137451\n",
      "\tGenerator loss: 0.965671181678772, Discriminator loss: 1.1674950122833252\n",
      "\tGenerator loss: 1.01396644115448, Discriminator loss: 1.172520637512207\n",
      "\tGenerator loss: 1.0210177898406982, Discriminator loss: 1.187812328338623\n",
      "\tGenerator loss: 1.0114014148712158, Discriminator loss: 1.158921718597412\n",
      "\tGenerator loss: 0.9777261018753052, Discriminator loss: 1.1503936052322388\n",
      "\tGenerator loss: 0.9255614280700684, Discriminator loss: 1.2237975597381592\n",
      "\tGenerator loss: 0.9509631395339966, Discriminator loss: 1.2644236087799072\n",
      "\tGenerator loss: 0.9667937755584717, Discriminator loss: 1.2313246726989746\n",
      "\tGenerator loss: 0.9958868622779846, Discriminator loss: 1.1842142343521118\n",
      "\tGenerator loss: 0.9904036521911621, Discriminator loss: 1.232550859451294\n",
      "\tGenerator loss: 1.0148515701293945, Discriminator loss: 1.1776269674301147\n",
      "\tGenerator loss: 0.9937303066253662, Discriminator loss: 1.1844208240509033\n",
      "\tGenerator loss: 0.9588431119918823, Discriminator loss: 1.2125234603881836\n",
      "\tGenerator loss: 0.9656529426574707, Discriminator loss: 1.2075167894363403\n",
      "\tGenerator loss: 1.0174884796142578, Discriminator loss: 1.1702842712402344\n",
      "\tGenerator loss: 1.086913824081421, Discriminator loss: 1.2021721601486206\n",
      "\tGenerator loss: 1.0647761821746826, Discriminator loss: 1.197347640991211\n",
      "\tGenerator loss: 1.0062313079833984, Discriminator loss: 1.1725106239318848\n",
      "\tGenerator loss: 1.0006929636001587, Discriminator loss: 1.1639784574508667\n",
      "\tGenerator loss: 0.9676922559738159, Discriminator loss: 1.1680028438568115\n",
      "\tGenerator loss: 0.9650121331214905, Discriminator loss: 1.1700608730316162\n",
      "\tGenerator loss: 1.0275449752807617, Discriminator loss: 1.184805154800415\n",
      "\tGenerator loss: 1.1088014841079712, Discriminator loss: 1.1700488328933716\n",
      "\tGenerator loss: 1.092327356338501, Discriminator loss: 1.2130770683288574\n",
      "\tGenerator loss: 1.1182960271835327, Discriminator loss: 1.184728741645813\n",
      "\tGenerator loss: 1.0492262840270996, Discriminator loss: 1.210469365119934\n",
      "\tGenerator loss: 0.9948800206184387, Discriminator loss: 1.2071306705474854\n",
      "\tGenerator loss: 0.9528402090072632, Discriminator loss: 1.2049250602722168\n",
      "\tGenerator loss: 0.9757066965103149, Discriminator loss: 1.191478967666626\n",
      "\tGenerator loss: 1.041231393814087, Discriminator loss: 1.183326244354248\n",
      "\tGenerator loss: 1.114874005317688, Discriminator loss: 1.1584396362304688\n",
      "\tGenerator loss: 1.128969669342041, Discriminator loss: 1.1362918615341187\n",
      "\tGenerator loss: 1.0744563341140747, Discriminator loss: 1.14198637008667\n",
      "\tGenerator loss: 1.041506052017212, Discriminator loss: 1.1805137395858765\n",
      "\tGenerator loss: 1.0166196823120117, Discriminator loss: 1.1786565780639648\n",
      "\tGenerator loss: 0.9878765344619751, Discriminator loss: 1.1583012342453003\n",
      "\tGenerator loss: 1.039323091506958, Discriminator loss: 1.1734633445739746\n",
      "\tGenerator loss: 1.063378930091858, Discriminator loss: 1.1051479578018188\n",
      "\tGenerator loss: 1.0651501417160034, Discriminator loss: 1.1503751277923584\n",
      "\tGenerator loss: 1.0901309251785278, Discriminator loss: 1.1364253759384155\n",
      "\tGenerator loss: 1.0618467330932617, Discriminator loss: 1.1316028833389282\n",
      "\tGenerator loss: 1.0423774719238281, Discriminator loss: 1.1306840181350708\n",
      "\tGenerator loss: 1.0350836515426636, Discriminator loss: 1.1760144233703613\n",
      "\tGenerator loss: 1.0371333360671997, Discriminator loss: 1.180314302444458\n",
      "\tGenerator loss: 1.0207023620605469, Discriminator loss: 1.1853893995285034\n",
      "\tGenerator loss: 1.0141358375549316, Discriminator loss: 1.1717891693115234\n",
      "\tGenerator loss: 1.0442806482315063, Discriminator loss: 1.1924939155578613\n",
      "\tGenerator loss: 1.0931458473205566, Discriminator loss: 1.1321098804473877\n",
      "\tGenerator loss: 1.1016838550567627, Discriminator loss: 1.1334248781204224\n",
      "\tGenerator loss: 1.1046135425567627, Discriminator loss: 1.0975914001464844\n",
      "\tGenerator loss: 1.0266587734222412, Discriminator loss: 1.1589534282684326\n",
      "\tGenerator loss: 0.9537261724472046, Discriminator loss: 1.1724200248718262\n",
      "\tGenerator loss: 0.9657258987426758, Discriminator loss: 1.1744310855865479\n",
      "\tGenerator loss: 1.0575639009475708, Discriminator loss: 1.2136139869689941\n",
      "\tGenerator loss: 1.1084753274917603, Discriminator loss: 1.1950123310089111\n",
      "\tGenerator loss: 1.0781002044677734, Discriminator loss: 1.1922831535339355\n",
      "\tGenerator loss: 0.9983712434768677, Discriminator loss: 1.175565242767334\n",
      "\tGenerator loss: 0.9455722570419312, Discriminator loss: 1.196345567703247\n",
      "\tGenerator loss: 0.9399681091308594, Discriminator loss: 1.2236233949661255\n",
      "\tGenerator loss: 0.9771023392677307, Discriminator loss: 1.265447735786438\n",
      "\tGenerator loss: 0.997439980506897, Discriminator loss: 1.2025399208068848\n",
      "\tGenerator loss: 1.004129409790039, Discriminator loss: 1.1656253337860107\n",
      "\tGenerator loss: 1.0010905265808105, Discriminator loss: 1.1430232524871826\n",
      "\tGenerator loss: 1.0102239847183228, Discriminator loss: 1.1542270183563232\n",
      "\tGenerator loss: 1.0532325506210327, Discriminator loss: 1.1921464204788208\n",
      "\tGenerator loss: 1.0650802850723267, Discriminator loss: 1.1942105293273926\n",
      "\tGenerator loss: 0.9983783960342407, Discriminator loss: 1.1835967302322388\n",
      "\tGenerator loss: 0.9663107991218567, Discriminator loss: 1.1965420246124268\n",
      "\tGenerator loss: 0.9789767265319824, Discriminator loss: 1.1939886808395386\n",
      "\tGenerator loss: 1.007117509841919, Discriminator loss: 1.1964480876922607\n",
      "\tGenerator loss: 1.0534876585006714, Discriminator loss: 1.2296884059906006\n",
      "\tGenerator loss: 1.0585240125656128, Discriminator loss: 1.2104179859161377\n",
      "\tGenerator loss: 0.987729549407959, Discriminator loss: 1.207387924194336\n",
      "\tGenerator loss: 0.9242923855781555, Discriminator loss: 1.1891019344329834\n",
      "\tGenerator loss: 0.938879132270813, Discriminator loss: 1.1634180545806885\n",
      "\tGenerator loss: 0.9793651700019836, Discriminator loss: 1.1734728813171387\n",
      "\tGenerator loss: 1.0417900085449219, Discriminator loss: 1.1848795413970947\n",
      "\tGenerator loss: 1.0367430448532104, Discriminator loss: 1.1407597064971924\n",
      "\tGenerator loss: 1.0172146558761597, Discriminator loss: 1.1961253881454468\n",
      "\tGenerator loss: 0.9607166051864624, Discriminator loss: 1.1885149478912354\n",
      "\tGenerator loss: 0.95297771692276, Discriminator loss: 1.2208291292190552\n",
      "\tGenerator loss: 0.9759083986282349, Discriminator loss: 1.154492974281311\n",
      "\tGenerator loss: 1.0252346992492676, Discriminator loss: 1.1237132549285889\n",
      "\tGenerator loss: 1.0497395992279053, Discriminator loss: 1.1288671493530273\n",
      "\tGenerator loss: 1.0405118465423584, Discriminator loss: 1.1501240730285645\n",
      "\tGenerator loss: 1.0111597776412964, Discriminator loss: 1.1251795291900635\n",
      "\tGenerator loss: 0.9685225486755371, Discriminator loss: 1.1450656652450562\n",
      "\tGenerator loss: 0.9422171115875244, Discriminator loss: 1.1395037174224854\n",
      "\tGenerator loss: 0.9904699325561523, Discriminator loss: 1.1196833848953247\n",
      "\tGenerator loss: 1.074636459350586, Discriminator loss: 1.116835117340088\n",
      "\tGenerator loss: 1.101728916168213, Discriminator loss: 1.1379001140594482\n",
      "\tGenerator loss: 1.0914452075958252, Discriminator loss: 1.143925666809082\n",
      "\tGenerator loss: 1.0026215314865112, Discriminator loss: 1.206155776977539\n",
      "\tGenerator loss: 0.9283734560012817, Discriminator loss: 1.2572424411773682\n",
      "\tGenerator loss: 0.8881179094314575, Discriminator loss: 1.2249194383621216\n",
      "\tGenerator loss: 0.9784783720970154, Discriminator loss: 1.2276928424835205\n",
      "\tGenerator loss: 1.0115346908569336, Discriminator loss: 1.2544605731964111\n",
      "\tGenerator loss: 1.0177286863327026, Discriminator loss: 1.2809585332870483\n",
      "\tGenerator loss: 0.9753580689430237, Discriminator loss: 1.2650840282440186\n",
      "\tGenerator loss: 0.9366570711135864, Discriminator loss: 1.2552889585494995\n",
      "\tGenerator loss: 0.9186033606529236, Discriminator loss: 1.260010004043579\n",
      "\tGenerator loss: 0.9362915754318237, Discriminator loss: 1.2708070278167725\n",
      "\tGenerator loss: 0.9537158608436584, Discriminator loss: 1.2708117961883545\n",
      "\tGenerator loss: 0.9689657092094421, Discriminator loss: 1.2479687929153442\n",
      "\tGenerator loss: 0.9490628242492676, Discriminator loss: 1.267331600189209\n",
      "\tGenerator loss: 0.9475075006484985, Discriminator loss: 1.2714312076568604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9246304631233215, Discriminator loss: 1.2983667850494385\n",
      "\tGenerator loss: 0.9315171241760254, Discriminator loss: 1.243026614189148\n",
      "\tGenerator loss: 0.9426175951957703, Discriminator loss: 1.3145136833190918\n",
      "\tGenerator loss: 0.9461557865142822, Discriminator loss: 1.258545994758606\n",
      "\tGenerator loss: 0.9350367784500122, Discriminator loss: 1.2288391590118408\n",
      "\tGenerator loss: 0.9590291976928711, Discriminator loss: 1.2711669206619263\n",
      "\tGenerator loss: 0.9835230708122253, Discriminator loss: 1.34029221534729\n",
      "\tGenerator loss: 1.0146820545196533, Discriminator loss: 1.325624704360962\n",
      "\tGenerator loss: 0.9910438060760498, Discriminator loss: 1.2577440738677979\n",
      "Time for epoch 37 is 248.79216265678406 sec\n",
      "\tGenerator loss: 0.9470568299293518, Discriminator loss: 1.2907817363739014\n",
      "\tGenerator loss: 0.919360876083374, Discriminator loss: 1.2812285423278809\n",
      "\tGenerator loss: 0.897797167301178, Discriminator loss: 1.267345905303955\n",
      "\tGenerator loss: 0.9268250465393066, Discriminator loss: 1.2303857803344727\n",
      "\tGenerator loss: 0.9878055453300476, Discriminator loss: 1.2668285369873047\n",
      "\tGenerator loss: 0.9946104288101196, Discriminator loss: 1.2706308364868164\n",
      "\tGenerator loss: 1.0098989009857178, Discriminator loss: 1.2307184934616089\n",
      "\tGenerator loss: 0.9864256978034973, Discriminator loss: 1.2718161344528198\n",
      "\tGenerator loss: 0.9646663665771484, Discriminator loss: 1.2468600273132324\n",
      "\tGenerator loss: 0.9456651210784912, Discriminator loss: 1.2096903324127197\n",
      "\tGenerator loss: 0.9734596014022827, Discriminator loss: 1.2125871181488037\n",
      "\tGenerator loss: 1.0420639514923096, Discriminator loss: 1.215268850326538\n",
      "\tGenerator loss: 1.0542488098144531, Discriminator loss: 1.2083438634872437\n",
      "\tGenerator loss: 0.995842456817627, Discriminator loss: 1.1988024711608887\n",
      "\tGenerator loss: 0.9955759048461914, Discriminator loss: 1.1732094287872314\n",
      "\tGenerator loss: 0.9847270846366882, Discriminator loss: 1.1588021516799927\n",
      "\tGenerator loss: 0.9782343506813049, Discriminator loss: 1.1713316440582275\n",
      "\tGenerator loss: 1.016939640045166, Discriminator loss: 1.1359151601791382\n",
      "\tGenerator loss: 1.0719294548034668, Discriminator loss: 1.1360998153686523\n",
      "\tGenerator loss: 1.1023406982421875, Discriminator loss: 1.1272841691970825\n",
      "\tGenerator loss: 1.1105148792266846, Discriminator loss: 1.09385347366333\n",
      "\tGenerator loss: 1.1175552606582642, Discriminator loss: 1.1042654514312744\n",
      "\tGenerator loss: 1.0433199405670166, Discriminator loss: 1.141161322593689\n",
      "\tGenerator loss: 1.0510199069976807, Discriminator loss: 1.1053094863891602\n",
      "\tGenerator loss: 1.0558851957321167, Discriminator loss: 1.1005547046661377\n",
      "\tGenerator loss: 1.1034197807312012, Discriminator loss: 1.089674949645996\n",
      "\tGenerator loss: 1.1248339414596558, Discriminator loss: 1.172305941581726\n",
      "\tGenerator loss: 1.0586602687835693, Discriminator loss: 1.1479127407073975\n",
      "\tGenerator loss: 0.9792301654815674, Discriminator loss: 1.2129955291748047\n",
      "\tGenerator loss: 0.9035966396331787, Discriminator loss: 1.1759345531463623\n",
      "\tGenerator loss: 0.8927884101867676, Discriminator loss: 1.1691735982894897\n",
      "\tGenerator loss: 0.9373084306716919, Discriminator loss: 1.164597749710083\n",
      "\tGenerator loss: 1.032372236251831, Discriminator loss: 1.1531450748443604\n",
      "\tGenerator loss: 1.151435375213623, Discriminator loss: 1.1355262994766235\n",
      "\tGenerator loss: 1.1866514682769775, Discriminator loss: 1.1309664249420166\n",
      "\tGenerator loss: 1.1218724250793457, Discriminator loss: 1.1961560249328613\n",
      "\tGenerator loss: 1.036898136138916, Discriminator loss: 1.1964855194091797\n",
      "\tGenerator loss: 0.9312423467636108, Discriminator loss: 1.196642518043518\n",
      "\tGenerator loss: 0.8732402324676514, Discriminator loss: 1.1858540773391724\n",
      "\tGenerator loss: 0.9168391823768616, Discriminator loss: 1.1439285278320312\n",
      "\tGenerator loss: 1.0254783630371094, Discriminator loss: 1.1267260313034058\n",
      "\tGenerator loss: 1.1316571235656738, Discriminator loss: 1.1722650527954102\n",
      "\tGenerator loss: 1.210342288017273, Discriminator loss: 1.1826412677764893\n",
      "\tGenerator loss: 1.1249866485595703, Discriminator loss: 1.2149728536605835\n",
      "\tGenerator loss: 1.0022788047790527, Discriminator loss: 1.2245056629180908\n",
      "\tGenerator loss: 0.9222812652587891, Discriminator loss: 1.2141211032867432\n",
      "\tGenerator loss: 0.8818421363830566, Discriminator loss: 1.210463523864746\n",
      "\tGenerator loss: 0.9133439660072327, Discriminator loss: 1.1850318908691406\n",
      "\tGenerator loss: 1.0183864831924438, Discriminator loss: 1.1580275297164917\n",
      "\tGenerator loss: 1.1196224689483643, Discriminator loss: 1.1618151664733887\n",
      "\tGenerator loss: 1.1537857055664062, Discriminator loss: 1.2131617069244385\n",
      "\tGenerator loss: 1.099706768989563, Discriminator loss: 1.213680386543274\n",
      "\tGenerator loss: 1.0571600198745728, Discriminator loss: 1.1559054851531982\n",
      "\tGenerator loss: 0.9773305654525757, Discriminator loss: 1.168555498123169\n",
      "\tGenerator loss: 0.9442778825759888, Discriminator loss: 1.147896409034729\n",
      "\tGenerator loss: 0.9532341957092285, Discriminator loss: 1.1759474277496338\n",
      "\tGenerator loss: 1.0244102478027344, Discriminator loss: 1.1487475633621216\n",
      "\tGenerator loss: 1.1001176834106445, Discriminator loss: 1.136720895767212\n",
      "\tGenerator loss: 1.1214585304260254, Discriminator loss: 1.1471408605575562\n",
      "\tGenerator loss: 1.0971639156341553, Discriminator loss: 1.1143341064453125\n",
      "\tGenerator loss: 1.0593738555908203, Discriminator loss: 1.09637451171875\n",
      "\tGenerator loss: 1.042560338973999, Discriminator loss: 1.092531681060791\n",
      "\tGenerator loss: 1.0399739742279053, Discriminator loss: 1.1375904083251953\n",
      "\tGenerator loss: 1.0907208919525146, Discriminator loss: 1.131119728088379\n",
      "\tGenerator loss: 1.062420129776001, Discriminator loss: 1.1306674480438232\n",
      "\tGenerator loss: 1.0615341663360596, Discriminator loss: 1.0689480304718018\n",
      "\tGenerator loss: 1.1043492555618286, Discriminator loss: 1.0872323513031006\n",
      "\tGenerator loss: 1.1357150077819824, Discriminator loss: 1.057084560394287\n",
      "\tGenerator loss: 1.194187879562378, Discriminator loss: 1.0544884204864502\n",
      "\tGenerator loss: 1.1837482452392578, Discriminator loss: 1.0529252290725708\n",
      "\tGenerator loss: 1.1687949895858765, Discriminator loss: 1.0486104488372803\n",
      "\tGenerator loss: 1.164670467376709, Discriminator loss: 1.0842928886413574\n",
      "\tGenerator loss: 1.1380066871643066, Discriminator loss: 1.0520739555358887\n",
      "\tGenerator loss: 1.1138638257980347, Discriminator loss: 1.037656545639038\n",
      "\tGenerator loss: 1.1182790994644165, Discriminator loss: 1.011971354484558\n",
      "\tGenerator loss: 1.1605418920516968, Discriminator loss: 1.1579205989837646\n",
      "\tGenerator loss: 1.1934938430786133, Discriminator loss: 1.2991591691970825\n",
      "\tGenerator loss: 1.148551344871521, Discriminator loss: 1.2728571891784668\n",
      "\tGenerator loss: 1.1195530891418457, Discriminator loss: 1.2305508852005005\n",
      "\tGenerator loss: 1.0965769290924072, Discriminator loss: 1.1323966979980469\n",
      "\tGenerator loss: 1.0708982944488525, Discriminator loss: 1.1798492670059204\n",
      "\tGenerator loss: 1.1044877767562866, Discriminator loss: 1.1549279689788818\n",
      "\tGenerator loss: 1.1228265762329102, Discriminator loss: 1.1051912307739258\n",
      "\tGenerator loss: 1.1113981008529663, Discriminator loss: 1.145423412322998\n",
      "\tGenerator loss: 1.115739345550537, Discriminator loss: 1.104321002960205\n",
      "\tGenerator loss: 1.0896010398864746, Discriminator loss: 1.2691359519958496\n",
      "\tGenerator loss: 1.0759289264678955, Discriminator loss: 1.1611640453338623\n",
      "\tGenerator loss: 1.0512425899505615, Discriminator loss: 1.1695730686187744\n",
      "\tGenerator loss: 1.0472347736358643, Discriminator loss: 1.2884876728057861\n",
      "\tGenerator loss: 1.0493329763412476, Discriminator loss: 1.322519302368164\n",
      "\tGenerator loss: 1.0334384441375732, Discriminator loss: 1.2993489503860474\n",
      "\tGenerator loss: 0.9724977612495422, Discriminator loss: 1.2757439613342285\n",
      "\tGenerator loss: 0.9711194038391113, Discriminator loss: 1.1926966905593872\n",
      "\tGenerator loss: 1.025518536567688, Discriminator loss: 1.1929709911346436\n",
      "\tGenerator loss: 1.127061367034912, Discriminator loss: 1.2201130390167236\n",
      "\tGenerator loss: 1.0896861553192139, Discriminator loss: 1.2032510042190552\n",
      "\tGenerator loss: 1.0509394407272339, Discriminator loss: 1.2396278381347656\n",
      "\tGenerator loss: 1.0033596754074097, Discriminator loss: 1.2436089515686035\n",
      "\tGenerator loss: 0.9176265597343445, Discriminator loss: 1.2653781175613403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.982438325881958, Discriminator loss: 1.2611600160598755\n",
      "\tGenerator loss: 1.0267736911773682, Discriminator loss: 1.267791509628296\n",
      "\tGenerator loss: 1.0719282627105713, Discriminator loss: 1.2480512857437134\n",
      "\tGenerator loss: 1.0439696311950684, Discriminator loss: 1.2811110019683838\n",
      "\tGenerator loss: 0.9819093346595764, Discriminator loss: 1.3346320390701294\n",
      "\tGenerator loss: 0.9449478387832642, Discriminator loss: 1.292656421661377\n",
      "\tGenerator loss: 0.9002678394317627, Discriminator loss: 1.2870099544525146\n",
      "\tGenerator loss: 0.9770011901855469, Discriminator loss: 1.2673497200012207\n",
      "\tGenerator loss: 1.043533205986023, Discriminator loss: 1.2519879341125488\n",
      "\tGenerator loss: 1.0945219993591309, Discriminator loss: 1.2960915565490723\n",
      "\tGenerator loss: 1.040750503540039, Discriminator loss: 1.2735772132873535\n",
      "\tGenerator loss: 0.9790211915969849, Discriminator loss: 1.2892825603485107\n",
      "\tGenerator loss: 0.952564537525177, Discriminator loss: 1.2800827026367188\n",
      "\tGenerator loss: 0.9808826446533203, Discriminator loss: 1.2679555416107178\n",
      "\tGenerator loss: 0.9911205768585205, Discriminator loss: 1.3157892227172852\n",
      "\tGenerator loss: 1.015905737876892, Discriminator loss: 1.306705355644226\n",
      "\tGenerator loss: 0.9858226180076599, Discriminator loss: 1.2974295616149902\n",
      "\tGenerator loss: 0.9295988082885742, Discriminator loss: 1.3665571212768555\n",
      "\tGenerator loss: 0.8669477105140686, Discriminator loss: 1.4038712978363037\n",
      "\tGenerator loss: 0.8267083168029785, Discriminator loss: 1.3204219341278076\n",
      "\tGenerator loss: 0.8567051887512207, Discriminator loss: 1.3624267578125\n",
      "\tGenerator loss: 0.9269976615905762, Discriminator loss: 1.3386006355285645\n",
      "\tGenerator loss: 0.9393447637557983, Discriminator loss: 1.3980076313018799\n",
      "\tGenerator loss: 0.9285116791725159, Discriminator loss: 1.3948136568069458\n",
      "\tGenerator loss: 0.869521975517273, Discriminator loss: 1.4076933860778809\n",
      "\tGenerator loss: 0.8165132999420166, Discriminator loss: 1.3513833284378052\n",
      "\tGenerator loss: 0.816171407699585, Discriminator loss: 1.3475677967071533\n",
      "\tGenerator loss: 0.9036085605621338, Discriminator loss: 1.3295471668243408\n",
      "\tGenerator loss: 0.9823362231254578, Discriminator loss: 1.379465103149414\n",
      "\tGenerator loss: 0.9790005087852478, Discriminator loss: 1.318588137626648\n",
      "\tGenerator loss: 0.9502328634262085, Discriminator loss: 1.312631607055664\n",
      "\tGenerator loss: 0.9281565546989441, Discriminator loss: 1.2910821437835693\n",
      "\tGenerator loss: 0.8839794397354126, Discriminator loss: 1.2862504720687866\n",
      "\tGenerator loss: 0.8585094809532166, Discriminator loss: 1.2732901573181152\n",
      "\tGenerator loss: 0.8904918432235718, Discriminator loss: 1.2530202865600586\n",
      "\tGenerator loss: 0.9273200035095215, Discriminator loss: 1.2212625741958618\n",
      "\tGenerator loss: 0.951865553855896, Discriminator loss: 1.2685728073120117\n",
      "\tGenerator loss: 1.0151970386505127, Discriminator loss: 1.2317339181900024\n",
      "\tGenerator loss: 1.0356965065002441, Discriminator loss: 1.197105884552002\n",
      "\tGenerator loss: 1.003124475479126, Discriminator loss: 1.182949423789978\n",
      "\tGenerator loss: 0.9944106936454773, Discriminator loss: 1.157646894454956\n",
      "\tGenerator loss: 0.9684326648712158, Discriminator loss: 1.1441075801849365\n",
      "\tGenerator loss: 0.9732253551483154, Discriminator loss: 1.1169335842132568\n",
      "\tGenerator loss: 1.024404764175415, Discriminator loss: 1.1293048858642578\n",
      "\tGenerator loss: 1.0827606916427612, Discriminator loss: 1.1357710361480713\n",
      "\tGenerator loss: 1.1199054718017578, Discriminator loss: 1.1129634380340576\n",
      "\tGenerator loss: 1.120243787765503, Discriminator loss: 1.113309621810913\n",
      "\tGenerator loss: 1.1531798839569092, Discriminator loss: 1.0727412700653076\n",
      "\tGenerator loss: 1.1321055889129639, Discriminator loss: 1.0841190814971924\n",
      "\tGenerator loss: 1.117295742034912, Discriminator loss: 1.0267338752746582\n",
      "\tGenerator loss: 1.0558282136917114, Discriminator loss: 1.069826602935791\n",
      "\tGenerator loss: 1.0587363243103027, Discriminator loss: 1.0339065790176392\n",
      "\tGenerator loss: 1.0880868434906006, Discriminator loss: 1.028393268585205\n",
      "\tGenerator loss: 1.1238247156143188, Discriminator loss: 1.015580654144287\n",
      "\tGenerator loss: 1.152315378189087, Discriminator loss: 1.045894742012024\n",
      "\tGenerator loss: 1.1511048078536987, Discriminator loss: 1.0781993865966797\n",
      "\tGenerator loss: 1.1256680488586426, Discriminator loss: 1.0316388607025146\n",
      "\tGenerator loss: 1.1388647556304932, Discriminator loss: 1.0495246648788452\n",
      "\tGenerator loss: 1.1075663566589355, Discriminator loss: 1.0024652481079102\n",
      "\tGenerator loss: 1.116060733795166, Discriminator loss: 1.0420339107513428\n",
      "\tGenerator loss: 1.1113131046295166, Discriminator loss: 0.9812319874763489\n",
      "\tGenerator loss: 1.1258149147033691, Discriminator loss: 0.9703081846237183\n",
      "\tGenerator loss: 1.1599082946777344, Discriminator loss: 0.9614283442497253\n",
      "\tGenerator loss: 1.2139278650283813, Discriminator loss: 1.0013792514801025\n",
      "\tGenerator loss: 1.2071528434753418, Discriminator loss: 1.0130534172058105\n",
      "\tGenerator loss: 1.1519038677215576, Discriminator loss: 1.0991708040237427\n",
      "\tGenerator loss: 1.1114859580993652, Discriminator loss: 1.0509319305419922\n",
      "\tGenerator loss: 1.0880184173583984, Discriminator loss: 1.1003007888793945\n",
      "\tGenerator loss: 1.0920283794403076, Discriminator loss: 1.0537508726119995\n",
      "\tGenerator loss: 1.1263959407806396, Discriminator loss: 1.0405457019805908\n",
      "\tGenerator loss: 1.1443121433258057, Discriminator loss: 1.0595648288726807\n",
      "\tGenerator loss: 1.1764012575149536, Discriminator loss: 1.069061517715454\n",
      "\tGenerator loss: 1.1540346145629883, Discriminator loss: 0.9967241883277893\n",
      "\tGenerator loss: 1.1300146579742432, Discriminator loss: 0.9977266788482666\n",
      "\tGenerator loss: 1.1422526836395264, Discriminator loss: 1.0172384977340698\n",
      "\tGenerator loss: 1.148098111152649, Discriminator loss: 1.0377461910247803\n",
      "\tGenerator loss: 1.0987253189086914, Discriminator loss: 1.0995666980743408\n",
      "\tGenerator loss: 1.0985368490219116, Discriminator loss: 1.0802125930786133\n",
      "\tGenerator loss: 1.084526777267456, Discriminator loss: 1.0269906520843506\n",
      "\tGenerator loss: 1.047781229019165, Discriminator loss: 1.0882928371429443\n",
      "\tGenerator loss: 1.0927473306655884, Discriminator loss: 1.0869781970977783\n",
      "\tGenerator loss: 1.0865840911865234, Discriminator loss: 1.0568164587020874\n",
      "\tGenerator loss: 1.119699239730835, Discriminator loss: 1.0568262338638306\n",
      "\tGenerator loss: 1.123584270477295, Discriminator loss: 1.1072704792022705\n",
      "\tGenerator loss: 1.0866658687591553, Discriminator loss: 1.0926215648651123\n",
      "\tGenerator loss: 1.0844714641571045, Discriminator loss: 1.091123104095459\n",
      "\tGenerator loss: 1.0675431489944458, Discriminator loss: 1.150282621383667\n",
      "\tGenerator loss: 1.0730727910995483, Discriminator loss: 1.1527869701385498\n",
      "\tGenerator loss: 1.0764585733413696, Discriminator loss: 1.1616880893707275\n",
      "\tGenerator loss: 1.0827199220657349, Discriminator loss: 1.1931668519973755\n",
      "\tGenerator loss: 1.0630987882614136, Discriminator loss: 1.1603479385375977\n",
      "\tGenerator loss: 1.0699288845062256, Discriminator loss: 1.1744542121887207\n",
      "\tGenerator loss: 1.1013083457946777, Discriminator loss: 1.1400176286697388\n",
      "\tGenerator loss: 1.1037449836730957, Discriminator loss: 1.0877342224121094\n",
      "\tGenerator loss: 1.0894708633422852, Discriminator loss: 1.0634915828704834\n",
      "\tGenerator loss: 1.096360445022583, Discriminator loss: 1.0564534664154053\n",
      "\tGenerator loss: 1.1136785745620728, Discriminator loss: 1.0775214433670044\n",
      "\tGenerator loss: 1.1224312782287598, Discriminator loss: 1.079849123954773\n",
      "\tGenerator loss: 1.1254315376281738, Discriminator loss: 1.0816184282302856\n",
      "\tGenerator loss: 1.0869388580322266, Discriminator loss: 1.1131598949432373\n",
      "\tGenerator loss: 1.067716121673584, Discriminator loss: 1.1004345417022705\n",
      "\tGenerator loss: 1.082016944885254, Discriminator loss: 1.0837764739990234\n",
      "\tGenerator loss: 1.094374179840088, Discriminator loss: 1.0702966451644897\n",
      "\tGenerator loss: 1.154092788696289, Discriminator loss: 1.1223132610321045\n",
      "\tGenerator loss: 1.1290470361709595, Discriminator loss: 1.1553821563720703\n",
      "\tGenerator loss: 1.0625405311584473, Discriminator loss: 1.1619701385498047\n",
      "\tGenerator loss: 0.9714523553848267, Discriminator loss: 1.1711727380752563\n",
      "\tGenerator loss: 0.9707770943641663, Discriminator loss: 1.1839693784713745\n",
      "\tGenerator loss: 0.9899766445159912, Discriminator loss: 1.170536994934082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0693700313568115, Discriminator loss: 1.1673070192337036\n",
      "\tGenerator loss: 1.0758986473083496, Discriminator loss: 1.2029411792755127\n",
      "\tGenerator loss: 1.029623031616211, Discriminator loss: 1.2389185428619385\n",
      "\tGenerator loss: 1.0045034885406494, Discriminator loss: 1.2596361637115479\n",
      "\tGenerator loss: 0.9496992826461792, Discriminator loss: 1.2583122253417969\n",
      "\tGenerator loss: 0.9252468347549438, Discriminator loss: 1.2565639019012451\n",
      "\tGenerator loss: 0.9102774262428284, Discriminator loss: 1.27031672000885\n",
      "\tGenerator loss: 0.9318210482597351, Discriminator loss: 1.2843141555786133\n",
      "\tGenerator loss: 0.9474254846572876, Discriminator loss: 1.3121469020843506\n",
      "\tGenerator loss: 0.9430316686630249, Discriminator loss: 1.324700117111206\n",
      "\tGenerator loss: 0.9424260854721069, Discriminator loss: 1.3100546598434448\n",
      "\tGenerator loss: 0.9287123680114746, Discriminator loss: 1.3493058681488037\n",
      "\tGenerator loss: 0.89324951171875, Discriminator loss: 1.3780169486999512\n",
      "\tGenerator loss: 0.8493970632553101, Discriminator loss: 1.3635063171386719\n",
      "\tGenerator loss: 0.8230795860290527, Discriminator loss: 1.3686556816101074\n",
      "\tGenerator loss: 0.8217300176620483, Discriminator loss: 1.3860715627670288\n",
      "\tGenerator loss: 0.8074736595153809, Discriminator loss: 1.3798918724060059\n",
      "\tGenerator loss: 0.8196855187416077, Discriminator loss: 1.3878339529037476\n",
      "\tGenerator loss: 0.8809151649475098, Discriminator loss: 1.37746000289917\n",
      "\tGenerator loss: 0.8387008905410767, Discriminator loss: 1.3391635417938232\n",
      "\tGenerator loss: 0.8235794305801392, Discriminator loss: 1.3821475505828857\n",
      "\tGenerator loss: 0.8401651978492737, Discriminator loss: 1.3058500289916992\n",
      "\tGenerator loss: 0.8628166913986206, Discriminator loss: 1.2651017904281616\n",
      "\tGenerator loss: 0.8897910118103027, Discriminator loss: 1.3100130558013916\n",
      "\tGenerator loss: 0.9168726801872253, Discriminator loss: 1.3246729373931885\n",
      "\tGenerator loss: 0.9401568174362183, Discriminator loss: 1.314237356185913\n",
      "\tGenerator loss: 0.9354174733161926, Discriminator loss: 1.2727549076080322\n",
      "Time for epoch 38 is 252.90733933448792 sec\n",
      "\tGenerator loss: 0.9040817022323608, Discriminator loss: 1.2863134145736694\n",
      "\tGenerator loss: 0.8768087029457092, Discriminator loss: 1.2713507413864136\n",
      "\tGenerator loss: 0.8746259212493896, Discriminator loss: 1.2631287574768066\n",
      "\tGenerator loss: 0.8776088356971741, Discriminator loss: 1.2663159370422363\n",
      "\tGenerator loss: 0.9623924493789673, Discriminator loss: 1.2769345045089722\n",
      "\tGenerator loss: 0.9843029379844666, Discriminator loss: 1.3436157703399658\n",
      "\tGenerator loss: 0.9921467304229736, Discriminator loss: 1.2644083499908447\n",
      "\tGenerator loss: 0.9913725852966309, Discriminator loss: 1.3244543075561523\n",
      "\tGenerator loss: 0.9583300352096558, Discriminator loss: 1.288752794265747\n",
      "\tGenerator loss: 0.9256365299224854, Discriminator loss: 1.2736213207244873\n",
      "\tGenerator loss: 0.9376202821731567, Discriminator loss: 1.2539093494415283\n",
      "\tGenerator loss: 0.9711584448814392, Discriminator loss: 1.2411202192306519\n",
      "\tGenerator loss: 0.9917296171188354, Discriminator loss: 1.2296087741851807\n",
      "\tGenerator loss: 1.0318881273269653, Discriminator loss: 1.205655813217163\n",
      "\tGenerator loss: 1.0492284297943115, Discriminator loss: 1.226525902748108\n",
      "\tGenerator loss: 1.0417231321334839, Discriminator loss: 1.1865838766098022\n",
      "\tGenerator loss: 1.020636796951294, Discriminator loss: 1.1619768142700195\n",
      "\tGenerator loss: 1.0170536041259766, Discriminator loss: 1.150036334991455\n",
      "\tGenerator loss: 1.0126956701278687, Discriminator loss: 1.258920669555664\n",
      "\tGenerator loss: 1.0566775798797607, Discriminator loss: 1.2095156908035278\n",
      "\tGenerator loss: 1.0439209938049316, Discriminator loss: 1.190896987915039\n",
      "\tGenerator loss: 1.0248064994812012, Discriminator loss: 1.2302980422973633\n",
      "\tGenerator loss: 1.056183099746704, Discriminator loss: 1.194043755531311\n",
      "\tGenerator loss: 1.0172102451324463, Discriminator loss: 1.220400333404541\n",
      "\tGenerator loss: 1.0201737880706787, Discriminator loss: 1.2279237508773804\n",
      "\tGenerator loss: 1.0495936870574951, Discriminator loss: 1.1745140552520752\n",
      "\tGenerator loss: 1.069456696510315, Discriminator loss: 1.128843069076538\n",
      "\tGenerator loss: 1.0690796375274658, Discriminator loss: 1.0845897197723389\n",
      "\tGenerator loss: 1.0895872116088867, Discriminator loss: 1.0829253196716309\n",
      "\tGenerator loss: 1.0925936698913574, Discriminator loss: 1.0442512035369873\n",
      "\tGenerator loss: 1.0564932823181152, Discriminator loss: 1.0350157022476196\n",
      "\tGenerator loss: 1.0725170373916626, Discriminator loss: 1.0286586284637451\n",
      "\tGenerator loss: 1.122802734375, Discriminator loss: 1.0038888454437256\n",
      "\tGenerator loss: 1.1816136837005615, Discriminator loss: 1.0404043197631836\n",
      "\tGenerator loss: 1.2472422122955322, Discriminator loss: 1.00929856300354\n",
      "\tGenerator loss: 1.2527588605880737, Discriminator loss: 1.0009980201721191\n",
      "\tGenerator loss: 1.1647037267684937, Discriminator loss: 1.0087246894836426\n",
      "\tGenerator loss: 1.1056588888168335, Discriminator loss: 1.0136080980300903\n",
      "\tGenerator loss: 1.0937938690185547, Discriminator loss: 0.964585542678833\n",
      "\tGenerator loss: 1.1131205558776855, Discriminator loss: 0.9385659694671631\n",
      "\tGenerator loss: 1.1938014030456543, Discriminator loss: 0.9091550707817078\n",
      "\tGenerator loss: 1.321562647819519, Discriminator loss: 0.9193747639656067\n",
      "\tGenerator loss: 1.3666725158691406, Discriminator loss: 0.919837236404419\n",
      "\tGenerator loss: 1.372581958770752, Discriminator loss: 0.9410191774368286\n",
      "\tGenerator loss: 1.273404836654663, Discriminator loss: 0.9253465533256531\n",
      "\tGenerator loss: 1.1337910890579224, Discriminator loss: 0.9756897687911987\n",
      "\tGenerator loss: 1.0394220352172852, Discriminator loss: 0.9936116337776184\n",
      "\tGenerator loss: 1.0943548679351807, Discriminator loss: 0.9677829742431641\n",
      "\tGenerator loss: 1.184314489364624, Discriminator loss: 0.9674990177154541\n",
      "\tGenerator loss: 1.2572146654129028, Discriminator loss: 1.004331111907959\n",
      "\tGenerator loss: 1.33565354347229, Discriminator loss: 1.037983775138855\n",
      "\tGenerator loss: 1.3041008710861206, Discriminator loss: 1.0063858032226562\n",
      "\tGenerator loss: 1.1793440580368042, Discriminator loss: 0.9926835298538208\n",
      "\tGenerator loss: 1.094693660736084, Discriminator loss: 1.084256649017334\n",
      "\tGenerator loss: 1.0315797328948975, Discriminator loss: 1.1044342517852783\n",
      "\tGenerator loss: 0.973771333694458, Discriminator loss: 1.1276471614837646\n",
      "\tGenerator loss: 0.9916476607322693, Discriminator loss: 1.1902880668640137\n",
      "\tGenerator loss: 1.0421078205108643, Discriminator loss: 1.191518783569336\n",
      "\tGenerator loss: 1.0736743211746216, Discriminator loss: 1.1633927822113037\n",
      "\tGenerator loss: 1.0471125841140747, Discriminator loss: 1.1854488849639893\n",
      "\tGenerator loss: 0.9884957075119019, Discriminator loss: 1.2312066555023193\n",
      "\tGenerator loss: 0.9268056750297546, Discriminator loss: 1.2176337242126465\n",
      "\tGenerator loss: 0.9047421216964722, Discriminator loss: 1.204735279083252\n",
      "\tGenerator loss: 0.9243312478065491, Discriminator loss: 1.1755976676940918\n",
      "\tGenerator loss: 0.931256890296936, Discriminator loss: 1.1944907903671265\n",
      "\tGenerator loss: 0.9864189028739929, Discriminator loss: 1.187495231628418\n",
      "\tGenerator loss: 1.0546610355377197, Discriminator loss: 1.1801300048828125\n",
      "\tGenerator loss: 1.01426362991333, Discriminator loss: 1.162116289138794\n",
      "\tGenerator loss: 1.0168111324310303, Discriminator loss: 1.1854336261749268\n",
      "\tGenerator loss: 0.9999682903289795, Discriminator loss: 1.161828875541687\n",
      "\tGenerator loss: 0.9614646434783936, Discriminator loss: 1.1647162437438965\n",
      "\tGenerator loss: 0.9979041814804077, Discriminator loss: 1.1444424390792847\n",
      "\tGenerator loss: 1.0382596254348755, Discriminator loss: 1.1138134002685547\n",
      "\tGenerator loss: 1.0839056968688965, Discriminator loss: 1.0614562034606934\n",
      "\tGenerator loss: 1.1352647542953491, Discriminator loss: 1.0436655282974243\n",
      "\tGenerator loss: 1.1940889358520508, Discriminator loss: 1.086946725845337\n",
      "\tGenerator loss: 1.24808669090271, Discriminator loss: 1.1271445751190186\n",
      "\tGenerator loss: 1.2027513980865479, Discriminator loss: 1.1015557050704956\n",
      "\tGenerator loss: 1.1450769901275635, Discriminator loss: 1.090501070022583\n",
      "\tGenerator loss: 1.116452932357788, Discriminator loss: 1.0585451126098633\n",
      "\tGenerator loss: 1.1568187475204468, Discriminator loss: 1.0563340187072754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1956429481506348, Discriminator loss: 1.0555747747421265\n",
      "\tGenerator loss: 1.2502937316894531, Discriminator loss: 0.9835535883903503\n",
      "\tGenerator loss: 1.2700873613357544, Discriminator loss: 1.0060689449310303\n",
      "\tGenerator loss: 1.3126533031463623, Discriminator loss: 0.9352681636810303\n",
      "\tGenerator loss: 1.2990508079528809, Discriminator loss: 1.1609079837799072\n",
      "\tGenerator loss: 1.2443387508392334, Discriminator loss: 1.043386459350586\n",
      "\tGenerator loss: 1.2145960330963135, Discriminator loss: 1.0386555194854736\n",
      "\tGenerator loss: 1.2027909755706787, Discriminator loss: 1.2085375785827637\n",
      "\tGenerator loss: 1.1674929857254028, Discriminator loss: 1.2936182022094727\n",
      "\tGenerator loss: 1.1056649684906006, Discriminator loss: 1.2867164611816406\n",
      "\tGenerator loss: 1.084251880645752, Discriminator loss: 1.2118873596191406\n",
      "\tGenerator loss: 1.0953134298324585, Discriminator loss: 1.083977460861206\n",
      "\tGenerator loss: 1.1563243865966797, Discriminator loss: 1.0900835990905762\n",
      "\tGenerator loss: 1.199216365814209, Discriminator loss: 1.1925978660583496\n",
      "\tGenerator loss: 1.2159532308578491, Discriminator loss: 1.1510531902313232\n",
      "\tGenerator loss: 1.1951091289520264, Discriminator loss: 1.2247123718261719\n",
      "\tGenerator loss: 1.095921277999878, Discriminator loss: 1.1721795797348022\n",
      "\tGenerator loss: 1.007561445236206, Discriminator loss: 1.2192111015319824\n",
      "\tGenerator loss: 0.9934786558151245, Discriminator loss: 1.373196005821228\n",
      "\tGenerator loss: 0.9679343700408936, Discriminator loss: 1.3173017501831055\n",
      "\tGenerator loss: 1.0458691120147705, Discriminator loss: 1.2867528200149536\n",
      "\tGenerator loss: 1.1017279624938965, Discriminator loss: 1.2892653942108154\n",
      "\tGenerator loss: 1.11786687374115, Discriminator loss: 1.2464929819107056\n",
      "\tGenerator loss: 1.0804235935211182, Discriminator loss: 1.369246244430542\n",
      "\tGenerator loss: 0.9821078777313232, Discriminator loss: 1.3346115350723267\n",
      "\tGenerator loss: 0.9270403385162354, Discriminator loss: 1.382049322128296\n",
      "\tGenerator loss: 0.8903480768203735, Discriminator loss: 1.3176648616790771\n",
      "\tGenerator loss: 0.9249866008758545, Discriminator loss: 1.2746479511260986\n",
      "\tGenerator loss: 1.0566470623016357, Discriminator loss: 1.4676305055618286\n",
      "\tGenerator loss: 1.1058924198150635, Discriminator loss: 1.5969226360321045\n",
      "\tGenerator loss: 1.0279653072357178, Discriminator loss: 1.6071758270263672\n",
      "\tGenerator loss: 0.8979526162147522, Discriminator loss: 1.5479228496551514\n",
      "\tGenerator loss: 0.8472582101821899, Discriminator loss: 1.4511196613311768\n",
      "\tGenerator loss: 0.8425133228302002, Discriminator loss: 1.5632497072219849\n",
      "\tGenerator loss: 0.9287483096122742, Discriminator loss: 1.455315351486206\n",
      "\tGenerator loss: 1.0076850652694702, Discriminator loss: 1.436572551727295\n",
      "\tGenerator loss: 1.0809390544891357, Discriminator loss: 1.40009343624115\n",
      "\tGenerator loss: 1.0366829633712769, Discriminator loss: 1.34798002243042\n",
      "\tGenerator loss: 0.9720953702926636, Discriminator loss: 1.2950594425201416\n",
      "\tGenerator loss: 0.9217042326927185, Discriminator loss: 1.2833638191223145\n",
      "\tGenerator loss: 0.9535236358642578, Discriminator loss: 1.2559740543365479\n",
      "\tGenerator loss: 1.0265381336212158, Discriminator loss: 1.25021493434906\n",
      "\tGenerator loss: 1.0880529880523682, Discriminator loss: 1.2241663932800293\n",
      "\tGenerator loss: 1.1193253993988037, Discriminator loss: 1.1880849599838257\n",
      "\tGenerator loss: 1.113218069076538, Discriminator loss: 1.2150449752807617\n",
      "\tGenerator loss: 1.046186089515686, Discriminator loss: 1.2801485061645508\n",
      "\tGenerator loss: 1.0106409788131714, Discriminator loss: 1.1999192237854004\n",
      "\tGenerator loss: 1.00569486618042, Discriminator loss: 1.1310133934020996\n",
      "\tGenerator loss: 1.0437052249908447, Discriminator loss: 1.1440389156341553\n",
      "\tGenerator loss: 1.1808531284332275, Discriminator loss: 1.1162856817245483\n",
      "\tGenerator loss: 1.2449994087219238, Discriminator loss: 1.1394001245498657\n",
      "\tGenerator loss: 1.202134609222412, Discriminator loss: 1.135447382926941\n",
      "\tGenerator loss: 1.1489852666854858, Discriminator loss: 1.1047210693359375\n",
      "\tGenerator loss: 1.097839117050171, Discriminator loss: 1.0429174900054932\n",
      "\tGenerator loss: 1.091571569442749, Discriminator loss: 1.0975450277328491\n",
      "\tGenerator loss: 1.1442675590515137, Discriminator loss: 1.0657916069030762\n",
      "\tGenerator loss: 1.1887919902801514, Discriminator loss: 1.0806187391281128\n",
      "\tGenerator loss: 1.2024908065795898, Discriminator loss: 1.0664677619934082\n",
      "\tGenerator loss: 1.1983565092086792, Discriminator loss: 1.0578233003616333\n",
      "\tGenerator loss: 1.180382490158081, Discriminator loss: 1.1517817974090576\n",
      "\tGenerator loss: 1.0813071727752686, Discriminator loss: 1.0837857723236084\n",
      "\tGenerator loss: 1.023876667022705, Discriminator loss: 1.0965979099273682\n",
      "\tGenerator loss: 1.0227367877960205, Discriminator loss: 1.0759024620056152\n",
      "\tGenerator loss: 1.1410167217254639, Discriminator loss: 1.0932961702346802\n",
      "\tGenerator loss: 1.237838625907898, Discriminator loss: 1.0809836387634277\n",
      "\tGenerator loss: 1.2825753688812256, Discriminator loss: 1.1710638999938965\n",
      "\tGenerator loss: 1.21583092212677, Discriminator loss: 1.1889874935150146\n",
      "\tGenerator loss: 1.098983883857727, Discriminator loss: 1.1734817028045654\n",
      "\tGenerator loss: 0.9567835330963135, Discriminator loss: 1.2270915508270264\n",
      "\tGenerator loss: 0.8944128751754761, Discriminator loss: 1.2211167812347412\n",
      "\tGenerator loss: 0.8665362596511841, Discriminator loss: 1.2246732711791992\n",
      "\tGenerator loss: 0.9451457262039185, Discriminator loss: 1.1868629455566406\n",
      "\tGenerator loss: 1.0606319904327393, Discriminator loss: 1.1790053844451904\n",
      "\tGenerator loss: 1.1360416412353516, Discriminator loss: 1.2120344638824463\n",
      "\tGenerator loss: 1.1791361570358276, Discriminator loss: 1.3424632549285889\n",
      "\tGenerator loss: 1.09442138671875, Discriminator loss: 1.2649121284484863\n",
      "\tGenerator loss: 0.9705145955085754, Discriminator loss: 1.2230401039123535\n",
      "\tGenerator loss: 0.8478103876113892, Discriminator loss: 1.2544490098953247\n",
      "\tGenerator loss: 0.7939677238464355, Discriminator loss: 1.269857406616211\n",
      "\tGenerator loss: 0.835498571395874, Discriminator loss: 1.232311487197876\n",
      "\tGenerator loss: 0.9165664911270142, Discriminator loss: 1.2471234798431396\n",
      "\tGenerator loss: 0.9821140170097351, Discriminator loss: 1.320068359375\n",
      "\tGenerator loss: 1.0489554405212402, Discriminator loss: 1.2994370460510254\n",
      "\tGenerator loss: 1.033531904220581, Discriminator loss: 1.2291779518127441\n",
      "\tGenerator loss: 0.9897611737251282, Discriminator loss: 1.199479103088379\n",
      "\tGenerator loss: 0.9370213747024536, Discriminator loss: 1.180942416191101\n",
      "\tGenerator loss: 0.9292219877243042, Discriminator loss: 1.1557788848876953\n",
      "\tGenerator loss: 0.9371833801269531, Discriminator loss: 1.141845703125\n",
      "\tGenerator loss: 1.0039727687835693, Discriminator loss: 1.1169434785842896\n",
      "\tGenerator loss: 1.0407521724700928, Discriminator loss: 1.0952577590942383\n",
      "\tGenerator loss: 1.0855393409729004, Discriminator loss: 1.0440382957458496\n",
      "\tGenerator loss: 1.1422994136810303, Discriminator loss: 1.0259268283843994\n",
      "\tGenerator loss: 1.1412951946258545, Discriminator loss: 1.0149943828582764\n",
      "\tGenerator loss: 1.149211049079895, Discriminator loss: 1.0037481784820557\n",
      "\tGenerator loss: 1.1658267974853516, Discriminator loss: 0.9899106621742249\n",
      "\tGenerator loss: 1.1436679363250732, Discriminator loss: 0.9621169567108154\n",
      "\tGenerator loss: 1.11130952835083, Discriminator loss: 0.9371317625045776\n",
      "\tGenerator loss: 1.1173845529556274, Discriminator loss: 0.945928692817688\n",
      "\tGenerator loss: 1.1731724739074707, Discriminator loss: 0.9316142797470093\n",
      "\tGenerator loss: 1.2467467784881592, Discriminator loss: 0.8873332142829895\n",
      "\tGenerator loss: 1.3131442070007324, Discriminator loss: 0.8948782682418823\n",
      "\tGenerator loss: 1.3632264137268066, Discriminator loss: 0.9209562540054321\n",
      "\tGenerator loss: 1.3968253135681152, Discriminator loss: 0.8917736411094666\n",
      "\tGenerator loss: 1.347188949584961, Discriminator loss: 0.8714791536331177\n",
      "\tGenerator loss: 1.2924505472183228, Discriminator loss: 0.9844078421592712\n",
      "\tGenerator loss: 1.2730364799499512, Discriminator loss: 1.0422289371490479\n",
      "\tGenerator loss: 1.2772784233093262, Discriminator loss: 1.0755831003189087\n",
      "\tGenerator loss: 1.2271469831466675, Discriminator loss: 1.138127088546753\n",
      "\tGenerator loss: 1.195497751235962, Discriminator loss: 1.1441634893417358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.1836856603622437, Discriminator loss: 1.120046615600586\n",
      "\tGenerator loss: 1.1859641075134277, Discriminator loss: 1.0291965007781982\n",
      "\tGenerator loss: 1.2105145454406738, Discriminator loss: 1.0025129318237305\n",
      "\tGenerator loss: 1.2692620754241943, Discriminator loss: 1.0027766227722168\n",
      "\tGenerator loss: 1.254972219467163, Discriminator loss: 0.9610152244567871\n",
      "\tGenerator loss: 1.2610470056533813, Discriminator loss: 0.989510178565979\n",
      "\tGenerator loss: 1.2658202648162842, Discriminator loss: 1.012542724609375\n",
      "\tGenerator loss: 1.2599784135818481, Discriminator loss: 1.0304118394851685\n",
      "\tGenerator loss: 1.166243314743042, Discriminator loss: 1.16617751121521\n",
      "\tGenerator loss: 1.0919567346572876, Discriminator loss: 1.2197684049606323\n",
      "\tGenerator loss: 1.0564193725585938, Discriminator loss: 1.3198041915893555\n",
      "\tGenerator loss: 1.0218418836593628, Discriminator loss: 1.2399473190307617\n",
      "\tGenerator loss: 0.991203784942627, Discriminator loss: 1.1982510089874268\n",
      "\tGenerator loss: 1.0085691213607788, Discriminator loss: 1.180672287940979\n",
      "\tGenerator loss: 1.0874526500701904, Discriminator loss: 1.2459735870361328\n",
      "\tGenerator loss: 1.1425936222076416, Discriminator loss: 1.204342007637024\n",
      "\tGenerator loss: 1.1534212827682495, Discriminator loss: 1.2397351264953613\n",
      "\tGenerator loss: 1.0972158908843994, Discriminator loss: 1.3140522241592407\n",
      "\tGenerator loss: 1.0048348903656006, Discriminator loss: 1.269291639328003\n",
      "\tGenerator loss: 0.9264534711837769, Discriminator loss: 1.2429673671722412\n",
      "\tGenerator loss: 0.9105208516120911, Discriminator loss: 1.2310504913330078\n",
      "\tGenerator loss: 0.9695693254470825, Discriminator loss: 1.2522742748260498\n",
      "\tGenerator loss: 1.0508129596710205, Discriminator loss: 1.3313502073287964\n",
      "\tGenerator loss: 1.074029564857483, Discriminator loss: 1.4205434322357178\n",
      "\tGenerator loss: 1.0249463319778442, Discriminator loss: 1.3629586696624756\n",
      "\tGenerator loss: 0.9489967823028564, Discriminator loss: 1.3829331398010254\n",
      "\tGenerator loss: 0.8602568507194519, Discriminator loss: 1.3838541507720947\n",
      "\tGenerator loss: 0.846538782119751, Discriminator loss: 1.4371616840362549\n",
      "\tGenerator loss: 0.8823191523551941, Discriminator loss: 1.33351731300354\n",
      "\tGenerator loss: 0.9540122747421265, Discriminator loss: 1.291447401046753\n",
      "\tGenerator loss: 1.0275671482086182, Discriminator loss: 1.2898011207580566\n",
      "\tGenerator loss: 1.095686912536621, Discriminator loss: 1.2695891857147217\n",
      "\tGenerator loss: 1.073408603668213, Discriminator loss: 1.2214667797088623\n",
      "\tGenerator loss: 1.0275485515594482, Discriminator loss: 1.1699271202087402\n",
      "\tGenerator loss: 1.0021990537643433, Discriminator loss: 1.1403133869171143\n",
      "\tGenerator loss: 0.9908149838447571, Discriminator loss: 1.1143004894256592\n",
      "\tGenerator loss: 1.0099568367004395, Discriminator loss: 1.1338319778442383\n",
      "\tGenerator loss: 1.049297571182251, Discriminator loss: 1.0939311981201172\n",
      "\tGenerator loss: 1.096814513206482, Discriminator loss: 1.1337614059448242\n",
      "\tGenerator loss: 1.1278233528137207, Discriminator loss: 1.0962202548980713\n",
      "\tGenerator loss: 1.169942021369934, Discriminator loss: 1.0145812034606934\n",
      "\tGenerator loss: 1.1679399013519287, Discriminator loss: 1.0139745473861694\n",
      "\tGenerator loss: 1.158382773399353, Discriminator loss: 1.0326919555664062\n",
      "\tGenerator loss: 1.1626880168914795, Discriminator loss: 1.0521430969238281\n",
      "\tGenerator loss: 1.1534581184387207, Discriminator loss: 1.1751024723052979\n",
      "Time for epoch 39 is 241.85984635353088 sec\n",
      "\tGenerator loss: 1.0787746906280518, Discriminator loss: 1.1612958908081055\n",
      "\tGenerator loss: 0.9916644096374512, Discriminator loss: 1.1738201379776\n",
      "\tGenerator loss: 0.9581358432769775, Discriminator loss: 1.1546671390533447\n",
      "\tGenerator loss: 0.975588321685791, Discriminator loss: 1.1362144947052002\n",
      "\tGenerator loss: 1.0701279640197754, Discriminator loss: 1.1723712682724\n",
      "\tGenerator loss: 1.1083321571350098, Discriminator loss: 1.14533269405365\n",
      "\tGenerator loss: 1.1435010433197021, Discriminator loss: 1.1821849346160889\n",
      "\tGenerator loss: 1.1396487951278687, Discriminator loss: 1.1865427494049072\n",
      "\tGenerator loss: 1.073287010192871, Discriminator loss: 1.1595027446746826\n",
      "\tGenerator loss: 1.0050873756408691, Discriminator loss: 1.172460675239563\n",
      "\tGenerator loss: 0.9939497113227844, Discriminator loss: 1.1760966777801514\n",
      "\tGenerator loss: 1.007665991783142, Discriminator loss: 1.1924495697021484\n",
      "\tGenerator loss: 1.0229885578155518, Discriminator loss: 1.2125108242034912\n",
      "\tGenerator loss: 1.0169533491134644, Discriminator loss: 1.1997671127319336\n",
      "\tGenerator loss: 0.9894635677337646, Discriminator loss: 1.230080008506775\n",
      "\tGenerator loss: 0.9654010534286499, Discriminator loss: 1.2363767623901367\n",
      "\tGenerator loss: 0.9515109658241272, Discriminator loss: 1.239755630493164\n",
      "\tGenerator loss: 0.9387192130088806, Discriminator loss: 1.2276062965393066\n",
      "\tGenerator loss: 0.9844990968704224, Discriminator loss: 1.2315833568572998\n",
      "\tGenerator loss: 1.0099904537200928, Discriminator loss: 1.2244620323181152\n",
      "\tGenerator loss: 0.9764773845672607, Discriminator loss: 1.2378859519958496\n",
      "\tGenerator loss: 0.9547824263572693, Discriminator loss: 1.2207648754119873\n",
      "\tGenerator loss: 0.961800217628479, Discriminator loss: 1.2408297061920166\n",
      "\tGenerator loss: 0.9614691734313965, Discriminator loss: 1.2343428134918213\n",
      "\tGenerator loss: 0.9765205383300781, Discriminator loss: 1.2012386322021484\n",
      "\tGenerator loss: 1.0024878978729248, Discriminator loss: 1.2398855686187744\n",
      "\tGenerator loss: 0.9921853542327881, Discriminator loss: 1.2886574268341064\n",
      "\tGenerator loss: 0.945564329624176, Discriminator loss: 1.2709038257598877\n",
      "\tGenerator loss: 0.8921909332275391, Discriminator loss: 1.3627066612243652\n",
      "\tGenerator loss: 0.802839457988739, Discriminator loss: 1.3470721244812012\n",
      "\tGenerator loss: 0.7877407073974609, Discriminator loss: 1.3068524599075317\n",
      "\tGenerator loss: 0.8096370697021484, Discriminator loss: 1.2729518413543701\n",
      "\tGenerator loss: 0.869540810585022, Discriminator loss: 1.2681132555007935\n",
      "\tGenerator loss: 0.9201235771179199, Discriminator loss: 1.2491984367370605\n",
      "\tGenerator loss: 0.9945270419120789, Discriminator loss: 1.25627863407135\n",
      "\tGenerator loss: 1.0308606624603271, Discriminator loss: 1.2711365222930908\n",
      "\tGenerator loss: 1.0247795581817627, Discriminator loss: 1.2747193574905396\n",
      "\tGenerator loss: 0.9634014368057251, Discriminator loss: 1.2379741668701172\n",
      "\tGenerator loss: 0.894249677658081, Discriminator loss: 1.2042367458343506\n",
      "\tGenerator loss: 0.8340005874633789, Discriminator loss: 1.1976183652877808\n",
      "\tGenerator loss: 0.8508492708206177, Discriminator loss: 1.184863805770874\n",
      "\tGenerator loss: 0.9415729641914368, Discriminator loss: 1.1362841129302979\n",
      "\tGenerator loss: 1.0276952981948853, Discriminator loss: 1.1407746076583862\n",
      "\tGenerator loss: 1.115565538406372, Discriminator loss: 1.171191692352295\n",
      "\tGenerator loss: 1.1419343948364258, Discriminator loss: 1.1604351997375488\n",
      "\tGenerator loss: 1.1197834014892578, Discriminator loss: 1.1504619121551514\n",
      "\tGenerator loss: 1.0969865322113037, Discriminator loss: 1.1051783561706543\n",
      "\tGenerator loss: 1.0321955680847168, Discriminator loss: 1.1410541534423828\n",
      "\tGenerator loss: 0.971049427986145, Discriminator loss: 1.156322717666626\n",
      "\tGenerator loss: 0.9490315914154053, Discriminator loss: 1.1441452503204346\n",
      "\tGenerator loss: 0.9640960097312927, Discriminator loss: 1.144029140472412\n",
      "\tGenerator loss: 1.0330443382263184, Discriminator loss: 1.1884937286376953\n",
      "\tGenerator loss: 1.1097214221954346, Discriminator loss: 1.1564141511917114\n",
      "\tGenerator loss: 1.1284819841384888, Discriminator loss: 1.169694423675537\n",
      "\tGenerator loss: 1.1612166166305542, Discriminator loss: 1.151924729347229\n",
      "\tGenerator loss: 1.162705421447754, Discriminator loss: 1.201364517211914\n",
      "\tGenerator loss: 1.0791008472442627, Discriminator loss: 1.1488176584243774\n",
      "\tGenerator loss: 1.0141538381576538, Discriminator loss: 1.1173832416534424\n",
      "\tGenerator loss: 1.0037531852722168, Discriminator loss: 1.10762619972229\n",
      "\tGenerator loss: 0.9843763113021851, Discriminator loss: 1.0706968307495117\n",
      "\tGenerator loss: 1.038256287574768, Discriminator loss: 1.0519344806671143\n",
      "\tGenerator loss: 1.1831104755401611, Discriminator loss: 1.0179376602172852\n",
      "\tGenerator loss: 1.2627874612808228, Discriminator loss: 1.1427251100540161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.264003038406372, Discriminator loss: 1.1579046249389648\n",
      "\tGenerator loss: 1.1411956548690796, Discriminator loss: 1.1307626962661743\n",
      "\tGenerator loss: 1.019299030303955, Discriminator loss: 1.106360912322998\n",
      "\tGenerator loss: 0.9688769578933716, Discriminator loss: 1.151227593421936\n",
      "\tGenerator loss: 0.983270525932312, Discriminator loss: 1.1750586032867432\n",
      "\tGenerator loss: 1.0218348503112793, Discriminator loss: 1.13742995262146\n",
      "\tGenerator loss: 1.1069873571395874, Discriminator loss: 1.137438416481018\n",
      "\tGenerator loss: 1.1625630855560303, Discriminator loss: 1.1734681129455566\n",
      "\tGenerator loss: 1.1117898225784302, Discriminator loss: 1.277825117111206\n",
      "\tGenerator loss: 1.0495274066925049, Discriminator loss: 1.221045732498169\n",
      "\tGenerator loss: 0.9743753671646118, Discriminator loss: 1.1908546686172485\n",
      "\tGenerator loss: 0.9639750719070435, Discriminator loss: 1.135713815689087\n",
      "\tGenerator loss: 0.9832248091697693, Discriminator loss: 1.317006230354309\n",
      "\tGenerator loss: 1.0061641931533813, Discriminator loss: 1.4408528804779053\n",
      "\tGenerator loss: 1.0227665901184082, Discriminator loss: 1.4701541662216187\n",
      "\tGenerator loss: 1.0289376974105835, Discriminator loss: 1.3876843452453613\n",
      "\tGenerator loss: 1.0018670558929443, Discriminator loss: 1.3225916624069214\n",
      "\tGenerator loss: 0.9593088626861572, Discriminator loss: 1.3758957386016846\n",
      "\tGenerator loss: 0.966483473777771, Discriminator loss: 1.3130311965942383\n",
      "\tGenerator loss: 0.9719293713569641, Discriminator loss: 1.2381484508514404\n",
      "\tGenerator loss: 0.9946681261062622, Discriminator loss: 1.2526090145111084\n",
      "\tGenerator loss: 1.0265945196151733, Discriminator loss: 1.190421462059021\n",
      "\tGenerator loss: 1.0664441585540771, Discriminator loss: 1.3442282676696777\n",
      "\tGenerator loss: 1.0814108848571777, Discriminator loss: 1.236738681793213\n",
      "\tGenerator loss: 1.1111788749694824, Discriminator loss: 1.2057677507400513\n",
      "\tGenerator loss: 1.0785984992980957, Discriminator loss: 1.25681734085083\n",
      "\tGenerator loss: 1.0335667133331299, Discriminator loss: 1.2504024505615234\n",
      "\tGenerator loss: 0.9885013103485107, Discriminator loss: 1.2568397521972656\n",
      "\tGenerator loss: 0.999570369720459, Discriminator loss: 1.1877903938293457\n",
      "\tGenerator loss: 1.018976092338562, Discriminator loss: 1.1305009126663208\n",
      "\tGenerator loss: 1.0707581043243408, Discriminator loss: 1.1141340732574463\n",
      "\tGenerator loss: 1.1251018047332764, Discriminator loss: 1.1264796257019043\n",
      "\tGenerator loss: 1.1768289804458618, Discriminator loss: 1.0678075551986694\n",
      "\tGenerator loss: 1.150668740272522, Discriminator loss: 1.0826871395111084\n",
      "\tGenerator loss: 1.099039077758789, Discriminator loss: 1.085937261581421\n",
      "\tGenerator loss: 1.1028586626052856, Discriminator loss: 1.052473783493042\n",
      "\tGenerator loss: 1.0768152475357056, Discriminator loss: 1.0918810367584229\n",
      "\tGenerator loss: 1.1002593040466309, Discriminator loss: 1.0735175609588623\n",
      "\tGenerator loss: 1.1058207750320435, Discriminator loss: 1.0791020393371582\n",
      "\tGenerator loss: 1.1451430320739746, Discriminator loss: 1.0696074962615967\n",
      "\tGenerator loss: 1.132448434829712, Discriminator loss: 1.1055972576141357\n",
      "\tGenerator loss: 1.0570440292358398, Discriminator loss: 1.13149094581604\n",
      "\tGenerator loss: 1.0310217142105103, Discriminator loss: 1.0869373083114624\n",
      "\tGenerator loss: 1.0332527160644531, Discriminator loss: 1.1076561212539673\n",
      "\tGenerator loss: 1.086762547492981, Discriminator loss: 1.113105058670044\n",
      "\tGenerator loss: 1.1390578746795654, Discriminator loss: 1.1011465787887573\n",
      "\tGenerator loss: 1.1411151885986328, Discriminator loss: 1.08223295211792\n",
      "\tGenerator loss: 1.1132525205612183, Discriminator loss: 1.0821020603179932\n",
      "\tGenerator loss: 1.0861327648162842, Discriminator loss: 1.0971169471740723\n",
      "\tGenerator loss: 1.0846285820007324, Discriminator loss: 1.110363483428955\n",
      "\tGenerator loss: 1.0872009992599487, Discriminator loss: 1.164434790611267\n",
      "\tGenerator loss: 1.0353093147277832, Discriminator loss: 1.1794509887695312\n",
      "\tGenerator loss: 1.0152759552001953, Discriminator loss: 1.1956549882888794\n",
      "\tGenerator loss: 1.012260913848877, Discriminator loss: 1.2945644855499268\n",
      "\tGenerator loss: 0.927253246307373, Discriminator loss: 1.319756269454956\n",
      "\tGenerator loss: 0.8800074458122253, Discriminator loss: 1.3039371967315674\n",
      "\tGenerator loss: 0.8389431238174438, Discriminator loss: 1.3352972269058228\n",
      "\tGenerator loss: 0.8378897905349731, Discriminator loss: 1.3386573791503906\n",
      "\tGenerator loss: 0.8940659165382385, Discriminator loss: 1.3320544958114624\n",
      "\tGenerator loss: 0.8973706960678101, Discriminator loss: 1.3521698713302612\n",
      "\tGenerator loss: 0.9170981645584106, Discriminator loss: 1.3658044338226318\n",
      "\tGenerator loss: 0.8990504741668701, Discriminator loss: 1.3026412725448608\n",
      "\tGenerator loss: 0.8672010898590088, Discriminator loss: 1.3198802471160889\n",
      "\tGenerator loss: 0.8748075366020203, Discriminator loss: 1.2910099029541016\n",
      "\tGenerator loss: 0.8908451795578003, Discriminator loss: 1.3365223407745361\n",
      "\tGenerator loss: 0.8883023262023926, Discriminator loss: 1.3085612058639526\n",
      "\tGenerator loss: 0.8988505005836487, Discriminator loss: 1.3041841983795166\n",
      "\tGenerator loss: 0.9146144390106201, Discriminator loss: 1.2878541946411133\n",
      "\tGenerator loss: 0.9145707488059998, Discriminator loss: 1.3326504230499268\n",
      "\tGenerator loss: 0.8704763650894165, Discriminator loss: 1.357871174812317\n",
      "\tGenerator loss: 0.8616763353347778, Discriminator loss: 1.3096809387207031\n",
      "\tGenerator loss: 0.8540467619895935, Discriminator loss: 1.2884464263916016\n",
      "\tGenerator loss: 0.8279503583908081, Discriminator loss: 1.3207297325134277\n",
      "\tGenerator loss: 0.8515636920928955, Discriminator loss: 1.2933990955352783\n",
      "\tGenerator loss: 0.8934841752052307, Discriminator loss: 1.2710330486297607\n",
      "\tGenerator loss: 0.9187861680984497, Discriminator loss: 1.238640308380127\n",
      "\tGenerator loss: 0.9511229991912842, Discriminator loss: 1.232446312904358\n",
      "\tGenerator loss: 0.9325627684593201, Discriminator loss: 1.2011466026306152\n",
      "\tGenerator loss: 0.9286435842514038, Discriminator loss: 1.2064988613128662\n",
      "\tGenerator loss: 0.9428678750991821, Discriminator loss: 1.1819825172424316\n",
      "\tGenerator loss: 0.9714663624763489, Discriminator loss: 1.2158700227737427\n",
      "\tGenerator loss: 0.9694011211395264, Discriminator loss: 1.2219566106796265\n",
      "\tGenerator loss: 0.9830704927444458, Discriminator loss: 1.1969404220581055\n",
      "\tGenerator loss: 0.9894559383392334, Discriminator loss: 1.154595136642456\n",
      "\tGenerator loss: 0.9954909086227417, Discriminator loss: 1.1449332237243652\n",
      "\tGenerator loss: 1.0227311849594116, Discriminator loss: 1.0997648239135742\n",
      "\tGenerator loss: 1.035172700881958, Discriminator loss: 1.113967776298523\n",
      "\tGenerator loss: 1.0228097438812256, Discriminator loss: 1.1150065660476685\n",
      "\tGenerator loss: 1.0461432933807373, Discriminator loss: 1.0885307788848877\n",
      "\tGenerator loss: 1.0260906219482422, Discriminator loss: 1.0928080081939697\n",
      "\tGenerator loss: 1.0562430620193481, Discriminator loss: 1.1583831310272217\n",
      "\tGenerator loss: 1.053035020828247, Discriminator loss: 1.1869549751281738\n",
      "\tGenerator loss: 1.0173404216766357, Discriminator loss: 1.1210328340530396\n",
      "\tGenerator loss: 1.0391753911972046, Discriminator loss: 1.1348260641098022\n",
      "\tGenerator loss: 1.0566256046295166, Discriminator loss: 1.0959093570709229\n",
      "\tGenerator loss: 1.0857527256011963, Discriminator loss: 1.156899094581604\n",
      "\tGenerator loss: 1.0978111028671265, Discriminator loss: 1.0851320028305054\n",
      "\tGenerator loss: 1.1106939315795898, Discriminator loss: 1.0750012397766113\n",
      "\tGenerator loss: 1.097754716873169, Discriminator loss: 1.0966389179229736\n",
      "\tGenerator loss: 1.0952396392822266, Discriminator loss: 1.1122605800628662\n",
      "\tGenerator loss: 1.1091828346252441, Discriminator loss: 1.1496180295944214\n",
      "\tGenerator loss: 1.062996506690979, Discriminator loss: 1.2529971599578857\n",
      "\tGenerator loss: 1.009321689605713, Discriminator loss: 1.2250741720199585\n",
      "\tGenerator loss: 0.9895002841949463, Discriminator loss: 1.2634544372558594\n",
      "\tGenerator loss: 0.9519766569137573, Discriminator loss: 1.2479740381240845\n",
      "\tGenerator loss: 1.0147472620010376, Discriminator loss: 1.2126569747924805\n",
      "\tGenerator loss: 1.0635316371917725, Discriminator loss: 1.2118206024169922\n",
      "\tGenerator loss: 1.096866488456726, Discriminator loss: 1.2354501485824585\n",
      "\tGenerator loss: 1.0659618377685547, Discriminator loss: 1.1722207069396973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0442932844161987, Discriminator loss: 1.167679786682129\n",
      "\tGenerator loss: 1.0093891620635986, Discriminator loss: 1.1860932111740112\n",
      "\tGenerator loss: 0.9821655750274658, Discriminator loss: 1.1881029605865479\n",
      "\tGenerator loss: 0.9705523252487183, Discriminator loss: 1.2456486225128174\n",
      "\tGenerator loss: 0.9662464261054993, Discriminator loss: 1.2853078842163086\n",
      "\tGenerator loss: 1.0014902353286743, Discriminator loss: 1.228603482246399\n",
      "\tGenerator loss: 1.0366604328155518, Discriminator loss: 1.2467586994171143\n",
      "\tGenerator loss: 1.0373413562774658, Discriminator loss: 1.2274824380874634\n",
      "\tGenerator loss: 0.993520200252533, Discriminator loss: 1.1970924139022827\n",
      "\tGenerator loss: 0.9698002934455872, Discriminator loss: 1.2151029109954834\n",
      "\tGenerator loss: 0.9466991424560547, Discriminator loss: 1.2986518144607544\n",
      "\tGenerator loss: 0.9438256621360779, Discriminator loss: 1.297074556350708\n",
      "\tGenerator loss: 0.9777905941009521, Discriminator loss: 1.241086721420288\n",
      "\tGenerator loss: 0.9973571300506592, Discriminator loss: 1.3447567224502563\n",
      "\tGenerator loss: 0.9910638332366943, Discriminator loss: 1.326714277267456\n",
      "\tGenerator loss: 0.9746572375297546, Discriminator loss: 1.3600190877914429\n",
      "\tGenerator loss: 0.9544767141342163, Discriminator loss: 1.3798067569732666\n",
      "\tGenerator loss: 0.9165862202644348, Discriminator loss: 1.3478807210922241\n",
      "\tGenerator loss: 0.96783447265625, Discriminator loss: 1.2942407131195068\n",
      "\tGenerator loss: 0.9901048541069031, Discriminator loss: 1.23262619972229\n",
      "\tGenerator loss: 1.0242265462875366, Discriminator loss: 1.1724897623062134\n",
      "\tGenerator loss: 1.0609372854232788, Discriminator loss: 1.14601731300354\n",
      "\tGenerator loss: 1.0949084758758545, Discriminator loss: 1.1154537200927734\n",
      "\tGenerator loss: 1.1125344038009644, Discriminator loss: 1.1013457775115967\n",
      "\tGenerator loss: 1.0848774909973145, Discriminator loss: 1.097080945968628\n",
      "\tGenerator loss: 1.0803314447402954, Discriminator loss: 1.0750190019607544\n",
      "\tGenerator loss: 1.0950299501419067, Discriminator loss: 1.0734503269195557\n",
      "\tGenerator loss: 1.103844404220581, Discriminator loss: 1.0489563941955566\n",
      "\tGenerator loss: 1.1466894149780273, Discriminator loss: 1.0301405191421509\n",
      "\tGenerator loss: 1.181289792060852, Discriminator loss: 0.9896399974822998\n",
      "\tGenerator loss: 1.203674554824829, Discriminator loss: 1.0181653499603271\n",
      "\tGenerator loss: 1.2036479711532593, Discriminator loss: 1.03971266746521\n",
      "\tGenerator loss: 1.1215381622314453, Discriminator loss: 1.0492846965789795\n",
      "\tGenerator loss: 1.0626516342163086, Discriminator loss: 1.035698413848877\n",
      "\tGenerator loss: 1.0738413333892822, Discriminator loss: 1.046279788017273\n",
      "\tGenerator loss: 1.136074423789978, Discriminator loss: 1.0348700284957886\n",
      "\tGenerator loss: 1.1976149082183838, Discriminator loss: 1.0745503902435303\n",
      "\tGenerator loss: 1.227414608001709, Discriminator loss: 1.0895085334777832\n",
      "\tGenerator loss: 1.2160028219223022, Discriminator loss: 1.111009120941162\n",
      "\tGenerator loss: 1.1425397396087646, Discriminator loss: 1.111630916595459\n",
      "\tGenerator loss: 1.0613648891448975, Discriminator loss: 1.115288257598877\n",
      "\tGenerator loss: 0.9991174936294556, Discriminator loss: 1.1394659280776978\n",
      "\tGenerator loss: 0.9954649806022644, Discriminator loss: 1.1484296321868896\n",
      "\tGenerator loss: 1.072574496269226, Discriminator loss: 1.1579737663269043\n",
      "\tGenerator loss: 1.1392861604690552, Discriminator loss: 1.1982741355895996\n",
      "\tGenerator loss: 1.1629700660705566, Discriminator loss: 1.1546883583068848\n",
      "\tGenerator loss: 1.1381046772003174, Discriminator loss: 1.1874570846557617\n",
      "\tGenerator loss: 1.06922447681427, Discriminator loss: 1.2550642490386963\n",
      "\tGenerator loss: 0.9522303342819214, Discriminator loss: 1.3320231437683105\n",
      "\tGenerator loss: 0.8207688331604004, Discriminator loss: 1.3751516342163086\n",
      "\tGenerator loss: 0.800390899181366, Discriminator loss: 1.40972900390625\n",
      "\tGenerator loss: 0.8604100942611694, Discriminator loss: 1.3646800518035889\n",
      "\tGenerator loss: 0.92097008228302, Discriminator loss: 1.326998233795166\n",
      "\tGenerator loss: 0.9575204849243164, Discriminator loss: 1.3605883121490479\n",
      "\tGenerator loss: 0.9805516600608826, Discriminator loss: 1.3925211429595947\n",
      "\tGenerator loss: 0.8724441528320312, Discriminator loss: 1.4069687128067017\n",
      "\tGenerator loss: 0.8265389800071716, Discriminator loss: 1.397244930267334\n",
      "\tGenerator loss: 0.7679809331893921, Discriminator loss: 1.3884127140045166\n",
      "\tGenerator loss: 0.7834740877151489, Discriminator loss: 1.3329620361328125\n",
      "\tGenerator loss: 0.8114937543869019, Discriminator loss: 1.3236685991287231\n",
      "\tGenerator loss: 0.93433678150177, Discriminator loss: 1.2690186500549316\n",
      "\tGenerator loss: 1.0322320461273193, Discriminator loss: 1.2943490743637085\n",
      "\tGenerator loss: 1.0510107278823853, Discriminator loss: 1.4299302101135254\n",
      "Time for epoch 40 is 243.95894241333008 sec\n",
      "\tGenerator loss: 0.9310407638549805, Discriminator loss: 1.3936156034469604\n",
      "\tGenerator loss: 0.7969623804092407, Discriminator loss: 1.37874174118042\n",
      "\tGenerator loss: 0.706974983215332, Discriminator loss: 1.3605061769485474\n",
      "\tGenerator loss: 0.7067083716392517, Discriminator loss: 1.3315016031265259\n",
      "\tGenerator loss: 0.7875572443008423, Discriminator loss: 1.3378183841705322\n",
      "\tGenerator loss: 0.912202775478363, Discriminator loss: 1.3160642385482788\n",
      "\tGenerator loss: 1.0266321897506714, Discriminator loss: 1.3354172706604004\n",
      "\tGenerator loss: 1.063877820968628, Discriminator loss: 1.314100980758667\n",
      "\tGenerator loss: 1.0067507028579712, Discriminator loss: 1.30784010887146\n",
      "\tGenerator loss: 0.9263070821762085, Discriminator loss: 1.2570282220840454\n",
      "\tGenerator loss: 0.8767504096031189, Discriminator loss: 1.2473750114440918\n",
      "\tGenerator loss: 0.8637020587921143, Discriminator loss: 1.2330883741378784\n",
      "\tGenerator loss: 0.908358633518219, Discriminator loss: 1.197269082069397\n",
      "\tGenerator loss: 0.9370182752609253, Discriminator loss: 1.1909523010253906\n",
      "\tGenerator loss: 0.9964730143547058, Discriminator loss: 1.2614448070526123\n",
      "\tGenerator loss: 1.0550074577331543, Discriminator loss: 1.2230685949325562\n",
      "\tGenerator loss: 1.0687955617904663, Discriminator loss: 1.2000761032104492\n",
      "\tGenerator loss: 1.0490524768829346, Discriminator loss: 1.1603699922561646\n",
      "\tGenerator loss: 1.0086960792541504, Discriminator loss: 1.2199348211288452\n",
      "\tGenerator loss: 0.9461053609848022, Discriminator loss: 1.2197840213775635\n",
      "\tGenerator loss: 0.9226623773574829, Discriminator loss: 1.2144389152526855\n",
      "\tGenerator loss: 0.9699012637138367, Discriminator loss: 1.2347584962844849\n",
      "\tGenerator loss: 1.0091495513916016, Discriminator loss: 1.2040133476257324\n",
      "\tGenerator loss: 1.0793685913085938, Discriminator loss: 1.2728646993637085\n",
      "\tGenerator loss: 1.1061046123504639, Discriminator loss: 1.2827916145324707\n",
      "\tGenerator loss: 1.10707688331604, Discriminator loss: 1.213165044784546\n",
      "\tGenerator loss: 1.0553364753723145, Discriminator loss: 1.1290972232818604\n",
      "\tGenerator loss: 1.0113306045532227, Discriminator loss: 1.1109541654586792\n",
      "\tGenerator loss: 1.0340378284454346, Discriminator loss: 1.0696971416473389\n",
      "\tGenerator loss: 1.0345518589019775, Discriminator loss: 1.049379825592041\n",
      "\tGenerator loss: 1.0927000045776367, Discriminator loss: 1.094740629196167\n",
      "\tGenerator loss: 1.1080858707427979, Discriminator loss: 1.1650424003601074\n",
      "\tGenerator loss: 1.104859471321106, Discriminator loss: 1.1481397151947021\n",
      "\tGenerator loss: 1.0692822933197021, Discriminator loss: 1.3304173946380615\n",
      "\tGenerator loss: 1.0141197443008423, Discriminator loss: 1.2453365325927734\n",
      "\tGenerator loss: 0.9522370100021362, Discriminator loss: 1.2048044204711914\n",
      "\tGenerator loss: 0.9764931201934814, Discriminator loss: 1.1735196113586426\n",
      "\tGenerator loss: 0.9655354619026184, Discriminator loss: 1.2166352272033691\n",
      "\tGenerator loss: 0.9901269674301147, Discriminator loss: 1.1557650566101074\n",
      "\tGenerator loss: 1.0207741260528564, Discriminator loss: 1.206547498703003\n",
      "\tGenerator loss: 1.0673508644104004, Discriminator loss: 1.3090101480484009\n",
      "\tGenerator loss: 1.1017061471939087, Discriminator loss: 1.2224352359771729\n",
      "\tGenerator loss: 1.0731310844421387, Discriminator loss: 1.233557939529419\n",
      "\tGenerator loss: 0.9872649908065796, Discriminator loss: 1.2529925107955933\n",
      "\tGenerator loss: 0.9343749284744263, Discriminator loss: 1.2342512607574463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.911777138710022, Discriminator loss: 1.2558820247650146\n",
      "\tGenerator loss: 0.9275811910629272, Discriminator loss: 1.2604751586914062\n",
      "\tGenerator loss: 0.9536927342414856, Discriminator loss: 1.2793231010437012\n",
      "\tGenerator loss: 0.9991472959518433, Discriminator loss: 1.260674238204956\n",
      "\tGenerator loss: 0.9826656579971313, Discriminator loss: 1.2011997699737549\n",
      "\tGenerator loss: 0.9938479065895081, Discriminator loss: 1.236257553100586\n",
      "\tGenerator loss: 0.9955838918685913, Discriminator loss: 1.2446074485778809\n",
      "\tGenerator loss: 0.9782915711402893, Discriminator loss: 1.2168632745742798\n",
      "\tGenerator loss: 0.9578560590744019, Discriminator loss: 1.2183458805084229\n",
      "\tGenerator loss: 0.9521576166152954, Discriminator loss: 1.2119114398956299\n",
      "\tGenerator loss: 0.9752466678619385, Discriminator loss: 1.2372461557388306\n",
      "\tGenerator loss: 0.9874207377433777, Discriminator loss: 1.1883537769317627\n",
      "\tGenerator loss: 0.9950357675552368, Discriminator loss: 1.1731171607971191\n",
      "\tGenerator loss: 1.0158367156982422, Discriminator loss: 1.1464874744415283\n",
      "\tGenerator loss: 1.0226476192474365, Discriminator loss: 1.1236891746520996\n",
      "\tGenerator loss: 1.028634786605835, Discriminator loss: 1.1214804649353027\n",
      "\tGenerator loss: 0.9890695214271545, Discriminator loss: 1.1123225688934326\n",
      "\tGenerator loss: 1.0018033981323242, Discriminator loss: 1.1543850898742676\n",
      "\tGenerator loss: 1.0149734020233154, Discriminator loss: 1.1611007452011108\n",
      "\tGenerator loss: 1.0246069431304932, Discriminator loss: 1.147873878479004\n",
      "\tGenerator loss: 1.0644716024398804, Discriminator loss: 1.1250112056732178\n",
      "\tGenerator loss: 1.0782291889190674, Discriminator loss: 1.1442713737487793\n",
      "\tGenerator loss: 1.0237462520599365, Discriminator loss: 1.110733985900879\n",
      "\tGenerator loss: 0.9662677049636841, Discriminator loss: 1.1799412965774536\n",
      "\tGenerator loss: 0.9566609263420105, Discriminator loss: 1.202160120010376\n",
      "\tGenerator loss: 0.9621450901031494, Discriminator loss: 1.1739925146102905\n",
      "\tGenerator loss: 0.9792885780334473, Discriminator loss: 1.1970629692077637\n",
      "\tGenerator loss: 0.9785310626029968, Discriminator loss: 1.1996049880981445\n",
      "\tGenerator loss: 1.0241080522537231, Discriminator loss: 1.1564089059829712\n",
      "\tGenerator loss: 1.0198452472686768, Discriminator loss: 1.1583225727081299\n",
      "\tGenerator loss: 1.0355182886123657, Discriminator loss: 1.1562120914459229\n",
      "\tGenerator loss: 0.9977840185165405, Discriminator loss: 1.1854236125946045\n",
      "\tGenerator loss: 1.0057748556137085, Discriminator loss: 1.1991939544677734\n",
      "\tGenerator loss: 1.027424693107605, Discriminator loss: 1.1944977045059204\n",
      "\tGenerator loss: 1.0123114585876465, Discriminator loss: 1.2199347019195557\n",
      "\tGenerator loss: 0.9802603721618652, Discriminator loss: 1.2222225666046143\n",
      "\tGenerator loss: 0.962303638458252, Discriminator loss: 1.2145121097564697\n",
      "\tGenerator loss: 0.9180965423583984, Discriminator loss: 1.2124942541122437\n",
      "\tGenerator loss: 0.9153465032577515, Discriminator loss: 1.2217761278152466\n",
      "\tGenerator loss: 0.9150075912475586, Discriminator loss: 1.2129359245300293\n",
      "\tGenerator loss: 0.9352550506591797, Discriminator loss: 1.2406014204025269\n",
      "\tGenerator loss: 0.9929021596908569, Discriminator loss: 1.2205395698547363\n",
      "\tGenerator loss: 1.0253512859344482, Discriminator loss: 1.2276332378387451\n",
      "\tGenerator loss: 0.9771553874015808, Discriminator loss: 1.2508366107940674\n",
      "\tGenerator loss: 0.9577969312667847, Discriminator loss: 1.2544697523117065\n",
      "\tGenerator loss: 0.9170989990234375, Discriminator loss: 1.2626348733901978\n",
      "\tGenerator loss: 0.8832910060882568, Discriminator loss: 1.2936758995056152\n",
      "\tGenerator loss: 0.8941590785980225, Discriminator loss: 1.300874948501587\n",
      "\tGenerator loss: 0.8667215704917908, Discriminator loss: 1.3628367185592651\n",
      "\tGenerator loss: 0.8557226657867432, Discriminator loss: 1.3514254093170166\n",
      "\tGenerator loss: 0.8725329637527466, Discriminator loss: 1.2816647291183472\n",
      "\tGenerator loss: 0.8904783129692078, Discriminator loss: 1.2869007587432861\n",
      "\tGenerator loss: 0.8858681321144104, Discriminator loss: 1.3212475776672363\n",
      "\tGenerator loss: 0.905174970626831, Discriminator loss: 1.2923414707183838\n",
      "\tGenerator loss: 0.914676308631897, Discriminator loss: 1.2897839546203613\n",
      "\tGenerator loss: 0.9157513380050659, Discriminator loss: 1.2897305488586426\n",
      "\tGenerator loss: 0.9010353088378906, Discriminator loss: 1.311638355255127\n",
      "\tGenerator loss: 0.8617534637451172, Discriminator loss: 1.3310962915420532\n",
      "\tGenerator loss: 0.8166435956954956, Discriminator loss: 1.3701057434082031\n",
      "\tGenerator loss: 0.8267425894737244, Discriminator loss: 1.3794130086898804\n",
      "\tGenerator loss: 0.8185703754425049, Discriminator loss: 1.3268989324569702\n",
      "\tGenerator loss: 0.8325455784797668, Discriminator loss: 1.3824896812438965\n",
      "\tGenerator loss: 0.8567157983779907, Discriminator loss: 1.3656318187713623\n",
      "\tGenerator loss: 0.8645902872085571, Discriminator loss: 1.337112545967102\n",
      "\tGenerator loss: 0.8608132600784302, Discriminator loss: 1.3423947095870972\n",
      "\tGenerator loss: 0.8839846849441528, Discriminator loss: 1.3359712362289429\n",
      "\tGenerator loss: 0.8980409502983093, Discriminator loss: 1.3480353355407715\n",
      "\tGenerator loss: 0.9149503707885742, Discriminator loss: 1.2979328632354736\n",
      "\tGenerator loss: 0.8860732316970825, Discriminator loss: 1.3088983297348022\n",
      "\tGenerator loss: 0.9024969935417175, Discriminator loss: 1.3299062252044678\n",
      "\tGenerator loss: 0.8844637870788574, Discriminator loss: 1.2968789339065552\n",
      "\tGenerator loss: 0.8898471593856812, Discriminator loss: 1.2859175205230713\n",
      "\tGenerator loss: 0.8894962072372437, Discriminator loss: 1.2380294799804688\n",
      "\tGenerator loss: 0.9048056602478027, Discriminator loss: 1.2318789958953857\n",
      "\tGenerator loss: 0.9025949239730835, Discriminator loss: 1.2414369583129883\n",
      "\tGenerator loss: 0.9442926645278931, Discriminator loss: 1.2220271825790405\n",
      "\tGenerator loss: 0.9296160936355591, Discriminator loss: 1.2175354957580566\n",
      "\tGenerator loss: 0.9720613360404968, Discriminator loss: 1.1973164081573486\n",
      "\tGenerator loss: 0.9750173091888428, Discriminator loss: 1.1648603677749634\n",
      "\tGenerator loss: 0.9619543552398682, Discriminator loss: 1.1750648021697998\n",
      "\tGenerator loss: 1.0199270248413086, Discriminator loss: 1.2287936210632324\n",
      "\tGenerator loss: 1.0313963890075684, Discriminator loss: 1.2820100784301758\n",
      "\tGenerator loss: 1.0042270421981812, Discriminator loss: 1.2431917190551758\n",
      "\tGenerator loss: 0.9979114532470703, Discriminator loss: 1.1893601417541504\n",
      "\tGenerator loss: 0.9930635690689087, Discriminator loss: 1.200588345527649\n",
      "\tGenerator loss: 0.944277822971344, Discriminator loss: 1.1835697889328003\n",
      "\tGenerator loss: 0.9846631288528442, Discriminator loss: 1.2271311283111572\n",
      "\tGenerator loss: 1.0415055751800537, Discriminator loss: 1.270143985748291\n",
      "\tGenerator loss: 1.0298819541931152, Discriminator loss: 1.2276062965393066\n",
      "\tGenerator loss: 1.0123836994171143, Discriminator loss: 1.216220736503601\n",
      "\tGenerator loss: 0.9838825464248657, Discriminator loss: 1.2661845684051514\n",
      "\tGenerator loss: 0.987028956413269, Discriminator loss: 1.240861177444458\n",
      "\tGenerator loss: 0.9647414684295654, Discriminator loss: 1.193610668182373\n",
      "\tGenerator loss: 0.9653510451316833, Discriminator loss: 1.1938114166259766\n",
      "\tGenerator loss: 1.041325330734253, Discriminator loss: 1.132494568824768\n",
      "\tGenerator loss: 1.0756645202636719, Discriminator loss: 1.0866994857788086\n",
      "\tGenerator loss: 1.0944995880126953, Discriminator loss: 1.1669957637786865\n",
      "\tGenerator loss: 1.1102005243301392, Discriminator loss: 1.1458276510238647\n",
      "\tGenerator loss: 1.0630898475646973, Discriminator loss: 1.2222380638122559\n",
      "\tGenerator loss: 1.0351207256317139, Discriminator loss: 1.1999573707580566\n",
      "\tGenerator loss: 0.9766416549682617, Discriminator loss: 1.2245407104492188\n",
      "\tGenerator loss: 0.9411142468452454, Discriminator loss: 1.1871237754821777\n",
      "\tGenerator loss: 0.9913771152496338, Discriminator loss: 1.1190943717956543\n",
      "\tGenerator loss: 1.0224683284759521, Discriminator loss: 1.1273105144500732\n",
      "\tGenerator loss: 1.1040347814559937, Discriminator loss: 1.129577875137329\n",
      "\tGenerator loss: 1.1199218034744263, Discriminator loss: 1.094893455505371\n",
      "\tGenerator loss: 1.1032767295837402, Discriminator loss: 1.0705609321594238\n",
      "\tGenerator loss: 1.0380876064300537, Discriminator loss: 1.1025099754333496\n",
      "\tGenerator loss: 0.9896523952484131, Discriminator loss: 1.1437089443206787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9773821234703064, Discriminator loss: 1.1503970623016357\n",
      "\tGenerator loss: 0.980205774307251, Discriminator loss: 1.0903961658477783\n",
      "\tGenerator loss: 1.0099183320999146, Discriminator loss: 1.101369023323059\n",
      "\tGenerator loss: 1.0735135078430176, Discriminator loss: 1.0383269786834717\n",
      "\tGenerator loss: 1.1295212507247925, Discriminator loss: 1.0531113147735596\n",
      "\tGenerator loss: 1.18894362449646, Discriminator loss: 1.0606391429901123\n",
      "\tGenerator loss: 1.150726318359375, Discriminator loss: 1.0654654502868652\n",
      "\tGenerator loss: 1.0809366703033447, Discriminator loss: 1.0439091920852661\n",
      "\tGenerator loss: 1.0155284404754639, Discriminator loss: 1.0894196033477783\n",
      "\tGenerator loss: 0.9823045134544373, Discriminator loss: 1.1009032726287842\n",
      "\tGenerator loss: 0.9499797821044922, Discriminator loss: 1.1076213121414185\n",
      "\tGenerator loss: 1.006460189819336, Discriminator loss: 1.1071836948394775\n",
      "\tGenerator loss: 1.0545952320098877, Discriminator loss: 1.1121454238891602\n",
      "\tGenerator loss: 1.0853760242462158, Discriminator loss: 1.0923166275024414\n",
      "\tGenerator loss: 1.100422739982605, Discriminator loss: 1.1183226108551025\n",
      "\tGenerator loss: 1.0842057466506958, Discriminator loss: 1.0721724033355713\n",
      "\tGenerator loss: 1.0327413082122803, Discriminator loss: 1.1172876358032227\n",
      "\tGenerator loss: 1.0004035234451294, Discriminator loss: 1.1333754062652588\n",
      "\tGenerator loss: 0.981474757194519, Discriminator loss: 1.1070927381515503\n",
      "\tGenerator loss: 0.9395661950111389, Discriminator loss: 1.1594116687774658\n",
      "\tGenerator loss: 0.9615868330001831, Discriminator loss: 1.2074912786483765\n",
      "\tGenerator loss: 0.9898077845573425, Discriminator loss: 1.221663475036621\n",
      "\tGenerator loss: 0.9931974411010742, Discriminator loss: 1.2155195474624634\n",
      "\tGenerator loss: 0.977994978427887, Discriminator loss: 1.1997969150543213\n",
      "\tGenerator loss: 0.9696685075759888, Discriminator loss: 1.201525092124939\n",
      "\tGenerator loss: 0.9184015989303589, Discriminator loss: 1.2929024696350098\n",
      "\tGenerator loss: 0.8851044178009033, Discriminator loss: 1.2574222087860107\n",
      "\tGenerator loss: 0.8180093765258789, Discriminator loss: 1.2584450244903564\n",
      "\tGenerator loss: 0.8329070806503296, Discriminator loss: 1.2337006330490112\n",
      "\tGenerator loss: 0.9048616886138916, Discriminator loss: 1.2239266633987427\n",
      "\tGenerator loss: 1.0038747787475586, Discriminator loss: 1.2610347270965576\n",
      "\tGenerator loss: 1.0191144943237305, Discriminator loss: 1.2600237131118774\n",
      "\tGenerator loss: 0.9656736254692078, Discriminator loss: 1.2672340869903564\n",
      "\tGenerator loss: 0.9077068567276001, Discriminator loss: 1.3111709356307983\n",
      "\tGenerator loss: 0.8632776141166687, Discriminator loss: 1.3079707622528076\n",
      "\tGenerator loss: 0.8654417991638184, Discriminator loss: 1.291799783706665\n",
      "\tGenerator loss: 0.8748400807380676, Discriminator loss: 1.3208909034729004\n",
      "\tGenerator loss: 0.91884446144104, Discriminator loss: 1.3221123218536377\n",
      "\tGenerator loss: 0.896664023399353, Discriminator loss: 1.3257474899291992\n",
      "\tGenerator loss: 0.8907560706138611, Discriminator loss: 1.3304424285888672\n",
      "\tGenerator loss: 0.8814762234687805, Discriminator loss: 1.3173936605453491\n",
      "\tGenerator loss: 0.8540276288986206, Discriminator loss: 1.332705020904541\n",
      "\tGenerator loss: 0.857185959815979, Discriminator loss: 1.3108177185058594\n",
      "\tGenerator loss: 0.8419080972671509, Discriminator loss: 1.3152494430541992\n",
      "\tGenerator loss: 0.8534351587295532, Discriminator loss: 1.36521577835083\n",
      "\tGenerator loss: 0.8799896836280823, Discriminator loss: 1.341849684715271\n",
      "\tGenerator loss: 0.8926493525505066, Discriminator loss: 1.3914766311645508\n",
      "\tGenerator loss: 0.8934776782989502, Discriminator loss: 1.3503477573394775\n",
      "\tGenerator loss: 0.8819600939750671, Discriminator loss: 1.3467590808868408\n",
      "\tGenerator loss: 0.891193151473999, Discriminator loss: 1.3389872312545776\n",
      "\tGenerator loss: 0.8722394704818726, Discriminator loss: 1.3435266017913818\n",
      "\tGenerator loss: 0.8521913290023804, Discriminator loss: 1.2983615398406982\n",
      "\tGenerator loss: 0.8600555062294006, Discriminator loss: 1.3187357187271118\n",
      "\tGenerator loss: 0.8778364062309265, Discriminator loss: 1.3409132957458496\n",
      "\tGenerator loss: 0.911945104598999, Discriminator loss: 1.3344435691833496\n",
      "\tGenerator loss: 0.9560988545417786, Discriminator loss: 1.2599362134933472\n",
      "\tGenerator loss: 0.9321005940437317, Discriminator loss: 1.2924728393554688\n",
      "\tGenerator loss: 0.9247152209281921, Discriminator loss: 1.2663631439208984\n",
      "\tGenerator loss: 0.8848706483840942, Discriminator loss: 1.3336174488067627\n",
      "\tGenerator loss: 0.8930438756942749, Discriminator loss: 1.377105712890625\n",
      "\tGenerator loss: 0.8841097354888916, Discriminator loss: 1.3519794940948486\n",
      "\tGenerator loss: 0.8856024742126465, Discriminator loss: 1.3730744123458862\n",
      "\tGenerator loss: 0.8860883116722107, Discriminator loss: 1.378730058670044\n",
      "\tGenerator loss: 0.8895577192306519, Discriminator loss: 1.488402247428894\n",
      "\tGenerator loss: 0.885766863822937, Discriminator loss: 1.4395244121551514\n",
      "\tGenerator loss: 0.8979306221008301, Discriminator loss: 1.4054718017578125\n",
      "\tGenerator loss: 0.8949867486953735, Discriminator loss: 1.411145567893982\n",
      "\tGenerator loss: 0.869655430316925, Discriminator loss: 1.4035356044769287\n",
      "\tGenerator loss: 0.8349809646606445, Discriminator loss: 1.392859935760498\n",
      "\tGenerator loss: 0.8330487608909607, Discriminator loss: 1.364713191986084\n",
      "\tGenerator loss: 0.8353716135025024, Discriminator loss: 1.3713722229003906\n",
      "\tGenerator loss: 0.9093303084373474, Discriminator loss: 1.2950776815414429\n",
      "\tGenerator loss: 0.9327502250671387, Discriminator loss: 1.295703649520874\n",
      "\tGenerator loss: 0.9309252500534058, Discriminator loss: 1.2829703092575073\n",
      "\tGenerator loss: 0.940342366695404, Discriminator loss: 1.3245537281036377\n",
      "\tGenerator loss: 0.8995534181594849, Discriminator loss: 1.270842432975769\n",
      "\tGenerator loss: 0.8964778184890747, Discriminator loss: 1.232515573501587\n",
      "\tGenerator loss: 0.8638864159584045, Discriminator loss: 1.292730450630188\n",
      "\tGenerator loss: 0.9068326950073242, Discriminator loss: 1.3670334815979004\n",
      "\tGenerator loss: 0.9656836986541748, Discriminator loss: 1.3714385032653809\n",
      "\tGenerator loss: 0.9934348464012146, Discriminator loss: 1.295037031173706\n",
      "Time for epoch 41 is 241.88187980651855 sec\n",
      "\tGenerator loss: 0.9880913496017456, Discriminator loss: 1.2877353429794312\n",
      "\tGenerator loss: 0.9183377027511597, Discriminator loss: 1.2832834720611572\n",
      "\tGenerator loss: 0.848954439163208, Discriminator loss: 1.2891113758087158\n",
      "\tGenerator loss: 0.8300458192825317, Discriminator loss: 1.2667689323425293\n",
      "\tGenerator loss: 0.8687388896942139, Discriminator loss: 1.3002487421035767\n",
      "\tGenerator loss: 0.9556888937950134, Discriminator loss: 1.2792270183563232\n",
      "\tGenerator loss: 1.0062237977981567, Discriminator loss: 1.2263062000274658\n",
      "\tGenerator loss: 1.0341012477874756, Discriminator loss: 1.2853256464004517\n",
      "\tGenerator loss: 1.010610818862915, Discriminator loss: 1.2502238750457764\n",
      "\tGenerator loss: 0.929004967212677, Discriminator loss: 1.2041478157043457\n",
      "\tGenerator loss: 0.8862209320068359, Discriminator loss: 1.2072927951812744\n",
      "\tGenerator loss: 0.9173246622085571, Discriminator loss: 1.186738133430481\n",
      "\tGenerator loss: 0.9691515564918518, Discriminator loss: 1.1752245426177979\n",
      "\tGenerator loss: 1.0607731342315674, Discriminator loss: 1.1696219444274902\n",
      "\tGenerator loss: 1.0796467065811157, Discriminator loss: 1.210004448890686\n",
      "\tGenerator loss: 1.0542865991592407, Discriminator loss: 1.145611047744751\n",
      "\tGenerator loss: 1.0102486610412598, Discriminator loss: 1.117013931274414\n",
      "\tGenerator loss: 0.968195915222168, Discriminator loss: 1.1048775911331177\n",
      "\tGenerator loss: 0.9481289386749268, Discriminator loss: 1.1734217405319214\n",
      "\tGenerator loss: 0.9789355993270874, Discriminator loss: 1.1565202474594116\n",
      "\tGenerator loss: 1.0287773609161377, Discriminator loss: 1.125176191329956\n",
      "\tGenerator loss: 1.0853649377822876, Discriminator loss: 1.0985372066497803\n",
      "\tGenerator loss: 1.0968208312988281, Discriminator loss: 1.1195374727249146\n",
      "\tGenerator loss: 1.084762692451477, Discriminator loss: 1.0962051153182983\n",
      "\tGenerator loss: 1.0671629905700684, Discriminator loss: 1.1100220680236816\n",
      "\tGenerator loss: 1.0321671962738037, Discriminator loss: 1.0914719104766846\n",
      "\tGenerator loss: 1.0257116556167603, Discriminator loss: 1.1257729530334473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9890782237052917, Discriminator loss: 1.1356509923934937\n",
      "\tGenerator loss: 0.9689467549324036, Discriminator loss: 1.2139320373535156\n",
      "\tGenerator loss: 0.9258544445037842, Discriminator loss: 1.1966259479522705\n",
      "\tGenerator loss: 0.89715975522995, Discriminator loss: 1.1582832336425781\n",
      "\tGenerator loss: 0.9225870966911316, Discriminator loss: 1.1441929340362549\n",
      "\tGenerator loss: 0.9986501932144165, Discriminator loss: 1.1407949924468994\n",
      "\tGenerator loss: 1.0858919620513916, Discriminator loss: 1.1375410556793213\n",
      "\tGenerator loss: 1.1421750783920288, Discriminator loss: 1.1216537952423096\n",
      "\tGenerator loss: 1.075387716293335, Discriminator loss: 1.177940845489502\n",
      "\tGenerator loss: 1.004676103591919, Discriminator loss: 1.1933619976043701\n",
      "\tGenerator loss: 0.9069877862930298, Discriminator loss: 1.2154419422149658\n",
      "\tGenerator loss: 0.8770543336868286, Discriminator loss: 1.1799030303955078\n",
      "\tGenerator loss: 0.8874687552452087, Discriminator loss: 1.140162467956543\n",
      "\tGenerator loss: 0.949317455291748, Discriminator loss: 1.1492726802825928\n",
      "\tGenerator loss: 1.0703868865966797, Discriminator loss: 1.1834385395050049\n",
      "\tGenerator loss: 1.1507692337036133, Discriminator loss: 1.1612508296966553\n",
      "\tGenerator loss: 1.1233675479888916, Discriminator loss: 1.1678893566131592\n",
      "\tGenerator loss: 1.0102719068527222, Discriminator loss: 1.1860973834991455\n",
      "\tGenerator loss: 0.9103866219520569, Discriminator loss: 1.223082184791565\n",
      "\tGenerator loss: 0.8502929210662842, Discriminator loss: 1.2189728021621704\n",
      "\tGenerator loss: 0.8337476849555969, Discriminator loss: 1.208794355392456\n",
      "\tGenerator loss: 0.8798802495002747, Discriminator loss: 1.2034573554992676\n",
      "\tGenerator loss: 0.9373897314071655, Discriminator loss: 1.2170493602752686\n",
      "\tGenerator loss: 1.0084047317504883, Discriminator loss: 1.2733573913574219\n",
      "\tGenerator loss: 1.0287127494812012, Discriminator loss: 1.23024582862854\n",
      "\tGenerator loss: 1.0062330961227417, Discriminator loss: 1.2232352495193481\n",
      "\tGenerator loss: 0.9522841572761536, Discriminator loss: 1.2653694152832031\n",
      "\tGenerator loss: 0.8595809936523438, Discriminator loss: 1.2702367305755615\n",
      "\tGenerator loss: 0.799515962600708, Discriminator loss: 1.3038983345031738\n",
      "\tGenerator loss: 0.7900035381317139, Discriminator loss: 1.304762601852417\n",
      "\tGenerator loss: 0.8403639197349548, Discriminator loss: 1.2769393920898438\n",
      "\tGenerator loss: 0.9012018442153931, Discriminator loss: 1.2634682655334473\n",
      "\tGenerator loss: 0.9444925785064697, Discriminator loss: 1.2714046239852905\n",
      "\tGenerator loss: 0.9618465900421143, Discriminator loss: 1.275495171546936\n",
      "\tGenerator loss: 0.8949049711227417, Discriminator loss: 1.2483429908752441\n",
      "\tGenerator loss: 0.8514268398284912, Discriminator loss: 1.271440863609314\n",
      "\tGenerator loss: 0.8165122270584106, Discriminator loss: 1.2801854610443115\n",
      "\tGenerator loss: 0.8279948234558105, Discriminator loss: 1.290903091430664\n",
      "\tGenerator loss: 0.8708397746086121, Discriminator loss: 1.2404789924621582\n",
      "\tGenerator loss: 0.9204537868499756, Discriminator loss: 1.239678978919983\n",
      "\tGenerator loss: 0.980669379234314, Discriminator loss: 1.1944315433502197\n",
      "\tGenerator loss: 0.9754589796066284, Discriminator loss: 1.2127163410186768\n",
      "\tGenerator loss: 0.9715340733528137, Discriminator loss: 1.1850879192352295\n",
      "\tGenerator loss: 0.9307391047477722, Discriminator loss: 1.1756515502929688\n",
      "\tGenerator loss: 0.934989869594574, Discriminator loss: 1.2105724811553955\n",
      "\tGenerator loss: 0.9137953519821167, Discriminator loss: 1.1751251220703125\n",
      "\tGenerator loss: 0.9368209838867188, Discriminator loss: 1.148925542831421\n",
      "\tGenerator loss: 0.9640032052993774, Discriminator loss: 1.111304521560669\n",
      "\tGenerator loss: 1.001078724861145, Discriminator loss: 1.2305998802185059\n",
      "\tGenerator loss: 1.0559558868408203, Discriminator loss: 1.3106560707092285\n",
      "\tGenerator loss: 1.0462875366210938, Discriminator loss: 1.3292289972305298\n",
      "\tGenerator loss: 1.0194276571273804, Discriminator loss: 1.2957878112792969\n",
      "\tGenerator loss: 0.9683703184127808, Discriminator loss: 1.2515219449996948\n",
      "\tGenerator loss: 0.9414210915565491, Discriminator loss: 1.2675280570983887\n",
      "\tGenerator loss: 0.9292199611663818, Discriminator loss: 1.2370659112930298\n",
      "\tGenerator loss: 0.9693751335144043, Discriminator loss: 1.183713674545288\n",
      "\tGenerator loss: 1.026525616645813, Discriminator loss: 1.199894905090332\n",
      "\tGenerator loss: 1.0595121383666992, Discriminator loss: 1.1387677192687988\n",
      "\tGenerator loss: 1.0779988765716553, Discriminator loss: 1.3075544834136963\n",
      "\tGenerator loss: 1.0477397441864014, Discriminator loss: 1.2147777080535889\n",
      "\tGenerator loss: 1.0434951782226562, Discriminator loss: 1.198508381843567\n",
      "\tGenerator loss: 0.9938970804214478, Discriminator loss: 1.3032504320144653\n",
      "\tGenerator loss: 0.9638829231262207, Discriminator loss: 1.3326942920684814\n",
      "\tGenerator loss: 0.928770124912262, Discriminator loss: 1.3534241914749146\n",
      "\tGenerator loss: 0.913817286491394, Discriminator loss: 1.3124096393585205\n",
      "\tGenerator loss: 0.9127621650695801, Discriminator loss: 1.2197195291519165\n",
      "\tGenerator loss: 0.9954900145530701, Discriminator loss: 1.208542823791504\n",
      "\tGenerator loss: 1.058742642402649, Discriminator loss: 1.245065689086914\n",
      "\tGenerator loss: 1.0471540689468384, Discriminator loss: 1.1975364685058594\n",
      "\tGenerator loss: 1.0168406963348389, Discriminator loss: 1.2301056385040283\n",
      "\tGenerator loss: 0.9836840629577637, Discriminator loss: 1.199202299118042\n",
      "\tGenerator loss: 0.9444669485092163, Discriminator loss: 1.1959991455078125\n",
      "\tGenerator loss: 0.930948793888092, Discriminator loss: 1.258567214012146\n",
      "\tGenerator loss: 0.9453785419464111, Discriminator loss: 1.2130364179611206\n",
      "\tGenerator loss: 0.9910159111022949, Discriminator loss: 1.1899628639221191\n",
      "\tGenerator loss: 1.0159051418304443, Discriminator loss: 1.200286865234375\n",
      "\tGenerator loss: 1.0299605131149292, Discriminator loss: 1.1721632480621338\n",
      "\tGenerator loss: 0.9997406601905823, Discriminator loss: 1.1933040618896484\n",
      "\tGenerator loss: 0.9492605924606323, Discriminator loss: 1.1745357513427734\n",
      "\tGenerator loss: 0.9268033504486084, Discriminator loss: 1.2051212787628174\n",
      "\tGenerator loss: 0.9516861438751221, Discriminator loss: 1.1760268211364746\n",
      "\tGenerator loss: 0.9981263875961304, Discriminator loss: 1.1498868465423584\n",
      "\tGenerator loss: 1.0436255931854248, Discriminator loss: 1.1834053993225098\n",
      "\tGenerator loss: 1.03697669506073, Discriminator loss: 1.2276959419250488\n",
      "\tGenerator loss: 1.028449296951294, Discriminator loss: 1.2256596088409424\n",
      "\tGenerator loss: 1.0194222927093506, Discriminator loss: 1.1778137683868408\n",
      "\tGenerator loss: 0.9930335283279419, Discriminator loss: 1.1903107166290283\n",
      "\tGenerator loss: 0.9524707794189453, Discriminator loss: 1.232184648513794\n",
      "\tGenerator loss: 0.9771949052810669, Discriminator loss: 1.2086272239685059\n",
      "\tGenerator loss: 0.9639309644699097, Discriminator loss: 1.2658867835998535\n",
      "\tGenerator loss: 0.9612038731575012, Discriminator loss: 1.2238068580627441\n",
      "\tGenerator loss: 0.9465007781982422, Discriminator loss: 1.1930979490280151\n",
      "\tGenerator loss: 0.9214663505554199, Discriminator loss: 1.2416468858718872\n",
      "\tGenerator loss: 0.9443323612213135, Discriminator loss: 1.2308655977249146\n",
      "\tGenerator loss: 0.9459573030471802, Discriminator loss: 1.234315037727356\n",
      "\tGenerator loss: 0.9527285099029541, Discriminator loss: 1.2268362045288086\n",
      "\tGenerator loss: 0.9547786116600037, Discriminator loss: 1.2314741611480713\n",
      "\tGenerator loss: 0.965910792350769, Discriminator loss: 1.1838634014129639\n",
      "\tGenerator loss: 0.978057324886322, Discriminator loss: 1.1843814849853516\n",
      "\tGenerator loss: 0.9827734231948853, Discriminator loss: 1.1837637424468994\n",
      "\tGenerator loss: 0.9752695560455322, Discriminator loss: 1.2446529865264893\n",
      "\tGenerator loss: 0.929012656211853, Discriminator loss: 1.223109483718872\n",
      "\tGenerator loss: 0.9188010692596436, Discriminator loss: 1.2565096616744995\n",
      "\tGenerator loss: 0.9257708787918091, Discriminator loss: 1.2555360794067383\n",
      "\tGenerator loss: 0.9195117354393005, Discriminator loss: 1.3184977769851685\n",
      "\tGenerator loss: 0.9126662015914917, Discriminator loss: 1.3298416137695312\n",
      "\tGenerator loss: 0.8670037388801575, Discriminator loss: 1.3102549314498901\n",
      "\tGenerator loss: 0.8405781984329224, Discriminator loss: 1.2950212955474854\n",
      "\tGenerator loss: 0.8528211116790771, Discriminator loss: 1.322090983390808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8960893154144287, Discriminator loss: 1.2944740056991577\n",
      "\tGenerator loss: 0.9191029071807861, Discriminator loss: 1.2870275974273682\n",
      "\tGenerator loss: 0.9269528985023499, Discriminator loss: 1.3087894916534424\n",
      "\tGenerator loss: 0.9407267570495605, Discriminator loss: 1.2969386577606201\n",
      "\tGenerator loss: 0.9140877723693848, Discriminator loss: 1.298905611038208\n",
      "\tGenerator loss: 0.8777584433555603, Discriminator loss: 1.2945386171340942\n",
      "\tGenerator loss: 0.8551033735275269, Discriminator loss: 1.2848811149597168\n",
      "\tGenerator loss: 0.8500337600708008, Discriminator loss: 1.303101658821106\n",
      "\tGenerator loss: 0.8722668886184692, Discriminator loss: 1.3297922611236572\n",
      "\tGenerator loss: 0.9106922149658203, Discriminator loss: 1.320224404335022\n",
      "\tGenerator loss: 0.9533552527427673, Discriminator loss: 1.3013521432876587\n",
      "\tGenerator loss: 0.9714881777763367, Discriminator loss: 1.2840924263000488\n",
      "\tGenerator loss: 0.9312430620193481, Discriminator loss: 1.2954846620559692\n",
      "\tGenerator loss: 0.8919515609741211, Discriminator loss: 1.2925262451171875\n",
      "\tGenerator loss: 0.8426439166069031, Discriminator loss: 1.3188968896865845\n",
      "\tGenerator loss: 0.8420315980911255, Discriminator loss: 1.2626631259918213\n",
      "\tGenerator loss: 0.8572921752929688, Discriminator loss: 1.2697739601135254\n",
      "\tGenerator loss: 0.87299644947052, Discriminator loss: 1.3309967517852783\n",
      "\tGenerator loss: 0.9252500534057617, Discriminator loss: 1.3434933423995972\n",
      "\tGenerator loss: 0.9396617412567139, Discriminator loss: 1.2997183799743652\n",
      "\tGenerator loss: 0.92127525806427, Discriminator loss: 1.315162181854248\n",
      "\tGenerator loss: 0.865530788898468, Discriminator loss: 1.2800180912017822\n",
      "\tGenerator loss: 0.8484205603599548, Discriminator loss: 1.295482873916626\n",
      "\tGenerator loss: 0.8589167594909668, Discriminator loss: 1.2786903381347656\n",
      "\tGenerator loss: 0.8797492384910583, Discriminator loss: 1.2660906314849854\n",
      "\tGenerator loss: 0.9248415231704712, Discriminator loss: 1.2505598068237305\n",
      "\tGenerator loss: 0.9486551284790039, Discriminator loss: 1.3200194835662842\n",
      "\tGenerator loss: 0.9385482668876648, Discriminator loss: 1.315317153930664\n",
      "\tGenerator loss: 0.9044681787490845, Discriminator loss: 1.3181602954864502\n",
      "\tGenerator loss: 0.8713780045509338, Discriminator loss: 1.2861993312835693\n",
      "\tGenerator loss: 0.8388000726699829, Discriminator loss: 1.33673095703125\n",
      "\tGenerator loss: 0.8350294232368469, Discriminator loss: 1.279938817024231\n",
      "\tGenerator loss: 0.8922799825668335, Discriminator loss: 1.2586524486541748\n",
      "\tGenerator loss: 0.9536523818969727, Discriminator loss: 1.2415319681167603\n",
      "\tGenerator loss: 0.987282395362854, Discriminator loss: 1.277569055557251\n",
      "\tGenerator loss: 0.9593409299850464, Discriminator loss: 1.2505947351455688\n",
      "\tGenerator loss: 0.9177727699279785, Discriminator loss: 1.2316193580627441\n",
      "\tGenerator loss: 0.9314881563186646, Discriminator loss: 1.2026240825653076\n",
      "\tGenerator loss: 0.9313740730285645, Discriminator loss: 1.2290111780166626\n",
      "\tGenerator loss: 0.9108015298843384, Discriminator loss: 1.2628793716430664\n",
      "\tGenerator loss: 0.9088515043258667, Discriminator loss: 1.2483177185058594\n",
      "\tGenerator loss: 0.9060552716255188, Discriminator loss: 1.2285428047180176\n",
      "\tGenerator loss: 0.9350756406784058, Discriminator loss: 1.2486058473587036\n",
      "\tGenerator loss: 0.9752006530761719, Discriminator loss: 1.2571227550506592\n",
      "\tGenerator loss: 0.9351544976234436, Discriminator loss: 1.2118414640426636\n",
      "\tGenerator loss: 0.9074448943138123, Discriminator loss: 1.2200424671173096\n",
      "\tGenerator loss: 0.9190840125083923, Discriminator loss: 1.1890511512756348\n",
      "\tGenerator loss: 0.9372388124465942, Discriminator loss: 1.1818571090698242\n",
      "\tGenerator loss: 0.9969460964202881, Discriminator loss: 1.1950569152832031\n",
      "\tGenerator loss: 1.0269036293029785, Discriminator loss: 1.2181936502456665\n",
      "\tGenerator loss: 1.0120017528533936, Discriminator loss: 1.1995408535003662\n",
      "\tGenerator loss: 0.9877587556838989, Discriminator loss: 1.2249884605407715\n",
      "\tGenerator loss: 0.9365605115890503, Discriminator loss: 1.2510184049606323\n",
      "\tGenerator loss: 0.8954861164093018, Discriminator loss: 1.2594881057739258\n",
      "\tGenerator loss: 0.9032971858978271, Discriminator loss: 1.2710623741149902\n",
      "\tGenerator loss: 0.9620521664619446, Discriminator loss: 1.2375391721725464\n",
      "\tGenerator loss: 0.9768447875976562, Discriminator loss: 1.2044658660888672\n",
      "\tGenerator loss: 0.9808459877967834, Discriminator loss: 1.1942737102508545\n",
      "\tGenerator loss: 0.9860506057739258, Discriminator loss: 1.1750941276550293\n",
      "\tGenerator loss: 0.9709815382957458, Discriminator loss: 1.1657497882843018\n",
      "\tGenerator loss: 0.9439224004745483, Discriminator loss: 1.1792317628860474\n",
      "\tGenerator loss: 0.9220446348190308, Discriminator loss: 1.1687626838684082\n",
      "\tGenerator loss: 0.9023736715316772, Discriminator loss: 1.2062705755233765\n",
      "\tGenerator loss: 0.9625372886657715, Discriminator loss: 1.1665606498718262\n",
      "\tGenerator loss: 1.0036213397979736, Discriminator loss: 1.1871428489685059\n",
      "\tGenerator loss: 1.038527250289917, Discriminator loss: 1.158535122871399\n",
      "\tGenerator loss: 1.0159751176834106, Discriminator loss: 1.1445229053497314\n",
      "\tGenerator loss: 0.9884388446807861, Discriminator loss: 1.1330430507659912\n",
      "\tGenerator loss: 0.9675135612487793, Discriminator loss: 1.1126461029052734\n",
      "\tGenerator loss: 0.9033346176147461, Discriminator loss: 1.1319992542266846\n",
      "\tGenerator loss: 0.9140825271606445, Discriminator loss: 1.1540172100067139\n",
      "\tGenerator loss: 0.9612988233566284, Discriminator loss: 1.1663817167282104\n",
      "\tGenerator loss: 1.0542700290679932, Discriminator loss: 1.1446330547332764\n",
      "\tGenerator loss: 1.0544753074645996, Discriminator loss: 1.1283211708068848\n",
      "\tGenerator loss: 1.0350620746612549, Discriminator loss: 1.13450026512146\n",
      "\tGenerator loss: 1.0070968866348267, Discriminator loss: 1.1196895837783813\n",
      "\tGenerator loss: 0.9622905254364014, Discriminator loss: 1.1590492725372314\n",
      "\tGenerator loss: 0.947433352470398, Discriminator loss: 1.1904264688491821\n",
      "\tGenerator loss: 0.9255218505859375, Discriminator loss: 1.1789453029632568\n",
      "\tGenerator loss: 0.9356061816215515, Discriminator loss: 1.221605896949768\n",
      "\tGenerator loss: 0.9749380350112915, Discriminator loss: 1.2126009464263916\n",
      "\tGenerator loss: 0.9981656670570374, Discriminator loss: 1.2326204776763916\n",
      "\tGenerator loss: 0.9927893877029419, Discriminator loss: 1.1931068897247314\n",
      "\tGenerator loss: 1.0005230903625488, Discriminator loss: 1.1782041788101196\n",
      "\tGenerator loss: 0.958751916885376, Discriminator loss: 1.1979951858520508\n",
      "\tGenerator loss: 0.907589316368103, Discriminator loss: 1.2015775442123413\n",
      "\tGenerator loss: 0.8818985223770142, Discriminator loss: 1.219404935836792\n",
      "\tGenerator loss: 0.9265711307525635, Discriminator loss: 1.1920814514160156\n",
      "\tGenerator loss: 0.952025294303894, Discriminator loss: 1.178399920463562\n",
      "\tGenerator loss: 0.9880203008651733, Discriminator loss: 1.1741833686828613\n",
      "\tGenerator loss: 1.0136067867279053, Discriminator loss: 1.1995187997817993\n",
      "\tGenerator loss: 0.9795629382133484, Discriminator loss: 1.150810956954956\n",
      "\tGenerator loss: 0.947838544845581, Discriminator loss: 1.1755584478378296\n",
      "\tGenerator loss: 0.8806508779525757, Discriminator loss: 1.1819555759429932\n",
      "\tGenerator loss: 0.8946573734283447, Discriminator loss: 1.1453745365142822\n",
      "\tGenerator loss: 0.9521839618682861, Discriminator loss: 1.1379510164260864\n",
      "\tGenerator loss: 1.0346698760986328, Discriminator loss: 1.1824188232421875\n",
      "\tGenerator loss: 1.1096259355545044, Discriminator loss: 1.1937493085861206\n",
      "\tGenerator loss: 1.0647677183151245, Discriminator loss: 1.223421335220337\n",
      "Time for epoch 42 is 22934.236925840378 sec\n",
      "\tGenerator loss: 0.9774999022483826, Discriminator loss: 1.2133369445800781\n",
      "\tGenerator loss: 0.880009651184082, Discriminator loss: 1.234104037284851\n",
      "\tGenerator loss: 0.822679877281189, Discriminator loss: 1.2398489713668823\n",
      "\tGenerator loss: 0.8179752826690674, Discriminator loss: 1.2583389282226562\n",
      "\tGenerator loss: 0.8956594467163086, Discriminator loss: 1.2629916667938232\n",
      "\tGenerator loss: 0.9766815900802612, Discriminator loss: 1.2469011545181274\n",
      "\tGenerator loss: 1.048113226890564, Discriminator loss: 1.2629687786102295\n",
      "\tGenerator loss: 1.0292545557022095, Discriminator loss: 1.2965641021728516\n",
      "\tGenerator loss: 0.9619961977005005, Discriminator loss: 1.281783103942871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.846858561038971, Discriminator loss: 1.2570502758026123\n",
      "\tGenerator loss: 0.7993230819702148, Discriminator loss: 1.2879259586334229\n",
      "\tGenerator loss: 0.8044993877410889, Discriminator loss: 1.3324334621429443\n",
      "\tGenerator loss: 0.9040406346321106, Discriminator loss: 1.3211381435394287\n",
      "\tGenerator loss: 0.9497662782669067, Discriminator loss: 1.3215327262878418\n",
      "\tGenerator loss: 0.9653467535972595, Discriminator loss: 1.339128851890564\n",
      "\tGenerator loss: 0.8790799379348755, Discriminator loss: 1.3394393920898438\n",
      "\tGenerator loss: 0.8325501680374146, Discriminator loss: 1.3481796979904175\n",
      "\tGenerator loss: 0.8212594985961914, Discriminator loss: 1.3249578475952148\n",
      "\tGenerator loss: 0.832606852054596, Discriminator loss: 1.3445031642913818\n",
      "\tGenerator loss: 0.8703601360321045, Discriminator loss: 1.3521456718444824\n",
      "\tGenerator loss: 0.8990410566329956, Discriminator loss: 1.3118860721588135\n",
      "\tGenerator loss: 0.8921904563903809, Discriminator loss: 1.356312870979309\n",
      "\tGenerator loss: 0.9071144461631775, Discriminator loss: 1.3504507541656494\n",
      "\tGenerator loss: 0.9031671285629272, Discriminator loss: 1.3194303512573242\n",
      "\tGenerator loss: 0.8877651691436768, Discriminator loss: 1.3211710453033447\n",
      "\tGenerator loss: 0.8299092650413513, Discriminator loss: 1.3475792407989502\n",
      "\tGenerator loss: 0.830280601978302, Discriminator loss: 1.3805341720581055\n",
      "\tGenerator loss: 0.8356693387031555, Discriminator loss: 1.3702082633972168\n",
      "\tGenerator loss: 0.8430095911026001, Discriminator loss: 1.442251443862915\n",
      "\tGenerator loss: 0.7922779321670532, Discriminator loss: 1.4264545440673828\n",
      "\tGenerator loss: 0.7735236287117004, Discriminator loss: 1.373744249343872\n",
      "\tGenerator loss: 0.7681541442871094, Discriminator loss: 1.3702160120010376\n",
      "\tGenerator loss: 0.8111097812652588, Discriminator loss: 1.3394503593444824\n",
      "\tGenerator loss: 0.8867736458778381, Discriminator loss: 1.3608132600784302\n",
      "\tGenerator loss: 0.9435515403747559, Discriminator loss: 1.3658199310302734\n",
      "\tGenerator loss: 0.9239873886108398, Discriminator loss: 1.4005212783813477\n",
      "\tGenerator loss: 0.8720681667327881, Discriminator loss: 1.3893836736679077\n",
      "\tGenerator loss: 0.7759793400764465, Discriminator loss: 1.4055325984954834\n",
      "\tGenerator loss: 0.7314997911453247, Discriminator loss: 1.3660964965820312\n",
      "\tGenerator loss: 0.7385454177856445, Discriminator loss: 1.3551169633865356\n",
      "\tGenerator loss: 0.8307573795318604, Discriminator loss: 1.3482708930969238\n",
      "\tGenerator loss: 0.9511575102806091, Discriminator loss: 1.354909062385559\n",
      "\tGenerator loss: 0.9951996803283691, Discriminator loss: 1.3509814739227295\n",
      "\tGenerator loss: 0.9938202500343323, Discriminator loss: 1.3519527912139893\n",
      "\tGenerator loss: 0.8915551900863647, Discriminator loss: 1.3345818519592285\n",
      "\tGenerator loss: 0.7878756523132324, Discriminator loss: 1.3362915515899658\n",
      "\tGenerator loss: 0.7315332889556885, Discriminator loss: 1.351341962814331\n",
      "\tGenerator loss: 0.7430651187896729, Discriminator loss: 1.3256065845489502\n",
      "\tGenerator loss: 0.8270103931427002, Discriminator loss: 1.2893511056900024\n",
      "\tGenerator loss: 0.920790433883667, Discriminator loss: 1.288224458694458\n",
      "\tGenerator loss: 0.9692933559417725, Discriminator loss: 1.3287858963012695\n",
      "\tGenerator loss: 0.9907232522964478, Discriminator loss: 1.2903873920440674\n",
      "\tGenerator loss: 0.9373242259025574, Discriminator loss: 1.267491102218628\n",
      "\tGenerator loss: 0.8592553734779358, Discriminator loss: 1.3080029487609863\n",
      "\tGenerator loss: 0.8094840049743652, Discriminator loss: 1.2909750938415527\n",
      "\tGenerator loss: 0.7943872809410095, Discriminator loss: 1.2850658893585205\n",
      "\tGenerator loss: 0.8341953158378601, Discriminator loss: 1.258728265762329\n",
      "\tGenerator loss: 0.8830966949462891, Discriminator loss: 1.2271071672439575\n",
      "\tGenerator loss: 0.925815761089325, Discriminator loss: 1.2360981702804565\n",
      "\tGenerator loss: 0.9564920663833618, Discriminator loss: 1.2211816310882568\n",
      "\tGenerator loss: 0.9225137829780579, Discriminator loss: 1.210557222366333\n",
      "\tGenerator loss: 0.9107664823532104, Discriminator loss: 1.181533694267273\n",
      "\tGenerator loss: 0.8663271069526672, Discriminator loss: 1.2340474128723145\n",
      "\tGenerator loss: 0.83376145362854, Discriminator loss: 1.252166748046875\n",
      "\tGenerator loss: 0.856210470199585, Discriminator loss: 1.2227826118469238\n",
      "\tGenerator loss: 0.8824742436408997, Discriminator loss: 1.1977567672729492\n",
      "\tGenerator loss: 0.9389475584030151, Discriminator loss: 1.2012066841125488\n",
      "\tGenerator loss: 0.9603390097618103, Discriminator loss: 1.1829354763031006\n",
      "\tGenerator loss: 0.9689227342605591, Discriminator loss: 1.1639256477355957\n",
      "\tGenerator loss: 0.9559689164161682, Discriminator loss: 1.1597161293029785\n",
      "\tGenerator loss: 0.9249182939529419, Discriminator loss: 1.1470158100128174\n",
      "\tGenerator loss: 0.9338241219520569, Discriminator loss: 1.1544893980026245\n",
      "\tGenerator loss: 0.9453398585319519, Discriminator loss: 1.1186800003051758\n",
      "\tGenerator loss: 0.9501560926437378, Discriminator loss: 1.109518051147461\n",
      "\tGenerator loss: 0.9829393029212952, Discriminator loss: 1.0736240148544312\n",
      "\tGenerator loss: 0.9993188381195068, Discriminator loss: 1.155247449874878\n",
      "\tGenerator loss: 1.0322004556655884, Discriminator loss: 1.230204463005066\n",
      "\tGenerator loss: 1.0308489799499512, Discriminator loss: 1.22269868850708\n",
      "\tGenerator loss: 1.0013797283172607, Discriminator loss: 1.1664822101593018\n",
      "\tGenerator loss: 0.9785069227218628, Discriminator loss: 1.1309597492218018\n",
      "\tGenerator loss: 0.9730361104011536, Discriminator loss: 1.1449081897735596\n",
      "\tGenerator loss: 0.9558975696563721, Discriminator loss: 1.1504764556884766\n",
      "\tGenerator loss: 1.004164218902588, Discriminator loss: 1.091724157333374\n",
      "\tGenerator loss: 1.0362672805786133, Discriminator loss: 1.117518663406372\n",
      "\tGenerator loss: 1.0337728261947632, Discriminator loss: 1.0585404634475708\n",
      "\tGenerator loss: 1.0387423038482666, Discriminator loss: 1.1441848278045654\n",
      "\tGenerator loss: 1.033698558807373, Discriminator loss: 1.072615623474121\n",
      "\tGenerator loss: 1.0609996318817139, Discriminator loss: 1.0920944213867188\n",
      "\tGenerator loss: 1.0630097389221191, Discriminator loss: 1.1630525588989258\n",
      "\tGenerator loss: 1.0373996496200562, Discriminator loss: 1.1953318119049072\n",
      "\tGenerator loss: 0.9870485067367554, Discriminator loss: 1.1798546314239502\n",
      "\tGenerator loss: 0.9446803331375122, Discriminator loss: 1.181759238243103\n",
      "\tGenerator loss: 0.9176201820373535, Discriminator loss: 1.148895025253296\n",
      "\tGenerator loss: 0.958369791507721, Discriminator loss: 1.148784875869751\n",
      "\tGenerator loss: 1.0203005075454712, Discriminator loss: 1.202972173690796\n",
      "\tGenerator loss: 1.0554568767547607, Discriminator loss: 1.1517643928527832\n",
      "\tGenerator loss: 1.0452635288238525, Discriminator loss: 1.169531226158142\n",
      "\tGenerator loss: 0.9816821813583374, Discriminator loss: 1.1743195056915283\n",
      "\tGenerator loss: 0.9352917671203613, Discriminator loss: 1.1688790321350098\n",
      "\tGenerator loss: 0.9392841458320618, Discriminator loss: 1.1955281496047974\n",
      "\tGenerator loss: 0.9350790977478027, Discriminator loss: 1.2002317905426025\n",
      "\tGenerator loss: 0.9652907252311707, Discriminator loss: 1.196824312210083\n",
      "\tGenerator loss: 0.9998294115066528, Discriminator loss: 1.2054170370101929\n",
      "\tGenerator loss: 0.9809134006500244, Discriminator loss: 1.2103557586669922\n",
      "\tGenerator loss: 0.9403427839279175, Discriminator loss: 1.2291584014892578\n",
      "\tGenerator loss: 0.9160914421081543, Discriminator loss: 1.2186260223388672\n",
      "\tGenerator loss: 0.8881508708000183, Discriminator loss: 1.2475124597549438\n",
      "\tGenerator loss: 0.8988939523696899, Discriminator loss: 1.2394347190856934\n",
      "\tGenerator loss: 0.9617040753364563, Discriminator loss: 1.206936001777649\n",
      "\tGenerator loss: 0.9827215671539307, Discriminator loss: 1.236914873123169\n",
      "\tGenerator loss: 0.9757315516471863, Discriminator loss: 1.2893985509872437\n",
      "\tGenerator loss: 0.962670087814331, Discriminator loss: 1.304739236831665\n",
      "\tGenerator loss: 0.9486501216888428, Discriminator loss: 1.256187081336975\n",
      "\tGenerator loss: 0.9350180625915527, Discriminator loss: 1.2761106491088867\n",
      "\tGenerator loss: 0.9171981811523438, Discriminator loss: 1.3037124872207642\n",
      "\tGenerator loss: 0.8831665515899658, Discriminator loss: 1.3043855428695679\n",
      "\tGenerator loss: 0.9029010534286499, Discriminator loss: 1.317305088043213\n",
      "\tGenerator loss: 0.8872132301330566, Discriminator loss: 1.3241338729858398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8460512757301331, Discriminator loss: 1.3064885139465332\n",
      "\tGenerator loss: 0.8608531951904297, Discriminator loss: 1.3199374675750732\n",
      "\tGenerator loss: 0.8715066909790039, Discriminator loss: 1.3232189416885376\n",
      "\tGenerator loss: 0.8624722957611084, Discriminator loss: 1.319556474685669\n",
      "\tGenerator loss: 0.874663770198822, Discriminator loss: 1.3246099948883057\n",
      "\tGenerator loss: 0.8655388355255127, Discriminator loss: 1.3335847854614258\n",
      "\tGenerator loss: 0.8809502124786377, Discriminator loss: 1.3120123147964478\n",
      "\tGenerator loss: 0.8916125893592834, Discriminator loss: 1.32096529006958\n",
      "\tGenerator loss: 0.9014054536819458, Discriminator loss: 1.346625566482544\n",
      "\tGenerator loss: 0.9177598357200623, Discriminator loss: 1.3309024572372437\n",
      "\tGenerator loss: 0.88129061460495, Discriminator loss: 1.314910650253296\n",
      "\tGenerator loss: 0.8496092557907104, Discriminator loss: 1.3759973049163818\n",
      "\tGenerator loss: 0.8668539524078369, Discriminator loss: 1.3144264221191406\n",
      "\tGenerator loss: 0.8729580640792847, Discriminator loss: 1.3506534099578857\n",
      "\tGenerator loss: 0.8676759004592896, Discriminator loss: 1.352609634399414\n",
      "\tGenerator loss: 0.838984489440918, Discriminator loss: 1.3230085372924805\n",
      "\tGenerator loss: 0.8573042154312134, Discriminator loss: 1.2961562871932983\n",
      "\tGenerator loss: 0.8718816041946411, Discriminator loss: 1.3634223937988281\n",
      "\tGenerator loss: 0.8792997598648071, Discriminator loss: 1.3671623468399048\n",
      "\tGenerator loss: 0.8756542801856995, Discriminator loss: 1.3396987915039062\n",
      "\tGenerator loss: 0.8651821613311768, Discriminator loss: 1.3274312019348145\n",
      "\tGenerator loss: 0.8562711477279663, Discriminator loss: 1.320403814315796\n",
      "\tGenerator loss: 0.8453638553619385, Discriminator loss: 1.333214521408081\n",
      "\tGenerator loss: 0.8286458849906921, Discriminator loss: 1.3223286867141724\n",
      "\tGenerator loss: 0.8527787923812866, Discriminator loss: 1.3076953887939453\n",
      "\tGenerator loss: 0.8795152902603149, Discriminator loss: 1.302500605583191\n",
      "\tGenerator loss: 0.924349844455719, Discriminator loss: 1.3393137454986572\n",
      "\tGenerator loss: 0.9419771432876587, Discriminator loss: 1.3362399339675903\n",
      "\tGenerator loss: 0.959479570388794, Discriminator loss: 1.313354253768921\n",
      "\tGenerator loss: 0.9197839498519897, Discriminator loss: 1.2854208946228027\n",
      "\tGenerator loss: 0.850436806678772, Discriminator loss: 1.2971426248550415\n",
      "\tGenerator loss: 0.8354034423828125, Discriminator loss: 1.277653694152832\n",
      "\tGenerator loss: 0.8417623043060303, Discriminator loss: 1.2786166667938232\n",
      "\tGenerator loss: 0.8389398455619812, Discriminator loss: 1.2906323671340942\n",
      "\tGenerator loss: 0.8908689022064209, Discriminator loss: 1.2806097269058228\n",
      "\tGenerator loss: 0.9272493720054626, Discriminator loss: 1.2908604145050049\n",
      "\tGenerator loss: 0.9525629281997681, Discriminator loss: 1.2968473434448242\n",
      "\tGenerator loss: 0.9372952580451965, Discriminator loss: 1.3046839237213135\n",
      "\tGenerator loss: 0.9086827635765076, Discriminator loss: 1.3094834089279175\n",
      "\tGenerator loss: 0.8608278036117554, Discriminator loss: 1.244189739227295\n",
      "\tGenerator loss: 0.8200134038925171, Discriminator loss: 1.2607879638671875\n",
      "\tGenerator loss: 0.8442957997322083, Discriminator loss: 1.244990587234497\n",
      "\tGenerator loss: 0.8981679677963257, Discriminator loss: 1.2370953559875488\n",
      "\tGenerator loss: 0.901272177696228, Discriminator loss: 1.2486604452133179\n",
      "\tGenerator loss: 0.944218099117279, Discriminator loss: 1.2678248882293701\n",
      "\tGenerator loss: 0.934126615524292, Discriminator loss: 1.2720052003860474\n",
      "\tGenerator loss: 0.8952345252037048, Discriminator loss: 1.2626316547393799\n",
      "\tGenerator loss: 0.876955509185791, Discriminator loss: 1.2213943004608154\n",
      "\tGenerator loss: 0.8334395885467529, Discriminator loss: 1.2642707824707031\n",
      "\tGenerator loss: 0.8503851294517517, Discriminator loss: 1.2238891124725342\n",
      "\tGenerator loss: 0.9081789255142212, Discriminator loss: 1.1968798637390137\n",
      "\tGenerator loss: 0.94239342212677, Discriminator loss: 1.2070603370666504\n",
      "\tGenerator loss: 0.9813522696495056, Discriminator loss: 1.2203803062438965\n",
      "\tGenerator loss: 0.9971203804016113, Discriminator loss: 1.1787525415420532\n",
      "\tGenerator loss: 0.9599831104278564, Discriminator loss: 1.1582977771759033\n",
      "\tGenerator loss: 0.937065601348877, Discriminator loss: 1.161482572555542\n",
      "\tGenerator loss: 0.8911987543106079, Discriminator loss: 1.1826695203781128\n",
      "\tGenerator loss: 0.8679724335670471, Discriminator loss: 1.1930866241455078\n",
      "\tGenerator loss: 0.8788360357284546, Discriminator loss: 1.2003374099731445\n",
      "\tGenerator loss: 0.9179337620735168, Discriminator loss: 1.168921709060669\n",
      "\tGenerator loss: 0.9978833198547363, Discriminator loss: 1.1729323863983154\n",
      "\tGenerator loss: 1.0084974765777588, Discriminator loss: 1.201714038848877\n",
      "\tGenerator loss: 0.9804041385650635, Discriminator loss: 1.1387380361557007\n",
      "\tGenerator loss: 0.9070572257041931, Discriminator loss: 1.1826238632202148\n",
      "\tGenerator loss: 0.9232194423675537, Discriminator loss: 1.1867175102233887\n",
      "\tGenerator loss: 0.9248354434967041, Discriminator loss: 1.169087529182434\n",
      "\tGenerator loss: 0.9539697170257568, Discriminator loss: 1.171888828277588\n",
      "\tGenerator loss: 0.9556576013565063, Discriminator loss: 1.162622094154358\n",
      "\tGenerator loss: 0.9640742540359497, Discriminator loss: 1.2085049152374268\n",
      "\tGenerator loss: 0.9801405072212219, Discriminator loss: 1.2132171392440796\n",
      "\tGenerator loss: 1.0009678602218628, Discriminator loss: 1.244736909866333\n",
      "\tGenerator loss: 0.9904043674468994, Discriminator loss: 1.2538262605667114\n",
      "\tGenerator loss: 0.9442464113235474, Discriminator loss: 1.276695966720581\n",
      "\tGenerator loss: 0.9041895270347595, Discriminator loss: 1.2349233627319336\n",
      "\tGenerator loss: 0.8826983571052551, Discriminator loss: 1.2185851335525513\n",
      "\tGenerator loss: 0.8942050337791443, Discriminator loss: 1.1854188442230225\n",
      "\tGenerator loss: 0.9666013717651367, Discriminator loss: 1.1608796119689941\n",
      "\tGenerator loss: 1.0105270147323608, Discriminator loss: 1.1958085298538208\n",
      "\tGenerator loss: 1.0283489227294922, Discriminator loss: 1.2098023891448975\n",
      "\tGenerator loss: 0.9861639738082886, Discriminator loss: 1.1871089935302734\n",
      "\tGenerator loss: 0.9372096061706543, Discriminator loss: 1.2393492460250854\n",
      "\tGenerator loss: 0.8781139850616455, Discriminator loss: 1.2261465787887573\n",
      "\tGenerator loss: 0.8597400784492493, Discriminator loss: 1.2544183731079102\n",
      "\tGenerator loss: 0.8999780416488647, Discriminator loss: 1.2177693843841553\n",
      "\tGenerator loss: 0.9715774059295654, Discriminator loss: 1.2114309072494507\n",
      "\tGenerator loss: 0.9906302690505981, Discriminator loss: 1.205045461654663\n",
      "\tGenerator loss: 1.006094217300415, Discriminator loss: 1.236484169960022\n",
      "\tGenerator loss: 0.9799734950065613, Discriminator loss: 1.226872205734253\n",
      "\tGenerator loss: 0.9211137294769287, Discriminator loss: 1.2335822582244873\n",
      "\tGenerator loss: 0.8711563348770142, Discriminator loss: 1.2398160696029663\n",
      "\tGenerator loss: 0.8817305564880371, Discriminator loss: 1.2382464408874512\n",
      "\tGenerator loss: 0.9164013266563416, Discriminator loss: 1.2249213457107544\n",
      "\tGenerator loss: 0.9687488079071045, Discriminator loss: 1.2129015922546387\n",
      "\tGenerator loss: 1.0219464302062988, Discriminator loss: 1.2038772106170654\n",
      "\tGenerator loss: 0.9933958053588867, Discriminator loss: 1.2671998739242554\n",
      "\tGenerator loss: 0.9320814609527588, Discriminator loss: 1.2980496883392334\n",
      "\tGenerator loss: 0.8455938696861267, Discriminator loss: 1.283308744430542\n",
      "\tGenerator loss: 0.8532794117927551, Discriminator loss: 1.2865073680877686\n",
      "\tGenerator loss: 0.8910572528839111, Discriminator loss: 1.2843139171600342\n",
      "\tGenerator loss: 0.9576036930084229, Discriminator loss: 1.3130663633346558\n",
      "\tGenerator loss: 0.9814532995223999, Discriminator loss: 1.2778427600860596\n",
      "\tGenerator loss: 0.9626750349998474, Discriminator loss: 1.295815348625183\n",
      "\tGenerator loss: 0.9423685073852539, Discriminator loss: 1.2840200662612915\n",
      "\tGenerator loss: 0.8972567319869995, Discriminator loss: 1.296382188796997\n",
      "\tGenerator loss: 0.885421633720398, Discriminator loss: 1.271230936050415\n",
      "\tGenerator loss: 0.8521623611450195, Discriminator loss: 1.2624046802520752\n",
      "\tGenerator loss: 0.8664255142211914, Discriminator loss: 1.2395431995391846\n",
      "\tGenerator loss: 0.9739069938659668, Discriminator loss: 1.2302215099334717\n",
      "\tGenerator loss: 0.9817129969596863, Discriminator loss: 1.2575924396514893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9793589115142822, Discriminator loss: 1.202397346496582\n",
      "\tGenerator loss: 0.9133105278015137, Discriminator loss: 1.2366280555725098\n",
      "\tGenerator loss: 0.8975288271903992, Discriminator loss: 1.2199333906173706\n",
      "\tGenerator loss: 0.9139984846115112, Discriminator loss: 1.179521083831787\n",
      "\tGenerator loss: 0.9339735507965088, Discriminator loss: 1.1546345949172974\n",
      "\tGenerator loss: 0.9747002124786377, Discriminator loss: 1.1805567741394043\n",
      "\tGenerator loss: 1.0758428573608398, Discriminator loss: 1.1979451179504395\n",
      "\tGenerator loss: 1.0693907737731934, Discriminator loss: 1.2083923816680908\n",
      "Time for epoch 43 is 174.65948510169983 sec\n",
      "\tGenerator loss: 1.0058186054229736, Discriminator loss: 1.2104711532592773\n",
      "\tGenerator loss: 0.9263691902160645, Discriminator loss: 1.2233772277832031\n",
      "\tGenerator loss: 0.8322502374649048, Discriminator loss: 1.2410250902175903\n",
      "\tGenerator loss: 0.8164756298065186, Discriminator loss: 1.2266874313354492\n",
      "\tGenerator loss: 0.8764133453369141, Discriminator loss: 1.2740588188171387\n",
      "\tGenerator loss: 0.9265848398208618, Discriminator loss: 1.2539703845977783\n",
      "\tGenerator loss: 0.9978757500648499, Discriminator loss: 1.298139214515686\n",
      "\tGenerator loss: 0.9955953359603882, Discriminator loss: 1.310737133026123\n",
      "\tGenerator loss: 0.9285249710083008, Discriminator loss: 1.3005375862121582\n",
      "\tGenerator loss: 0.8498623371124268, Discriminator loss: 1.2638888359069824\n",
      "\tGenerator loss: 0.8262600302696228, Discriminator loss: 1.3115060329437256\n",
      "\tGenerator loss: 0.828392744064331, Discriminator loss: 1.3138742446899414\n",
      "\tGenerator loss: 0.8953394889831543, Discriminator loss: 1.3077892065048218\n",
      "\tGenerator loss: 0.9089202880859375, Discriminator loss: 1.2893874645233154\n",
      "\tGenerator loss: 0.9257274270057678, Discriminator loss: 1.2964705228805542\n",
      "\tGenerator loss: 0.8872464299201965, Discriminator loss: 1.2933101654052734\n",
      "\tGenerator loss: 0.8472867012023926, Discriminator loss: 1.2864830493927002\n",
      "\tGenerator loss: 0.8207145929336548, Discriminator loss: 1.283677339553833\n",
      "\tGenerator loss: 0.8388842940330505, Discriminator loss: 1.2951092720031738\n",
      "\tGenerator loss: 0.8676473498344421, Discriminator loss: 1.3106797933578491\n",
      "\tGenerator loss: 0.8699010014533997, Discriminator loss: 1.2705469131469727\n",
      "\tGenerator loss: 0.8885171413421631, Discriminator loss: 1.2716460227966309\n",
      "\tGenerator loss: 0.9180622100830078, Discriminator loss: 1.2707805633544922\n",
      "\tGenerator loss: 0.9230542182922363, Discriminator loss: 1.2570395469665527\n",
      "\tGenerator loss: 0.9336596727371216, Discriminator loss: 1.2364548444747925\n",
      "\tGenerator loss: 0.9037259817123413, Discriminator loss: 1.262317180633545\n",
      "\tGenerator loss: 0.882588803768158, Discriminator loss: 1.3030766248703003\n",
      "\tGenerator loss: 0.8614723682403564, Discriminator loss: 1.2723991870880127\n",
      "\tGenerator loss: 0.8326144218444824, Discriminator loss: 1.3068162202835083\n",
      "\tGenerator loss: 0.8037150502204895, Discriminator loss: 1.2965576648712158\n",
      "\tGenerator loss: 0.8100969195365906, Discriminator loss: 1.2674572467803955\n",
      "\tGenerator loss: 0.8347707986831665, Discriminator loss: 1.2807217836380005\n",
      "\tGenerator loss: 0.8790865540504456, Discriminator loss: 1.2582385540008545\n",
      "\tGenerator loss: 0.9295521974563599, Discriminator loss: 1.2916302680969238\n",
      "\tGenerator loss: 0.9753101468086243, Discriminator loss: 1.267433524131775\n",
      "\tGenerator loss: 0.9466218948364258, Discriminator loss: 1.2907660007476807\n",
      "\tGenerator loss: 0.9149917364120483, Discriminator loss: 1.268471598625183\n",
      "\tGenerator loss: 0.8855182528495789, Discriminator loss: 1.2879359722137451\n",
      "\tGenerator loss: 0.8364187479019165, Discriminator loss: 1.2340784072875977\n",
      "\tGenerator loss: 0.8482197523117065, Discriminator loss: 1.2272753715515137\n",
      "\tGenerator loss: 0.9073302149772644, Discriminator loss: 1.2466225624084473\n",
      "\tGenerator loss: 0.9649124145507812, Discriminator loss: 1.207309603691101\n",
      "\tGenerator loss: 1.0176262855529785, Discriminator loss: 1.2262516021728516\n",
      "\tGenerator loss: 1.0426366329193115, Discriminator loss: 1.2350878715515137\n",
      "\tGenerator loss: 1.0031142234802246, Discriminator loss: 1.2166659832000732\n",
      "\tGenerator loss: 0.9316892027854919, Discriminator loss: 1.2072970867156982\n",
      "\tGenerator loss: 0.8771318197250366, Discriminator loss: 1.2234846353530884\n",
      "\tGenerator loss: 0.8652588725090027, Discriminator loss: 1.2189862728118896\n",
      "\tGenerator loss: 0.8813191652297974, Discriminator loss: 1.2387771606445312\n",
      "\tGenerator loss: 0.9365420937538147, Discriminator loss: 1.203998327255249\n",
      "\tGenerator loss: 1.0143903493881226, Discriminator loss: 1.218489646911621\n",
      "\tGenerator loss: 1.0199708938598633, Discriminator loss: 1.2318446636199951\n",
      "\tGenerator loss: 1.0041099786758423, Discriminator loss: 1.2020646333694458\n",
      "\tGenerator loss: 0.9824254512786865, Discriminator loss: 1.1810097694396973\n",
      "\tGenerator loss: 0.9433667063713074, Discriminator loss: 1.191528081893921\n",
      "\tGenerator loss: 0.9099118113517761, Discriminator loss: 1.2386406660079956\n",
      "\tGenerator loss: 0.8919905424118042, Discriminator loss: 1.208894968032837\n",
      "\tGenerator loss: 0.9157206416130066, Discriminator loss: 1.2036323547363281\n",
      "\tGenerator loss: 0.9358482360839844, Discriminator loss: 1.1930568218231201\n",
      "\tGenerator loss: 0.9753702878952026, Discriminator loss: 1.1547808647155762\n",
      "\tGenerator loss: 0.9871580600738525, Discriminator loss: 1.152217984199524\n",
      "\tGenerator loss: 1.0294675827026367, Discriminator loss: 1.106078863143921\n",
      "\tGenerator loss: 1.0037901401519775, Discriminator loss: 1.1827058792114258\n",
      "\tGenerator loss: 0.9364882707595825, Discriminator loss: 1.2186585664749146\n",
      "\tGenerator loss: 0.8756136894226074, Discriminator loss: 1.2232892513275146\n",
      "\tGenerator loss: 0.8673693537712097, Discriminator loss: 1.185179591178894\n",
      "\tGenerator loss: 0.9103642702102661, Discriminator loss: 1.218656063079834\n",
      "\tGenerator loss: 0.9459994435310364, Discriminator loss: 1.2054734230041504\n",
      "\tGenerator loss: 0.966066837310791, Discriminator loss: 1.2091572284698486\n",
      "\tGenerator loss: 0.9671295881271362, Discriminator loss: 1.211660623550415\n",
      "\tGenerator loss: 0.9485961198806763, Discriminator loss: 1.192807674407959\n",
      "\tGenerator loss: 0.9213905334472656, Discriminator loss: 1.2161612510681152\n",
      "\tGenerator loss: 0.8705666065216064, Discriminator loss: 1.2071385383605957\n",
      "\tGenerator loss: 0.8924376964569092, Discriminator loss: 1.1949867010116577\n",
      "\tGenerator loss: 0.9197742342948914, Discriminator loss: 1.1686062812805176\n",
      "\tGenerator loss: 1.0004953145980835, Discriminator loss: 1.245596170425415\n",
      "\tGenerator loss: 0.9926968812942505, Discriminator loss: 1.2962077856063843\n",
      "\tGenerator loss: 0.9609099626541138, Discriminator loss: 1.3181991577148438\n",
      "\tGenerator loss: 0.904028058052063, Discriminator loss: 1.3047001361846924\n",
      "\tGenerator loss: 0.8761574029922485, Discriminator loss: 1.2484490871429443\n",
      "\tGenerator loss: 0.8828818202018738, Discriminator loss: 1.2440805435180664\n",
      "\tGenerator loss: 0.9077941179275513, Discriminator loss: 1.2352972030639648\n",
      "\tGenerator loss: 0.9573929905891418, Discriminator loss: 1.2288117408752441\n",
      "\tGenerator loss: 1.0068849325180054, Discriminator loss: 1.2633848190307617\n",
      "\tGenerator loss: 0.9942138195037842, Discriminator loss: 1.2119687795639038\n",
      "\tGenerator loss: 0.9389641880989075, Discriminator loss: 1.2553586959838867\n",
      "\tGenerator loss: 0.8989900946617126, Discriminator loss: 1.2399896383285522\n",
      "\tGenerator loss: 0.8937680721282959, Discriminator loss: 1.2444283962249756\n",
      "\tGenerator loss: 0.9437673091888428, Discriminator loss: 1.2530193328857422\n",
      "\tGenerator loss: 0.9680318236351013, Discriminator loss: 1.2676029205322266\n",
      "\tGenerator loss: 0.962481677532196, Discriminator loss: 1.2702462673187256\n",
      "\tGenerator loss: 0.9657349586486816, Discriminator loss: 1.260326623916626\n",
      "\tGenerator loss: 0.9077329635620117, Discriminator loss: 1.2469433546066284\n",
      "\tGenerator loss: 0.9046727418899536, Discriminator loss: 1.2488763332366943\n",
      "\tGenerator loss: 0.885292649269104, Discriminator loss: 1.2795889377593994\n",
      "\tGenerator loss: 0.8925121426582336, Discriminator loss: 1.25111722946167\n",
      "\tGenerator loss: 0.8900254964828491, Discriminator loss: 1.2544074058532715\n",
      "\tGenerator loss: 0.9011648893356323, Discriminator loss: 1.2787678241729736\n",
      "\tGenerator loss: 0.9131986498832703, Discriminator loss: 1.2557953596115112\n",
      "\tGenerator loss: 0.905228853225708, Discriminator loss: 1.2918813228607178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9101662635803223, Discriminator loss: 1.2936646938323975\n",
      "\tGenerator loss: 0.8707422614097595, Discriminator loss: 1.316774606704712\n",
      "\tGenerator loss: 0.8632161021232605, Discriminator loss: 1.2974673509597778\n",
      "\tGenerator loss: 0.850068211555481, Discriminator loss: 1.3627939224243164\n",
      "\tGenerator loss: 0.8156657814979553, Discriminator loss: 1.3346002101898193\n",
      "\tGenerator loss: 0.8221728801727295, Discriminator loss: 1.316563606262207\n",
      "\tGenerator loss: 0.8361012935638428, Discriminator loss: 1.3337959051132202\n",
      "\tGenerator loss: 0.8724374771118164, Discriminator loss: 1.3078891038894653\n",
      "\tGenerator loss: 0.8922224640846252, Discriminator loss: 1.2960669994354248\n",
      "\tGenerator loss: 0.888355016708374, Discriminator loss: 1.2878293991088867\n",
      "\tGenerator loss: 0.8705593347549438, Discriminator loss: 1.3202217817306519\n",
      "\tGenerator loss: 0.8809861540794373, Discriminator loss: 1.2764170169830322\n",
      "\tGenerator loss: 0.8545352220535278, Discriminator loss: 1.2928388118743896\n",
      "\tGenerator loss: 0.8550031185150146, Discriminator loss: 1.3148068189620972\n",
      "\tGenerator loss: 0.8562290668487549, Discriminator loss: 1.349677562713623\n",
      "\tGenerator loss: 0.8527545928955078, Discriminator loss: 1.315358281135559\n",
      "\tGenerator loss: 0.8576513528823853, Discriminator loss: 1.3129942417144775\n",
      "\tGenerator loss: 0.8453465104103088, Discriminator loss: 1.3376855850219727\n",
      "\tGenerator loss: 0.8311610221862793, Discriminator loss: 1.2785744667053223\n",
      "\tGenerator loss: 0.8440327644348145, Discriminator loss: 1.2951059341430664\n",
      "\tGenerator loss: 0.8253160715103149, Discriminator loss: 1.2923827171325684\n",
      "\tGenerator loss: 0.8502684831619263, Discriminator loss: 1.2778841257095337\n",
      "\tGenerator loss: 0.8323103785514832, Discriminator loss: 1.2707858085632324\n",
      "\tGenerator loss: 0.8630944490432739, Discriminator loss: 1.2565274238586426\n",
      "\tGenerator loss: 0.8646528124809265, Discriminator loss: 1.2384692430496216\n",
      "\tGenerator loss: 0.9169724583625793, Discriminator loss: 1.2349739074707031\n",
      "\tGenerator loss: 0.944808840751648, Discriminator loss: 1.2709054946899414\n",
      "\tGenerator loss: 0.9043480157852173, Discriminator loss: 1.2763619422912598\n",
      "\tGenerator loss: 0.8941149711608887, Discriminator loss: 1.2419395446777344\n",
      "\tGenerator loss: 0.8929277658462524, Discriminator loss: 1.270843744277954\n",
      "\tGenerator loss: 0.89666748046875, Discriminator loss: 1.216024398803711\n",
      "\tGenerator loss: 0.9278398752212524, Discriminator loss: 1.2141884565353394\n",
      "\tGenerator loss: 0.8950499296188354, Discriminator loss: 1.2545294761657715\n",
      "\tGenerator loss: 0.9091702699661255, Discriminator loss: 1.219962239265442\n",
      "\tGenerator loss: 0.9193516969680786, Discriminator loss: 1.2050766944885254\n",
      "\tGenerator loss: 0.9255743026733398, Discriminator loss: 1.2677156925201416\n",
      "\tGenerator loss: 0.9296844601631165, Discriminator loss: 1.2608232498168945\n",
      "\tGenerator loss: 0.8941813707351685, Discriminator loss: 1.230737566947937\n",
      "\tGenerator loss: 0.9130030870437622, Discriminator loss: 1.2266395092010498\n",
      "\tGenerator loss: 0.9195151329040527, Discriminator loss: 1.207033395767212\n",
      "\tGenerator loss: 0.9623283743858337, Discriminator loss: 1.1618483066558838\n",
      "\tGenerator loss: 0.9612487554550171, Discriminator loss: 1.2364325523376465\n",
      "\tGenerator loss: 0.9619800448417664, Discriminator loss: 1.2322509288787842\n",
      "\tGenerator loss: 0.9381580352783203, Discriminator loss: 1.2904551029205322\n",
      "\tGenerator loss: 0.9189666509628296, Discriminator loss: 1.2794313430786133\n",
      "\tGenerator loss: 0.9175536632537842, Discriminator loss: 1.2723013162612915\n",
      "\tGenerator loss: 0.9370170831680298, Discriminator loss: 1.2238950729370117\n",
      "\tGenerator loss: 0.9284415245056152, Discriminator loss: 1.21427321434021\n",
      "\tGenerator loss: 0.9372014999389648, Discriminator loss: 1.198053002357483\n",
      "\tGenerator loss: 0.9494601488113403, Discriminator loss: 1.1942682266235352\n",
      "\tGenerator loss: 0.9552881121635437, Discriminator loss: 1.1980246305465698\n",
      "\tGenerator loss: 0.9529072046279907, Discriminator loss: 1.1997008323669434\n",
      "\tGenerator loss: 0.9543890357017517, Discriminator loss: 1.196418046951294\n",
      "\tGenerator loss: 0.9448215961456299, Discriminator loss: 1.19480562210083\n",
      "\tGenerator loss: 0.915359377861023, Discriminator loss: 1.2253354787826538\n",
      "\tGenerator loss: 0.9132375717163086, Discriminator loss: 1.2125747203826904\n",
      "\tGenerator loss: 0.9143614172935486, Discriminator loss: 1.2271766662597656\n",
      "\tGenerator loss: 0.9286898374557495, Discriminator loss: 1.1852679252624512\n",
      "\tGenerator loss: 0.9283157587051392, Discriminator loss: 1.2048097848892212\n",
      "\tGenerator loss: 0.9551711082458496, Discriminator loss: 1.15647292137146\n",
      "\tGenerator loss: 0.966522216796875, Discriminator loss: 1.1756738424301147\n",
      "\tGenerator loss: 0.9618881344795227, Discriminator loss: 1.179047703742981\n",
      "\tGenerator loss: 0.9680989980697632, Discriminator loss: 1.215439796447754\n",
      "\tGenerator loss: 0.9543049931526184, Discriminator loss: 1.2116526365280151\n",
      "\tGenerator loss: 0.9409453868865967, Discriminator loss: 1.2157294750213623\n",
      "\tGenerator loss: 0.9366607666015625, Discriminator loss: 1.1938985586166382\n",
      "\tGenerator loss: 0.9084814786911011, Discriminator loss: 1.2288808822631836\n",
      "\tGenerator loss: 0.921786367893219, Discriminator loss: 1.1954559087753296\n",
      "\tGenerator loss: 0.9539930820465088, Discriminator loss: 1.2020940780639648\n",
      "\tGenerator loss: 0.9651673436164856, Discriminator loss: 1.1943591833114624\n",
      "\tGenerator loss: 0.9478046894073486, Discriminator loss: 1.2161681652069092\n",
      "\tGenerator loss: 0.9551389217376709, Discriminator loss: 1.2042547464370728\n",
      "\tGenerator loss: 0.9475365877151489, Discriminator loss: 1.1735053062438965\n",
      "\tGenerator loss: 0.9493884444236755, Discriminator loss: 1.1840307712554932\n",
      "\tGenerator loss: 0.9152054786682129, Discriminator loss: 1.2078688144683838\n",
      "\tGenerator loss: 0.9212379455566406, Discriminator loss: 1.2196452617645264\n",
      "\tGenerator loss: 0.8834128975868225, Discriminator loss: 1.2393550872802734\n",
      "\tGenerator loss: 0.9190821051597595, Discriminator loss: 1.2203187942504883\n",
      "\tGenerator loss: 0.9407652616500854, Discriminator loss: 1.2464051246643066\n",
      "\tGenerator loss: 0.8955442905426025, Discriminator loss: 1.309837818145752\n",
      "\tGenerator loss: 0.8493629693984985, Discriminator loss: 1.2744237184524536\n",
      "\tGenerator loss: 0.8258998394012451, Discriminator loss: 1.2627193927764893\n",
      "\tGenerator loss: 0.8374617099761963, Discriminator loss: 1.2600293159484863\n",
      "\tGenerator loss: 0.8967354893684387, Discriminator loss: 1.2349286079406738\n",
      "\tGenerator loss: 0.9681563377380371, Discriminator loss: 1.2917002439498901\n",
      "\tGenerator loss: 0.9721779823303223, Discriminator loss: 1.2573349475860596\n",
      "\tGenerator loss: 0.9813477396965027, Discriminator loss: 1.230902075767517\n",
      "\tGenerator loss: 0.925599217414856, Discriminator loss: 1.2516257762908936\n",
      "\tGenerator loss: 0.8821763396263123, Discriminator loss: 1.2533259391784668\n",
      "\tGenerator loss: 0.8538128137588501, Discriminator loss: 1.2741892337799072\n",
      "\tGenerator loss: 0.8601411581039429, Discriminator loss: 1.2983638048171997\n",
      "\tGenerator loss: 0.8969143629074097, Discriminator loss: 1.3160860538482666\n",
      "\tGenerator loss: 0.9188393354415894, Discriminator loss: 1.2817708253860474\n",
      "\tGenerator loss: 0.9097392559051514, Discriminator loss: 1.234161615371704\n",
      "\tGenerator loss: 0.8824054598808289, Discriminator loss: 1.2505974769592285\n",
      "\tGenerator loss: 0.8771618604660034, Discriminator loss: 1.2755242586135864\n",
      "\tGenerator loss: 0.8418803811073303, Discriminator loss: 1.2844552993774414\n",
      "\tGenerator loss: 0.8220053911209106, Discriminator loss: 1.328037977218628\n",
      "\tGenerator loss: 0.8255778551101685, Discriminator loss: 1.3288054466247559\n",
      "\tGenerator loss: 0.808991014957428, Discriminator loss: 1.3086256980895996\n",
      "\tGenerator loss: 0.8381810188293457, Discriminator loss: 1.2775787115097046\n",
      "\tGenerator loss: 0.8796465396881104, Discriminator loss: 1.2856297492980957\n",
      "\tGenerator loss: 0.9447015523910522, Discriminator loss: 1.3173431158065796\n",
      "\tGenerator loss: 0.9416208267211914, Discriminator loss: 1.3082141876220703\n",
      "\tGenerator loss: 0.8923583030700684, Discriminator loss: 1.2780019044876099\n",
      "\tGenerator loss: 0.8061919212341309, Discriminator loss: 1.2728867530822754\n",
      "\tGenerator loss: 0.7665901184082031, Discriminator loss: 1.303410530090332\n",
      "\tGenerator loss: 0.7829858660697937, Discriminator loss: 1.315126895904541\n",
      "\tGenerator loss: 0.8691033124923706, Discriminator loss: 1.299680233001709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9500125646591187, Discriminator loss: 1.2794029712677002\n",
      "\tGenerator loss: 0.9616252183914185, Discriminator loss: 1.2709589004516602\n",
      "\tGenerator loss: 0.907993733882904, Discriminator loss: 1.2915899753570557\n",
      "\tGenerator loss: 0.892410397529602, Discriminator loss: 1.336771011352539\n",
      "\tGenerator loss: 0.8387030363082886, Discriminator loss: 1.360223412513733\n",
      "\tGenerator loss: 0.7793678045272827, Discriminator loss: 1.324671983718872\n",
      "\tGenerator loss: 0.7947810888290405, Discriminator loss: 1.3159854412078857\n",
      "\tGenerator loss: 0.8224108219146729, Discriminator loss: 1.3269442319869995\n",
      "\tGenerator loss: 0.8802784085273743, Discriminator loss: 1.3599154949188232\n",
      "\tGenerator loss: 0.9102709293365479, Discriminator loss: 1.3564658164978027\n",
      "\tGenerator loss: 0.9263930320739746, Discriminator loss: 1.347030520439148\n",
      "\tGenerator loss: 0.8971197605133057, Discriminator loss: 1.3533645868301392\n",
      "\tGenerator loss: 0.8528673052787781, Discriminator loss: 1.352672815322876\n",
      "\tGenerator loss: 0.7852638959884644, Discriminator loss: 1.3467662334442139\n",
      "\tGenerator loss: 0.7858298420906067, Discriminator loss: 1.3237254619598389\n",
      "\tGenerator loss: 0.7989407777786255, Discriminator loss: 1.2994401454925537\n",
      "\tGenerator loss: 0.8654983043670654, Discriminator loss: 1.2600679397583008\n",
      "\tGenerator loss: 0.8950021862983704, Discriminator loss: 1.3082542419433594\n",
      "\tGenerator loss: 0.9290651082992554, Discriminator loss: 1.258234977722168\n",
      "\tGenerator loss: 0.9250878095626831, Discriminator loss: 1.286237359046936\n",
      "\tGenerator loss: 0.8992385864257812, Discriminator loss: 1.2435498237609863\n",
      "\tGenerator loss: 0.844228982925415, Discriminator loss: 1.202067255973816\n",
      "\tGenerator loss: 0.852721095085144, Discriminator loss: 1.249845027923584\n",
      "\tGenerator loss: 0.8879919648170471, Discriminator loss: 1.284822940826416\n",
      "\tGenerator loss: 0.9529497623443604, Discriminator loss: 1.2894713878631592\n",
      "\tGenerator loss: 1.0026168823242188, Discriminator loss: 1.2358293533325195\n",
      "Time for epoch 44 is 184.46268725395203 sec\n",
      "\tGenerator loss: 0.9604556560516357, Discriminator loss: 1.253872275352478\n",
      "\tGenerator loss: 0.8838217854499817, Discriminator loss: 1.2616565227508545\n",
      "\tGenerator loss: 0.8471348285675049, Discriminator loss: 1.2461198568344116\n",
      "\tGenerator loss: 0.8385360240936279, Discriminator loss: 1.232131004333496\n",
      "\tGenerator loss: 0.8688617944717407, Discriminator loss: 1.2663192749023438\n",
      "\tGenerator loss: 0.9496359825134277, Discriminator loss: 1.2413893938064575\n",
      "\tGenerator loss: 0.9936589002609253, Discriminator loss: 1.2289173603057861\n",
      "\tGenerator loss: 0.9979386329650879, Discriminator loss: 1.2558618783950806\n",
      "\tGenerator loss: 0.9504927396774292, Discriminator loss: 1.2571585178375244\n",
      "\tGenerator loss: 0.8820778131484985, Discriminator loss: 1.217437505722046\n",
      "\tGenerator loss: 0.859589695930481, Discriminator loss: 1.2079713344573975\n",
      "\tGenerator loss: 0.8709144592285156, Discriminator loss: 1.1984323263168335\n",
      "\tGenerator loss: 0.9097952842712402, Discriminator loss: 1.1991536617279053\n",
      "\tGenerator loss: 0.9476377964019775, Discriminator loss: 1.190830111503601\n",
      "\tGenerator loss: 0.9788764715194702, Discriminator loss: 1.2194054126739502\n",
      "\tGenerator loss: 0.9624724388122559, Discriminator loss: 1.190782070159912\n",
      "\tGenerator loss: 0.9323689937591553, Discriminator loss: 1.1801023483276367\n",
      "\tGenerator loss: 0.8857171535491943, Discriminator loss: 1.1828726530075073\n",
      "\tGenerator loss: 0.8937150239944458, Discriminator loss: 1.2157013416290283\n",
      "\tGenerator loss: 0.9176457524299622, Discriminator loss: 1.2045621871948242\n",
      "\tGenerator loss: 0.9549710750579834, Discriminator loss: 1.1797099113464355\n",
      "\tGenerator loss: 0.9848452806472778, Discriminator loss: 1.154830813407898\n",
      "\tGenerator loss: 1.011237382888794, Discriminator loss: 1.1662464141845703\n",
      "\tGenerator loss: 0.9851434230804443, Discriminator loss: 1.1731802225112915\n",
      "\tGenerator loss: 0.9643017053604126, Discriminator loss: 1.158902645111084\n",
      "\tGenerator loss: 0.9550751447677612, Discriminator loss: 1.135252594947815\n",
      "\tGenerator loss: 0.9701322317123413, Discriminator loss: 1.1748712062835693\n",
      "\tGenerator loss: 0.9284690022468567, Discriminator loss: 1.150475263595581\n",
      "\tGenerator loss: 0.9031079411506653, Discriminator loss: 1.2010247707366943\n",
      "\tGenerator loss: 0.8611555099487305, Discriminator loss: 1.202803373336792\n",
      "\tGenerator loss: 0.8931666612625122, Discriminator loss: 1.172874927520752\n",
      "\tGenerator loss: 0.9224278926849365, Discriminator loss: 1.1515345573425293\n",
      "\tGenerator loss: 0.9720306396484375, Discriminator loss: 1.1211332082748413\n",
      "\tGenerator loss: 0.9770491719245911, Discriminator loss: 1.1540706157684326\n",
      "\tGenerator loss: 1.0010724067687988, Discriminator loss: 1.139575481414795\n",
      "\tGenerator loss: 1.0153168439865112, Discriminator loss: 1.1646827459335327\n",
      "\tGenerator loss: 0.9715262055397034, Discriminator loss: 1.166985273361206\n",
      "\tGenerator loss: 0.9253076314926147, Discriminator loss: 1.1901495456695557\n",
      "\tGenerator loss: 0.8800415992736816, Discriminator loss: 1.141160011291504\n",
      "\tGenerator loss: 0.8540987968444824, Discriminator loss: 1.14644193649292\n",
      "\tGenerator loss: 0.8886050581932068, Discriminator loss: 1.121940016746521\n",
      "\tGenerator loss: 0.9774943590164185, Discriminator loss: 1.1245770454406738\n",
      "\tGenerator loss: 1.0794130563735962, Discriminator loss: 1.1435024738311768\n",
      "\tGenerator loss: 1.1181328296661377, Discriminator loss: 1.161194920539856\n",
      "\tGenerator loss: 1.066888689994812, Discriminator loss: 1.1376936435699463\n",
      "\tGenerator loss: 0.9703271389007568, Discriminator loss: 1.140630841255188\n",
      "\tGenerator loss: 0.8659679889678955, Discriminator loss: 1.1830534934997559\n",
      "\tGenerator loss: 0.8729252815246582, Discriminator loss: 1.144726276397705\n",
      "\tGenerator loss: 0.8866744041442871, Discriminator loss: 1.1494725942611694\n",
      "\tGenerator loss: 0.9606227874755859, Discriminator loss: 1.153350591659546\n",
      "\tGenerator loss: 1.0146654844284058, Discriminator loss: 1.166590690612793\n",
      "\tGenerator loss: 1.034386157989502, Discriminator loss: 1.1763238906860352\n",
      "\tGenerator loss: 1.0314613580703735, Discriminator loss: 1.1451034545898438\n",
      "\tGenerator loss: 1.0024969577789307, Discriminator loss: 1.1824028491973877\n",
      "\tGenerator loss: 0.9622552394866943, Discriminator loss: 1.180918574333191\n",
      "\tGenerator loss: 0.9060544371604919, Discriminator loss: 1.2500157356262207\n",
      "\tGenerator loss: 0.8645336627960205, Discriminator loss: 1.2263433933258057\n",
      "\tGenerator loss: 0.8727763295173645, Discriminator loss: 1.220333218574524\n",
      "\tGenerator loss: 0.8997205495834351, Discriminator loss: 1.2040741443634033\n",
      "\tGenerator loss: 0.9421910047531128, Discriminator loss: 1.1597579717636108\n",
      "\tGenerator loss: 0.9951723217964172, Discriminator loss: 1.1538186073303223\n",
      "\tGenerator loss: 1.0030542612075806, Discriminator loss: 1.1614058017730713\n",
      "\tGenerator loss: 0.9607851505279541, Discriminator loss: 1.216822624206543\n",
      "\tGenerator loss: 0.9193429946899414, Discriminator loss: 1.2274339199066162\n",
      "\tGenerator loss: 0.8572059869766235, Discriminator loss: 1.2355269193649292\n",
      "\tGenerator loss: 0.8564587831497192, Discriminator loss: 1.2144982814788818\n",
      "\tGenerator loss: 0.8778372406959534, Discriminator loss: 1.2365779876708984\n",
      "\tGenerator loss: 0.9299842119216919, Discriminator loss: 1.251866340637207\n",
      "\tGenerator loss: 0.9682498574256897, Discriminator loss: 1.2593908309936523\n",
      "\tGenerator loss: 0.9566617012023926, Discriminator loss: 1.2716587781906128\n",
      "\tGenerator loss: 0.9008764028549194, Discriminator loss: 1.3045958280563354\n",
      "\tGenerator loss: 0.8779054284095764, Discriminator loss: 1.3098564147949219\n",
      "\tGenerator loss: 0.8537619113922119, Discriminator loss: 1.30562162399292\n",
      "\tGenerator loss: 0.8216626048088074, Discriminator loss: 1.2926623821258545\n",
      "\tGenerator loss: 0.8487098217010498, Discriminator loss: 1.2676260471343994\n",
      "\tGenerator loss: 0.9173386693000793, Discriminator loss: 1.348437786102295\n",
      "\tGenerator loss: 0.9453251361846924, Discriminator loss: 1.436775803565979\n",
      "\tGenerator loss: 0.9505536556243896, Discriminator loss: 1.4180388450622559\n",
      "\tGenerator loss: 0.9448109865188599, Discriminator loss: 1.3861217498779297\n",
      "\tGenerator loss: 0.8601009249687195, Discriminator loss: 1.3703773021697998\n",
      "\tGenerator loss: 0.8148820400238037, Discriminator loss: 1.406191110610962\n",
      "\tGenerator loss: 0.8083252906799316, Discriminator loss: 1.386948585510254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8543608784675598, Discriminator loss: 1.3492189645767212\n",
      "\tGenerator loss: 0.8967615962028503, Discriminator loss: 1.3683838844299316\n",
      "\tGenerator loss: 0.9051226377487183, Discriminator loss: 1.3103604316711426\n",
      "\tGenerator loss: 0.9229503870010376, Discriminator loss: 1.3581643104553223\n",
      "\tGenerator loss: 0.9193810224533081, Discriminator loss: 1.3176839351654053\n",
      "\tGenerator loss: 0.8982644081115723, Discriminator loss: 1.358635425567627\n",
      "\tGenerator loss: 0.8723734617233276, Discriminator loss: 1.3983299732208252\n",
      "\tGenerator loss: 0.8506113290786743, Discriminator loss: 1.4193463325500488\n",
      "\tGenerator loss: 0.838407576084137, Discriminator loss: 1.4128773212432861\n",
      "\tGenerator loss: 0.8491524457931519, Discriminator loss: 1.383115291595459\n",
      "\tGenerator loss: 0.8651706576347351, Discriminator loss: 1.332030177116394\n",
      "\tGenerator loss: 0.8716781139373779, Discriminator loss: 1.3264572620391846\n",
      "\tGenerator loss: 0.901374101638794, Discriminator loss: 1.3337876796722412\n",
      "\tGenerator loss: 0.8938594460487366, Discriminator loss: 1.340888261795044\n",
      "\tGenerator loss: 0.8809584379196167, Discriminator loss: 1.3389335870742798\n",
      "\tGenerator loss: 0.8694454431533813, Discriminator loss: 1.3613977432250977\n",
      "\tGenerator loss: 0.8666561245918274, Discriminator loss: 1.3006740808486938\n",
      "\tGenerator loss: 0.876767635345459, Discriminator loss: 1.2717748880386353\n",
      "\tGenerator loss: 0.8617496490478516, Discriminator loss: 1.333522081375122\n",
      "\tGenerator loss: 0.9099619388580322, Discriminator loss: 1.324632167816162\n",
      "\tGenerator loss: 0.903834879398346, Discriminator loss: 1.3279911279678345\n",
      "\tGenerator loss: 0.8756986856460571, Discriminator loss: 1.3657976388931274\n",
      "\tGenerator loss: 0.815321683883667, Discriminator loss: 1.3377676010131836\n",
      "\tGenerator loss: 0.7974395751953125, Discriminator loss: 1.314531922340393\n",
      "\tGenerator loss: 0.8139232993125916, Discriminator loss: 1.341271162033081\n",
      "\tGenerator loss: 0.8332302570343018, Discriminator loss: 1.3355817794799805\n",
      "\tGenerator loss: 0.9066311120986938, Discriminator loss: 1.328739047050476\n",
      "\tGenerator loss: 0.8964267373085022, Discriminator loss: 1.308607816696167\n",
      "\tGenerator loss: 0.886860728263855, Discriminator loss: 1.292109727859497\n",
      "\tGenerator loss: 0.8874653577804565, Discriminator loss: 1.258216142654419\n",
      "\tGenerator loss: 0.8683463335037231, Discriminator loss: 1.2700634002685547\n",
      "\tGenerator loss: 0.8548530340194702, Discriminator loss: 1.3544385433197021\n",
      "\tGenerator loss: 0.8313441276550293, Discriminator loss: 1.3390278816223145\n",
      "\tGenerator loss: 0.8307057619094849, Discriminator loss: 1.3214892148971558\n",
      "\tGenerator loss: 0.8261566162109375, Discriminator loss: 1.34266996383667\n",
      "\tGenerator loss: 0.7997573614120483, Discriminator loss: 1.3834854364395142\n",
      "\tGenerator loss: 0.775278627872467, Discriminator loss: 1.3261878490447998\n",
      "\tGenerator loss: 0.7685138583183289, Discriminator loss: 1.3466072082519531\n",
      "\tGenerator loss: 0.7759659290313721, Discriminator loss: 1.324129581451416\n",
      "\tGenerator loss: 0.8097936511039734, Discriminator loss: 1.2949012517929077\n",
      "\tGenerator loss: 0.8459210395812988, Discriminator loss: 1.2722007036209106\n",
      "\tGenerator loss: 0.8575858473777771, Discriminator loss: 1.2729086875915527\n",
      "\tGenerator loss: 0.8361163139343262, Discriminator loss: 1.2344257831573486\n",
      "\tGenerator loss: 0.8281170129776001, Discriminator loss: 1.2409818172454834\n",
      "\tGenerator loss: 0.8596194982528687, Discriminator loss: 1.2110651731491089\n",
      "\tGenerator loss: 0.8819890022277832, Discriminator loss: 1.1978657245635986\n",
      "\tGenerator loss: 0.8884952664375305, Discriminator loss: 1.1849571466445923\n",
      "\tGenerator loss: 0.9220564365386963, Discriminator loss: 1.202965259552002\n",
      "\tGenerator loss: 0.9246039390563965, Discriminator loss: 1.1650922298431396\n",
      "\tGenerator loss: 0.9324694871902466, Discriminator loss: 1.1435385942459106\n",
      "\tGenerator loss: 0.9291988015174866, Discriminator loss: 1.1321561336517334\n",
      "\tGenerator loss: 0.9773991107940674, Discriminator loss: 1.0919522047042847\n",
      "\tGenerator loss: 0.969641923904419, Discriminator loss: 1.1114678382873535\n",
      "\tGenerator loss: 0.984300971031189, Discriminator loss: 1.1228530406951904\n",
      "\tGenerator loss: 0.9897029399871826, Discriminator loss: 1.0940055847167969\n",
      "\tGenerator loss: 0.9940502047538757, Discriminator loss: 1.0411877632141113\n",
      "\tGenerator loss: 0.9985955953598022, Discriminator loss: 1.0885019302368164\n",
      "\tGenerator loss: 1.036600947380066, Discriminator loss: 1.068095326423645\n",
      "\tGenerator loss: 1.0567431449890137, Discriminator loss: 1.0086147785186768\n",
      "\tGenerator loss: 1.074660301208496, Discriminator loss: 1.1285438537597656\n",
      "\tGenerator loss: 1.106823205947876, Discriminator loss: 1.1121420860290527\n",
      "\tGenerator loss: 1.1026554107666016, Discriminator loss: 1.195468544960022\n",
      "\tGenerator loss: 1.0848701000213623, Discriminator loss: 1.1927909851074219\n",
      "\tGenerator loss: 1.0244826078414917, Discriminator loss: 1.2182714939117432\n",
      "\tGenerator loss: 0.9867826104164124, Discriminator loss: 1.1352580785751343\n",
      "\tGenerator loss: 0.9868748188018799, Discriminator loss: 1.1287028789520264\n",
      "\tGenerator loss: 1.035883903503418, Discriminator loss: 1.1116654872894287\n",
      "\tGenerator loss: 1.074023962020874, Discriminator loss: 1.126081943511963\n",
      "\tGenerator loss: 1.1213163137435913, Discriminator loss: 1.1429173946380615\n",
      "\tGenerator loss: 1.1460098028182983, Discriminator loss: 1.128749132156372\n",
      "\tGenerator loss: 1.0770187377929688, Discriminator loss: 1.169003963470459\n",
      "\tGenerator loss: 1.0276196002960205, Discriminator loss: 1.2258819341659546\n",
      "\tGenerator loss: 0.9563669562339783, Discriminator loss: 1.2798042297363281\n",
      "\tGenerator loss: 0.9166001081466675, Discriminator loss: 1.2022857666015625\n",
      "\tGenerator loss: 0.9313974380493164, Discriminator loss: 1.2200640439987183\n",
      "\tGenerator loss: 0.9910579919815063, Discriminator loss: 1.1817774772644043\n",
      "\tGenerator loss: 1.0496406555175781, Discriminator loss: 1.2140644788742065\n",
      "\tGenerator loss: 1.067495346069336, Discriminator loss: 1.1868782043457031\n",
      "\tGenerator loss: 1.0833576917648315, Discriminator loss: 1.1613340377807617\n",
      "\tGenerator loss: 1.0500373840332031, Discriminator loss: 1.1393054723739624\n",
      "\tGenerator loss: 1.0028332471847534, Discriminator loss: 1.1561617851257324\n",
      "\tGenerator loss: 1.0051360130310059, Discriminator loss: 1.175769329071045\n",
      "\tGenerator loss: 0.9919614791870117, Discriminator loss: 1.1881496906280518\n",
      "\tGenerator loss: 0.9604018330574036, Discriminator loss: 1.1812561750411987\n",
      "\tGenerator loss: 0.9783874154090881, Discriminator loss: 1.2372477054595947\n",
      "\tGenerator loss: 1.0164121389389038, Discriminator loss: 1.2252323627471924\n",
      "\tGenerator loss: 1.0318303108215332, Discriminator loss: 1.213471531867981\n",
      "\tGenerator loss: 1.023597240447998, Discriminator loss: 1.2015984058380127\n",
      "\tGenerator loss: 0.985973060131073, Discriminator loss: 1.1945152282714844\n",
      "\tGenerator loss: 0.9954938888549805, Discriminator loss: 1.174480676651001\n",
      "\tGenerator loss: 0.9832126498222351, Discriminator loss: 1.1396634578704834\n",
      "\tGenerator loss: 0.9773703813552856, Discriminator loss: 1.1604681015014648\n",
      "\tGenerator loss: 0.9994748830795288, Discriminator loss: 1.213478446006775\n",
      "\tGenerator loss: 1.0106865167617798, Discriminator loss: 1.2371689081192017\n",
      "\tGenerator loss: 0.9976572394371033, Discriminator loss: 1.2218503952026367\n",
      "\tGenerator loss: 0.9496594071388245, Discriminator loss: 1.222449779510498\n",
      "\tGenerator loss: 0.9144915342330933, Discriminator loss: 1.2666224241256714\n",
      "\tGenerator loss: 0.8991788625717163, Discriminator loss: 1.3492889404296875\n",
      "\tGenerator loss: 0.8695788383483887, Discriminator loss: 1.316989541053772\n",
      "\tGenerator loss: 0.8507878184318542, Discriminator loss: 1.310016393661499\n",
      "\tGenerator loss: 0.8793401718139648, Discriminator loss: 1.278235673904419\n",
      "\tGenerator loss: 0.9265339374542236, Discriminator loss: 1.2584233283996582\n",
      "\tGenerator loss: 0.9447290897369385, Discriminator loss: 1.387635588645935\n",
      "\tGenerator loss: 0.9627729654312134, Discriminator loss: 1.3103735446929932\n",
      "\tGenerator loss: 0.9352397918701172, Discriminator loss: 1.2707712650299072\n",
      "\tGenerator loss: 0.8830972909927368, Discriminator loss: 1.312547206878662\n",
      "\tGenerator loss: 0.8741639256477356, Discriminator loss: 1.2904903888702393\n",
      "\tGenerator loss: 0.9068304300308228, Discriminator loss: 1.2847771644592285\n",
      "\tGenerator loss: 0.9462652206420898, Discriminator loss: 1.3190886974334717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.939057469367981, Discriminator loss: 1.4264962673187256\n",
      "\tGenerator loss: 0.879056453704834, Discriminator loss: 1.418961763381958\n",
      "\tGenerator loss: 0.7797203660011292, Discriminator loss: 1.4205942153930664\n",
      "\tGenerator loss: 0.729648768901825, Discriminator loss: 1.4432380199432373\n",
      "\tGenerator loss: 0.7040252685546875, Discriminator loss: 1.4431917667388916\n",
      "\tGenerator loss: 0.7430390119552612, Discriminator loss: 1.473400592803955\n",
      "\tGenerator loss: 0.7598468065261841, Discriminator loss: 1.5100600719451904\n",
      "\tGenerator loss: 0.7668043375015259, Discriminator loss: 1.4814093112945557\n",
      "\tGenerator loss: 0.8057603240013123, Discriminator loss: 1.3950895071029663\n",
      "\tGenerator loss: 0.812105655670166, Discriminator loss: 1.3541083335876465\n",
      "\tGenerator loss: 0.8133010864257812, Discriminator loss: 1.38166344165802\n",
      "\tGenerator loss: 0.8397439122200012, Discriminator loss: 1.3903021812438965\n",
      "\tGenerator loss: 0.7857304811477661, Discriminator loss: 1.4155347347259521\n",
      "\tGenerator loss: 0.7457799911499023, Discriminator loss: 1.3999550342559814\n",
      "\tGenerator loss: 0.7317975759506226, Discriminator loss: 1.348581314086914\n",
      "\tGenerator loss: 0.7424243092536926, Discriminator loss: 1.328242540359497\n",
      "\tGenerator loss: 0.8072804808616638, Discriminator loss: 1.3027992248535156\n",
      "\tGenerator loss: 0.862602710723877, Discriminator loss: 1.3173670768737793\n",
      "\tGenerator loss: 0.9130771160125732, Discriminator loss: 1.2801485061645508\n",
      "\tGenerator loss: 0.9153971076011658, Discriminator loss: 1.2524135112762451\n",
      "\tGenerator loss: 0.8720239400863647, Discriminator loss: 1.2543025016784668\n",
      "\tGenerator loss: 0.8469629287719727, Discriminator loss: 1.2788262367248535\n",
      "\tGenerator loss: 0.8310948610305786, Discriminator loss: 1.2678793668746948\n",
      "\tGenerator loss: 0.839580774307251, Discriminator loss: 1.2380762100219727\n",
      "\tGenerator loss: 0.8783238530158997, Discriminator loss: 1.2528342008590698\n",
      "\tGenerator loss: 0.9482183456420898, Discriminator loss: 1.249573826789856\n",
      "\tGenerator loss: 0.9863770008087158, Discriminator loss: 1.2827656269073486\n",
      "\tGenerator loss: 1.0196895599365234, Discriminator loss: 1.2269536256790161\n",
      "\tGenerator loss: 0.9989694356918335, Discriminator loss: 1.2152738571166992\n",
      "\tGenerator loss: 0.9463956356048584, Discriminator loss: 1.1791845560073853\n",
      "\tGenerator loss: 0.9131172895431519, Discriminator loss: 1.2176815271377563\n",
      "\tGenerator loss: 0.9030988812446594, Discriminator loss: 1.1802468299865723\n",
      "\tGenerator loss: 0.9745146036148071, Discriminator loss: 1.1238837242126465\n",
      "\tGenerator loss: 1.016745924949646, Discriminator loss: 1.0973747968673706\n",
      "\tGenerator loss: 1.0533490180969238, Discriminator loss: 1.0558850765228271\n",
      "\tGenerator loss: 1.10514497756958, Discriminator loss: 1.0748584270477295\n",
      "\tGenerator loss: 1.106222152709961, Discriminator loss: 1.0570496320724487\n",
      "\tGenerator loss: 1.082554578781128, Discriminator loss: 1.112699270248413\n",
      "\tGenerator loss: 1.0575385093688965, Discriminator loss: 1.033818244934082\n",
      "\tGenerator loss: 1.0704028606414795, Discriminator loss: 1.0153179168701172\n",
      "\tGenerator loss: 1.0655838251113892, Discriminator loss: 1.162135362625122\n",
      "\tGenerator loss: 1.0554161071777344, Discriminator loss: 1.296623945236206\n",
      "\tGenerator loss: 1.041977047920227, Discriminator loss: 1.2937989234924316\n",
      "\tGenerator loss: 1.009840488433838, Discriminator loss: 1.1313204765319824\n",
      "Time for epoch 45 is 187.33449506759644 sec\n",
      "\tGenerator loss: 0.9953941106796265, Discriminator loss: 1.1764999628067017\n",
      "\tGenerator loss: 1.011120080947876, Discriminator loss: 1.1950165033340454\n",
      "\tGenerator loss: 1.0079636573791504, Discriminator loss: 1.1965205669403076\n",
      "\tGenerator loss: 1.0185580253601074, Discriminator loss: 1.195595383644104\n",
      "\tGenerator loss: 1.0159580707550049, Discriminator loss: 1.2788872718811035\n",
      "\tGenerator loss: 0.9472460746765137, Discriminator loss: 1.3665763139724731\n",
      "\tGenerator loss: 0.9427569508552551, Discriminator loss: 1.2741690874099731\n",
      "\tGenerator loss: 0.9167383909225464, Discriminator loss: 1.3642194271087646\n",
      "\tGenerator loss: 0.9240244626998901, Discriminator loss: 1.3452813625335693\n",
      "\tGenerator loss: 0.914108157157898, Discriminator loss: 1.2943545579910278\n",
      "\tGenerator loss: 0.931795597076416, Discriminator loss: 1.2933733463287354\n",
      "\tGenerator loss: 0.9498312473297119, Discriminator loss: 1.2890503406524658\n",
      "\tGenerator loss: 0.9690632820129395, Discriminator loss: 1.250584363937378\n",
      "\tGenerator loss: 0.976142168045044, Discriminator loss: 1.2352430820465088\n",
      "\tGenerator loss: 0.9746712446212769, Discriminator loss: 1.2468750476837158\n",
      "\tGenerator loss: 0.9317009449005127, Discriminator loss: 1.229835867881775\n",
      "\tGenerator loss: 0.9330856204032898, Discriminator loss: 1.205573558807373\n",
      "\tGenerator loss: 0.945574164390564, Discriminator loss: 1.2154254913330078\n",
      "\tGenerator loss: 1.0294744968414307, Discriminator loss: 1.2570432424545288\n",
      "\tGenerator loss: 1.0169731378555298, Discriminator loss: 1.2203118801116943\n",
      "\tGenerator loss: 1.0112028121948242, Discriminator loss: 1.178582787513733\n",
      "\tGenerator loss: 0.9829978942871094, Discriminator loss: 1.1799211502075195\n",
      "\tGenerator loss: 1.0028619766235352, Discriminator loss: 1.141277551651001\n",
      "\tGenerator loss: 1.0110793113708496, Discriminator loss: 1.1171901226043701\n",
      "\tGenerator loss: 1.0662071704864502, Discriminator loss: 1.088529348373413\n",
      "\tGenerator loss: 1.1225965023040771, Discriminator loss: 1.0802921056747437\n",
      "\tGenerator loss: 1.1617662906646729, Discriminator loss: 1.1071245670318604\n",
      "\tGenerator loss: 1.1253843307495117, Discriminator loss: 1.0685197114944458\n",
      "\tGenerator loss: 1.0389666557312012, Discriminator loss: 1.136913776397705\n",
      "\tGenerator loss: 0.9398311972618103, Discriminator loss: 1.1439400911331177\n",
      "\tGenerator loss: 0.8732395172119141, Discriminator loss: 1.1279149055480957\n",
      "\tGenerator loss: 0.9404337406158447, Discriminator loss: 1.1270314455032349\n",
      "\tGenerator loss: 1.0566213130950928, Discriminator loss: 1.1285583972930908\n",
      "\tGenerator loss: 1.1714354753494263, Discriminator loss: 1.1081558465957642\n",
      "\tGenerator loss: 1.2248822450637817, Discriminator loss: 1.1477725505828857\n",
      "\tGenerator loss: 1.1980316638946533, Discriminator loss: 1.2128654718399048\n",
      "\tGenerator loss: 1.0694981813430786, Discriminator loss: 1.2391108274459839\n",
      "\tGenerator loss: 0.914390504360199, Discriminator loss: 1.2795472145080566\n",
      "\tGenerator loss: 0.787392795085907, Discriminator loss: 1.2947750091552734\n",
      "\tGenerator loss: 0.7801235914230347, Discriminator loss: 1.2702486515045166\n",
      "\tGenerator loss: 0.8731068968772888, Discriminator loss: 1.1852654218673706\n",
      "\tGenerator loss: 1.0071502923965454, Discriminator loss: 1.2557377815246582\n",
      "\tGenerator loss: 1.1146645545959473, Discriminator loss: 1.2716825008392334\n",
      "\tGenerator loss: 1.139697790145874, Discriminator loss: 1.3378125429153442\n",
      "\tGenerator loss: 1.0662140846252441, Discriminator loss: 1.3612630367279053\n",
      "\tGenerator loss: 0.9182983040809631, Discriminator loss: 1.3775947093963623\n",
      "\tGenerator loss: 0.7878742814064026, Discriminator loss: 1.4093252420425415\n",
      "\tGenerator loss: 0.70257568359375, Discriminator loss: 1.4117116928100586\n",
      "\tGenerator loss: 0.691826581954956, Discriminator loss: 1.4163100719451904\n",
      "\tGenerator loss: 0.7707855701446533, Discriminator loss: 1.400776743888855\n",
      "\tGenerator loss: 0.8624358177185059, Discriminator loss: 1.4355477094650269\n",
      "\tGenerator loss: 0.925460934638977, Discriminator loss: 1.3996577262878418\n",
      "\tGenerator loss: 0.9263997077941895, Discriminator loss: 1.371313214302063\n",
      "\tGenerator loss: 0.9241507649421692, Discriminator loss: 1.4899592399597168\n",
      "\tGenerator loss: 0.8371765613555908, Discriminator loss: 1.4725403785705566\n",
      "\tGenerator loss: 0.7579107284545898, Discriminator loss: 1.4456156492233276\n",
      "\tGenerator loss: 0.6831763386726379, Discriminator loss: 1.4566500186920166\n",
      "\tGenerator loss: 0.6435885429382324, Discriminator loss: 1.475776195526123\n",
      "\tGenerator loss: 0.6701810359954834, Discriminator loss: 1.4326181411743164\n",
      "\tGenerator loss: 0.7361021041870117, Discriminator loss: 1.375150203704834\n",
      "\tGenerator loss: 0.8107008934020996, Discriminator loss: 1.320989727973938\n",
      "\tGenerator loss: 0.8845070600509644, Discriminator loss: 1.2606587409973145\n",
      "\tGenerator loss: 0.9154379367828369, Discriminator loss: 1.2722947597503662\n",
      "\tGenerator loss: 0.9418449401855469, Discriminator loss: 1.227518916130066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9288670420646667, Discriminator loss: 1.1811034679412842\n",
      "\tGenerator loss: 0.9387409687042236, Discriminator loss: 1.0921034812927246\n",
      "\tGenerator loss: 0.9519423246383667, Discriminator loss: 1.098015546798706\n",
      "\tGenerator loss: 0.9948639273643494, Discriminator loss: 1.08333420753479\n",
      "\tGenerator loss: 1.0357894897460938, Discriminator loss: 1.036550521850586\n",
      "\tGenerator loss: 1.052497148513794, Discriminator loss: 1.0028414726257324\n",
      "\tGenerator loss: 1.1302233934402466, Discriminator loss: 0.9624908566474915\n",
      "\tGenerator loss: 1.2062811851501465, Discriminator loss: 0.968063235282898\n",
      "\tGenerator loss: 1.261392593383789, Discriminator loss: 0.9278141856193542\n",
      "\tGenerator loss: 1.289980411529541, Discriminator loss: 0.8966711759567261\n",
      "\tGenerator loss: 1.3047865629196167, Discriminator loss: 0.8463626503944397\n",
      "\tGenerator loss: 1.326364517211914, Discriminator loss: 0.975812554359436\n",
      "\tGenerator loss: 1.3019548654556274, Discriminator loss: 1.0887049436569214\n",
      "\tGenerator loss: 1.2554562091827393, Discriminator loss: 1.0870630741119385\n",
      "\tGenerator loss: 1.2378286123275757, Discriminator loss: 1.034958839416504\n",
      "\tGenerator loss: 1.21055006980896, Discriminator loss: 0.9689483642578125\n",
      "\tGenerator loss: 1.2229880094528198, Discriminator loss: 0.9870357513427734\n",
      "\tGenerator loss: 1.2579009532928467, Discriminator loss: 0.9941664934158325\n",
      "\tGenerator loss: 1.316836953163147, Discriminator loss: 0.9139321446418762\n",
      "\tGenerator loss: 1.3701221942901611, Discriminator loss: 0.964475154876709\n",
      "\tGenerator loss: 1.3852643966674805, Discriminator loss: 0.912869930267334\n",
      "\tGenerator loss: 1.3806967735290527, Discriminator loss: 1.234566330909729\n",
      "\tGenerator loss: 1.2971525192260742, Discriminator loss: 1.1122021675109863\n",
      "\tGenerator loss: 1.1681653261184692, Discriminator loss: 1.1138927936553955\n",
      "\tGenerator loss: 1.0877777338027954, Discriminator loss: 1.3283790349960327\n",
      "\tGenerator loss: 0.98929762840271, Discriminator loss: 1.440030813217163\n",
      "\tGenerator loss: 0.9199492335319519, Discriminator loss: 1.5099999904632568\n",
      "\tGenerator loss: 0.9158484935760498, Discriminator loss: 1.4420409202575684\n",
      "\tGenerator loss: 0.94999098777771, Discriminator loss: 1.3059972524642944\n",
      "\tGenerator loss: 1.029421091079712, Discriminator loss: 1.3537836074829102\n",
      "\tGenerator loss: 1.077812671661377, Discriminator loss: 1.4724483489990234\n",
      "\tGenerator loss: 1.0715346336364746, Discriminator loss: 1.4748551845550537\n",
      "\tGenerator loss: 1.017645239830017, Discriminator loss: 1.5872318744659424\n",
      "\tGenerator loss: 0.906020998954773, Discriminator loss: 1.5193389654159546\n",
      "\tGenerator loss: 0.7972400188446045, Discriminator loss: 1.5832369327545166\n",
      "\tGenerator loss: 0.7579460144042969, Discriminator loss: 1.716447353363037\n",
      "\tGenerator loss: 0.8210390210151672, Discriminator loss: 1.5887315273284912\n",
      "\tGenerator loss: 0.9226193428039551, Discriminator loss: 1.550051212310791\n",
      "\tGenerator loss: 0.9959561824798584, Discriminator loss: 1.5181522369384766\n",
      "\tGenerator loss: 0.9889634847640991, Discriminator loss: 1.4826301336288452\n",
      "\tGenerator loss: 0.9181824922561646, Discriminator loss: 1.5646998882293701\n",
      "\tGenerator loss: 0.8675357103347778, Discriminator loss: 1.4747951030731201\n",
      "\tGenerator loss: 0.8265963792800903, Discriminator loss: 1.464983582496643\n",
      "\tGenerator loss: 0.8418833017349243, Discriminator loss: 1.417475938796997\n",
      "\tGenerator loss: 0.8892748355865479, Discriminator loss: 1.3872507810592651\n",
      "\tGenerator loss: 0.9775905609130859, Discriminator loss: 1.4190163612365723\n",
      "\tGenerator loss: 1.079425573348999, Discriminator loss: 1.3924111127853394\n",
      "\tGenerator loss: 1.0900319814682007, Discriminator loss: 1.3878111839294434\n",
      "\tGenerator loss: 1.074737310409546, Discriminator loss: 1.3050909042358398\n",
      "\tGenerator loss: 1.013504981994629, Discriminator loss: 1.2583259344100952\n",
      "\tGenerator loss: 0.9619590044021606, Discriminator loss: 1.2482314109802246\n",
      "\tGenerator loss: 0.9655588269233704, Discriminator loss: 1.1822726726531982\n",
      "\tGenerator loss: 1.003572940826416, Discriminator loss: 1.1726363897323608\n",
      "\tGenerator loss: 1.0755484104156494, Discriminator loss: 1.167823314666748\n",
      "\tGenerator loss: 1.1095905303955078, Discriminator loss: 1.1067924499511719\n",
      "\tGenerator loss: 1.1309643983840942, Discriminator loss: 1.1163768768310547\n",
      "\tGenerator loss: 1.1101183891296387, Discriminator loss: 1.1013386249542236\n",
      "\tGenerator loss: 1.0845272541046143, Discriminator loss: 1.092308759689331\n",
      "\tGenerator loss: 1.0959157943725586, Discriminator loss: 1.0989707708358765\n",
      "\tGenerator loss: 1.0643011331558228, Discriminator loss: 1.123311996459961\n",
      "\tGenerator loss: 1.0592749118804932, Discriminator loss: 1.0717828273773193\n",
      "\tGenerator loss: 1.0631239414215088, Discriminator loss: 1.0648119449615479\n",
      "\tGenerator loss: 1.0836906433105469, Discriminator loss: 1.0581746101379395\n",
      "\tGenerator loss: 1.111653447151184, Discriminator loss: 1.109786868095398\n",
      "\tGenerator loss: 1.128673791885376, Discriminator loss: 1.0622496604919434\n",
      "\tGenerator loss: 1.1409860849380493, Discriminator loss: 1.0879263877868652\n",
      "\tGenerator loss: 1.1571111679077148, Discriminator loss: 1.135205626487732\n",
      "\tGenerator loss: 1.0945056676864624, Discriminator loss: 1.198627233505249\n",
      "\tGenerator loss: 1.0019316673278809, Discriminator loss: 1.1642181873321533\n",
      "\tGenerator loss: 0.912828803062439, Discriminator loss: 1.2018613815307617\n",
      "\tGenerator loss: 0.8927632570266724, Discriminator loss: 1.1804747581481934\n",
      "\tGenerator loss: 0.9277243614196777, Discriminator loss: 1.2499778270721436\n",
      "\tGenerator loss: 1.0059434175491333, Discriminator loss: 1.2285501956939697\n",
      "\tGenerator loss: 1.0566513538360596, Discriminator loss: 1.293792963027954\n",
      "\tGenerator loss: 1.0702977180480957, Discriminator loss: 1.2636280059814453\n",
      "\tGenerator loss: 0.9839784502983093, Discriminator loss: 1.2961440086364746\n",
      "\tGenerator loss: 0.9128481149673462, Discriminator loss: 1.3956446647644043\n",
      "\tGenerator loss: 0.7950478792190552, Discriminator loss: 1.319642186164856\n",
      "\tGenerator loss: 0.7540484070777893, Discriminator loss: 1.3302183151245117\n",
      "\tGenerator loss: 0.7682498693466187, Discriminator loss: 1.2714729309082031\n",
      "\tGenerator loss: 0.8786292672157288, Discriminator loss: 1.270785927772522\n",
      "\tGenerator loss: 1.0066686868667603, Discriminator loss: 1.2426719665527344\n",
      "\tGenerator loss: 1.0712653398513794, Discriminator loss: 1.3939571380615234\n",
      "\tGenerator loss: 1.0770387649536133, Discriminator loss: 1.4061481952667236\n",
      "\tGenerator loss: 0.9728835225105286, Discriminator loss: 1.4010632038116455\n",
      "\tGenerator loss: 0.842185378074646, Discriminator loss: 1.4222520589828491\n",
      "\tGenerator loss: 0.7040755152702332, Discriminator loss: 1.470096230506897\n",
      "\tGenerator loss: 0.6690284609794617, Discriminator loss: 1.4205964803695679\n",
      "\tGenerator loss: 0.6499234437942505, Discriminator loss: 1.4072654247283936\n",
      "\tGenerator loss: 0.711487889289856, Discriminator loss: 1.3797783851623535\n",
      "\tGenerator loss: 0.8070167899131775, Discriminator loss: 1.3322261571884155\n",
      "\tGenerator loss: 0.9114800691604614, Discriminator loss: 1.4734997749328613\n",
      "\tGenerator loss: 0.9599667191505432, Discriminator loss: 1.4323599338531494\n",
      "\tGenerator loss: 0.9721596240997314, Discriminator loss: 1.369429588317871\n",
      "\tGenerator loss: 0.9105766415596008, Discriminator loss: 1.3526502847671509\n",
      "\tGenerator loss: 0.8155798316001892, Discriminator loss: 1.330237627029419\n",
      "\tGenerator loss: 0.7553350925445557, Discriminator loss: 1.3038182258605957\n",
      "\tGenerator loss: 0.7358196973800659, Discriminator loss: 1.2994170188903809\n",
      "\tGenerator loss: 0.8021258115768433, Discriminator loss: 1.2585200071334839\n",
      "\tGenerator loss: 0.8454564213752747, Discriminator loss: 1.2196300029754639\n",
      "\tGenerator loss: 0.8939317464828491, Discriminator loss: 1.2033731937408447\n",
      "\tGenerator loss: 0.9564523100852966, Discriminator loss: 1.1716086864471436\n",
      "\tGenerator loss: 1.0101795196533203, Discriminator loss: 1.1933552026748657\n",
      "\tGenerator loss: 1.035832166671753, Discriminator loss: 1.1345059871673584\n",
      "\tGenerator loss: 1.0723567008972168, Discriminator loss: 1.0903472900390625\n",
      "\tGenerator loss: 1.0617092847824097, Discriminator loss: 1.0829894542694092\n",
      "\tGenerator loss: 1.0805306434631348, Discriminator loss: 1.0495058298110962\n",
      "\tGenerator loss: 1.0862443447113037, Discriminator loss: 0.9712393879890442\n",
      "\tGenerator loss: 1.077862024307251, Discriminator loss: 0.9856462478637695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0841455459594727, Discriminator loss: 0.970152735710144\n",
      "\tGenerator loss: 1.1367526054382324, Discriminator loss: 0.9316345453262329\n",
      "\tGenerator loss: 1.16878342628479, Discriminator loss: 0.936447262763977\n",
      "\tGenerator loss: 1.233339786529541, Discriminator loss: 0.9375337362289429\n",
      "\tGenerator loss: 1.3082938194274902, Discriminator loss: 0.8655099868774414\n",
      "\tGenerator loss: 1.3315026760101318, Discriminator loss: 0.87335205078125\n",
      "\tGenerator loss: 1.3799500465393066, Discriminator loss: 0.8328155875205994\n",
      "\tGenerator loss: 1.3755426406860352, Discriminator loss: 0.8045166730880737\n",
      "\tGenerator loss: 1.3753013610839844, Discriminator loss: 0.8223389983177185\n",
      "\tGenerator loss: 1.3782939910888672, Discriminator loss: 0.890107274055481\n",
      "\tGenerator loss: 1.3546710014343262, Discriminator loss: 0.8649082183837891\n",
      "\tGenerator loss: 1.302182674407959, Discriminator loss: 0.8315697908401489\n",
      "\tGenerator loss: 1.3390291929244995, Discriminator loss: 0.9280959367752075\n",
      "\tGenerator loss: 1.3287875652313232, Discriminator loss: 1.040178894996643\n",
      "\tGenerator loss: 1.3006653785705566, Discriminator loss: 1.0875908136367798\n",
      "\tGenerator loss: 1.3161718845367432, Discriminator loss: 1.1481225490570068\n",
      "\tGenerator loss: 1.3063766956329346, Discriminator loss: 1.099173903465271\n",
      "\tGenerator loss: 1.253149390220642, Discriminator loss: 1.1143165826797485\n",
      "\tGenerator loss: 1.1941394805908203, Discriminator loss: 1.0111523866653442\n",
      "\tGenerator loss: 1.1572442054748535, Discriminator loss: 1.020869255065918\n",
      "\tGenerator loss: 1.1381070613861084, Discriminator loss: 1.018519401550293\n",
      "\tGenerator loss: 1.1699999570846558, Discriminator loss: 0.9894313812255859\n",
      "\tGenerator loss: 1.2737987041473389, Discriminator loss: 0.9784879088401794\n",
      "\tGenerator loss: 1.3361672163009644, Discriminator loss: 0.9817328453063965\n",
      "\tGenerator loss: 1.2576735019683838, Discriminator loss: 1.0341124534606934\n",
      "\tGenerator loss: 1.2308100461959839, Discriminator loss: 1.2198339700698853\n",
      "\tGenerator loss: 1.0925681591033936, Discriminator loss: 1.2880198955535889\n",
      "\tGenerator loss: 0.9840961694717407, Discriminator loss: 1.3770724534988403\n",
      "\tGenerator loss: 0.9102437496185303, Discriminator loss: 1.3086538314819336\n",
      "\tGenerator loss: 0.8733595013618469, Discriminator loss: 1.289505958557129\n",
      "\tGenerator loss: 0.9256473779678345, Discriminator loss: 1.2401103973388672\n",
      "\tGenerator loss: 1.0215699672698975, Discriminator loss: 1.308061122894287\n",
      "\tGenerator loss: 1.093271017074585, Discriminator loss: 1.29945707321167\n",
      "\tGenerator loss: 1.0720452070236206, Discriminator loss: 1.3768296241760254\n",
      "\tGenerator loss: 1.056626319885254, Discriminator loss: 1.4066489934921265\n",
      "\tGenerator loss: 0.9465621709823608, Discriminator loss: 1.383204698562622\n",
      "\tGenerator loss: 0.8679894208908081, Discriminator loss: 1.3307559490203857\n",
      "\tGenerator loss: 0.8216534852981567, Discriminator loss: 1.3534014225006104\n",
      "\tGenerator loss: 0.842044472694397, Discriminator loss: 1.4017508029937744\n",
      "\tGenerator loss: 0.8917965888977051, Discriminator loss: 1.486570119857788\n",
      "\tGenerator loss: 0.9753859639167786, Discriminator loss: 1.5913503170013428\n",
      "\tGenerator loss: 0.9842536449432373, Discriminator loss: 1.5152455568313599\n",
      "\tGenerator loss: 0.9434074759483337, Discriminator loss: 1.5161025524139404\n",
      "\tGenerator loss: 0.8984012603759766, Discriminator loss: 1.492523193359375\n",
      "\tGenerator loss: 0.8189196586608887, Discriminator loss: 1.5896745920181274\n",
      "\tGenerator loss: 0.7817122936248779, Discriminator loss: 1.5132834911346436\n",
      "\tGenerator loss: 0.7967572212219238, Discriminator loss: 1.445650339126587\n",
      "\tGenerator loss: 0.8682211637496948, Discriminator loss: 1.3956881761550903\n",
      "\tGenerator loss: 0.943667471408844, Discriminator loss: 1.3513238430023193\n",
      "\tGenerator loss: 1.025977373123169, Discriminator loss: 1.3074476718902588\n",
      "\tGenerator loss: 1.0297484397888184, Discriminator loss: 1.2655073404312134\n",
      "\tGenerator loss: 1.0383079051971436, Discriminator loss: 1.1960475444793701\n",
      "\tGenerator loss: 1.0196475982666016, Discriminator loss: 1.162520170211792\n",
      "\tGenerator loss: 0.9822260141372681, Discriminator loss: 1.1677569150924683\n",
      "\tGenerator loss: 0.9494221210479736, Discriminator loss: 1.1144373416900635\n",
      "\tGenerator loss: 0.9615376591682434, Discriminator loss: 1.1388719081878662\n",
      "\tGenerator loss: 0.9949936866760254, Discriminator loss: 1.0981279611587524\n",
      "\tGenerator loss: 1.0553796291351318, Discriminator loss: 1.0285389423370361\n",
      "\tGenerator loss: 1.129976511001587, Discriminator loss: 0.9906952381134033\n",
      "\tGenerator loss: 1.1960467100143433, Discriminator loss: 0.9838290214538574\n",
      "\tGenerator loss: 1.2317464351654053, Discriminator loss: 1.0096453428268433\n",
      "\tGenerator loss: 1.2523083686828613, Discriminator loss: 1.0932598114013672\n",
      "Time for epoch 46 is 211.55505537986755 sec\n",
      "\tGenerator loss: 1.182996153831482, Discriminator loss: 1.1008650064468384\n",
      "\tGenerator loss: 1.0449237823486328, Discriminator loss: 1.1037753820419312\n",
      "\tGenerator loss: 0.952307939529419, Discriminator loss: 1.0958423614501953\n",
      "\tGenerator loss: 0.9180588126182556, Discriminator loss: 1.1007235050201416\n",
      "\tGenerator loss: 0.9488613605499268, Discriminator loss: 1.1388155221939087\n",
      "\tGenerator loss: 1.0261098146438599, Discriminator loss: 1.0949254035949707\n",
      "\tGenerator loss: 1.1437675952911377, Discriminator loss: 1.1253018379211426\n",
      "\tGenerator loss: 1.189753532409668, Discriminator loss: 1.1546599864959717\n",
      "\tGenerator loss: 1.1727396249771118, Discriminator loss: 1.1395361423492432\n",
      "\tGenerator loss: 1.0918500423431396, Discriminator loss: 1.1272594928741455\n",
      "\tGenerator loss: 1.0293641090393066, Discriminator loss: 1.1548006534576416\n",
      "\tGenerator loss: 0.9887553453445435, Discriminator loss: 1.170694351196289\n",
      "\tGenerator loss: 0.9700100421905518, Discriminator loss: 1.2082313299179077\n",
      "\tGenerator loss: 0.9530290365219116, Discriminator loss: 1.2390692234039307\n",
      "\tGenerator loss: 0.9378048181533813, Discriminator loss: 1.2759778499603271\n",
      "\tGenerator loss: 0.924198567867279, Discriminator loss: 1.2698662281036377\n",
      "\tGenerator loss: 0.9227290153503418, Discriminator loss: 1.2815933227539062\n",
      "\tGenerator loss: 0.9519211053848267, Discriminator loss: 1.266550064086914\n",
      "\tGenerator loss: 0.9515599012374878, Discriminator loss: 1.2999403476715088\n",
      "\tGenerator loss: 0.9688044786453247, Discriminator loss: 1.3163385391235352\n",
      "\tGenerator loss: 1.0047731399536133, Discriminator loss: 1.2652519941329956\n",
      "\tGenerator loss: 0.9902337789535522, Discriminator loss: 1.2426509857177734\n",
      "\tGenerator loss: 1.0015981197357178, Discriminator loss: 1.2737486362457275\n",
      "\tGenerator loss: 0.9928973317146301, Discriminator loss: 1.2461775541305542\n",
      "\tGenerator loss: 0.9696755409240723, Discriminator loss: 1.243476152420044\n",
      "\tGenerator loss: 0.9638817310333252, Discriminator loss: 1.2936086654663086\n",
      "\tGenerator loss: 0.9365563988685608, Discriminator loss: 1.4813532829284668\n",
      "\tGenerator loss: 0.8654987812042236, Discriminator loss: 1.4436066150665283\n",
      "\tGenerator loss: 0.7936580777168274, Discriminator loss: 1.5645089149475098\n",
      "\tGenerator loss: 0.725044846534729, Discriminator loss: 1.5298564434051514\n",
      "\tGenerator loss: 0.6960101127624512, Discriminator loss: 1.4759045839309692\n",
      "\tGenerator loss: 0.6748005747795105, Discriminator loss: 1.4844653606414795\n",
      "\tGenerator loss: 0.7035219669342041, Discriminator loss: 1.4526698589324951\n",
      "\tGenerator loss: 0.7895101308822632, Discriminator loss: 1.3561562299728394\n",
      "\tGenerator loss: 0.926935613155365, Discriminator loss: 1.4205549955368042\n",
      "\tGenerator loss: 1.0477491617202759, Discriminator loss: 1.5195796489715576\n",
      "\tGenerator loss: 1.0271177291870117, Discriminator loss: 1.5576812028884888\n",
      "\tGenerator loss: 0.9300898313522339, Discriminator loss: 1.5230717658996582\n",
      "\tGenerator loss: 0.8181832432746887, Discriminator loss: 1.4730126857757568\n",
      "\tGenerator loss: 0.7276924848556519, Discriminator loss: 1.438104271888733\n",
      "\tGenerator loss: 0.6677652597427368, Discriminator loss: 1.4284288883209229\n",
      "\tGenerator loss: 0.685039222240448, Discriminator loss: 1.3852627277374268\n",
      "\tGenerator loss: 0.7623165845870972, Discriminator loss: 1.322666049003601\n",
      "\tGenerator loss: 0.8640703558921814, Discriminator loss: 1.3420968055725098\n",
      "\tGenerator loss: 0.9644006490707397, Discriminator loss: 1.3486567735671997\n",
      "\tGenerator loss: 1.0376721620559692, Discriminator loss: 1.315873146057129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 1.0500617027282715, Discriminator loss: 1.306854009628296\n",
      "\tGenerator loss: 0.9962021708488464, Discriminator loss: 1.2690412998199463\n",
      "\tGenerator loss: 0.9079834222793579, Discriminator loss: 1.2478547096252441\n",
      "\tGenerator loss: 0.8617300987243652, Discriminator loss: 1.2355153560638428\n",
      "\tGenerator loss: 0.8167523145675659, Discriminator loss: 1.2164976596832275\n",
      "\tGenerator loss: 0.7993720173835754, Discriminator loss: 1.2136991024017334\n",
      "\tGenerator loss: 0.8530220985412598, Discriminator loss: 1.1772619485855103\n",
      "\tGenerator loss: 0.903488039970398, Discriminator loss: 1.1895289421081543\n",
      "\tGenerator loss: 0.9947569370269775, Discriminator loss: 1.1326104402542114\n",
      "\tGenerator loss: 1.063458800315857, Discriminator loss: 1.1866025924682617\n",
      "\tGenerator loss: 1.132812738418579, Discriminator loss: 1.1240521669387817\n",
      "\tGenerator loss: 1.1419627666473389, Discriminator loss: 1.049241542816162\n",
      "\tGenerator loss: 1.1028834581375122, Discriminator loss: 1.0202776193618774\n",
      "\tGenerator loss: 1.0581104755401611, Discriminator loss: 0.9862456917762756\n",
      "\tGenerator loss: 1.0683834552764893, Discriminator loss: 0.9386335015296936\n",
      "\tGenerator loss: 1.0700783729553223, Discriminator loss: 0.9075649976730347\n",
      "\tGenerator loss: 1.1145453453063965, Discriminator loss: 0.9728151559829712\n",
      "\tGenerator loss: 1.148005723953247, Discriminator loss: 0.989012598991394\n",
      "\tGenerator loss: 1.1823934316635132, Discriminator loss: 0.9550690650939941\n",
      "\tGenerator loss: 1.2093391418457031, Discriminator loss: 0.8884711861610413\n",
      "\tGenerator loss: 1.2377567291259766, Discriminator loss: 0.9191886186599731\n",
      "\tGenerator loss: 1.283534288406372, Discriminator loss: 0.9113637804985046\n",
      "\tGenerator loss: 1.2559432983398438, Discriminator loss: 0.8661348819732666\n",
      "\tGenerator loss: 1.2868543863296509, Discriminator loss: 0.8388245105743408\n",
      "\tGenerator loss: 1.2790162563323975, Discriminator loss: 0.8830865621566772\n",
      "\tGenerator loss: 1.2420876026153564, Discriminator loss: 0.9256526231765747\n",
      "\tGenerator loss: 1.2359724044799805, Discriminator loss: 0.8864378929138184\n",
      "\tGenerator loss: 1.2292197942733765, Discriminator loss: 0.8805434703826904\n",
      "\tGenerator loss: 1.2473585605621338, Discriminator loss: 0.8343154191970825\n",
      "\tGenerator loss: 1.2448921203613281, Discriminator loss: 1.024917483329773\n",
      "\tGenerator loss: 1.2760939598083496, Discriminator loss: 1.1893706321716309\n",
      "\tGenerator loss: 1.2438337802886963, Discriminator loss: 1.1526374816894531\n",
      "\tGenerator loss: 1.1553798913955688, Discriminator loss: 1.0885100364685059\n",
      "\tGenerator loss: 1.1229138374328613, Discriminator loss: 1.032745599746704\n",
      "\tGenerator loss: 1.111863613128662, Discriminator loss: 1.0711430311203003\n",
      "\tGenerator loss: 1.103751301765442, Discriminator loss: 1.0783240795135498\n",
      "\tGenerator loss: 1.1213816404342651, Discriminator loss: 1.0127439498901367\n",
      "\tGenerator loss: 1.1286673545837402, Discriminator loss: 1.0779118537902832\n",
      "\tGenerator loss: 1.1710273027420044, Discriminator loss: 1.0197969675064087\n",
      "\tGenerator loss: 1.2092256546020508, Discriminator loss: 1.3581552505493164\n",
      "\tGenerator loss: 1.166700839996338, Discriminator loss: 1.1951066255569458\n",
      "\tGenerator loss: 1.1232620477676392, Discriminator loss: 1.1980688571929932\n",
      "\tGenerator loss: 1.0479358434677124, Discriminator loss: 1.4222720861434937\n",
      "\tGenerator loss: 0.9673238396644592, Discriminator loss: 1.5017485618591309\n",
      "\tGenerator loss: 0.9098716974258423, Discriminator loss: 1.5352530479431152\n",
      "\tGenerator loss: 0.8384471535682678, Discriminator loss: 1.507848858833313\n",
      "\tGenerator loss: 0.8480923175811768, Discriminator loss: 1.318989872932434\n",
      "\tGenerator loss: 0.9163693785667419, Discriminator loss: 1.3502848148345947\n",
      "\tGenerator loss: 0.9720373153686523, Discriminator loss: 1.4396986961364746\n",
      "\tGenerator loss: 1.0204763412475586, Discriminator loss: 1.409486174583435\n",
      "\tGenerator loss: 1.025248408317566, Discriminator loss: 1.5067236423492432\n",
      "\tGenerator loss: 0.9636279344558716, Discriminator loss: 1.4578741788864136\n",
      "\tGenerator loss: 0.9056797027587891, Discriminator loss: 1.4445407390594482\n",
      "\tGenerator loss: 0.8548678159713745, Discriminator loss: 1.5623195171356201\n",
      "\tGenerator loss: 0.8646786212921143, Discriminator loss: 1.4462759494781494\n",
      "\tGenerator loss: 0.8639763593673706, Discriminator loss: 1.413659930229187\n",
      "\tGenerator loss: 0.9123218059539795, Discriminator loss: 1.3930641412734985\n",
      "\tGenerator loss: 0.9467405080795288, Discriminator loss: 1.3443617820739746\n",
      "\tGenerator loss: 0.9703060388565063, Discriminator loss: 1.3835203647613525\n",
      "\tGenerator loss: 0.990083634853363, Discriminator loss: 1.3164886236190796\n",
      "\tGenerator loss: 0.9681823253631592, Discriminator loss: 1.3134832382202148\n",
      "\tGenerator loss: 0.9444032907485962, Discriminator loss: 1.2712810039520264\n",
      "\tGenerator loss: 0.9520688652992249, Discriminator loss: 1.206777811050415\n",
      "\tGenerator loss: 0.9790676832199097, Discriminator loss: 1.2665339708328247\n",
      "\tGenerator loss: 1.0177037715911865, Discriminator loss: 1.2799029350280762\n",
      "\tGenerator loss: 1.0426334142684937, Discriminator loss: 1.2656495571136475\n",
      "\tGenerator loss: 1.0267395973205566, Discriminator loss: 1.2041971683502197\n",
      "\tGenerator loss: 1.0518616437911987, Discriminator loss: 1.1608712673187256\n",
      "\tGenerator loss: 1.0422914028167725, Discriminator loss: 1.1880018711090088\n",
      "\tGenerator loss: 1.0272037982940674, Discriminator loss: 1.161902904510498\n",
      "\tGenerator loss: 1.0440648794174194, Discriminator loss: 1.1827659606933594\n",
      "\tGenerator loss: 1.0394259691238403, Discriminator loss: 1.1643280982971191\n",
      "\tGenerator loss: 1.0270893573760986, Discriminator loss: 1.1094602346420288\n",
      "\tGenerator loss: 1.0698018074035645, Discriminator loss: 1.1105791330337524\n",
      "\tGenerator loss: 1.0576374530792236, Discriminator loss: 1.1182899475097656\n",
      "\tGenerator loss: 1.058868408203125, Discriminator loss: 1.1082448959350586\n",
      "\tGenerator loss: 1.0567452907562256, Discriminator loss: 1.105714201927185\n",
      "\tGenerator loss: 1.058555245399475, Discriminator loss: 1.1179568767547607\n",
      "\tGenerator loss: 1.0691696405410767, Discriminator loss: 1.068316102027893\n",
      "\tGenerator loss: 1.0380277633666992, Discriminator loss: 1.0958296060562134\n",
      "\tGenerator loss: 1.0571353435516357, Discriminator loss: 1.1052157878875732\n",
      "\tGenerator loss: 1.0729711055755615, Discriminator loss: 1.1654045581817627\n",
      "\tGenerator loss: 1.0862776041030884, Discriminator loss: 1.1333314180374146\n",
      "\tGenerator loss: 1.0800244808197021, Discriminator loss: 1.1528313159942627\n",
      "\tGenerator loss: 1.0584920644760132, Discriminator loss: 1.1711689233779907\n",
      "\tGenerator loss: 0.9983959197998047, Discriminator loss: 1.2540481090545654\n",
      "\tGenerator loss: 0.9794695973396301, Discriminator loss: 1.2280926704406738\n",
      "\tGenerator loss: 0.9319853782653809, Discriminator loss: 1.2195343971252441\n",
      "\tGenerator loss: 0.8914557695388794, Discriminator loss: 1.2256710529327393\n",
      "\tGenerator loss: 0.9200469255447388, Discriminator loss: 1.2942776679992676\n",
      "\tGenerator loss: 0.9769347310066223, Discriminator loss: 1.252396821975708\n",
      "\tGenerator loss: 1.004571795463562, Discriminator loss: 1.2988090515136719\n",
      "\tGenerator loss: 1.0359041690826416, Discriminator loss: 1.280989408493042\n",
      "\tGenerator loss: 0.9946630001068115, Discriminator loss: 1.3027758598327637\n",
      "\tGenerator loss: 0.908058226108551, Discriminator loss: 1.3958274126052856\n",
      "\tGenerator loss: 0.7995269298553467, Discriminator loss: 1.3355529308319092\n",
      "\tGenerator loss: 0.7753797769546509, Discriminator loss: 1.3380333185195923\n",
      "\tGenerator loss: 0.7978190183639526, Discriminator loss: 1.2614421844482422\n",
      "\tGenerator loss: 0.8557034134864807, Discriminator loss: 1.3188707828521729\n",
      "\tGenerator loss: 0.9592993259429932, Discriminator loss: 1.2698265314102173\n",
      "\tGenerator loss: 1.0210084915161133, Discriminator loss: 1.3870010375976562\n",
      "\tGenerator loss: 1.0074234008789062, Discriminator loss: 1.411023497581482\n",
      "\tGenerator loss: 0.9608163833618164, Discriminator loss: 1.4069349765777588\n",
      "\tGenerator loss: 0.8634687662124634, Discriminator loss: 1.413541555404663\n",
      "\tGenerator loss: 0.751236081123352, Discriminator loss: 1.445775032043457\n",
      "\tGenerator loss: 0.6747380495071411, Discriminator loss: 1.4524805545806885\n",
      "\tGenerator loss: 0.6735950708389282, Discriminator loss: 1.3991143703460693\n",
      "\tGenerator loss: 0.7109345197677612, Discriminator loss: 1.4019643068313599\n",
      "\tGenerator loss: 0.7826237678527832, Discriminator loss: 1.394599199295044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9074961543083191, Discriminator loss: 1.5178683996200562\n",
      "\tGenerator loss: 0.9373887777328491, Discriminator loss: 1.4724600315093994\n",
      "\tGenerator loss: 0.93760085105896, Discriminator loss: 1.4161796569824219\n",
      "\tGenerator loss: 0.8705999255180359, Discriminator loss: 1.4163020849227905\n",
      "\tGenerator loss: 0.776382565498352, Discriminator loss: 1.4313116073608398\n",
      "\tGenerator loss: 0.7339440584182739, Discriminator loss: 1.3794549703598022\n",
      "\tGenerator loss: 0.7066246271133423, Discriminator loss: 1.3993605375289917\n",
      "\tGenerator loss: 0.7120027542114258, Discriminator loss: 1.4020452499389648\n",
      "\tGenerator loss: 0.727024257183075, Discriminator loss: 1.3720781803131104\n",
      "\tGenerator loss: 0.7854455709457397, Discriminator loss: 1.3303256034851074\n",
      "\tGenerator loss: 0.8359583020210266, Discriminator loss: 1.3252924680709839\n",
      "\tGenerator loss: 0.8799924850463867, Discriminator loss: 1.3158605098724365\n",
      "\tGenerator loss: 0.91441810131073, Discriminator loss: 1.3028686046600342\n",
      "\tGenerator loss: 0.9226298332214355, Discriminator loss: 1.2737932205200195\n",
      "\tGenerator loss: 0.9309045076370239, Discriminator loss: 1.2464450597763062\n",
      "\tGenerator loss: 0.9220708012580872, Discriminator loss: 1.2292983531951904\n",
      "\tGenerator loss: 0.9014662504196167, Discriminator loss: 1.1841611862182617\n",
      "\tGenerator loss: 0.9094532132148743, Discriminator loss: 1.1540837287902832\n",
      "\tGenerator loss: 0.899634599685669, Discriminator loss: 1.152329444885254\n",
      "\tGenerator loss: 0.9037697911262512, Discriminator loss: 1.1173512935638428\n",
      "\tGenerator loss: 0.9216805696487427, Discriminator loss: 1.119443655014038\n",
      "\tGenerator loss: 0.9555596113204956, Discriminator loss: 1.101905107498169\n",
      "\tGenerator loss: 0.9993176460266113, Discriminator loss: 1.0765795707702637\n",
      "\tGenerator loss: 1.0484217405319214, Discriminator loss: 1.0528979301452637\n",
      "\tGenerator loss: 1.0685901641845703, Discriminator loss: 1.0844755172729492\n",
      "\tGenerator loss: 1.0822652578353882, Discriminator loss: 1.035506248474121\n",
      "\tGenerator loss: 1.0809295177459717, Discriminator loss: 1.0271856784820557\n",
      "\tGenerator loss: 1.0660769939422607, Discriminator loss: 1.0629909038543701\n",
      "\tGenerator loss: 1.0705889463424683, Discriminator loss: 1.046067714691162\n",
      "\tGenerator loss: 1.061642050743103, Discriminator loss: 1.018788456916809\n",
      "\tGenerator loss: 1.0801610946655273, Discriminator loss: 1.095993995666504\n",
      "\tGenerator loss: 1.0972826480865479, Discriminator loss: 1.1206767559051514\n",
      "\tGenerator loss: 1.0972850322723389, Discriminator loss: 1.1556494235992432\n",
      "\tGenerator loss: 1.085416316986084, Discriminator loss: 1.1923657655715942\n",
      "\tGenerator loss: 1.0310052633285522, Discriminator loss: 1.2236390113830566\n",
      "\tGenerator loss: 1.0230882167816162, Discriminator loss: 1.222421646118164\n",
      "\tGenerator loss: 1.0588239431381226, Discriminator loss: 1.1280879974365234\n",
      "\tGenerator loss: 1.0362634658813477, Discriminator loss: 1.128970742225647\n",
      "\tGenerator loss: 1.0237603187561035, Discriminator loss: 1.12480890750885\n",
      "\tGenerator loss: 1.0428929328918457, Discriminator loss: 1.0751349925994873\n",
      "\tGenerator loss: 1.0906641483306885, Discriminator loss: 1.0659410953521729\n",
      "\tGenerator loss: 1.0963900089263916, Discriminator loss: 1.0823171138763428\n",
      "\tGenerator loss: 1.1354150772094727, Discriminator loss: 1.0548644065856934\n",
      "\tGenerator loss: 1.125950574874878, Discriminator loss: 1.1698840856552124\n",
      "\tGenerator loss: 1.0535227060317993, Discriminator loss: 1.216355323791504\n",
      "\tGenerator loss: 1.0062048435211182, Discriminator loss: 1.2728722095489502\n",
      "\tGenerator loss: 0.939926028251648, Discriminator loss: 1.2457693815231323\n",
      "\tGenerator loss: 0.9125598669052124, Discriminator loss: 1.2076046466827393\n",
      "\tGenerator loss: 0.9189479351043701, Discriminator loss: 1.1687471866607666\n",
      "\tGenerator loss: 0.9867054224014282, Discriminator loss: 1.211058259010315\n",
      "\tGenerator loss: 1.0390956401824951, Discriminator loss: 1.2103822231292725\n",
      "\tGenerator loss: 1.0632290840148926, Discriminator loss: 1.2537208795547485\n",
      "\tGenerator loss: 1.0622748136520386, Discriminator loss: 1.3049581050872803\n",
      "\tGenerator loss: 1.0143966674804688, Discriminator loss: 1.2342778444290161\n",
      "\tGenerator loss: 0.9622864723205566, Discriminator loss: 1.1896929740905762\n",
      "\tGenerator loss: 0.9227319359779358, Discriminator loss: 1.1976696252822876\n",
      "\tGenerator loss: 0.9160342216491699, Discriminator loss: 1.2231218814849854\n",
      "\tGenerator loss: 0.9217441082000732, Discriminator loss: 1.314610242843628\n",
      "\tGenerator loss: 0.9505742788314819, Discriminator loss: 1.3980724811553955\n",
      "\tGenerator loss: 0.978549063205719, Discriminator loss: 1.349584698677063\n",
      "\tGenerator loss: 0.9597634077072144, Discriminator loss: 1.362607717514038\n",
      "\tGenerator loss: 0.9274708032608032, Discriminator loss: 1.3645637035369873\n",
      "\tGenerator loss: 0.8961730599403381, Discriminator loss: 1.4482753276824951\n",
      "\tGenerator loss: 0.8783856630325317, Discriminator loss: 1.3649191856384277\n",
      "\tGenerator loss: 0.9111319780349731, Discriminator loss: 1.3327033519744873\n",
      "\tGenerator loss: 0.9204316139221191, Discriminator loss: 1.3047691583633423\n",
      "\tGenerator loss: 0.9408907890319824, Discriminator loss: 1.299238681793213\n",
      "\tGenerator loss: 0.9593249559402466, Discriminator loss: 1.2647902965545654\n",
      "\tGenerator loss: 0.9721711277961731, Discriminator loss: 1.219863772392273\n",
      "\tGenerator loss: 0.9975583553314209, Discriminator loss: 1.1730234622955322\n",
      "\tGenerator loss: 1.0082426071166992, Discriminator loss: 1.1278454065322876\n",
      "\tGenerator loss: 1.016442060470581, Discriminator loss: 1.1294584274291992\n",
      "\tGenerator loss: 1.023207664489746, Discriminator loss: 1.0851423740386963\n",
      "\tGenerator loss: 1.0154051780700684, Discriminator loss: 1.1001834869384766\n",
      "\tGenerator loss: 1.031873106956482, Discriminator loss: 1.0870561599731445\n",
      "\tGenerator loss: 1.0446478128433228, Discriminator loss: 1.0385560989379883\n",
      "\tGenerator loss: 1.0537545680999756, Discriminator loss: 1.0374436378479004\n",
      "\tGenerator loss: 1.105902910232544, Discriminator loss: 1.0518826246261597\n",
      "\tGenerator loss: 1.1340018510818481, Discriminator loss: 1.0936654806137085\n",
      "\tGenerator loss: 1.1614859104156494, Discriminator loss: 1.1414484977722168\n",
      "Time for epoch 47 is 214.47284173965454 sec\n",
      "\tGenerator loss: 1.1260418891906738, Discriminator loss: 1.1277915239334106\n",
      "\tGenerator loss: 1.0441635847091675, Discriminator loss: 1.1126854419708252\n",
      "\tGenerator loss: 0.9704604148864746, Discriminator loss: 1.108551263809204\n",
      "\tGenerator loss: 0.9429724216461182, Discriminator loss: 1.0929386615753174\n",
      "\tGenerator loss: 0.9440815448760986, Discriminator loss: 1.133382797241211\n",
      "\tGenerator loss: 1.0217232704162598, Discriminator loss: 1.1028404235839844\n",
      "\tGenerator loss: 1.1046788692474365, Discriminator loss: 1.0956273078918457\n",
      "\tGenerator loss: 1.146435260772705, Discriminator loss: 1.1027436256408691\n",
      "\tGenerator loss: 1.1700439453125, Discriminator loss: 1.0807669162750244\n",
      "\tGenerator loss: 1.1403840780258179, Discriminator loss: 1.0822473764419556\n",
      "\tGenerator loss: 1.0991426706314087, Discriminator loss: 1.0842232704162598\n",
      "\tGenerator loss: 1.0365420579910278, Discriminator loss: 1.1096205711364746\n",
      "\tGenerator loss: 1.0225567817687988, Discriminator loss: 1.1357182264328003\n",
      "\tGenerator loss: 0.9925402402877808, Discriminator loss: 1.1593170166015625\n",
      "\tGenerator loss: 1.0003576278686523, Discriminator loss: 1.167364239692688\n",
      "\tGenerator loss: 0.9648066163063049, Discriminator loss: 1.169623613357544\n",
      "\tGenerator loss: 0.9883722066879272, Discriminator loss: 1.156436800956726\n",
      "\tGenerator loss: 0.9777731895446777, Discriminator loss: 1.1695420742034912\n",
      "\tGenerator loss: 1.0159070491790771, Discriminator loss: 1.1961387395858765\n",
      "\tGenerator loss: 1.0117172002792358, Discriminator loss: 1.2276391983032227\n",
      "\tGenerator loss: 1.0036039352416992, Discriminator loss: 1.2093183994293213\n",
      "\tGenerator loss: 1.016145944595337, Discriminator loss: 1.183384656906128\n",
      "\tGenerator loss: 0.9887789487838745, Discriminator loss: 1.2199984788894653\n",
      "\tGenerator loss: 0.9765692949295044, Discriminator loss: 1.1878873109817505\n",
      "\tGenerator loss: 0.9775949120521545, Discriminator loss: 1.1569428443908691\n",
      "\tGenerator loss: 0.9791437983512878, Discriminator loss: 1.2173815965652466\n",
      "\tGenerator loss: 0.976783037185669, Discriminator loss: 1.349318265914917\n",
      "\tGenerator loss: 0.9313480257987976, Discriminator loss: 1.3250490427017212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9039877653121948, Discriminator loss: 1.4119902849197388\n",
      "\tGenerator loss: 0.8368687629699707, Discriminator loss: 1.3716797828674316\n",
      "\tGenerator loss: 0.7787288427352905, Discriminator loss: 1.3185713291168213\n",
      "\tGenerator loss: 0.7454719543457031, Discriminator loss: 1.338167667388916\n",
      "\tGenerator loss: 0.7724671363830566, Discriminator loss: 1.319663405418396\n",
      "\tGenerator loss: 0.8795607089996338, Discriminator loss: 1.2369554042816162\n",
      "\tGenerator loss: 0.993878960609436, Discriminator loss: 1.275282621383667\n",
      "\tGenerator loss: 1.0524134635925293, Discriminator loss: 1.3984094858169556\n",
      "\tGenerator loss: 1.049344539642334, Discriminator loss: 1.423046350479126\n",
      "\tGenerator loss: 0.971884548664093, Discriminator loss: 1.3901174068450928\n",
      "\tGenerator loss: 0.8226969242095947, Discriminator loss: 1.3871567249298096\n",
      "\tGenerator loss: 0.7330049872398376, Discriminator loss: 1.3483014106750488\n",
      "\tGenerator loss: 0.6899785995483398, Discriminator loss: 1.3545317649841309\n",
      "\tGenerator loss: 0.7241888642311096, Discriminator loss: 1.3540560007095337\n",
      "\tGenerator loss: 0.8275556564331055, Discriminator loss: 1.3052661418914795\n",
      "\tGenerator loss: 0.9127292633056641, Discriminator loss: 1.339438557624817\n",
      "\tGenerator loss: 0.9989464282989502, Discriminator loss: 1.3647513389587402\n",
      "\tGenerator loss: 1.0227991342544556, Discriminator loss: 1.3797786235809326\n",
      "\tGenerator loss: 0.9661117196083069, Discriminator loss: 1.3967905044555664\n",
      "\tGenerator loss: 0.8871046304702759, Discriminator loss: 1.3565068244934082\n",
      "\tGenerator loss: 0.7957985997200012, Discriminator loss: 1.3842597007751465\n",
      "\tGenerator loss: 0.7117220163345337, Discriminator loss: 1.3987491130828857\n",
      "\tGenerator loss: 0.6982161998748779, Discriminator loss: 1.3917491436004639\n",
      "\tGenerator loss: 0.7373139262199402, Discriminator loss: 1.3429518938064575\n",
      "\tGenerator loss: 0.8003711104393005, Discriminator loss: 1.322559118270874\n",
      "\tGenerator loss: 0.912042498588562, Discriminator loss: 1.3480660915374756\n",
      "\tGenerator loss: 0.9429817199707031, Discriminator loss: 1.3294222354888916\n",
      "\tGenerator loss: 0.9555962681770325, Discriminator loss: 1.326190710067749\n",
      "\tGenerator loss: 0.9429377317428589, Discriminator loss: 1.308168649673462\n",
      "\tGenerator loss: 0.8819482326507568, Discriminator loss: 1.275619387626648\n",
      "\tGenerator loss: 0.8468420505523682, Discriminator loss: 1.2637293338775635\n",
      "\tGenerator loss: 0.8134801387786865, Discriminator loss: 1.2375110387802124\n",
      "\tGenerator loss: 0.8204192519187927, Discriminator loss: 1.2209937572479248\n",
      "\tGenerator loss: 0.8605948686599731, Discriminator loss: 1.181695818901062\n",
      "\tGenerator loss: 0.8637264966964722, Discriminator loss: 1.225994348526001\n",
      "\tGenerator loss: 0.9211540818214417, Discriminator loss: 1.2326152324676514\n",
      "\tGenerator loss: 0.9331327080726624, Discriminator loss: 1.2130558490753174\n",
      "\tGenerator loss: 0.9694386720657349, Discriminator loss: 1.159083604812622\n",
      "\tGenerator loss: 0.9710726141929626, Discriminator loss: 1.1964170932769775\n",
      "\tGenerator loss: 0.9660505056381226, Discriminator loss: 1.1843726634979248\n",
      "\tGenerator loss: 0.9613893032073975, Discriminator loss: 1.1460180282592773\n",
      "\tGenerator loss: 0.9415991902351379, Discriminator loss: 1.1337387561798096\n",
      "\tGenerator loss: 0.9340463876724243, Discriminator loss: 1.1154276132583618\n",
      "\tGenerator loss: 0.9359699487686157, Discriminator loss: 1.1481008529663086\n",
      "\tGenerator loss: 0.9525865316390991, Discriminator loss: 1.1225799322128296\n",
      "\tGenerator loss: 0.9621976613998413, Discriminator loss: 1.1055364608764648\n",
      "\tGenerator loss: 0.9932586550712585, Discriminator loss: 1.0635905265808105\n",
      "\tGenerator loss: 1.0723518133163452, Discriminator loss: 1.155580759048462\n",
      "\tGenerator loss: 1.07838773727417, Discriminator loss: 1.224966287612915\n",
      "\tGenerator loss: 1.074709415435791, Discriminator loss: 1.2373437881469727\n",
      "\tGenerator loss: 1.067450761795044, Discriminator loss: 1.1811808347702026\n",
      "\tGenerator loss: 1.0078226327896118, Discriminator loss: 1.1524133682250977\n",
      "\tGenerator loss: 0.9711723923683167, Discriminator loss: 1.1996663808822632\n",
      "\tGenerator loss: 0.9423346519470215, Discriminator loss: 1.185166358947754\n",
      "\tGenerator loss: 0.9930362701416016, Discriminator loss: 1.10551118850708\n",
      "\tGenerator loss: 1.036200761795044, Discriminator loss: 1.1240376234054565\n",
      "\tGenerator loss: 1.0707590579986572, Discriminator loss: 1.0780365467071533\n",
      "\tGenerator loss: 1.0888519287109375, Discriminator loss: 1.2909713983535767\n",
      "\tGenerator loss: 1.0884352922439575, Discriminator loss: 1.1923699378967285\n",
      "\tGenerator loss: 1.0620989799499512, Discriminator loss: 1.2073031663894653\n",
      "\tGenerator loss: 1.0362958908081055, Discriminator loss: 1.347726583480835\n",
      "\tGenerator loss: 0.9983529448509216, Discriminator loss: 1.3751221895217896\n",
      "\tGenerator loss: 0.9215697050094604, Discriminator loss: 1.3860487937927246\n",
      "\tGenerator loss: 0.8660090565681458, Discriminator loss: 1.3453251123428345\n",
      "\tGenerator loss: 0.8479647636413574, Discriminator loss: 1.2451457977294922\n",
      "\tGenerator loss: 0.8672881722450256, Discriminator loss: 1.26302969455719\n",
      "\tGenerator loss: 0.9368411302566528, Discriminator loss: 1.3133063316345215\n",
      "\tGenerator loss: 0.9997804760932922, Discriminator loss: 1.2850199937820435\n",
      "\tGenerator loss: 1.0331816673278809, Discriminator loss: 1.3464618921279907\n",
      "\tGenerator loss: 1.0374329090118408, Discriminator loss: 1.2986102104187012\n",
      "\tGenerator loss: 0.9929969310760498, Discriminator loss: 1.2600728273391724\n",
      "\tGenerator loss: 0.9162981510162354, Discriminator loss: 1.3521509170532227\n",
      "\tGenerator loss: 0.8710155487060547, Discriminator loss: 1.2798097133636475\n",
      "\tGenerator loss: 0.8748266696929932, Discriminator loss: 1.2664660215377808\n",
      "\tGenerator loss: 0.8969945907592773, Discriminator loss: 1.2620799541473389\n",
      "\tGenerator loss: 0.9556121826171875, Discriminator loss: 1.230954647064209\n",
      "\tGenerator loss: 0.9702785015106201, Discriminator loss: 1.281761646270752\n",
      "\tGenerator loss: 0.9941401481628418, Discriminator loss: 1.2181878089904785\n",
      "\tGenerator loss: 0.9874739646911621, Discriminator loss: 1.2358635663986206\n",
      "\tGenerator loss: 0.9771465063095093, Discriminator loss: 1.215989112854004\n",
      "\tGenerator loss: 0.9407535195350647, Discriminator loss: 1.180509090423584\n",
      "\tGenerator loss: 0.9381974935531616, Discriminator loss: 1.2345110177993774\n",
      "\tGenerator loss: 0.9363217353820801, Discriminator loss: 1.2567861080169678\n",
      "\tGenerator loss: 0.9488039016723633, Discriminator loss: 1.2540407180786133\n",
      "\tGenerator loss: 0.9871461987495422, Discriminator loss: 1.181514024734497\n",
      "\tGenerator loss: 0.9939630031585693, Discriminator loss: 1.1683212518692017\n",
      "\tGenerator loss: 1.008722186088562, Discriminator loss: 1.2024608850479126\n",
      "\tGenerator loss: 1.033612847328186, Discriminator loss: 1.1642310619354248\n",
      "\tGenerator loss: 1.0130538940429688, Discriminator loss: 1.1779043674468994\n",
      "\tGenerator loss: 0.9870973229408264, Discriminator loss: 1.1632505655288696\n",
      "\tGenerator loss: 0.9536300897598267, Discriminator loss: 1.1692819595336914\n",
      "\tGenerator loss: 0.9506850242614746, Discriminator loss: 1.1568933725357056\n",
      "\tGenerator loss: 0.9329049587249756, Discriminator loss: 1.169748306274414\n",
      "\tGenerator loss: 0.9593706130981445, Discriminator loss: 1.148587942123413\n",
      "\tGenerator loss: 0.983305037021637, Discriminator loss: 1.1551693677902222\n",
      "\tGenerator loss: 0.9833084344863892, Discriminator loss: 1.1552743911743164\n",
      "\tGenerator loss: 0.9992358088493347, Discriminator loss: 1.122585654258728\n",
      "\tGenerator loss: 1.0148314237594604, Discriminator loss: 1.1510820388793945\n",
      "\tGenerator loss: 0.9978830814361572, Discriminator loss: 1.1744849681854248\n",
      "\tGenerator loss: 0.9884076118469238, Discriminator loss: 1.1952590942382812\n",
      "\tGenerator loss: 0.9541617631912231, Discriminator loss: 1.186033844947815\n",
      "\tGenerator loss: 0.946344256401062, Discriminator loss: 1.1818859577178955\n",
      "\tGenerator loss: 0.9340782761573792, Discriminator loss: 1.1829099655151367\n",
      "\tGenerator loss: 0.9329546689987183, Discriminator loss: 1.2379580736160278\n",
      "\tGenerator loss: 0.9047259092330933, Discriminator loss: 1.2695837020874023\n",
      "\tGenerator loss: 0.9166098833084106, Discriminator loss: 1.2437201738357544\n",
      "\tGenerator loss: 0.9375568628311157, Discriminator loss: 1.2244484424591064\n",
      "\tGenerator loss: 0.9382741451263428, Discriminator loss: 1.2535815238952637\n",
      "\tGenerator loss: 0.9319357872009277, Discriminator loss: 1.2297723293304443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9386464953422546, Discriminator loss: 1.219200611114502\n",
      "\tGenerator loss: 0.9339081645011902, Discriminator loss: 1.2062005996704102\n",
      "\tGenerator loss: 0.9066451787948608, Discriminator loss: 1.2384148836135864\n",
      "\tGenerator loss: 0.9030575156211853, Discriminator loss: 1.2898147106170654\n",
      "\tGenerator loss: 0.875028133392334, Discriminator loss: 1.2600538730621338\n",
      "\tGenerator loss: 0.867724597454071, Discriminator loss: 1.2451610565185547\n",
      "\tGenerator loss: 0.8750979900360107, Discriminator loss: 1.2349567413330078\n",
      "\tGenerator loss: 0.8958105444908142, Discriminator loss: 1.2591795921325684\n",
      "\tGenerator loss: 0.9270853996276855, Discriminator loss: 1.2505850791931152\n",
      "\tGenerator loss: 0.9265410304069519, Discriminator loss: 1.2970798015594482\n",
      "\tGenerator loss: 0.9142228364944458, Discriminator loss: 1.3248465061187744\n",
      "\tGenerator loss: 0.8825809359550476, Discriminator loss: 1.319451928138733\n",
      "\tGenerator loss: 0.8410705924034119, Discriminator loss: 1.348982334136963\n",
      "\tGenerator loss: 0.8175845146179199, Discriminator loss: 1.3235387802124023\n",
      "\tGenerator loss: 0.7858899235725403, Discriminator loss: 1.312766194343567\n",
      "\tGenerator loss: 0.788650631904602, Discriminator loss: 1.2948486804962158\n",
      "\tGenerator loss: 0.7787390351295471, Discriminator loss: 1.3383536338806152\n",
      "\tGenerator loss: 0.8363305330276489, Discriminator loss: 1.3339128494262695\n",
      "\tGenerator loss: 0.8765959739685059, Discriminator loss: 1.3827698230743408\n",
      "\tGenerator loss: 0.8760851621627808, Discriminator loss: 1.3756568431854248\n",
      "\tGenerator loss: 0.8858901262283325, Discriminator loss: 1.2956277132034302\n",
      "\tGenerator loss: 0.8391777276992798, Discriminator loss: 1.3284251689910889\n",
      "\tGenerator loss: 0.8060852885246277, Discriminator loss: 1.3140913248062134\n",
      "\tGenerator loss: 0.7626372575759888, Discriminator loss: 1.314880132675171\n",
      "\tGenerator loss: 0.7545909881591797, Discriminator loss: 1.3061085939407349\n",
      "\tGenerator loss: 0.8104749917984009, Discriminator loss: 1.3089648485183716\n",
      "\tGenerator loss: 0.8362901210784912, Discriminator loss: 1.3249080181121826\n",
      "\tGenerator loss: 0.8827611804008484, Discriminator loss: 1.2947748899459839\n",
      "\tGenerator loss: 0.875328540802002, Discriminator loss: 1.3040120601654053\n",
      "\tGenerator loss: 0.8922780752182007, Discriminator loss: 1.2853364944458008\n",
      "\tGenerator loss: 0.8538978099822998, Discriminator loss: 1.2597522735595703\n",
      "\tGenerator loss: 0.856501579284668, Discriminator loss: 1.2495081424713135\n",
      "\tGenerator loss: 0.8480685949325562, Discriminator loss: 1.2359099388122559\n",
      "\tGenerator loss: 0.8661471009254456, Discriminator loss: 1.2389075756072998\n",
      "\tGenerator loss: 0.8829035758972168, Discriminator loss: 1.2147246599197388\n",
      "\tGenerator loss: 0.891048789024353, Discriminator loss: 1.1801927089691162\n",
      "\tGenerator loss: 0.9053199887275696, Discriminator loss: 1.2047796249389648\n",
      "\tGenerator loss: 0.9164535999298096, Discriminator loss: 1.2064344882965088\n",
      "\tGenerator loss: 0.9370121359825134, Discriminator loss: 1.2069164514541626\n",
      "\tGenerator loss: 0.9386194944381714, Discriminator loss: 1.1853053569793701\n",
      "\tGenerator loss: 0.9578824639320374, Discriminator loss: 1.1564176082611084\n",
      "\tGenerator loss: 0.9224054217338562, Discriminator loss: 1.1676340103149414\n",
      "\tGenerator loss: 0.908176600933075, Discriminator loss: 1.1839709281921387\n",
      "\tGenerator loss: 0.9155591130256653, Discriminator loss: 1.1244746446609497\n",
      "\tGenerator loss: 0.9316381216049194, Discriminator loss: 1.149193286895752\n",
      "\tGenerator loss: 0.9631986618041992, Discriminator loss: 1.180389165878296\n",
      "\tGenerator loss: 0.9980254769325256, Discriminator loss: 1.1980926990509033\n",
      "\tGenerator loss: 1.0216771364212036, Discriminator loss: 1.1675424575805664\n",
      "\tGenerator loss: 1.0098751783370972, Discriminator loss: 1.2104182243347168\n",
      "\tGenerator loss: 0.974315345287323, Discriminator loss: 1.2592267990112305\n",
      "\tGenerator loss: 0.9186443090438843, Discriminator loss: 1.3049815893173218\n",
      "\tGenerator loss: 0.8714191913604736, Discriminator loss: 1.3481345176696777\n",
      "\tGenerator loss: 0.8957488536834717, Discriminator loss: 1.3316597938537598\n",
      "\tGenerator loss: 0.8958672285079956, Discriminator loss: 1.3062050342559814\n",
      "\tGenerator loss: 0.9126567244529724, Discriminator loss: 1.2585277557373047\n",
      "\tGenerator loss: 0.9560519456863403, Discriminator loss: 1.2245869636535645\n",
      "\tGenerator loss: 0.9886116981506348, Discriminator loss: 1.221651554107666\n",
      "\tGenerator loss: 1.0114212036132812, Discriminator loss: 1.1767356395721436\n",
      "\tGenerator loss: 0.9954887628555298, Discriminator loss: 1.1836848258972168\n",
      "\tGenerator loss: 0.9596636295318604, Discriminator loss: 1.19302499294281\n",
      "\tGenerator loss: 0.9381210803985596, Discriminator loss: 1.1729896068572998\n",
      "\tGenerator loss: 0.9221981763839722, Discriminator loss: 1.2731475830078125\n",
      "\tGenerator loss: 0.9138904213905334, Discriminator loss: 1.2763550281524658\n",
      "\tGenerator loss: 0.9257731437683105, Discriminator loss: 1.3111653327941895\n",
      "\tGenerator loss: 0.9603666067123413, Discriminator loss: 1.24527907371521\n",
      "\tGenerator loss: 0.9704084396362305, Discriminator loss: 1.2174102067947388\n",
      "\tGenerator loss: 0.9606059789657593, Discriminator loss: 1.1958105564117432\n",
      "\tGenerator loss: 0.9307358264923096, Discriminator loss: 1.2460963726043701\n",
      "\tGenerator loss: 0.930923581123352, Discriminator loss: 1.2294745445251465\n",
      "\tGenerator loss: 0.9244745373725891, Discriminator loss: 1.2464232444763184\n",
      "\tGenerator loss: 0.9415246248245239, Discriminator loss: 1.2499333620071411\n",
      "\tGenerator loss: 0.9360321760177612, Discriminator loss: 1.2279555797576904\n",
      "\tGenerator loss: 0.9589346647262573, Discriminator loss: 1.190267562866211\n",
      "\tGenerator loss: 0.9776565432548523, Discriminator loss: 1.187063455581665\n",
      "\tGenerator loss: 0.9682378768920898, Discriminator loss: 1.1869969367980957\n",
      "\tGenerator loss: 0.9774255752563477, Discriminator loss: 1.2478162050247192\n",
      "\tGenerator loss: 0.970248818397522, Discriminator loss: 1.2840702533721924\n",
      "\tGenerator loss: 0.9317740201950073, Discriminator loss: 1.2659077644348145\n",
      "\tGenerator loss: 0.9138656258583069, Discriminator loss: 1.2707350254058838\n",
      "\tGenerator loss: 0.8753607273101807, Discriminator loss: 1.2940056324005127\n",
      "\tGenerator loss: 0.8949897289276123, Discriminator loss: 1.295229434967041\n",
      "\tGenerator loss: 0.9563283920288086, Discriminator loss: 1.24137544631958\n",
      "\tGenerator loss: 0.9875487685203552, Discriminator loss: 1.2406972646713257\n",
      "\tGenerator loss: 1.0108662843704224, Discriminator loss: 1.2987847328186035\n",
      "\tGenerator loss: 0.9454491138458252, Discriminator loss: 1.2955262660980225\n",
      "\tGenerator loss: 0.9209392070770264, Discriminator loss: 1.2650448083877563\n",
      "\tGenerator loss: 0.8698270320892334, Discriminator loss: 1.2382900714874268\n",
      "\tGenerator loss: 0.895157516002655, Discriminator loss: 1.1956112384796143\n",
      "\tGenerator loss: 0.9265800714492798, Discriminator loss: 1.204185962677002\n",
      "\tGenerator loss: 0.9599156379699707, Discriminator loss: 1.2382290363311768\n",
      "\tGenerator loss: 0.9846162796020508, Discriminator loss: 1.2006547451019287\n",
      "\tGenerator loss: 1.015743613243103, Discriminator loss: 1.1922202110290527\n",
      "\tGenerator loss: 0.9869822263717651, Discriminator loss: 1.1753281354904175\n",
      "\tGenerator loss: 0.9320497512817383, Discriminator loss: 1.1497700214385986\n",
      "\tGenerator loss: 0.8933576345443726, Discriminator loss: 1.1640498638153076\n",
      "\tGenerator loss: 0.926407516002655, Discriminator loss: 1.167405605316162\n",
      "\tGenerator loss: 1.016005039215088, Discriminator loss: 1.1729460954666138\n",
      "\tGenerator loss: 1.1005300283432007, Discriminator loss: 1.248744249343872\n",
      "Time for epoch 48 is 208.4189167022705 sec\n",
      "\tGenerator loss: 1.1044716835021973, Discriminator loss: 1.2585206031799316\n",
      "\tGenerator loss: 1.0130045413970947, Discriminator loss: 1.2590336799621582\n",
      "\tGenerator loss: 0.8697199821472168, Discriminator loss: 1.2752224206924438\n",
      "\tGenerator loss: 0.8056002259254456, Discriminator loss: 1.2530428171157837\n",
      "\tGenerator loss: 0.7732335329055786, Discriminator loss: 1.2934327125549316\n",
      "\tGenerator loss: 0.8352067470550537, Discriminator loss: 1.2721948623657227\n",
      "\tGenerator loss: 0.9359413385391235, Discriminator loss: 1.2819615602493286\n",
      "\tGenerator loss: 1.0087690353393555, Discriminator loss: 1.3163158893585205\n",
      "\tGenerator loss: 1.0345721244812012, Discriminator loss: 1.296284794807434\n",
      "\tGenerator loss: 1.000096321105957, Discriminator loss: 1.2617499828338623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.9202861785888672, Discriminator loss: 1.2833995819091797\n",
      "\tGenerator loss: 0.862636148929596, Discriminator loss: 1.2764841318130493\n",
      "\tGenerator loss: 0.8285552263259888, Discriminator loss: 1.2927806377410889\n",
      "\tGenerator loss: 0.8159209489822388, Discriminator loss: 1.2996864318847656\n",
      "\tGenerator loss: 0.8215528130531311, Discriminator loss: 1.3536266088485718\n",
      "\tGenerator loss: 0.8552128076553345, Discriminator loss: 1.3179117441177368\n",
      "\tGenerator loss: 0.856593132019043, Discriminator loss: 1.3271231651306152\n",
      "\tGenerator loss: 0.8774816989898682, Discriminator loss: 1.3174610137939453\n",
      "\tGenerator loss: 0.8891677260398865, Discriminator loss: 1.3584613800048828\n",
      "\tGenerator loss: 0.858751654624939, Discriminator loss: 1.376894474029541\n",
      "\tGenerator loss: 0.8563473224639893, Discriminator loss: 1.3286174535751343\n",
      "\tGenerator loss: 0.8669925928115845, Discriminator loss: 1.2984898090362549\n",
      "\tGenerator loss: 0.8835651278495789, Discriminator loss: 1.3064271211624146\n",
      "\tGenerator loss: 0.8715158700942993, Discriminator loss: 1.28969144821167\n",
      "\tGenerator loss: 0.8983221054077148, Discriminator loss: 1.279522180557251\n",
      "\tGenerator loss: 0.9316970109939575, Discriminator loss: 1.2954862117767334\n",
      "\tGenerator loss: 0.9204614162445068, Discriminator loss: 1.3857507705688477\n",
      "\tGenerator loss: 0.881935179233551, Discriminator loss: 1.3590872287750244\n",
      "\tGenerator loss: 0.8383792638778687, Discriminator loss: 1.4368785619735718\n",
      "\tGenerator loss: 0.791635274887085, Discriminator loss: 1.3900830745697021\n",
      "\tGenerator loss: 0.741353452205658, Discriminator loss: 1.3399789333343506\n",
      "\tGenerator loss: 0.7173097133636475, Discriminator loss: 1.3316199779510498\n",
      "\tGenerator loss: 0.7593886852264404, Discriminator loss: 1.293396234512329\n",
      "\tGenerator loss: 0.8360515832901001, Discriminator loss: 1.2685596942901611\n",
      "\tGenerator loss: 0.9737890958786011, Discriminator loss: 1.289496660232544\n",
      "\tGenerator loss: 1.0656059980392456, Discriminator loss: 1.3626441955566406\n",
      "\tGenerator loss: 1.0321295261383057, Discriminator loss: 1.404289960861206\n",
      "\tGenerator loss: 0.9118669629096985, Discriminator loss: 1.3893365859985352\n",
      "\tGenerator loss: 0.799691915512085, Discriminator loss: 1.3555243015289307\n",
      "\tGenerator loss: 0.7286996841430664, Discriminator loss: 1.3482460975646973\n",
      "\tGenerator loss: 0.723706066608429, Discriminator loss: 1.314229965209961\n",
      "\tGenerator loss: 0.786213755607605, Discriminator loss: 1.2864363193511963\n",
      "\tGenerator loss: 0.865319013595581, Discriminator loss: 1.2430394887924194\n",
      "\tGenerator loss: 0.9450068473815918, Discriminator loss: 1.2599332332611084\n",
      "\tGenerator loss: 1.0269691944122314, Discriminator loss: 1.28750479221344\n",
      "\tGenerator loss: 1.0573577880859375, Discriminator loss: 1.2778244018554688\n",
      "\tGenerator loss: 1.008623480796814, Discriminator loss: 1.262424349784851\n",
      "\tGenerator loss: 0.9270337224006653, Discriminator loss: 1.2456659078598022\n",
      "\tGenerator loss: 0.8279697895050049, Discriminator loss: 1.2553997039794922\n",
      "\tGenerator loss: 0.7755159139633179, Discriminator loss: 1.2595349550247192\n",
      "\tGenerator loss: 0.7892603874206543, Discriminator loss: 1.2495684623718262\n",
      "\tGenerator loss: 0.8458124995231628, Discriminator loss: 1.2140501737594604\n",
      "\tGenerator loss: 0.8799363970756531, Discriminator loss: 1.2095890045166016\n",
      "\tGenerator loss: 0.9673770666122437, Discriminator loss: 1.230370044708252\n",
      "\tGenerator loss: 0.9977023601531982, Discriminator loss: 1.2231135368347168\n",
      "\tGenerator loss: 1.0205600261688232, Discriminator loss: 1.2084903717041016\n",
      "\tGenerator loss: 0.9987348318099976, Discriminator loss: 1.1964911222457886\n",
      "\tGenerator loss: 0.961525559425354, Discriminator loss: 1.1714653968811035\n",
      "\tGenerator loss: 0.8893726468086243, Discriminator loss: 1.197340488433838\n",
      "\tGenerator loss: 0.8435052633285522, Discriminator loss: 1.184299111366272\n",
      "\tGenerator loss: 0.8681976199150085, Discriminator loss: 1.1445484161376953\n",
      "\tGenerator loss: 0.894294261932373, Discriminator loss: 1.1266329288482666\n",
      "\tGenerator loss: 0.8995181322097778, Discriminator loss: 1.1846269369125366\n",
      "\tGenerator loss: 0.9564984440803528, Discriminator loss: 1.187699794769287\n",
      "\tGenerator loss: 1.0104080438613892, Discriminator loss: 1.1825491189956665\n",
      "\tGenerator loss: 1.0189712047576904, Discriminator loss: 1.1556894779205322\n",
      "\tGenerator loss: 0.9947220087051392, Discriminator loss: 1.1688048839569092\n",
      "\tGenerator loss: 0.9645273685455322, Discriminator loss: 1.1597682237625122\n",
      "\tGenerator loss: 0.9139909744262695, Discriminator loss: 1.147603988647461\n",
      "\tGenerator loss: 0.8774706125259399, Discriminator loss: 1.172773838043213\n",
      "\tGenerator loss: 0.8658843040466309, Discriminator loss: 1.183095932006836\n",
      "\tGenerator loss: 0.9095252752304077, Discriminator loss: 1.2256871461868286\n",
      "\tGenerator loss: 0.9358131885528564, Discriminator loss: 1.1796271800994873\n",
      "\tGenerator loss: 0.9822428822517395, Discriminator loss: 1.163559913635254\n",
      "\tGenerator loss: 0.9841421246528625, Discriminator loss: 1.1341910362243652\n",
      "\tGenerator loss: 1.0138615369796753, Discriminator loss: 1.2060878276824951\n",
      "\tGenerator loss: 0.9858573079109192, Discriminator loss: 1.2741193771362305\n",
      "\tGenerator loss: 0.9456264972686768, Discriminator loss: 1.2849117517471313\n",
      "\tGenerator loss: 0.9396359920501709, Discriminator loss: 1.2689487934112549\n",
      "\tGenerator loss: 0.8971351981163025, Discriminator loss: 1.2446856498718262\n",
      "\tGenerator loss: 0.8970696330070496, Discriminator loss: 1.2362284660339355\n",
      "\tGenerator loss: 0.8815946578979492, Discriminator loss: 1.2222870588302612\n",
      "\tGenerator loss: 0.9476331472396851, Discriminator loss: 1.1531271934509277\n",
      "\tGenerator loss: 0.9872041344642639, Discriminator loss: 1.1878749132156372\n",
      "\tGenerator loss: 1.0114221572875977, Discriminator loss: 1.1514673233032227\n",
      "\tGenerator loss: 1.0153980255126953, Discriminator loss: 1.242139458656311\n",
      "\tGenerator loss: 0.989124059677124, Discriminator loss: 1.189789056777954\n",
      "\tGenerator loss: 0.9684386849403381, Discriminator loss: 1.1969408988952637\n",
      "\tGenerator loss: 0.9638277292251587, Discriminator loss: 1.2318038940429688\n",
      "\tGenerator loss: 0.9226837754249573, Discriminator loss: 1.2581799030303955\n",
      "\tGenerator loss: 0.8888243436813354, Discriminator loss: 1.2908488512039185\n",
      "\tGenerator loss: 0.886578381061554, Discriminator loss: 1.2511873245239258\n",
      "\tGenerator loss: 0.9280635118484497, Discriminator loss: 1.1928353309631348\n",
      "\tGenerator loss: 0.9615185260772705, Discriminator loss: 1.226843237876892\n",
      "\tGenerator loss: 0.9808197021484375, Discriminator loss: 1.246245265007019\n",
      "\tGenerator loss: 0.9660638570785522, Discriminator loss: 1.2157015800476074\n",
      "\tGenerator loss: 0.9235752820968628, Discriminator loss: 1.2545666694641113\n",
      "\tGenerator loss: 0.8781161308288574, Discriminator loss: 1.2584080696105957\n",
      "\tGenerator loss: 0.8712031841278076, Discriminator loss: 1.2335481643676758\n",
      "\tGenerator loss: 0.8684936165809631, Discriminator loss: 1.2840043306350708\n",
      "\tGenerator loss: 0.8931609392166138, Discriminator loss: 1.2454581260681152\n",
      "\tGenerator loss: 0.8994346857070923, Discriminator loss: 1.2530457973480225\n",
      "\tGenerator loss: 0.9146701693534851, Discriminator loss: 1.2741420269012451\n",
      "\tGenerator loss: 0.9286051988601685, Discriminator loss: 1.2712544202804565\n",
      "\tGenerator loss: 0.9064103364944458, Discriminator loss: 1.2740600109100342\n",
      "\tGenerator loss: 0.8690823316574097, Discriminator loss: 1.243898868560791\n",
      "\tGenerator loss: 0.878995418548584, Discriminator loss: 1.254112958908081\n",
      "\tGenerator loss: 0.846227765083313, Discriminator loss: 1.2880817651748657\n",
      "\tGenerator loss: 0.8784844279289246, Discriminator loss: 1.248192310333252\n",
      "\tGenerator loss: 0.8959330916404724, Discriminator loss: 1.2349075078964233\n",
      "\tGenerator loss: 0.9180229306221008, Discriminator loss: 1.2629108428955078\n",
      "\tGenerator loss: 0.903843879699707, Discriminator loss: 1.3070626258850098\n",
      "\tGenerator loss: 0.935643196105957, Discriminator loss: 1.260393500328064\n",
      "\tGenerator loss: 0.8973861932754517, Discriminator loss: 1.3008103370666504\n",
      "\tGenerator loss: 0.8682048916816711, Discriminator loss: 1.329114556312561\n",
      "\tGenerator loss: 0.8435399532318115, Discriminator loss: 1.313443660736084\n",
      "\tGenerator loss: 0.817733883857727, Discriminator loss: 1.3432748317718506\n",
      "\tGenerator loss: 0.809377908706665, Discriminator loss: 1.341098666191101\n",
      "\tGenerator loss: 0.8118593692779541, Discriminator loss: 1.311279058456421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8206007480621338, Discriminator loss: 1.3178532123565674\n",
      "\tGenerator loss: 0.8444002270698547, Discriminator loss: 1.32178795337677\n",
      "\tGenerator loss: 0.8686947822570801, Discriminator loss: 1.2917389869689941\n",
      "\tGenerator loss: 0.8583037853240967, Discriminator loss: 1.30765700340271\n",
      "\tGenerator loss: 0.840501070022583, Discriminator loss: 1.3131372928619385\n",
      "\tGenerator loss: 0.8315265774726868, Discriminator loss: 1.2808504104614258\n",
      "\tGenerator loss: 0.8096985816955566, Discriminator loss: 1.336220622062683\n",
      "\tGenerator loss: 0.819831371307373, Discriminator loss: 1.3471693992614746\n",
      "\tGenerator loss: 0.8143874406814575, Discriminator loss: 1.3564791679382324\n",
      "\tGenerator loss: 0.8009957075119019, Discriminator loss: 1.346484899520874\n",
      "\tGenerator loss: 0.7968682050704956, Discriminator loss: 1.3720985651016235\n",
      "\tGenerator loss: 0.8165770769119263, Discriminator loss: 1.308034896850586\n",
      "\tGenerator loss: 0.8247480392456055, Discriminator loss: 1.356476068496704\n",
      "\tGenerator loss: 0.8238760828971863, Discriminator loss: 1.3665403127670288\n",
      "\tGenerator loss: 0.8108060359954834, Discriminator loss: 1.3431901931762695\n",
      "\tGenerator loss: 0.8046945333480835, Discriminator loss: 1.3356044292449951\n",
      "\tGenerator loss: 0.8073883056640625, Discriminator loss: 1.3818933963775635\n",
      "\tGenerator loss: 0.8002930879592896, Discriminator loss: 1.3853285312652588\n",
      "\tGenerator loss: 0.810877799987793, Discriminator loss: 1.3344166278839111\n",
      "\tGenerator loss: 0.7991369962692261, Discriminator loss: 1.337414026260376\n",
      "\tGenerator loss: 0.8227325081825256, Discriminator loss: 1.3260735273361206\n",
      "\tGenerator loss: 0.8326705694198608, Discriminator loss: 1.2938499450683594\n",
      "\tGenerator loss: 0.8268766403198242, Discriminator loss: 1.318995475769043\n",
      "\tGenerator loss: 0.8411833047866821, Discriminator loss: 1.3142030239105225\n",
      "\tGenerator loss: 0.8485003113746643, Discriminator loss: 1.3202842473983765\n",
      "\tGenerator loss: 0.8457958698272705, Discriminator loss: 1.3270630836486816\n",
      "\tGenerator loss: 0.8382624983787537, Discriminator loss: 1.3142602443695068\n",
      "\tGenerator loss: 0.8461835980415344, Discriminator loss: 1.2888240814208984\n",
      "\tGenerator loss: 0.8521440029144287, Discriminator loss: 1.2726198434829712\n",
      "\tGenerator loss: 0.8587588667869568, Discriminator loss: 1.2728767395019531\n",
      "\tGenerator loss: 0.86834716796875, Discriminator loss: 1.2823784351348877\n",
      "\tGenerator loss: 0.8652164936065674, Discriminator loss: 1.2758234739303589\n",
      "\tGenerator loss: 0.855663537979126, Discriminator loss: 1.239487648010254\n",
      "\tGenerator loss: 0.8457605838775635, Discriminator loss: 1.2226252555847168\n",
      "\tGenerator loss: 0.8357083797454834, Discriminator loss: 1.26801335811615\n",
      "\tGenerator loss: 0.8599224090576172, Discriminator loss: 1.2689740657806396\n",
      "\tGenerator loss: 0.8741186857223511, Discriminator loss: 1.2503868341445923\n",
      "\tGenerator loss: 0.9229545593261719, Discriminator loss: 1.2489910125732422\n",
      "\tGenerator loss: 0.8959929347038269, Discriminator loss: 1.2226487398147583\n",
      "\tGenerator loss: 0.8693026900291443, Discriminator loss: 1.2548465728759766\n",
      "\tGenerator loss: 0.8646224737167358, Discriminator loss: 1.2297180891036987\n",
      "\tGenerator loss: 0.873422384262085, Discriminator loss: 1.2103533744812012\n",
      "\tGenerator loss: 0.8721679449081421, Discriminator loss: 1.214353322982788\n",
      "\tGenerator loss: 0.9118710160255432, Discriminator loss: 1.231713056564331\n",
      "\tGenerator loss: 0.9304391145706177, Discriminator loss: 1.2197682857513428\n",
      "\tGenerator loss: 0.9015405178070068, Discriminator loss: 1.2436840534210205\n",
      "\tGenerator loss: 0.8847008347511292, Discriminator loss: 1.2243945598602295\n",
      "\tGenerator loss: 0.873621940612793, Discriminator loss: 1.2359671592712402\n",
      "\tGenerator loss: 0.8669007420539856, Discriminator loss: 1.2078869342803955\n",
      "\tGenerator loss: 0.9045451879501343, Discriminator loss: 1.1829012632369995\n",
      "\tGenerator loss: 0.9495121836662292, Discriminator loss: 1.1418319940567017\n",
      "\tGenerator loss: 0.9785951375961304, Discriminator loss: 1.1573545932769775\n",
      "\tGenerator loss: 0.992100715637207, Discriminator loss: 1.139928936958313\n",
      "\tGenerator loss: 0.9811975359916687, Discriminator loss: 1.11448073387146\n",
      "\tGenerator loss: 0.9829857349395752, Discriminator loss: 1.1161824464797974\n",
      "\tGenerator loss: 0.9544104933738708, Discriminator loss: 1.1402404308319092\n",
      "\tGenerator loss: 0.9309521913528442, Discriminator loss: 1.1572635173797607\n",
      "\tGenerator loss: 0.9163873195648193, Discriminator loss: 1.161668062210083\n",
      "\tGenerator loss: 0.8929588198661804, Discriminator loss: 1.1579564809799194\n",
      "\tGenerator loss: 0.9247375726699829, Discriminator loss: 1.1572155952453613\n",
      "\tGenerator loss: 0.972217857837677, Discriminator loss: 1.1820873022079468\n",
      "\tGenerator loss: 0.9676091074943542, Discriminator loss: 1.1417534351348877\n",
      "\tGenerator loss: 0.9394521713256836, Discriminator loss: 1.1498417854309082\n",
      "\tGenerator loss: 0.9043686985969543, Discriminator loss: 1.1678718328475952\n",
      "\tGenerator loss: 0.9338068962097168, Discriminator loss: 1.1573140621185303\n",
      "\tGenerator loss: 0.969255805015564, Discriminator loss: 1.157606601715088\n",
      "\tGenerator loss: 0.9630884528160095, Discriminator loss: 1.193407654762268\n",
      "\tGenerator loss: 0.968620777130127, Discriminator loss: 1.1881389617919922\n",
      "\tGenerator loss: 0.9594269394874573, Discriminator loss: 1.229278564453125\n",
      "\tGenerator loss: 0.9385010004043579, Discriminator loss: 1.2407605648040771\n",
      "\tGenerator loss: 0.906330943107605, Discriminator loss: 1.2671899795532227\n",
      "\tGenerator loss: 0.9189193248748779, Discriminator loss: 1.2621638774871826\n",
      "\tGenerator loss: 0.9254181385040283, Discriminator loss: 1.2342729568481445\n",
      "\tGenerator loss: 0.9201641082763672, Discriminator loss: 1.2152900695800781\n",
      "\tGenerator loss: 0.9054406881332397, Discriminator loss: 1.2197189331054688\n",
      "\tGenerator loss: 0.9196677803993225, Discriminator loss: 1.1923418045043945\n",
      "\tGenerator loss: 0.9072848558425903, Discriminator loss: 1.2159106731414795\n",
      "\tGenerator loss: 0.9400858879089355, Discriminator loss: 1.2142362594604492\n",
      "\tGenerator loss: 0.919593870639801, Discriminator loss: 1.1940076351165771\n",
      "\tGenerator loss: 0.8898248672485352, Discriminator loss: 1.2860898971557617\n",
      "\tGenerator loss: 0.8778971433639526, Discriminator loss: 1.273770809173584\n",
      "\tGenerator loss: 0.9065335988998413, Discriminator loss: 1.2845633029937744\n",
      "\tGenerator loss: 0.9338167905807495, Discriminator loss: 1.2469534873962402\n",
      "\tGenerator loss: 0.959585428237915, Discriminator loss: 1.2441937923431396\n",
      "\tGenerator loss: 0.9602538347244263, Discriminator loss: 1.2275986671447754\n",
      "\tGenerator loss: 0.9150029420852661, Discriminator loss: 1.2502381801605225\n",
      "\tGenerator loss: 0.872553288936615, Discriminator loss: 1.238471508026123\n",
      "\tGenerator loss: 0.855663537979126, Discriminator loss: 1.244662880897522\n",
      "\tGenerator loss: 0.8598847985267639, Discriminator loss: 1.239415168762207\n",
      "\tGenerator loss: 0.8917917013168335, Discriminator loss: 1.242567539215088\n",
      "\tGenerator loss: 0.9195981025695801, Discriminator loss: 1.2431827783584595\n",
      "\tGenerator loss: 0.9506968855857849, Discriminator loss: 1.2474477291107178\n",
      "\tGenerator loss: 0.9597302675247192, Discriminator loss: 1.2454946041107178\n",
      "\tGenerator loss: 0.8996156454086304, Discriminator loss: 1.3067950010299683\n",
      "\tGenerator loss: 0.8495321273803711, Discriminator loss: 1.3496564626693726\n",
      "\tGenerator loss: 0.828583836555481, Discriminator loss: 1.3305208683013916\n",
      "\tGenerator loss: 0.8274438381195068, Discriminator loss: 1.3604334592819214\n",
      "\tGenerator loss: 0.8238227367401123, Discriminator loss: 1.361055850982666\n",
      "\tGenerator loss: 0.8404276371002197, Discriminator loss: 1.3808565139770508\n",
      "\tGenerator loss: 0.8525933623313904, Discriminator loss: 1.3655869960784912\n",
      "\tGenerator loss: 0.8836828470230103, Discriminator loss: 1.3653345108032227\n",
      "\tGenerator loss: 0.8958677649497986, Discriminator loss: 1.3850159645080566\n",
      "\tGenerator loss: 0.8651794195175171, Discriminator loss: 1.3740023374557495\n",
      "\tGenerator loss: 0.8172844052314758, Discriminator loss: 1.4012181758880615\n",
      "\tGenerator loss: 0.7714881896972656, Discriminator loss: 1.3711082935333252\n",
      "\tGenerator loss: 0.7676483988761902, Discriminator loss: 1.338226556777954\n",
      "\tGenerator loss: 0.8166587352752686, Discriminator loss: 1.3202683925628662\n",
      "\tGenerator loss: 0.8574441075325012, Discriminator loss: 1.3358843326568604\n",
      "\tGenerator loss: 0.8851028680801392, Discriminator loss: 1.321761965751648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8805707693099976, Discriminator loss: 1.377336025238037\n",
      "\tGenerator loss: 0.828560471534729, Discriminator loss: 1.3579760789871216\n",
      "\tGenerator loss: 0.804832935333252, Discriminator loss: 1.3078758716583252\n",
      "\tGenerator loss: 0.77855384349823, Discriminator loss: 1.3050751686096191\n",
      "\tGenerator loss: 0.8034475445747375, Discriminator loss: 1.311335802078247\n",
      "\tGenerator loss: 0.8614840507507324, Discriminator loss: 1.3332961797714233\n",
      "\tGenerator loss: 0.9127986431121826, Discriminator loss: 1.3714148998260498\n",
      "Time for epoch 49 is 212.26299357414246 sec\n",
      "\tGenerator loss: 0.9406111836433411, Discriminator loss: 1.3493359088897705\n",
      "\tGenerator loss: 0.89690101146698, Discriminator loss: 1.3336178064346313\n",
      "\tGenerator loss: 0.8061063289642334, Discriminator loss: 1.326317548751831\n",
      "\tGenerator loss: 0.746006965637207, Discriminator loss: 1.3237160444259644\n",
      "\tGenerator loss: 0.751339316368103, Discriminator loss: 1.3354780673980713\n",
      "\tGenerator loss: 0.7925572395324707, Discriminator loss: 1.307449221611023\n",
      "\tGenerator loss: 0.8669830560684204, Discriminator loss: 1.3038873672485352\n",
      "\tGenerator loss: 0.9243838787078857, Discriminator loss: 1.3322601318359375\n",
      "\tGenerator loss: 0.9311187267303467, Discriminator loss: 1.3508092164993286\n",
      "\tGenerator loss: 0.9256381392478943, Discriminator loss: 1.2990288734436035\n",
      "\tGenerator loss: 0.893417239189148, Discriminator loss: 1.2910192012786865\n",
      "\tGenerator loss: 0.8248704671859741, Discriminator loss: 1.3049393892288208\n",
      "\tGenerator loss: 0.8027729988098145, Discriminator loss: 1.3083906173706055\n",
      "\tGenerator loss: 0.7921949625015259, Discriminator loss: 1.2962759733200073\n",
      "\tGenerator loss: 0.8113296031951904, Discriminator loss: 1.3126883506774902\n",
      "\tGenerator loss: 0.8491644859313965, Discriminator loss: 1.3079774379730225\n",
      "\tGenerator loss: 0.8669554591178894, Discriminator loss: 1.3102389574050903\n",
      "\tGenerator loss: 0.8705059289932251, Discriminator loss: 1.2983753681182861\n",
      "\tGenerator loss: 0.8801663517951965, Discriminator loss: 1.315977692604065\n",
      "\tGenerator loss: 0.8721674680709839, Discriminator loss: 1.3227837085723877\n",
      "\tGenerator loss: 0.8621412515640259, Discriminator loss: 1.2787749767303467\n",
      "\tGenerator loss: 0.8358970880508423, Discriminator loss: 1.2854406833648682\n",
      "\tGenerator loss: 0.8567123413085938, Discriminator loss: 1.2752151489257812\n",
      "\tGenerator loss: 0.8867601156234741, Discriminator loss: 1.2552850246429443\n",
      "\tGenerator loss: 0.9206762909889221, Discriminator loss: 1.2617210149765015\n",
      "\tGenerator loss: 0.9132643938064575, Discriminator loss: 1.2575044631958008\n",
      "\tGenerator loss: 0.9128630757331848, Discriminator loss: 1.2757859230041504\n",
      "\tGenerator loss: 0.898902416229248, Discriminator loss: 1.2473164796829224\n",
      "\tGenerator loss: 0.8647122383117676, Discriminator loss: 1.260488510131836\n",
      "\tGenerator loss: 0.8183434009552002, Discriminator loss: 1.2521089315414429\n",
      "\tGenerator loss: 0.7837543487548828, Discriminator loss: 1.2401652336120605\n",
      "\tGenerator loss: 0.8167022466659546, Discriminator loss: 1.2353757619857788\n",
      "\tGenerator loss: 0.9104793667793274, Discriminator loss: 1.1778004169464111\n",
      "\tGenerator loss: 0.9771456718444824, Discriminator loss: 1.1997711658477783\n",
      "\tGenerator loss: 0.9994858503341675, Discriminator loss: 1.2095369100570679\n",
      "\tGenerator loss: 0.9942163825035095, Discriminator loss: 1.2279143333435059\n",
      "\tGenerator loss: 0.9527422785758972, Discriminator loss: 1.2353787422180176\n",
      "\tGenerator loss: 0.8901373147964478, Discriminator loss: 1.264253854751587\n",
      "\tGenerator loss: 0.8427292108535767, Discriminator loss: 1.1935536861419678\n",
      "\tGenerator loss: 0.8166948556900024, Discriminator loss: 1.1845004558563232\n",
      "\tGenerator loss: 0.8500421047210693, Discriminator loss: 1.1974859237670898\n",
      "\tGenerator loss: 0.9110915064811707, Discriminator loss: 1.18290376663208\n",
      "\tGenerator loss: 1.0032490491867065, Discriminator loss: 1.1848082542419434\n",
      "\tGenerator loss: 1.0368163585662842, Discriminator loss: 1.2088847160339355\n",
      "\tGenerator loss: 1.068161129951477, Discriminator loss: 1.1889053583145142\n",
      "\tGenerator loss: 0.9977731704711914, Discriminator loss: 1.1866135597229004\n",
      "\tGenerator loss: 0.9145952463150024, Discriminator loss: 1.2113221883773804\n",
      "\tGenerator loss: 0.8359039425849915, Discriminator loss: 1.205941915512085\n",
      "\tGenerator loss: 0.8180400133132935, Discriminator loss: 1.1879591941833496\n",
      "\tGenerator loss: 0.8661144971847534, Discriminator loss: 1.1618633270263672\n",
      "\tGenerator loss: 0.9518637657165527, Discriminator loss: 1.1750940084457397\n",
      "\tGenerator loss: 1.0088354349136353, Discriminator loss: 1.15353524684906\n",
      "\tGenerator loss: 1.0402569770812988, Discriminator loss: 1.1498684883117676\n",
      "\tGenerator loss: 1.0630005598068237, Discriminator loss: 1.1840360164642334\n",
      "\tGenerator loss: 1.022702932357788, Discriminator loss: 1.1591742038726807\n",
      "\tGenerator loss: 0.9146238565444946, Discriminator loss: 1.2074819803237915\n",
      "\tGenerator loss: 0.8851175308227539, Discriminator loss: 1.1783740520477295\n",
      "\tGenerator loss: 0.8684346675872803, Discriminator loss: 1.1738688945770264\n",
      "\tGenerator loss: 0.8609210252761841, Discriminator loss: 1.1953320503234863\n",
      "\tGenerator loss: 0.8976739048957825, Discriminator loss: 1.1706030368804932\n",
      "\tGenerator loss: 0.9884752035140991, Discriminator loss: 1.136016607284546\n",
      "\tGenerator loss: 0.9914657473564148, Discriminator loss: 1.156934142112732\n",
      "\tGenerator loss: 1.0040980577468872, Discriminator loss: 1.20253324508667\n",
      "\tGenerator loss: 0.9601484537124634, Discriminator loss: 1.2028597593307495\n",
      "\tGenerator loss: 0.8940732479095459, Discriminator loss: 1.202622890472412\n",
      "\tGenerator loss: 0.8519442081451416, Discriminator loss: 1.1817435026168823\n",
      "\tGenerator loss: 0.840707004070282, Discriminator loss: 1.1858210563659668\n",
      "\tGenerator loss: 0.8561031818389893, Discriminator loss: 1.1930776834487915\n",
      "\tGenerator loss: 0.8872182369232178, Discriminator loss: 1.2228611707687378\n",
      "\tGenerator loss: 0.946807324886322, Discriminator loss: 1.2410848140716553\n",
      "\tGenerator loss: 0.9799517393112183, Discriminator loss: 1.2220823764801025\n",
      "\tGenerator loss: 0.9380630254745483, Discriminator loss: 1.2534606456756592\n",
      "\tGenerator loss: 0.8960368633270264, Discriminator loss: 1.2271407842636108\n",
      "\tGenerator loss: 0.8496953248977661, Discriminator loss: 1.2091107368469238\n",
      "\tGenerator loss: 0.8146721720695496, Discriminator loss: 1.2091460227966309\n",
      "\tGenerator loss: 0.827243447303772, Discriminator loss: 1.2583417892456055\n",
      "\tGenerator loss: 0.8924740552902222, Discriminator loss: 1.2944691181182861\n",
      "\tGenerator loss: 0.9759749174118042, Discriminator loss: 1.267953634262085\n",
      "\tGenerator loss: 0.9705716967582703, Discriminator loss: 1.2679656744003296\n",
      "\tGenerator loss: 0.968482494354248, Discriminator loss: 1.2529698610305786\n",
      "\tGenerator loss: 0.9279654026031494, Discriminator loss: 1.2628755569458008\n",
      "\tGenerator loss: 0.8721486330032349, Discriminator loss: 1.25954270362854\n",
      "\tGenerator loss: 0.8479103446006775, Discriminator loss: 1.249322533607483\n",
      "\tGenerator loss: 0.823333740234375, Discriminator loss: 1.2632114887237549\n",
      "\tGenerator loss: 0.819871187210083, Discriminator loss: 1.2576990127563477\n",
      "\tGenerator loss: 0.8543189167976379, Discriminator loss: 1.2812561988830566\n",
      "\tGenerator loss: 0.9185488224029541, Discriminator loss: 1.2327296733856201\n",
      "\tGenerator loss: 0.9716896414756775, Discriminator loss: 1.2657639980316162\n",
      "\tGenerator loss: 0.9480283260345459, Discriminator loss: 1.3136701583862305\n",
      "\tGenerator loss: 0.9359751343727112, Discriminator loss: 1.292709231376648\n",
      "\tGenerator loss: 0.8639790415763855, Discriminator loss: 1.323872685432434\n",
      "\tGenerator loss: 0.8027399778366089, Discriminator loss: 1.3145959377288818\n",
      "\tGenerator loss: 0.7710385322570801, Discriminator loss: 1.3101791143417358\n",
      "\tGenerator loss: 0.7827582955360413, Discriminator loss: 1.3421258926391602\n",
      "\tGenerator loss: 0.8358907699584961, Discriminator loss: 1.3439644575119019\n",
      "\tGenerator loss: 0.8769744634628296, Discriminator loss: 1.3142378330230713\n",
      "\tGenerator loss: 0.900154173374176, Discriminator loss: 1.330540657043457\n",
      "\tGenerator loss: 0.8791623711585999, Discriminator loss: 1.3239420652389526\n",
      "\tGenerator loss: 0.8285309672355652, Discriminator loss: 1.3292443752288818\n",
      "\tGenerator loss: 0.8178924322128296, Discriminator loss: 1.3319615125656128\n",
      "\tGenerator loss: 0.8129656314849854, Discriminator loss: 1.3230568170547485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.8152477145195007, Discriminator loss: 1.3322560787200928\n",
      "\tGenerator loss: 0.831363320350647, Discriminator loss: 1.3508166074752808\n",
      "\tGenerator loss: 0.8560906648635864, Discriminator loss: 1.3645955324172974\n",
      "\tGenerator loss: 0.8309641480445862, Discriminator loss: 1.369215726852417\n",
      "\tGenerator loss: 0.8068283200263977, Discriminator loss: 1.3572518825531006\n",
      "\tGenerator loss: 0.8101013898849487, Discriminator loss: 1.3416043519973755\n",
      "\tGenerator loss: 0.7930613160133362, Discriminator loss: 1.3325327634811401\n",
      "\tGenerator loss: 0.8033643960952759, Discriminator loss: 1.327148199081421\n",
      "\tGenerator loss: 0.8311284780502319, Discriminator loss: 1.3081258535385132\n",
      "\tGenerator loss: 0.8301048874855042, Discriminator loss: 1.3302509784698486\n",
      "\tGenerator loss: 0.8547900915145874, Discriminator loss: 1.3291127681732178\n",
      "\tGenerator loss: 0.886275053024292, Discriminator loss: 1.3361318111419678\n",
      "\tGenerator loss: 0.894615888595581, Discriminator loss: 1.3531012535095215\n",
      "\tGenerator loss: 0.8556283712387085, Discriminator loss: 1.3418933153152466\n",
      "\tGenerator loss: 0.8212074637413025, Discriminator loss: 1.3048806190490723\n",
      "\tGenerator loss: 0.7876365780830383, Discriminator loss: 1.3365079164505005\n",
      "\tGenerator loss: 0.7541283965110779, Discriminator loss: 1.3540951013565063\n",
      "\tGenerator loss: 0.7651103734970093, Discriminator loss: 1.323063850402832\n",
      "\tGenerator loss: 0.8214863538742065, Discriminator loss: 1.305034875869751\n",
      "\tGenerator loss: 0.8666374683380127, Discriminator loss: 1.2916828393936157\n",
      "\tGenerator loss: 0.8901075124740601, Discriminator loss: 1.2585062980651855\n",
      "\tGenerator loss: 0.8824326395988464, Discriminator loss: 1.2659388780593872\n",
      "\tGenerator loss: 0.8382678031921387, Discriminator loss: 1.2853238582611084\n",
      "\tGenerator loss: 0.8309022188186646, Discriminator loss: 1.250585675239563\n",
      "\tGenerator loss: 0.8207879662513733, Discriminator loss: 1.2915725708007812\n",
      "\tGenerator loss: 0.8260077238082886, Discriminator loss: 1.3317718505859375\n",
      "\tGenerator loss: 0.8747729063034058, Discriminator loss: 1.2951196432113647\n",
      "\tGenerator loss: 0.8801068067550659, Discriminator loss: 1.270129919052124\n",
      "\tGenerator loss: 0.890680730342865, Discriminator loss: 1.2849833965301514\n",
      "\tGenerator loss: 0.8626675009727478, Discriminator loss: 1.2488429546356201\n",
      "\tGenerator loss: 0.8557947874069214, Discriminator loss: 1.2822809219360352\n",
      "\tGenerator loss: 0.8680492043495178, Discriminator loss: 1.2647194862365723\n",
      "\tGenerator loss: 0.8891485929489136, Discriminator loss: 1.2369444370269775\n",
      "\tGenerator loss: 0.8923139572143555, Discriminator loss: 1.2513431310653687\n",
      "\tGenerator loss: 0.9055232405662537, Discriminator loss: 1.2837822437286377\n",
      "\tGenerator loss: 0.8811418414115906, Discriminator loss: 1.2899552583694458\n",
      "\tGenerator loss: 0.8871914148330688, Discriminator loss: 1.2248353958129883\n",
      "\tGenerator loss: 0.8674461841583252, Discriminator loss: 1.2469241619110107\n",
      "\tGenerator loss: 0.8591288924217224, Discriminator loss: 1.2253429889678955\n",
      "\tGenerator loss: 0.8905878663063049, Discriminator loss: 1.1795917749404907\n",
      "\tGenerator loss: 0.9051753282546997, Discriminator loss: 1.2164227962493896\n",
      "\tGenerator loss: 0.9073486328125, Discriminator loss: 1.257484793663025\n",
      "\tGenerator loss: 0.9128907918930054, Discriminator loss: 1.277490496635437\n",
      "\tGenerator loss: 0.9389687180519104, Discriminator loss: 1.2781275510787964\n",
      "\tGenerator loss: 0.9397455453872681, Discriminator loss: 1.2669284343719482\n",
      "\tGenerator loss: 0.9370557069778442, Discriminator loss: 1.1966999769210815\n",
      "\tGenerator loss: 0.9003509283065796, Discriminator loss: 1.2044708728790283\n",
      "\tGenerator loss: 0.8955398797988892, Discriminator loss: 1.1926600933074951\n",
      "\tGenerator loss: 0.9253354072570801, Discriminator loss: 1.1884593963623047\n",
      "\tGenerator loss: 0.9019136428833008, Discriminator loss: 1.2252273559570312\n",
      "\tGenerator loss: 0.9269120693206787, Discriminator loss: 1.1832728385925293\n",
      "\tGenerator loss: 0.9255852103233337, Discriminator loss: 1.1861989498138428\n",
      "\tGenerator loss: 0.9133044481277466, Discriminator loss: 1.2252843379974365\n",
      "\tGenerator loss: 0.9344741106033325, Discriminator loss: 1.2386581897735596\n",
      "\tGenerator loss: 0.9441462755203247, Discriminator loss: 1.2323269844055176\n",
      "\tGenerator loss: 0.923140287399292, Discriminator loss: 1.2400435209274292\n",
      "\tGenerator loss: 0.8954402208328247, Discriminator loss: 1.1958177089691162\n",
      "\tGenerator loss: 0.8745308518409729, Discriminator loss: 1.2136969566345215\n",
      "\tGenerator loss: 0.8649005889892578, Discriminator loss: 1.1978610754013062\n",
      "\tGenerator loss: 0.8881475329399109, Discriminator loss: 1.1929137706756592\n",
      "\tGenerator loss: 0.9213166236877441, Discriminator loss: 1.196298360824585\n",
      "\tGenerator loss: 0.9484454393386841, Discriminator loss: 1.240187168121338\n",
      "\tGenerator loss: 0.9635275602340698, Discriminator loss: 1.2387549877166748\n",
      "\tGenerator loss: 0.9009985327720642, Discriminator loss: 1.2471672296524048\n",
      "\tGenerator loss: 0.8404927253723145, Discriminator loss: 1.2371692657470703\n",
      "\tGenerator loss: 0.8463250398635864, Discriminator loss: 1.2455217838287354\n",
      "\tGenerator loss: 0.8387959599494934, Discriminator loss: 1.2194225788116455\n",
      "\tGenerator loss: 0.8810827732086182, Discriminator loss: 1.2156870365142822\n",
      "\tGenerator loss: 0.9123629331588745, Discriminator loss: 1.205808401107788\n",
      "\tGenerator loss: 0.9518799185752869, Discriminator loss: 1.230095624923706\n",
      "\tGenerator loss: 0.9679482579231262, Discriminator loss: 1.2243332862854004\n",
      "\tGenerator loss: 0.9346663951873779, Discriminator loss: 1.1953941583633423\n",
      "\tGenerator loss: 0.9086669683456421, Discriminator loss: 1.1848771572113037\n",
      "\tGenerator loss: 0.8797570466995239, Discriminator loss: 1.2222561836242676\n",
      "\tGenerator loss: 0.8757989406585693, Discriminator loss: 1.2402409315109253\n",
      "\tGenerator loss: 0.8652132749557495, Discriminator loss: 1.2143419981002808\n",
      "\tGenerator loss: 0.857330858707428, Discriminator loss: 1.23164701461792\n",
      "\tGenerator loss: 0.8744362592697144, Discriminator loss: 1.2535936832427979\n",
      "\tGenerator loss: 0.8867745995521545, Discriminator loss: 1.277269959449768\n",
      "\tGenerator loss: 0.8779035806655884, Discriminator loss: 1.2547228336334229\n",
      "\tGenerator loss: 0.8666019439697266, Discriminator loss: 1.223966121673584\n",
      "\tGenerator loss: 0.8720594048500061, Discriminator loss: 1.2151542901992798\n",
      "\tGenerator loss: 0.8628839254379272, Discriminator loss: 1.233962059020996\n",
      "\tGenerator loss: 0.8897793292999268, Discriminator loss: 1.2376381158828735\n",
      "\tGenerator loss: 0.888555109500885, Discriminator loss: 1.2492656707763672\n",
      "\tGenerator loss: 0.8805454969406128, Discriminator loss: 1.282322883605957\n",
      "\tGenerator loss: 0.8815574049949646, Discriminator loss: 1.2840940952301025\n",
      "\tGenerator loss: 0.901015043258667, Discriminator loss: 1.2790296077728271\n",
      "\tGenerator loss: 0.9117451310157776, Discriminator loss: 1.2919503450393677\n",
      "\tGenerator loss: 0.8904554843902588, Discriminator loss: 1.3207054138183594\n",
      "\tGenerator loss: 0.8721792697906494, Discriminator loss: 1.3114769458770752\n",
      "\tGenerator loss: 0.8265590667724609, Discriminator loss: 1.3106693029403687\n",
      "\tGenerator loss: 0.8118529319763184, Discriminator loss: 1.2936146259307861\n",
      "\tGenerator loss: 0.8226023316383362, Discriminator loss: 1.2645304203033447\n",
      "\tGenerator loss: 0.8393317461013794, Discriminator loss: 1.2801790237426758\n",
      "\tGenerator loss: 0.8600426912307739, Discriminator loss: 1.3181345462799072\n",
      "\tGenerator loss: 0.8861793279647827, Discriminator loss: 1.289363145828247\n",
      "\tGenerator loss: 0.9013962745666504, Discriminator loss: 1.3089320659637451\n",
      "\tGenerator loss: 0.8681640625, Discriminator loss: 1.2806593179702759\n",
      "\tGenerator loss: 0.826024055480957, Discriminator loss: 1.2893428802490234\n",
      "\tGenerator loss: 0.8238511085510254, Discriminator loss: 1.2773997783660889\n",
      "\tGenerator loss: 0.8609262704849243, Discriminator loss: 1.2671550512313843\n",
      "\tGenerator loss: 0.8544278144836426, Discriminator loss: 1.2901095151901245\n",
      "\tGenerator loss: 0.8737242221832275, Discriminator loss: 1.2815628051757812\n",
      "\tGenerator loss: 0.8921465873718262, Discriminator loss: 1.249953031539917\n",
      "\tGenerator loss: 0.8896075487136841, Discriminator loss: 1.2554967403411865\n",
      "\tGenerator loss: 0.8770092725753784, Discriminator loss: 1.2477521896362305\n",
      "\tGenerator loss: 0.8494726419448853, Discriminator loss: 1.2490100860595703\n",
      "\tGenerator loss: 0.8443686962127686, Discriminator loss: 1.2294131517410278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerator loss: 0.852105975151062, Discriminator loss: 1.2377057075500488\n",
      "\tGenerator loss: 0.8741967678070068, Discriminator loss: 1.2416014671325684\n",
      "\tGenerator loss: 0.900969386100769, Discriminator loss: 1.2957558631896973\n",
      "\tGenerator loss: 0.9163423776626587, Discriminator loss: 1.3212847709655762\n",
      "\tGenerator loss: 0.9030583500862122, Discriminator loss: 1.2677454948425293\n",
      "\tGenerator loss: 0.8624303936958313, Discriminator loss: 1.2914462089538574\n",
      "\tGenerator loss: 0.8169568777084351, Discriminator loss: 1.2991386651992798\n",
      "\tGenerator loss: 0.8023027181625366, Discriminator loss: 1.3360991477966309\n",
      "\tGenerator loss: 0.8383927941322327, Discriminator loss: 1.320946216583252\n",
      "\tGenerator loss: 0.8911209106445312, Discriminator loss: 1.2910798788070679\n",
      "\tGenerator loss: 0.9036047458648682, Discriminator loss: 1.3256535530090332\n",
      "\tGenerator loss: 0.9064269065856934, Discriminator loss: 1.3176515102386475\n",
      "\tGenerator loss: 0.8704128265380859, Discriminator loss: 1.3199565410614014\n",
      "\tGenerator loss: 0.8574300408363342, Discriminator loss: 1.2745317220687866\n",
      "\tGenerator loss: 0.820649266242981, Discriminator loss: 1.2584748268127441\n",
      "\tGenerator loss: 0.8141669631004333, Discriminator loss: 1.2413976192474365\n",
      "\tGenerator loss: 0.8375569581985474, Discriminator loss: 1.2677809000015259\n",
      "\tGenerator loss: 0.889778196811676, Discriminator loss: 1.2253570556640625\n",
      "\tGenerator loss: 0.9548922777175903, Discriminator loss: 1.2448642253875732\n",
      "\tGenerator loss: 0.955387532711029, Discriminator loss: 1.197293758392334\n",
      "\tGenerator loss: 0.9336408972740173, Discriminator loss: 1.1811645030975342\n",
      "\tGenerator loss: 0.8989877104759216, Discriminator loss: 1.2225395441055298\n",
      "\tGenerator loss: 0.8963146209716797, Discriminator loss: 1.2623720169067383\n",
      "\tGenerator loss: 0.9144308567047119, Discriminator loss: 1.263592004776001\n",
      "\tGenerator loss: 0.9080907106399536, Discriminator loss: 1.2181791067123413\n",
      "Time for epoch 50 is 213.73211240768433 sec\n"
     ]
    }
   ],
   "source": [
    "# Flag telling if it has been done the first batch\n",
    "first_batch_done = False\n",
    "\n",
    "# Generator and discriminator losses, computed incrementally over the batches\n",
    "generator_loss, discriminator_loss = None, None\n",
    "\n",
    "# Iterating over all the epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    # EPOCH\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Iterating over all the batches in that epoch\n",
    "    for batch_real_images in x_train:\n",
    "      # TRAINING STEP  \n",
    "        \n",
    "      # Generator and discriminator losses in that batch \n",
    "      generator_loss_batch, discriminator_loss_batch = train_step(batch_real_images)\n",
    "        \n",
    "      # Updating the actual generator and discriminator losses\n",
    "      if not first_batch_done:\n",
    "        generator_loss, discriminator_loss = generator_loss_batch, discriminator_loss_batch\n",
    "      else:\n",
    "        generator_loss = 1/2 * (generator_loss + generator_loss_batch)\n",
    "        discriminator_loss = 1/2 * (discriminator_loss + discriminator_loss_batch)\n",
    "      \n",
    "      first_batch_done = True\n",
    "        \n",
    "      # End training step\n",
    "      print(f'\\tGenerator loss: {generator_loss}, Discriminator loss: {discriminator_loss}')\n",
    "    \n",
    "    # End epoch\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8128cb6",
   "metadata": {},
   "source": [
    "As it can be seen, the training is like a fight between the generator and the discriminator: Min-Max game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8facac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_weights('generator.h5')\n",
    "discriminator.save_weights('discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d18884",
   "metadata": {},
   "source": [
    "**Better training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbcb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\tBatch step: 0\n",
      "\tGenerator loss: 0.6700984835624695, Discriminator loss: 1.3224706649780273\n",
      "\tBatch step: 1\n",
      "\tGenerator loss: 0.6615570783615112, Discriminator loss: 1.3071839809417725\n",
      "\tBatch step: 2\n",
      "\tGenerator loss: 0.6537616848945618, Discriminator loss: 1.2941184043884277\n",
      "\tBatch step: 3\n",
      "\tGenerator loss: 0.6471368670463562, Discriminator loss: 1.2813929319381714\n",
      "\tBatch step: 4\n",
      "\tGenerator loss: 0.6411234736442566, Discriminator loss: 1.2683271169662476\n",
      "\tBatch step: 5\n",
      "\tGenerator loss: 0.6370881795883179, Discriminator loss: 1.2533745765686035\n",
      "\tBatch step: 6\n",
      "\tGenerator loss: 0.6335670351982117, Discriminator loss: 1.2388981580734253\n",
      "\tBatch step: 7\n",
      "\tGenerator loss: 0.63039231300354, Discriminator loss: 1.2246625423431396\n",
      "\tBatch step: 8\n",
      "\tGenerator loss: 0.6270624399185181, Discriminator loss: 1.211728811264038\n",
      "\tBatch step: 9\n",
      "\tGenerator loss: 0.6240742802619934, Discriminator loss: 1.199331283569336\n",
      "\tBatch step: 10\n",
      "\tGenerator loss: 0.620613157749176, Discriminator loss: 1.1882010698318481\n",
      "\tBatch step: 11\n",
      "\tGenerator loss: 0.6171819567680359, Discriminator loss: 1.1781530380249023\n",
      "\tBatch step: 12\n",
      "\tGenerator loss: 0.6133807897567749, Discriminator loss: 1.1684706211090088\n",
      "\tBatch step: 13\n",
      "\tGenerator loss: 0.6091675162315369, Discriminator loss: 1.1605607271194458\n",
      "\tBatch step: 14\n",
      "\tGenerator loss: 0.6045320630073547, Discriminator loss: 1.1547930240631104\n",
      "\tBatch step: 15\n",
      "\tGenerator loss: 0.5995017886161804, Discriminator loss: 1.1497461795806885\n",
      "\tBatch step: 16\n",
      "\tGenerator loss: 0.5938436388969421, Discriminator loss: 1.1464204788208008\n",
      "\tBatch step: 17\n",
      "\tGenerator loss: 0.5879838466644287, Discriminator loss: 1.1444391012191772\n",
      "\tBatch step: 18\n",
      "\tGenerator loss: 0.5819175839424133, Discriminator loss: 1.14411199092865\n",
      "\tBatch step: 19\n",
      "\tGenerator loss: 0.5758935213088989, Discriminator loss: 1.1440465450286865\n",
      "\tBatch step: 20\n",
      "\tGenerator loss: 0.56993168592453, Discriminator loss: 1.1447279453277588\n",
      "\tBatch step: 21\n",
      "\tGenerator loss: 0.5643703937530518, Discriminator loss: 1.145518183708191\n",
      "\tBatch step: 22\n",
      "\tGenerator loss: 0.5591854453086853, Discriminator loss: 1.1459962129592896\n",
      "\tBatch step: 23\n",
      "\tGenerator loss: 0.5544053316116333, Discriminator loss: 1.14707350730896\n",
      "\tBatch step: 24\n",
      "\tGenerator loss: 0.549944281578064, Discriminator loss: 1.1477766036987305\n",
      "\tBatch step: 25\n",
      "\tGenerator loss: 0.545951783657074, Discriminator loss: 1.1481562852859497\n",
      "\tBatch step: 26\n",
      "\tGenerator loss: 0.5422166585922241, Discriminator loss: 1.1484267711639404\n",
      "\tBatch step: 27\n",
      "\tGenerator loss: 0.5388163924217224, Discriminator loss: 1.1489284038543701\n",
      "\tBatch step: 28\n",
      "\tGenerator loss: 0.5358057618141174, Discriminator loss: 1.1490044593811035\n",
      "\tBatch step: 29\n",
      "\tGenerator loss: 0.5331971645355225, Discriminator loss: 1.149032711982727\n",
      "\tBatch step: 30\n",
      "\tGenerator loss: 0.53078693151474, Discriminator loss: 1.1494722366333008\n",
      "\tBatch step: 31\n",
      "\tGenerator loss: 0.5287097096443176, Discriminator loss: 1.1498198509216309\n",
      "\tBatch step: 32\n",
      "\tGenerator loss: 0.5268509387969971, Discriminator loss: 1.1500561237335205\n",
      "\tBatch step: 33\n",
      "\tGenerator loss: 0.5254637002944946, Discriminator loss: 1.150864601135254\n",
      "\tBatch step: 34\n",
      "\tGenerator loss: 0.524376630783081, Discriminator loss: 1.1506983041763306\n",
      "\tBatch step: 35\n",
      "\tGenerator loss: 0.523604691028595, Discriminator loss: 1.1503597497940063\n",
      "\tBatch step: 36\n",
      "\tGenerator loss: 0.523199737071991, Discriminator loss: 1.150037169456482\n",
      "\tBatch step: 37\n",
      "\tGenerator loss: 0.5231069326400757, Discriminator loss: 1.149977207183838\n",
      "\tBatch step: 38\n",
      "\tGenerator loss: 0.5232215523719788, Discriminator loss: 1.1496347188949585\n",
      "\tBatch step: 39\n",
      "\tGenerator loss: 0.5235313177108765, Discriminator loss: 1.14968740940094\n",
      "\tBatch step: 40\n",
      "\tGenerator loss: 0.5240167379379272, Discriminator loss: 1.1504731178283691\n",
      "\tBatch step: 41\n",
      "\tGenerator loss: 0.5245277285575867, Discriminator loss: 1.1504991054534912\n",
      "\tBatch step: 42\n",
      "\tGenerator loss: 0.5251033902168274, Discriminator loss: 1.1512240171432495\n",
      "\tBatch step: 43\n",
      "\tGenerator loss: 0.5257740616798401, Discriminator loss: 1.1520178318023682\n",
      "\tBatch step: 44\n",
      "\tGenerator loss: 0.5264966487884521, Discriminator loss: 1.1527761220932007\n",
      "\tBatch step: 45\n",
      "\tGenerator loss: 0.5272381901741028, Discriminator loss: 1.1536710262298584\n",
      "\tBatch step: 46\n",
      "\tGenerator loss: 0.5278983116149902, Discriminator loss: 1.155003309249878\n",
      "\tBatch step: 47\n",
      "\tGenerator loss: 0.5283095240592957, Discriminator loss: 1.1570230722427368\n",
      "\tBatch step: 48\n",
      "\tGenerator loss: 0.52830570936203, Discriminator loss: 1.1599324941635132\n",
      "\tBatch step: 49\n",
      "\tGenerator loss: 0.5278969407081604, Discriminator loss: 1.163314938545227\n",
      "\tBatch step: 50\n",
      "\tGenerator loss: 0.526996374130249, Discriminator loss: 1.1679140329360962\n",
      "\tBatch step: 51\n",
      "\tGenerator loss: 0.5257003307342529, Discriminator loss: 1.173262119293213\n",
      "\tBatch step: 52\n",
      "\tGenerator loss: 0.5241261124610901, Discriminator loss: 1.1790450811386108\n",
      "\tBatch step: 53\n",
      "\tGenerator loss: 0.5224480032920837, Discriminator loss: 1.1844682693481445\n",
      "\tBatch step: 54\n",
      "\tGenerator loss: 0.5207322239875793, Discriminator loss: 1.1904362440109253\n",
      "\tBatch step: 55\n",
      "\tGenerator loss: 0.5192444920539856, Discriminator loss: 1.1969801187515259\n",
      "\tBatch step: 56\n",
      "\tGenerator loss: 0.5179399251937866, Discriminator loss: 1.2017885446548462\n",
      "\tBatch step: 57\n",
      "\tGenerator loss: 0.5169585943222046, Discriminator loss: 1.2070790529251099\n",
      "\tBatch step: 58\n",
      "\tGenerator loss: 0.5163581371307373, Discriminator loss: 1.2104887962341309\n",
      "\tBatch step: 59\n",
      "\tGenerator loss: 0.5161316394805908, Discriminator loss: 1.21317720413208\n",
      "\tBatch step: 60\n",
      "\tGenerator loss: 0.5162267088890076, Discriminator loss: 1.2152764797210693\n",
      "\tBatch step: 61\n",
      "\tGenerator loss: 0.5165971517562866, Discriminator loss: 1.2169699668884277\n",
      "\tBatch step: 62\n",
      "\tGenerator loss: 0.5173546075820923, Discriminator loss: 1.2182509899139404\n",
      "\tBatch step: 63\n",
      "\tGenerator loss: 0.5185588002204895, Discriminator loss: 1.218799352645874\n",
      "\tBatch step: 64\n",
      "\tGenerator loss: 0.5202054977416992, Discriminator loss: 1.2183856964111328\n",
      "\tBatch step: 65\n",
      "\tGenerator loss: 0.5223618745803833, Discriminator loss: 1.2173287868499756\n",
      "\tBatch step: 66\n",
      "\tGenerator loss: 0.5250418782234192, Discriminator loss: 1.2156472206115723\n",
      "\tBatch step: 67\n",
      "\tGenerator loss: 0.528237521648407, Discriminator loss: 1.2135038375854492\n",
      "\tBatch step: 68\n",
      "\tGenerator loss: 0.5319303274154663, Discriminator loss: 1.2104556560516357\n",
      "\tBatch step: 69\n",
      "\tGenerator loss: 0.5361534953117371, Discriminator loss: 1.2067785263061523\n",
      "\tBatch step: 70\n",
      "\tGenerator loss: 0.5406765937805176, Discriminator loss: 1.2027239799499512\n",
      "\tBatch step: 71\n",
      "\tGenerator loss: 0.5454246997833252, Discriminator loss: 1.1983726024627686\n",
      "\tBatch step: 72\n",
      "\tGenerator loss: 0.5503203272819519, Discriminator loss: 1.193918228149414\n",
      "\tBatch step: 73\n",
      "\tGenerator loss: 0.5550345778465271, Discriminator loss: 1.1893608570098877\n",
      "\tBatch step: 74\n",
      "\tGenerator loss: 0.5595521330833435, Discriminator loss: 1.1846373081207275\n",
      "\tBatch step: 75\n",
      "\tGenerator loss: 0.5638461709022522, Discriminator loss: 1.1805130243301392\n",
      "\tBatch step: 76\n",
      "\tGenerator loss: 0.5677351951599121, Discriminator loss: 1.1764764785766602\n",
      "\tBatch step: 77\n",
      "\tGenerator loss: 0.5712440013885498, Discriminator loss: 1.172870397567749\n",
      "\tBatch step: 78\n",
      "\tGenerator loss: 0.574408233165741, Discriminator loss: 1.1694587469100952\n",
      "\tBatch step: 79\n",
      "\tGenerator loss: 0.5772769451141357, Discriminator loss: 1.1657679080963135\n",
      "\tBatch step: 80\n",
      "\tGenerator loss: 0.5800326466560364, Discriminator loss: 1.1621365547180176\n",
      "\tBatch step: 81\n",
      "\tGenerator loss: 0.5827054381370544, Discriminator loss: 1.1585904359817505\n",
      "\tBatch step: 82\n",
      "\tGenerator loss: 0.5854464173316956, Discriminator loss: 1.1549818515777588\n",
      "\tBatch step: 83\n",
      "\tGenerator loss: 0.5881791114807129, Discriminator loss: 1.1516395807266235\n",
      "\tBatch step: 84\n",
      "\tGenerator loss: 0.5909567475318909, Discriminator loss: 1.147905707359314\n",
      "\tBatch step: 85\n",
      "\tGenerator loss: 0.5937802791595459, Discriminator loss: 1.1446850299835205\n",
      "\tBatch step: 86\n",
      "\tGenerator loss: 0.5966291427612305, Discriminator loss: 1.1414825916290283\n",
      "\tBatch step: 87\n",
      "\tGenerator loss: 0.5995652675628662, Discriminator loss: 1.1378905773162842\n",
      "\tBatch step: 88\n",
      "\tGenerator loss: 0.6025060415267944, Discriminator loss: 1.1345771551132202\n",
      "\tBatch step: 89\n",
      "\tGenerator loss: 0.6052758693695068, Discriminator loss: 1.1314215660095215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch step: 90\n",
      "\tGenerator loss: 0.6080633997917175, Discriminator loss: 1.128258466720581\n",
      "\tBatch step: 91\n",
      "\tGenerator loss: 0.610565185546875, Discriminator loss: 1.1254092454910278\n",
      "\tBatch step: 92\n",
      "\tGenerator loss: 0.6131019592285156, Discriminator loss: 1.1224515438079834\n",
      "\tBatch step: 93\n",
      "\tGenerator loss: 0.6154345870018005, Discriminator loss: 1.1196348667144775\n",
      "\tBatch step: 94\n",
      "\tGenerator loss: 0.6175982356071472, Discriminator loss: 1.1169183254241943\n",
      "\tBatch step: 95\n",
      "\tGenerator loss: 0.6193554997444153, Discriminator loss: 1.1148638725280762\n",
      "\tBatch step: 96\n",
      "\tGenerator loss: 0.6207530498504639, Discriminator loss: 1.1129415035247803\n",
      "\tBatch step: 97\n",
      "\tGenerator loss: 0.6217412352561951, Discriminator loss: 1.1114715337753296\n",
      "\tBatch step: 98\n",
      "\tGenerator loss: 0.6222183704376221, Discriminator loss: 1.1107227802276611\n",
      "\tBatch step: 99\n",
      "\tGenerator loss: 0.6222955584526062, Discriminator loss: 1.1103301048278809\n",
      "\tBatch step: 100\n",
      "\tGenerator loss: 0.6221984028816223, Discriminator loss: 1.1101493835449219\n",
      "\tBatch step: 101\n",
      "\tGenerator loss: 0.6222440600395203, Discriminator loss: 1.1098322868347168\n",
      "\tBatch step: 102\n",
      "\tGenerator loss: 0.6227087378501892, Discriminator loss: 1.1089986562728882\n",
      "\tBatch step: 103\n",
      "\tGenerator loss: 0.6237858533859253, Discriminator loss: 1.1077549457550049\n",
      "\tBatch step: 104\n",
      "\tGenerator loss: 0.6254197359085083, Discriminator loss: 1.1061910390853882\n",
      "\tBatch step: 105\n",
      "\tGenerator loss: 0.6276276111602783, Discriminator loss: 1.1042264699935913\n",
      "\tBatch step: 106\n",
      "\tGenerator loss: 0.6304537057876587, Discriminator loss: 1.1022870540618896\n",
      "\tBatch step: 107\n",
      "\tGenerator loss: 0.6337302923202515, Discriminator loss: 1.0999635457992554\n",
      "\tBatch step: 108\n",
      "\tGenerator loss: 0.6373070478439331, Discriminator loss: 1.097404956817627\n",
      "\tBatch step: 109\n",
      "\tGenerator loss: 0.6410616636276245, Discriminator loss: 1.0946474075317383\n",
      "\tBatch step: 110\n",
      "\tGenerator loss: 0.6450222134590149, Discriminator loss: 1.0919419527053833\n",
      "\tBatch step: 111\n",
      "\tGenerator loss: 0.6488235592842102, Discriminator loss: 1.0892512798309326\n",
      "\tBatch step: 112\n",
      "\tGenerator loss: 0.6527769565582275, Discriminator loss: 1.0863674879074097\n",
      "\tBatch step: 113\n",
      "\tGenerator loss: 0.6566156148910522, Discriminator loss: 1.0836189985275269\n",
      "\tBatch step: 114\n",
      "\tGenerator loss: 0.6603847742080688, Discriminator loss: 1.0809955596923828\n",
      "\tBatch step: 115\n",
      "\tGenerator loss: 0.6637459993362427, Discriminator loss: 1.0785046815872192\n",
      "\tBatch step: 116\n",
      "\tGenerator loss: 0.666860818862915, Discriminator loss: 1.076183557510376\n",
      "\tBatch step: 117\n",
      "\tGenerator loss: 0.6696047782897949, Discriminator loss: 1.074269413948059\n",
      "\tBatch step: 118\n",
      "\tGenerator loss: 0.6720889210700989, Discriminator loss: 1.0725425481796265\n",
      "\tBatch step: 119\n",
      "\tGenerator loss: 0.6740980744361877, Discriminator loss: 1.0709069967269897\n",
      "\tBatch step: 120\n",
      "\tGenerator loss: 0.6758620738983154, Discriminator loss: 1.0694096088409424\n",
      "\tBatch step: 121\n",
      "\tGenerator loss: 0.6772637367248535, Discriminator loss: 1.0684654712677002\n",
      "\tBatch step: 122\n",
      "\tGenerator loss: 0.6782771348953247, Discriminator loss: 1.0676597356796265\n",
      "\tBatch step: 123\n",
      "\tGenerator loss: 0.6789700388908386, Discriminator loss: 1.0673139095306396\n",
      "\tBatch step: 124\n",
      "\tGenerator loss: 0.6792766451835632, Discriminator loss: 1.0674405097961426\n",
      "\tBatch step: 125\n",
      "\tGenerator loss: 0.6791471242904663, Discriminator loss: 1.0676311254501343\n",
      "\tBatch step: 126\n",
      "\tGenerator loss: 0.678615152835846, Discriminator loss: 1.0684040784835815\n",
      "\tBatch step: 127\n",
      "\tGenerator loss: 0.6778340935707092, Discriminator loss: 1.0696481466293335\n",
      "\tBatch step: 128\n",
      "\tGenerator loss: 0.6770641207695007, Discriminator loss: 1.0708916187286377\n",
      "\tBatch step: 129\n",
      "\tGenerator loss: 0.6763237714767456, Discriminator loss: 1.0721321105957031\n",
      "\tBatch step: 130\n",
      "\tGenerator loss: 0.6757223010063171, Discriminator loss: 1.0735282897949219\n",
      "\tBatch step: 131\n",
      "\tGenerator loss: 0.6753242015838623, Discriminator loss: 1.0744644403457642\n",
      "\tBatch step: 132\n",
      "\tGenerator loss: 0.6752424836158752, Discriminator loss: 1.0750728845596313\n",
      "\tBatch step: 133\n",
      "\tGenerator loss: 0.6754269599914551, Discriminator loss: 1.075778603553772\n",
      "\tBatch step: 134\n",
      "\tGenerator loss: 0.6757256388664246, Discriminator loss: 1.0764776468276978\n",
      "\tBatch step: 135\n",
      "\tGenerator loss: 0.6762890815734863, Discriminator loss: 1.0768402814865112\n",
      "\tBatch step: 136\n",
      "\tGenerator loss: 0.6770015358924866, Discriminator loss: 1.0769038200378418\n",
      "\tBatch step: 137\n",
      "\tGenerator loss: 0.6777634024620056, Discriminator loss: 1.076886773109436\n",
      "\tBatch step: 138\n",
      "\tGenerator loss: 0.6785592436790466, Discriminator loss: 1.0769639015197754\n",
      "\tBatch step: 139\n",
      "\tGenerator loss: 0.679163932800293, Discriminator loss: 1.0771185159683228\n",
      "\tBatch step: 140\n",
      "\tGenerator loss: 0.6796724796295166, Discriminator loss: 1.0773290395736694\n",
      "\tBatch step: 141\n",
      "\tGenerator loss: 0.6799591779708862, Discriminator loss: 1.0778757333755493\n",
      "\tBatch step: 142\n",
      "\tGenerator loss: 0.6800211071968079, Discriminator loss: 1.0780918598175049\n",
      "\tBatch step: 143\n",
      "\tGenerator loss: 0.6798633933067322, Discriminator loss: 1.0782315731048584\n",
      "\tBatch step: 144\n",
      "\tGenerator loss: 0.6796199083328247, Discriminator loss: 1.0784528255462646\n",
      "\tBatch step: 145\n",
      "\tGenerator loss: 0.6793401837348938, Discriminator loss: 1.078784465789795\n",
      "\tBatch step: 146\n",
      "\tGenerator loss: 0.6790709495544434, Discriminator loss: 1.0791592597961426\n",
      "\tBatch step: 147\n",
      "\tGenerator loss: 0.6787847280502319, Discriminator loss: 1.0797054767608643\n",
      "\tBatch step: 148\n",
      "\tGenerator loss: 0.6785924434661865, Discriminator loss: 1.0799561738967896\n",
      "\tBatch step: 149\n",
      "\tGenerator loss: 0.6784512996673584, Discriminator loss: 1.0802760124206543\n",
      "\tBatch step: 150\n",
      "\tGenerator loss: 0.6784696578979492, Discriminator loss: 1.080502986907959\n",
      "\tBatch step: 151\n",
      "\tGenerator loss: 0.6786432862281799, Discriminator loss: 1.0805870294570923\n",
      "\tBatch step: 152\n",
      "\tGenerator loss: 0.6789941787719727, Discriminator loss: 1.0806471109390259\n",
      "\tBatch step: 153\n",
      "\tGenerator loss: 0.6794823408126831, Discriminator loss: 1.0805466175079346\n",
      "\tBatch step: 154\n",
      "\tGenerator loss: 0.6801184415817261, Discriminator loss: 1.0802546739578247\n",
      "\tBatch step: 155\n",
      "\tGenerator loss: 0.6809501051902771, Discriminator loss: 1.0800657272338867\n",
      "\tBatch step: 156\n",
      "\tGenerator loss: 0.6818118095397949, Discriminator loss: 1.0797871351242065\n",
      "\tBatch step: 157\n",
      "\tGenerator loss: 0.682845950126648, Discriminator loss: 1.0794942378997803\n",
      "\tBatch step: 158\n",
      "\tGenerator loss: 0.6839194893836975, Discriminator loss: 1.0791535377502441\n",
      "\tBatch step: 159\n",
      "\tGenerator loss: 0.6850488185882568, Discriminator loss: 1.078726053237915\n",
      "\tBatch step: 160\n",
      "\tGenerator loss: 0.6862462162971497, Discriminator loss: 1.0781484842300415\n",
      "\tBatch step: 161\n",
      "\tGenerator loss: 0.687467634677887, Discriminator loss: 1.0777361392974854\n",
      "\tBatch step: 162\n",
      "\tGenerator loss: 0.6888271570205688, Discriminator loss: 1.0768682956695557\n",
      "\tBatch step: 163\n",
      "\tGenerator loss: 0.6902197003364563, Discriminator loss: 1.0760102272033691\n",
      "\tBatch step: 164\n",
      "\tGenerator loss: 0.6916462182998657, Discriminator loss: 1.0749274492263794\n",
      "\tBatch step: 165\n",
      "\tGenerator loss: 0.6930953860282898, Discriminator loss: 1.0741140842437744\n",
      "\tBatch step: 166\n",
      "\tGenerator loss: 0.6947349309921265, Discriminator loss: 1.0731120109558105\n",
      "\tBatch step: 167\n",
      "\tGenerator loss: 0.6963945031166077, Discriminator loss: 1.0718885660171509\n",
      "\tBatch step: 168\n",
      "\tGenerator loss: 0.6981220841407776, Discriminator loss: 1.07038152217865\n",
      "\tBatch step: 169\n",
      "\tGenerator loss: 0.6999143958091736, Discriminator loss: 1.068946123123169\n",
      "\tBatch step: 170\n",
      "\tGenerator loss: 0.7019050121307373, Discriminator loss: 1.0673850774765015\n",
      "\tBatch step: 171\n",
      "\tGenerator loss: 0.7039739489555359, Discriminator loss: 1.0657607316970825\n",
      "\tBatch step: 172\n",
      "\tGenerator loss: 0.7063459753990173, Discriminator loss: 1.064173936843872\n",
      "\tBatch step: 173\n",
      "\tGenerator loss: 0.7087633609771729, Discriminator loss: 1.062587857246399\n",
      "\tBatch step: 174\n",
      "\tGenerator loss: 0.7111822366714478, Discriminator loss: 1.0609986782073975\n",
      "\tBatch step: 175\n",
      "\tGenerator loss: 0.7137413620948792, Discriminator loss: 1.0592864751815796\n",
      "\tBatch step: 176\n",
      "\tGenerator loss: 0.7163060307502747, Discriminator loss: 1.057871699333191\n",
      "\tBatch step: 177\n",
      "\tGenerator loss: 0.718856930732727, Discriminator loss: 1.05631422996521\n",
      "\tBatch step: 178\n",
      "\tGenerator loss: 0.7213417887687683, Discriminator loss: 1.0548269748687744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch step: 179\n",
      "\tGenerator loss: 0.7238970994949341, Discriminator loss: 1.053146481513977\n",
      "\tBatch step: 180\n",
      "\tGenerator loss: 0.7263998985290527, Discriminator loss: 1.051657795906067\n",
      "\tBatch step: 181\n",
      "\tGenerator loss: 0.7289207577705383, Discriminator loss: 1.050470232963562\n",
      "\tBatch step: 182\n",
      "\tGenerator loss: 0.7311959266662598, Discriminator loss: 1.0494000911712646\n",
      "\tBatch step: 183\n",
      "\tGenerator loss: 0.7335020303726196, Discriminator loss: 1.048396110534668\n",
      "\tBatch step: 184\n",
      "\tGenerator loss: 0.7357159852981567, Discriminator loss: 1.0472877025604248\n",
      "\tBatch step: 185\n",
      "\tGenerator loss: 0.7376622557640076, Discriminator loss: 1.046476125717163\n",
      "\tBatch step: 186\n",
      "\tGenerator loss: 0.7395172119140625, Discriminator loss: 1.045859932899475\n",
      "\tBatch step: 187\n",
      "\tGenerator loss: 0.7413349747657776, Discriminator loss: 1.0449633598327637\n",
      "\tBatch step: 188\n",
      "\tGenerator loss: 0.7430185079574585, Discriminator loss: 1.0443483591079712\n",
      "\tBatch step: 189\n",
      "\tGenerator loss: 0.7445933222770691, Discriminator loss: 1.0437722206115723\n",
      "\tBatch step: 190\n",
      "\tGenerator loss: 0.7460787892341614, Discriminator loss: 1.0432270765304565\n",
      "\tBatch step: 191\n",
      "\tGenerator loss: 0.7476251721382141, Discriminator loss: 1.042797565460205\n",
      "\tBatch step: 192\n",
      "\tGenerator loss: 0.7490543723106384, Discriminator loss: 1.0424391031265259\n",
      "\tBatch step: 193\n",
      "\tGenerator loss: 0.7503489851951599, Discriminator loss: 1.042197346687317\n",
      "\tBatch step: 194\n",
      "\tGenerator loss: 0.7515559196472168, Discriminator loss: 1.0419059991836548\n",
      "\tBatch step: 195\n",
      "\tGenerator loss: 0.7524136900901794, Discriminator loss: 1.0414252281188965\n",
      "\tBatch step: 196\n",
      "\tGenerator loss: 0.7532519102096558, Discriminator loss: 1.041132926940918\n",
      "\tBatch step: 197\n",
      "\tGenerator loss: 0.7539507746696472, Discriminator loss: 1.0410938262939453\n",
      "\tBatch step: 198\n",
      "\tGenerator loss: 0.7545989751815796, Discriminator loss: 1.0407599210739136\n",
      "\tBatch step: 199\n",
      "\tGenerator loss: 0.755229651927948, Discriminator loss: 1.0405168533325195\n",
      "\tBatch step: 200\n",
      "\tGenerator loss: 0.755865216255188, Discriminator loss: 1.040529489517212\n",
      "\tBatch step: 201\n",
      "\tGenerator loss: 0.7564604878425598, Discriminator loss: 1.0407798290252686\n",
      "\tBatch step: 202\n",
      "\tGenerator loss: 0.7569700479507446, Discriminator loss: 1.0408474206924438\n",
      "\tBatch step: 203\n",
      "\tGenerator loss: 0.7574037909507751, Discriminator loss: 1.0412604808807373\n",
      "\tBatch step: 204\n",
      "\tGenerator loss: 0.7577065229415894, Discriminator loss: 1.04141366481781\n",
      "\tBatch step: 205\n",
      "\tGenerator loss: 0.7578357458114624, Discriminator loss: 1.0418440103530884\n",
      "\tBatch step: 206\n",
      "\tGenerator loss: 0.7577953934669495, Discriminator loss: 1.0423482656478882\n",
      "\tBatch step: 207\n",
      "\tGenerator loss: 0.7577378153800964, Discriminator loss: 1.0429123640060425\n",
      "\tBatch step: 208\n",
      "\tGenerator loss: 0.7576216459274292, Discriminator loss: 1.043986201286316\n",
      "\tBatch step: 209\n",
      "\tGenerator loss: 0.7574894428253174, Discriminator loss: 1.0452218055725098\n",
      "\tBatch step: 210\n",
      "\tGenerator loss: 0.7573095560073853, Discriminator loss: 1.046715497970581\n",
      "\tBatch step: 211\n",
      "\tGenerator loss: 0.7569100856781006, Discriminator loss: 1.0482183694839478\n",
      "\tBatch step: 212\n",
      "\tGenerator loss: 0.7563561797142029, Discriminator loss: 1.0498130321502686\n",
      "\tBatch step: 213\n",
      "\tGenerator loss: 0.7558396458625793, Discriminator loss: 1.0513297319412231\n",
      "\tBatch step: 214\n",
      "\tGenerator loss: 0.7552523612976074, Discriminator loss: 1.0534107685089111\n",
      "\tBatch step: 215\n",
      "\tGenerator loss: 0.754623532295227, Discriminator loss: 1.0553936958312988\n",
      "\tBatch step: 216\n",
      "\tGenerator loss: 0.7539006471633911, Discriminator loss: 1.0573534965515137\n",
      "\tBatch step: 217\n",
      "\tGenerator loss: 0.7531576156616211, Discriminator loss: 1.0594236850738525\n",
      "\tBatch step: 218\n",
      "\tGenerator loss: 0.7522709965705872, Discriminator loss: 1.061668038368225\n",
      "\tBatch step: 219\n",
      "\tGenerator loss: 0.7514232397079468, Discriminator loss: 1.0641576051712036\n",
      "\tBatch step: 220\n",
      "\tGenerator loss: 0.7505510449409485, Discriminator loss: 1.066872000694275\n",
      "\tBatch step: 221\n",
      "\tGenerator loss: 0.7495850324630737, Discriminator loss: 1.0698031187057495\n",
      "\tBatch step: 222\n",
      "\tGenerator loss: 0.7486039400100708, Discriminator loss: 1.072522521018982\n",
      "\tBatch step: 223\n",
      "\tGenerator loss: 0.7474780082702637, Discriminator loss: 1.0753461122512817\n",
      "\tBatch step: 224\n",
      "\tGenerator loss: 0.7463394999504089, Discriminator loss: 1.0781553983688354\n",
      "\tBatch step: 225\n",
      "\tGenerator loss: 0.7452561259269714, Discriminator loss: 1.0808502435684204\n",
      "\tBatch step: 226\n",
      "\tGenerator loss: 0.7440474629402161, Discriminator loss: 1.0838578939437866\n",
      "\tBatch step: 227\n",
      "\tGenerator loss: 0.7429465055465698, Discriminator loss: 1.0864582061767578\n",
      "\tBatch step: 228\n",
      "\tGenerator loss: 0.7418777346611023, Discriminator loss: 1.0888828039169312\n",
      "\tBatch step: 229\n",
      "\tGenerator loss: 0.7408750057220459, Discriminator loss: 1.0911659002304077\n",
      "\tBatch step: 230\n",
      "\tGenerator loss: 0.7399895191192627, Discriminator loss: 1.093314528465271\n",
      "\tBatch step: 231\n",
      "\tGenerator loss: 0.7391839027404785, Discriminator loss: 1.095204472541809\n",
      "\tBatch step: 232\n",
      "\tGenerator loss: 0.7385824918746948, Discriminator loss: 1.0971089601516724\n",
      "\tBatch step: 233\n",
      "\tGenerator loss: 0.7380392551422119, Discriminator loss: 1.0987313985824585\n",
      "\tBatch step: 234\n",
      "\tGenerator loss: 0.7375995516777039, Discriminator loss: 1.1006298065185547\n",
      "Time for epoch 1 is 249.3196039199829 sec\n",
      "Epoch 2\n",
      "\tBatch step: 0\n",
      "\tGenerator loss: 0.6288667321205139, Discriminator loss: 1.490837812423706\n",
      "\tBatch step: 1\n",
      "\tGenerator loss: 0.6341626644134521, Discriminator loss: 1.4702885150909424\n",
      "\tBatch step: 2\n",
      "\tGenerator loss: 0.635593593120575, Discriminator loss: 1.4512457847595215\n",
      "\tBatch step: 3\n",
      "\tGenerator loss: 0.6344069242477417, Discriminator loss: 1.43731689453125\n",
      "\tBatch step: 4\n",
      "\tGenerator loss: 0.6358092427253723, Discriminator loss: 1.419320821762085\n",
      "\tBatch step: 5\n",
      "\tGenerator loss: 0.6403594017028809, Discriminator loss: 1.4064149856567383\n",
      "\tBatch step: 6\n",
      "\tGenerator loss: 0.6480568051338196, Discriminator loss: 1.3863989114761353\n",
      "\tBatch step: 7\n",
      "\tGenerator loss: 0.6580003499984741, Discriminator loss: 1.3687450885772705\n",
      "\tBatch step: 8\n",
      "\tGenerator loss: 0.6694417595863342, Discriminator loss: 1.3539546728134155\n",
      "\tBatch step: 9\n",
      "\tGenerator loss: 0.6814667582511902, Discriminator loss: 1.33768892288208\n",
      "\tBatch step: 10\n",
      "\tGenerator loss: 0.6933920383453369, Discriminator loss: 1.3250409364700317\n",
      "\tBatch step: 11\n",
      "\tGenerator loss: 0.7073680758476257, Discriminator loss: 1.307387351989746\n",
      "\tBatch step: 12\n",
      "\tGenerator loss: 0.7191699147224426, Discriminator loss: 1.28779935836792\n",
      "\tBatch step: 13\n",
      "\tGenerator loss: 0.7313264608383179, Discriminator loss: 1.2724562883377075\n",
      "\tBatch step: 14\n",
      "\tGenerator loss: 0.7412235140800476, Discriminator loss: 1.2614105939865112\n",
      "\tBatch step: 15\n",
      "\tGenerator loss: 0.7512745261192322, Discriminator loss: 1.2447503805160522\n",
      "\tBatch step: 16\n",
      "\tGenerator loss: 0.7611544728279114, Discriminator loss: 1.229434847831726\n",
      "\tBatch step: 17\n",
      "\tGenerator loss: 0.7701543569564819, Discriminator loss: 1.2171177864074707\n",
      "\tBatch step: 18\n",
      "\tGenerator loss: 0.7787250280380249, Discriminator loss: 1.2108228206634521\n",
      "\tBatch step: 19\n",
      "\tGenerator loss: 0.7854413390159607, Discriminator loss: 1.2002809047698975\n",
      "\tBatch step: 20\n",
      "\tGenerator loss: 0.7916572093963623, Discriminator loss: 1.1896928548812866\n",
      "\tBatch step: 21\n",
      "\tGenerator loss: 0.7968897223472595, Discriminator loss: 1.1805119514465332\n",
      "\tBatch step: 22\n",
      "\tGenerator loss: 0.8023595213890076, Discriminator loss: 1.1705617904663086\n",
      "\tBatch step: 23\n",
      "\tGenerator loss: 0.8078164458274841, Discriminator loss: 1.1643098592758179\n",
      "\tBatch step: 24\n",
      "\tGenerator loss: 0.8131476044654846, Discriminator loss: 1.1579362154006958\n",
      "\tBatch step: 25\n",
      "\tGenerator loss: 0.8170693516731262, Discriminator loss: 1.1513961553573608\n",
      "\tBatch step: 26\n",
      "\tGenerator loss: 0.8210954070091248, Discriminator loss: 1.1445444822311401\n",
      "\tBatch step: 27\n",
      "\tGenerator loss: 0.8251164555549622, Discriminator loss: 1.138980746269226\n",
      "\tBatch step: 28\n",
      "\tGenerator loss: 0.8294981718063354, Discriminator loss: 1.1327859163284302\n",
      "\tBatch step: 29\n",
      "\tGenerator loss: 0.8334242701530457, Discriminator loss: 1.1287282705307007\n",
      "\tBatch step: 30\n",
      "\tGenerator loss: 0.8375338315963745, Discriminator loss: 1.1265597343444824\n",
      "\tBatch step: 31\n",
      "\tGenerator loss: 0.8409423232078552, Discriminator loss: 1.1249462366104126\n",
      "\tBatch step: 32\n",
      "\tGenerator loss: 0.8435574173927307, Discriminator loss: 1.1231287717819214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch step: 33\n",
      "\tGenerator loss: 0.8451100587844849, Discriminator loss: 1.1266794204711914\n",
      "\tBatch step: 34\n",
      "\tGenerator loss: 0.8456135392189026, Discriminator loss: 1.1272814273834229\n",
      "\tBatch step: 35\n",
      "\tGenerator loss: 0.8460779190063477, Discriminator loss: 1.1273514032363892\n",
      "\tBatch step: 36\n",
      "\tGenerator loss: 0.845707893371582, Discriminator loss: 1.1294952630996704\n",
      "\tBatch step: 37\n",
      "\tGenerator loss: 0.8459387421607971, Discriminator loss: 1.1333980560302734\n",
      "\tBatch step: 38\n",
      "\tGenerator loss: 0.8456546068191528, Discriminator loss: 1.1342735290527344\n",
      "\tBatch step: 39\n",
      "\tGenerator loss: 0.8444927334785461, Discriminator loss: 1.1375513076782227\n",
      "\tBatch step: 40\n",
      "\tGenerator loss: 0.8434051871299744, Discriminator loss: 1.1429628133773804\n",
      "\tBatch step: 41\n",
      "\tGenerator loss: 0.8422737121582031, Discriminator loss: 1.1460400819778442\n",
      "\tBatch step: 42\n",
      "\tGenerator loss: 0.8407044410705566, Discriminator loss: 1.1501106023788452\n",
      "\tBatch step: 43\n",
      "\tGenerator loss: 0.838579535484314, Discriminator loss: 1.154557704925537\n",
      "\tBatch step: 44\n",
      "\tGenerator loss: 0.8368249535560608, Discriminator loss: 1.158560037612915\n",
      "\tBatch step: 45\n",
      "\tGenerator loss: 0.8343775272369385, Discriminator loss: 1.1629348993301392\n",
      "\tBatch step: 46\n",
      "\tGenerator loss: 0.8316228985786438, Discriminator loss: 1.1677227020263672\n",
      "\tBatch step: 47\n",
      "\tGenerator loss: 0.8289413452148438, Discriminator loss: 1.1732994318008423\n",
      "\tBatch step: 48\n",
      "\tGenerator loss: 0.8261427879333496, Discriminator loss: 1.1796002388000488\n",
      "\tBatch step: 49\n",
      "\tGenerator loss: 0.8232356905937195, Discriminator loss: 1.1859447956085205\n",
      "\tBatch step: 50\n",
      "\tGenerator loss: 0.8201290369033813, Discriminator loss: 1.1927309036254883\n",
      "\tBatch step: 51\n",
      "\tGenerator loss: 0.8168149590492249, Discriminator loss: 1.1990277767181396\n",
      "\tBatch step: 52\n",
      "\tGenerator loss: 0.813347578048706, Discriminator loss: 1.204559326171875\n",
      "\tBatch step: 53\n",
      "\tGenerator loss: 0.8101156949996948, Discriminator loss: 1.2094591856002808\n",
      "\tBatch step: 54\n",
      "\tGenerator loss: 0.8072864413261414, Discriminator loss: 1.2153276205062866\n",
      "\tBatch step: 55\n",
      "\tGenerator loss: 0.8049386739730835, Discriminator loss: 1.222814917564392\n",
      "\tBatch step: 56\n",
      "\tGenerator loss: 0.8026321530342102, Discriminator loss: 1.2270934581756592\n",
      "\tBatch step: 57\n",
      "\tGenerator loss: 0.8005982637405396, Discriminator loss: 1.2358561754226685\n",
      "\tBatch step: 58\n",
      "\tGenerator loss: 0.7982127070426941, Discriminator loss: 1.2387217283248901\n",
      "\tBatch step: 59\n",
      "\tGenerator loss: 0.7959756255149841, Discriminator loss: 1.2411023378372192\n",
      "\tBatch step: 60\n",
      "\tGenerator loss: 0.7939637899398804, Discriminator loss: 1.2429850101470947\n",
      "\tBatch step: 61\n",
      "\tGenerator loss: 0.7922496199607849, Discriminator loss: 1.2445305585861206\n",
      "\tBatch step: 62\n",
      "\tGenerator loss: 0.7912274599075317, Discriminator loss: 1.246218204498291\n",
      "\tBatch step: 63\n",
      "\tGenerator loss: 0.790594756603241, Discriminator loss: 1.2473009824752808\n",
      "\tBatch step: 64\n",
      "\tGenerator loss: 0.7901912331581116, Discriminator loss: 1.2474957704544067\n",
      "\tBatch step: 65\n",
      "\tGenerator loss: 0.7899952530860901, Discriminator loss: 1.2488771677017212\n",
      "\tBatch step: 66\n",
      "\tGenerator loss: 0.7900363206863403, Discriminator loss: 1.2498738765716553\n",
      "\tBatch step: 67\n",
      "\tGenerator loss: 0.7901608943939209, Discriminator loss: 1.2500097751617432\n",
      "\tBatch step: 68\n",
      "\tGenerator loss: 0.790406346321106, Discriminator loss: 1.250196099281311\n",
      "\tBatch step: 69\n",
      "\tGenerator loss: 0.7905880212783813, Discriminator loss: 1.2505121231079102\n",
      "\tBatch step: 70\n",
      "\tGenerator loss: 0.7907886505126953, Discriminator loss: 1.249651551246643\n",
      "\tBatch step: 71\n",
      "\tGenerator loss: 0.7911661863327026, Discriminator loss: 1.2488489151000977\n",
      "\tBatch step: 72\n",
      "\tGenerator loss: 0.7912638187408447, Discriminator loss: 1.2485105991363525\n",
      "\tBatch step: 73\n",
      "\tGenerator loss: 0.7916277050971985, Discriminator loss: 1.247921347618103\n",
      "\tBatch step: 74\n",
      "\tGenerator loss: 0.7921449542045593, Discriminator loss: 1.2469384670257568\n",
      "\tBatch step: 75\n",
      "\tGenerator loss: 0.7931285500526428, Discriminator loss: 1.2455236911773682\n",
      "\tBatch step: 76\n",
      "\tGenerator loss: 0.7940705418586731, Discriminator loss: 1.2438493967056274\n",
      "\tBatch step: 77\n",
      "\tGenerator loss: 0.7952386140823364, Discriminator loss: 1.2433398962020874\n",
      "\tBatch step: 78\n",
      "\tGenerator loss: 0.7964552044868469, Discriminator loss: 1.2436168193817139\n",
      "\tBatch step: 79\n",
      "\tGenerator loss: 0.7976441383361816, Discriminator loss: 1.2421517372131348\n",
      "\tBatch step: 80\n",
      "\tGenerator loss: 0.7986192107200623, Discriminator loss: 1.2399017810821533\n",
      "\tBatch step: 81\n",
      "\tGenerator loss: 0.7997167706489563, Discriminator loss: 1.2384955883026123\n",
      "\tBatch step: 82\n",
      "\tGenerator loss: 0.8006857633590698, Discriminator loss: 1.2374364137649536\n",
      "\tBatch step: 83\n",
      "\tGenerator loss: 0.8019626140594482, Discriminator loss: 1.2360851764678955\n",
      "\tBatch step: 84\n",
      "\tGenerator loss: 0.802941083908081, Discriminator loss: 1.234513282775879\n",
      "\tBatch step: 85\n",
      "\tGenerator loss: 0.8039094805717468, Discriminator loss: 1.2323113679885864\n",
      "\tBatch step: 86\n",
      "\tGenerator loss: 0.8050185441970825, Discriminator loss: 1.2330634593963623\n",
      "\tBatch step: 87\n",
      "\tGenerator loss: 0.8060445189476013, Discriminator loss: 1.232287049293518\n",
      "\tBatch step: 88\n",
      "\tGenerator loss: 0.8068444132804871, Discriminator loss: 1.2309962511062622\n",
      "\tBatch step: 89\n",
      "\tGenerator loss: 0.8072909116744995, Discriminator loss: 1.2302366495132446\n",
      "\tBatch step: 90\n",
      "\tGenerator loss: 0.8076180219650269, Discriminator loss: 1.2294706106185913\n",
      "\tBatch step: 91\n",
      "\tGenerator loss: 0.8076868653297424, Discriminator loss: 1.2299120426177979\n",
      "\tBatch step: 92\n",
      "\tGenerator loss: 0.8074513077735901, Discriminator loss: 1.2311164140701294\n",
      "\tBatch step: 93\n",
      "\tGenerator loss: 0.8069204688072205, Discriminator loss: 1.231905221939087\n",
      "\tBatch step: 94\n",
      "\tGenerator loss: 0.8060479164123535, Discriminator loss: 1.2335361242294312\n",
      "\tBatch step: 95\n",
      "\tGenerator loss: 0.8049878478050232, Discriminator loss: 1.236376166343689\n",
      "\tBatch step: 96\n",
      "\tGenerator loss: 0.8034766316413879, Discriminator loss: 1.2392785549163818\n",
      "\tBatch step: 97\n",
      "\tGenerator loss: 0.801623523235321, Discriminator loss: 1.24364173412323\n",
      "\tBatch step: 98\n",
      "\tGenerator loss: 0.7994150519371033, Discriminator loss: 1.247666835784912\n",
      "\tBatch step: 99\n",
      "\tGenerator loss: 0.7968395948410034, Discriminator loss: 1.2517489194869995\n",
      "\tBatch step: 100\n",
      "\tGenerator loss: 0.7942759394645691, Discriminator loss: 1.2574018239974976\n",
      "\tBatch step: 101\n",
      "\tGenerator loss: 0.7917224764823914, Discriminator loss: 1.263917326927185\n",
      "\tBatch step: 102\n",
      "\tGenerator loss: 0.7890364527702332, Discriminator loss: 1.269859790802002\n",
      "\tBatch step: 103\n",
      "\tGenerator loss: 0.7863235473632812, Discriminator loss: 1.2772300243377686\n",
      "\tBatch step: 104\n",
      "\tGenerator loss: 0.7836170792579651, Discriminator loss: 1.2831306457519531\n",
      "\tBatch step: 105\n",
      "\tGenerator loss: 0.7808636426925659, Discriminator loss: 1.2891854047775269\n",
      "\tBatch step: 106\n",
      "\tGenerator loss: 0.7782672643661499, Discriminator loss: 1.2951834201812744\n",
      "\tBatch step: 107\n",
      "\tGenerator loss: 0.7760037779808044, Discriminator loss: 1.3011579513549805\n",
      "\tBatch step: 108\n",
      "\tGenerator loss: 0.7737837433815002, Discriminator loss: 1.3073415756225586\n",
      "\tBatch step: 109\n",
      "\tGenerator loss: 0.7716602683067322, Discriminator loss: 1.3110188245773315\n",
      "\tBatch step: 110\n",
      "\tGenerator loss: 0.7698369026184082, Discriminator loss: 1.314571499824524\n",
      "\tBatch step: 111\n",
      "\tGenerator loss: 0.7682350277900696, Discriminator loss: 1.318462610244751\n",
      "\tBatch step: 112\n",
      "\tGenerator loss: 0.7669406533241272, Discriminator loss: 1.3215444087982178\n",
      "\tBatch step: 113\n",
      "\tGenerator loss: 0.7658653855323792, Discriminator loss: 1.3245290517807007\n",
      "\tBatch step: 114\n",
      "\tGenerator loss: 0.7649288177490234, Discriminator loss: 1.3260180950164795\n",
      "\tBatch step: 115\n",
      "\tGenerator loss: 0.7640489935874939, Discriminator loss: 1.327441930770874\n",
      "\tBatch step: 116\n",
      "\tGenerator loss: 0.7634720802307129, Discriminator loss: 1.3294299840927124\n",
      "\tBatch step: 117\n",
      "\tGenerator loss: 0.7630226016044617, Discriminator loss: 1.3311606645584106\n",
      "\tBatch step: 118\n",
      "\tGenerator loss: 0.7624969482421875, Discriminator loss: 1.3316919803619385\n",
      "\tBatch step: 119\n",
      "\tGenerator loss: 0.7619212865829468, Discriminator loss: 1.3322042226791382\n",
      "\tBatch step: 120\n",
      "\tGenerator loss: 0.7614471912384033, Discriminator loss: 1.3320510387420654\n",
      "\tBatch step: 121\n",
      "\tGenerator loss: 0.7612097859382629, Discriminator loss: 1.3313548564910889\n",
      "\tBatch step: 122\n",
      "\tGenerator loss: 0.7609788179397583, Discriminator loss: 1.3306883573532104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch step: 123\n",
      "\tGenerator loss: 0.7609997987747192, Discriminator loss: 1.3300209045410156\n",
      "\tBatch step: 124\n",
      "\tGenerator loss: 0.761193037033081, Discriminator loss: 1.3288980722427368\n",
      "\tBatch step: 125\n",
      "\tGenerator loss: 0.7616151571273804, Discriminator loss: 1.3271633386611938\n",
      "\tBatch step: 126\n",
      "\tGenerator loss: 0.7622247934341431, Discriminator loss: 1.3255946636199951\n",
      "\tBatch step: 127\n",
      "\tGenerator loss: 0.7630648016929626, Discriminator loss: 1.3235169649124146\n",
      "\tBatch step: 128\n",
      "\tGenerator loss: 0.7643129825592041, Discriminator loss: 1.3211668729782104\n",
      "\tBatch step: 129\n",
      "\tGenerator loss: 0.7656182050704956, Discriminator loss: 1.3189059495925903\n",
      "\tBatch step: 130\n",
      "\tGenerator loss: 0.7670299410820007, Discriminator loss: 1.3168054819107056\n",
      "\tBatch step: 131\n",
      "\tGenerator loss: 0.768499493598938, Discriminator loss: 1.3145217895507812\n",
      "\tBatch step: 132\n",
      "\tGenerator loss: 0.7699869871139526, Discriminator loss: 1.3122726678848267\n",
      "\tBatch step: 133\n",
      "\tGenerator loss: 0.7714844346046448, Discriminator loss: 1.3101675510406494\n",
      "\tBatch step: 134\n",
      "\tGenerator loss: 0.7728444933891296, Discriminator loss: 1.3079110383987427\n",
      "\tBatch step: 135\n",
      "\tGenerator loss: 0.774090588092804, Discriminator loss: 1.3059138059616089\n",
      "\tBatch step: 136\n",
      "\tGenerator loss: 0.7750433683395386, Discriminator loss: 1.3041366338729858\n",
      "\tBatch step: 137\n",
      "\tGenerator loss: 0.7757570743560791, Discriminator loss: 1.3026196956634521\n",
      "\tBatch step: 138\n",
      "\tGenerator loss: 0.7762747406959534, Discriminator loss: 1.301166296005249\n",
      "\tBatch step: 139\n",
      "\tGenerator loss: 0.7765532732009888, Discriminator loss: 1.2997671365737915\n",
      "\tBatch step: 140\n",
      "\tGenerator loss: 0.7768722176551819, Discriminator loss: 1.2985117435455322\n",
      "\tBatch step: 141\n",
      "\tGenerator loss: 0.7770625948905945, Discriminator loss: 1.2977899312973022\n",
      "\tBatch step: 142\n",
      "\tGenerator loss: 0.7772446274757385, Discriminator loss: 1.2966316938400269\n",
      "\tBatch step: 143\n",
      "\tGenerator loss: 0.7774172425270081, Discriminator loss: 1.2958383560180664\n",
      "\tBatch step: 144\n",
      "\tGenerator loss: 0.7775927186012268, Discriminator loss: 1.2950129508972168\n",
      "\tBatch step: 145\n",
      "\tGenerator loss: 0.7777313590049744, Discriminator loss: 1.2950067520141602\n",
      "\tBatch step: 146\n",
      "\tGenerator loss: 0.7778196930885315, Discriminator loss: 1.294335961341858\n",
      "\tBatch step: 147\n",
      "\tGenerator loss: 0.7778003811836243, Discriminator loss: 1.293588638305664\n",
      "\tBatch step: 148\n",
      "\tGenerator loss: 0.7777162790298462, Discriminator loss: 1.292832851409912\n",
      "\tBatch step: 149\n",
      "\tGenerator loss: 0.7777118682861328, Discriminator loss: 1.292130470275879\n",
      "\tBatch step: 150\n",
      "\tGenerator loss: 0.7778069972991943, Discriminator loss: 1.2913827896118164\n",
      "\tBatch step: 151\n",
      "\tGenerator loss: 0.7778286933898926, Discriminator loss: 1.2906955480575562\n",
      "\tBatch step: 152\n",
      "\tGenerator loss: 0.7779186964035034, Discriminator loss: 1.2901180982589722\n",
      "\tBatch step: 153\n",
      "\tGenerator loss: 0.7782724499702454, Discriminator loss: 1.2897841930389404\n",
      "\tBatch step: 154\n",
      "\tGenerator loss: 0.778682291507721, Discriminator loss: 1.2894726991653442\n",
      "\tBatch step: 155\n",
      "\tGenerator loss: 0.7789732217788696, Discriminator loss: 1.2885339260101318\n",
      "\tBatch step: 156\n",
      "\tGenerator loss: 0.7793586850166321, Discriminator loss: 1.287909984588623\n",
      "\tBatch step: 157\n",
      "\tGenerator loss: 0.7798945903778076, Discriminator loss: 1.2870643138885498\n",
      "\tBatch step: 158\n",
      "\tGenerator loss: 0.7805452942848206, Discriminator loss: 1.2868950366973877\n",
      "\tBatch step: 159\n",
      "\tGenerator loss: 0.7811635732650757, Discriminator loss: 1.2860314846038818\n",
      "\tBatch step: 160\n",
      "\tGenerator loss: 0.7817073464393616, Discriminator loss: 1.2852420806884766\n",
      "\tBatch step: 161\n",
      "\tGenerator loss: 0.7823450565338135, Discriminator loss: 1.2848076820373535\n",
      "\tBatch step: 162\n",
      "\tGenerator loss: 0.7828080058097839, Discriminator loss: 1.2838988304138184\n",
      "\tBatch step: 163\n",
      "\tGenerator loss: 0.7833494544029236, Discriminator loss: 1.2829755544662476\n",
      "\tBatch step: 164\n",
      "\tGenerator loss: 0.7838162779808044, Discriminator loss: 1.2825937271118164\n",
      "\tBatch step: 165\n",
      "\tGenerator loss: 0.7843002676963806, Discriminator loss: 1.2819033861160278\n",
      "\tBatch step: 166\n",
      "\tGenerator loss: 0.7849841713905334, Discriminator loss: 1.2814236879348755\n",
      "\tBatch step: 167\n",
      "\tGenerator loss: 0.785468339920044, Discriminator loss: 1.2805240154266357\n",
      "\tBatch step: 168\n",
      "\tGenerator loss: 0.7859470248222351, Discriminator loss: 1.279399037361145\n",
      "\tBatch step: 169\n",
      "\tGenerator loss: 0.7862401008605957, Discriminator loss: 1.2785130739212036\n",
      "\tBatch step: 170\n",
      "\tGenerator loss: 0.7866071462631226, Discriminator loss: 1.2775214910507202\n",
      "\tBatch step: 171\n",
      "\tGenerator loss: 0.7871132493019104, Discriminator loss: 1.2763274908065796\n",
      "\tBatch step: 172\n",
      "\tGenerator loss: 0.7874571681022644, Discriminator loss: 1.2757177352905273\n",
      "\tBatch step: 173\n",
      "\tGenerator loss: 0.7879176735877991, Discriminator loss: 1.2751572132110596\n",
      "\tBatch step: 174\n",
      "\tGenerator loss: 0.7882553339004517, Discriminator loss: 1.2744067907333374\n",
      "\tBatch step: 175\n",
      "\tGenerator loss: 0.7885555028915405, Discriminator loss: 1.2739917039871216\n",
      "\tBatch step: 176\n",
      "\tGenerator loss: 0.7887194752693176, Discriminator loss: 1.2740225791931152\n",
      "\tBatch step: 177\n",
      "\tGenerator loss: 0.7885317802429199, Discriminator loss: 1.2739001512527466\n",
      "\tBatch step: 178\n",
      "\tGenerator loss: 0.788374125957489, Discriminator loss: 1.2742390632629395\n",
      "\tBatch step: 179\n",
      "\tGenerator loss: 0.7879542708396912, Discriminator loss: 1.2745552062988281\n",
      "\tBatch step: 180\n",
      "\tGenerator loss: 0.7874481678009033, Discriminator loss: 1.2751927375793457\n",
      "\tBatch step: 181\n",
      "\tGenerator loss: 0.7869747281074524, Discriminator loss: 1.2763803005218506\n",
      "\tBatch step: 182\n",
      "\tGenerator loss: 0.7864313125610352, Discriminator loss: 1.2780697345733643\n",
      "\tBatch step: 183\n",
      "\tGenerator loss: 0.7858356237411499, Discriminator loss: 1.2797222137451172\n",
      "\tBatch step: 184\n",
      "\tGenerator loss: 0.7852110266685486, Discriminator loss: 1.2810136079788208\n",
      "\tBatch step: 185\n",
      "\tGenerator loss: 0.7846147418022156, Discriminator loss: 1.283327341079712\n",
      "\tBatch step: 186\n",
      "\tGenerator loss: 0.7841722369194031, Discriminator loss: 1.285482406616211\n",
      "\tBatch step: 187\n",
      "\tGenerator loss: 0.7836341261863708, Discriminator loss: 1.2872700691223145\n",
      "\tBatch step: 188\n",
      "\tGenerator loss: 0.7829972505569458, Discriminator loss: 1.2892345190048218\n",
      "\tBatch step: 189\n",
      "\tGenerator loss: 0.7823936343193054, Discriminator loss: 1.29069983959198\n",
      "\tBatch step: 190\n",
      "\tGenerator loss: 0.7819889783859253, Discriminator loss: 1.291621208190918\n",
      "\tBatch step: 191\n",
      "\tGenerator loss: 0.7816385626792908, Discriminator loss: 1.2924883365631104\n",
      "\tBatch step: 192\n",
      "\tGenerator loss: 0.7814242243766785, Discriminator loss: 1.292938232421875\n",
      "\tBatch step: 193\n",
      "\tGenerator loss: 0.7814254760742188, Discriminator loss: 1.2933993339538574\n",
      "\tBatch step: 194\n",
      "\tGenerator loss: 0.781524121761322, Discriminator loss: 1.293479084968567\n",
      "\tBatch step: 195\n",
      "\tGenerator loss: 0.7817825078964233, Discriminator loss: 1.293137788772583\n",
      "\tBatch step: 196\n",
      "\tGenerator loss: 0.7821546196937561, Discriminator loss: 1.2925323247909546\n",
      "\tBatch step: 197\n",
      "\tGenerator loss: 0.7825756669044495, Discriminator loss: 1.2918975353240967\n",
      "\tBatch step: 198\n",
      "\tGenerator loss: 0.7830983996391296, Discriminator loss: 1.2908663749694824\n",
      "\tBatch step: 199\n",
      "\tGenerator loss: 0.7837353348731995, Discriminator loss: 1.289598822593689\n",
      "\tBatch step: 200\n",
      "\tGenerator loss: 0.7845547199249268, Discriminator loss: 1.2883429527282715\n",
      "\tBatch step: 201\n",
      "\tGenerator loss: 0.7854824066162109, Discriminator loss: 1.2869555950164795\n",
      "\tBatch step: 202\n",
      "\tGenerator loss: 0.7865608930587769, Discriminator loss: 1.2852957248687744\n",
      "\tBatch step: 203\n",
      "\tGenerator loss: 0.7877209782600403, Discriminator loss: 1.2838828563690186\n",
      "\tBatch step: 204\n",
      "\tGenerator loss: 0.7889418601989746, Discriminator loss: 1.28209388256073\n",
      "\tBatch step: 205\n",
      "\tGenerator loss: 0.7901607155799866, Discriminator loss: 1.2801162004470825\n",
      "\tBatch step: 206\n",
      "\tGenerator loss: 0.791338324546814, Discriminator loss: 1.2782061100006104\n",
      "\tBatch step: 207\n",
      "\tGenerator loss: 0.7926493287086487, Discriminator loss: 1.2760307788848877\n",
      "\tBatch step: 208\n",
      "\tGenerator loss: 0.7940093874931335, Discriminator loss: 1.2741543054580688\n",
      "\tBatch step: 209\n",
      "\tGenerator loss: 0.7954264879226685, Discriminator loss: 1.2723119258880615\n",
      "\tBatch step: 210\n",
      "\tGenerator loss: 0.7968007922172546, Discriminator loss: 1.2704535722732544\n",
      "\tBatch step: 211\n",
      "\tGenerator loss: 0.7982156276702881, Discriminator loss: 1.2686043977737427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch step: 212\n",
      "\tGenerator loss: 0.799612283706665, Discriminator loss: 1.2665135860443115\n",
      "\tBatch step: 213\n",
      "\tGenerator loss: 0.8009276390075684, Discriminator loss: 1.2643535137176514\n",
      "\tBatch step: 214\n",
      "\tGenerator loss: 0.8022513389587402, Discriminator loss: 1.262626051902771\n",
      "\tBatch step: 215\n",
      "\tGenerator loss: 0.8036059737205505, Discriminator loss: 1.2605913877487183\n",
      "\tBatch step: 216\n",
      "\tGenerator loss: 0.8049699068069458, Discriminator loss: 1.2586370706558228\n",
      "\tBatch step: 217\n",
      "\tGenerator loss: 0.8064311742782593, Discriminator loss: 1.2564747333526611\n",
      "\tBatch step: 218\n",
      "\tGenerator loss: 0.8079453110694885, Discriminator loss: 1.254457712173462\n",
      "\tBatch step: 219\n",
      "\tGenerator loss: 0.8095587491989136, Discriminator loss: 1.2527488470077515\n",
      "\tBatch step: 220\n",
      "\tGenerator loss: 0.8112342357635498, Discriminator loss: 1.2510974407196045\n",
      "\tBatch step: 221\n",
      "\tGenerator loss: 0.8129147887229919, Discriminator loss: 1.2494328022003174\n",
      "\tBatch step: 222\n",
      "\tGenerator loss: 0.814484179019928, Discriminator loss: 1.2477463483810425\n",
      "\tBatch step: 223\n",
      "\tGenerator loss: 0.815960705280304, Discriminator loss: 1.2460706233978271\n",
      "\tBatch step: 224\n",
      "\tGenerator loss: 0.8172881603240967, Discriminator loss: 1.244351863861084\n",
      "\tBatch step: 225\n",
      "\tGenerator loss: 0.8186423778533936, Discriminator loss: 1.2429229021072388\n",
      "\tBatch step: 226\n",
      "\tGenerator loss: 0.8198447823524475, Discriminator loss: 1.2415473461151123\n",
      "\tBatch step: 227\n",
      "\tGenerator loss: 0.8208679556846619, Discriminator loss: 1.2399924993515015\n",
      "\tBatch step: 228\n",
      "\tGenerator loss: 0.8219385743141174, Discriminator loss: 1.2383079528808594\n",
      "\tBatch step: 229\n",
      "\tGenerator loss: 0.8229929804801941, Discriminator loss: 1.236842393875122\n",
      "\tBatch step: 230\n",
      "\tGenerator loss: 0.8241726160049438, Discriminator loss: 1.2350623607635498\n",
      "\tBatch step: 231\n",
      "\tGenerator loss: 0.8254210948944092, Discriminator loss: 1.2329784631729126\n",
      "\tBatch step: 232\n",
      "\tGenerator loss: 0.8268165588378906, Discriminator loss: 1.2310112714767456\n",
      "\tBatch step: 233\n",
      "\tGenerator loss: 0.8283776044845581, Discriminator loss: 1.229109525680542\n",
      "\tBatch step: 234\n",
      "\tGenerator loss: 0.8300517797470093, Discriminator loss: 1.2285116910934448\n",
      "Time for epoch 2 is 276.7035572528839 sec\n",
      "Epoch 3\n",
      "\tBatch step: 0\n",
      "\tGenerator loss: 1.168533444404602, Discriminator loss: 0.9115073680877686\n",
      "\tBatch step: 1\n",
      "\tGenerator loss: 1.1483540534973145, Discriminator loss: 0.9215304851531982\n",
      "\tBatch step: 2\n",
      "\tGenerator loss: 1.1315405368804932, Discriminator loss: 0.9191824793815613\n",
      "\tBatch step: 3\n",
      "\tGenerator loss: 1.1034762859344482, Discriminator loss: 0.9250996708869934\n",
      "\tBatch step: 4\n",
      "\tGenerator loss: 1.0784022808074951, Discriminator loss: 0.9284305572509766\n",
      "\tBatch step: 5\n",
      "\tGenerator loss: 1.0554331541061401, Discriminator loss: 0.9263455271720886\n",
      "\tBatch step: 6\n",
      "\tGenerator loss: 1.040055513381958, Discriminator loss: 0.9338884353637695\n",
      "\tBatch step: 7\n",
      "\tGenerator loss: 1.0263218879699707, Discriminator loss: 0.9347521662712097\n",
      "\tBatch step: 8\n",
      "\tGenerator loss: 1.019629955291748, Discriminator loss: 0.937002420425415\n",
      "\tBatch step: 9\n",
      "\tGenerator loss: 1.0172206163406372, Discriminator loss: 0.9460737109184265\n",
      "\tBatch step: 10\n",
      "\tGenerator loss: 1.0136847496032715, Discriminator loss: 0.9563514590263367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a141f8f7ecff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m       \u001b[1;31m# Generator and discriminator losses in that batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[0mgenerator_loss_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator_loss_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_real_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m       \u001b[1;31m# Updating the actual generator and discriminator losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List of generator and discriminator losses across the epochs\n",
    "generator_loss_epochs = []\n",
    "discriminator_loss_epochs = []\n",
    "\n",
    "# Iterating over all the epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    # EPOCH\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    \n",
    "    # In each epoch, we start the updating of the losses from scratch\n",
    "    generator_epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    discriminator_epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Iterating over all the batches in that epoch\n",
    "    for batch_step, batch_real_images in enumerate(x_train):\n",
    "      # TRAINING STEP  \n",
    "        \n",
    "      # Generator and discriminator losses in that batch \n",
    "      generator_loss_batch, discriminator_loss_batch = train_step(batch_real_images)\n",
    "        \n",
    "      # Updating the actual generator and discriminator losses\n",
    "      generator_epoch_loss_avg.update_state(generator_loss_batch)\n",
    "      discriminator_epoch_loss_avg.update_state(discriminator_loss_batch)\n",
    "    \n",
    "      generator_loss_epoch = generator_epoch_loss_avg.result()\n",
    "      discriminator_loss_epoch = discriminator_epoch_loss_avg.result()\n",
    "      generator_loss_epochs.append(generator_loss_epoch)\n",
    "      discriminator_loss_epochs.append(discriminator_loss_epoch)\n",
    "        \n",
    "      # End training step\n",
    "      print(f'\\tBatch step: {batch_step}')\n",
    "      print(f'\\tGenerator loss: {generator_loss_epoch}, Discriminator loss: {discriminator_loss_epoch}')\n",
    "    \n",
    "    # End epoch\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431bf7b",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc322ee",
   "metadata": {},
   "source": [
    "Generating some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bcd13c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "05052331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sample shape: (10, 100)\n",
      "generated_images shape: (10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Sample of n latent vectors 'z'. Each of them is a vector with 'latent_dim' values.\n",
    "z_sample = np.random.normal(size=(n, latent_dim))\n",
    "print('z_sample shape:', z_sample.shape)\n",
    "\n",
    "# n generated MNISt images\n",
    "generated_images = generator.predict(z_sample)\n",
    "print('generated_images shape:', generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f34d51e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2*n, 2))\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  plt.imshow(generated_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "976237f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39dfcc78",
   "metadata": {},
   "source": [
    "## FINAL COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f7792",
   "metadata": {},
   "source": [
    "As it can be seen, the training is like a fight between the discriminator and the generator: both of them are trying to minimize their loss, but in this way they are trying to increase the loss of the other component. It's like a MIn-Max game between two opponents.\n",
    "\n",
    "In the end of this fight, the generator should win: it should be able to fool the discriminator.\n",
    "\n",
    "**So, training a GAN is a particular process, which can be tricky. Training can be difficult.** THis is a drawback with respect to VAE.\n",
    "\n",
    "But, on the contrary, GAN typically achieves better results. It reaches a better generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
