{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3597e5",
   "metadata": {},
   "source": [
    "# ConvVAE MNISTdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8565b",
   "metadata": {},
   "source": [
    "In the previous notebook we have seen the implementation of a Dense VAE. Now we see a Conv VAE (i.e. CVAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f96ff",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/generative/cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696cb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Import keras dataset Mnist\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2afcd",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4cdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c89127",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c5ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc15fc",
   "metadata": {},
   "source": [
    "Adding the channels dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f64d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (60000, 28, 28, 1)) \n",
    "\n",
    "x_test = np.reshape(x_test, (10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0f322",
   "metadata": {},
   "source": [
    "### Latent dimension\n",
    "\n",
    "We decide since now the dimensionality of $z$: $16$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0951213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a579a",
   "metadata": {},
   "source": [
    "### Sampling function\n",
    "\n",
    "We define the sampling function. Given the mean $\\mu(z|X)$ and std $\\sigma(z|X)$ produced by the encoder, it samples a latent encoding $z$, which is the variable to give to the generator.\n",
    "\n",
    "$z$ is computed as $\\mu(z|X)+\\sigma(z|X)*\\epsilon$, where $\\epsilon$ is sampled from the normal distribution $N(0,1)$.\n",
    "\n",
    "It is important to remark that we are talking about multivariate distributions: $z$, $\\mu(z|X)$, $\\sigma(z|X)$ and $\\epsilon$ are vectors of values. They are all vectors of dimensions $16$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0405c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf03e71",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a6770",
   "metadata": {},
   "source": [
    "The encoder takes in input an image: $28x28x1$ values. Structured input.\n",
    "\n",
    "We produce two outputs: the mean $\\mu(z|X)$ and the std $\\sigma(z|X)$. Both of them are flat vectors with $16$ values.\n",
    "\n",
    "Actually, the encoder produces the log-variance $log(\\sigma(z|X)^2)$ instead of the std $\\sigma(z|X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9bfbb",
   "metadata": {},
   "source": [
    "The structure is the following.\n",
    "- Some Conv layers\n",
    "- Flattening\n",
    "- Dense layer for producing $\\mu(z|X)$ and Dense layer for producing $log(\\sigma(z|X)^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c43702f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c09474b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image x\n",
    "xin = Input(shape=(28,28,1))\n",
    "\n",
    "# Conv layers\n",
    "x = Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(xin)\n",
    "x = Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(x)\n",
    "\n",
    "# Flattening from 7x7x32 to 1568\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Producing the mean and the log-variance\n",
    "z_mean = Dense(units=latent_dim)(x)  # From 1568 values to 16\n",
    "z_log_var = Dense(units=latent_dim)(x)  # From 1568 values to 16\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(inputs=xin, outputs=[z_mean, z_log_var], name='Encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a1b9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 14, 14, 16)   160         ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 7, 7, 32)     4640        ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 1568)         0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16)           25104       ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16)           25104       ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,008\n",
      "Trainable params: 55,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb28137",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "It takes as input a latent encoding $z$: dimension $16$. It generates a reconstructed image $\\hat{X}$: dimensions $28x28x1$. \n",
    "\n",
    "The last layer of the decoder uses the **sigmoid** activation function, since we want values between $0$ and $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71415d1",
   "metadata": {},
   "source": [
    "So, it starts from a flat input of dimension $16$, and it generates a structured output of dimensions $28x28x1$.\n",
    "\n",
    "For doing so, we follow this pattern.\n",
    "1. Input $z$: dimension $16$.\n",
    "2. Dense layer, producing $7*7*32=1568$ values.\n",
    "\n",
    "Now, we want to increase the spatial dimensions. For doing so, we use Transposed Conv layers.\n",
    "\n",
    "3. Reshaping from flat dimension $1568$ to dimensions $14, 14, 32$. \n",
    "4. Transposed Conv layer, with output dimensions $28, 28, 16$.\n",
    "5. Transposed Conv layer, with output dimensions $28, 28, 1$. The output is the generated image $\\hat{X}$. THe activation function is **sigmoid**, beacuse we want to generate values in the range $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bfac3",
   "metadata": {},
   "source": [
    "Very simmetric with respect to the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49300ccd",
   "metadata": {},
   "source": [
    "The decoder is our generator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4964c",
   "metadata": {},
   "source": [
    "The structure is the following.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd7946c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f3b551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: latent encoding z\n",
    "zin = Input(shape=(latent_dim,))\n",
    "\n",
    "# Dense layer: from 16 values to 1568\n",
    "z = Dense(units=1568)(zin)\n",
    "\n",
    "# Reshaping from 1568 to 7x7x32\n",
    "z = Reshape((7, 7, 32))(z)\n",
    "\n",
    "# Transpose Conv layers\n",
    "z = Conv2DTranspose(filters=32, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(z)\n",
    "z = Conv2DTranspose(filters=16, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(z)\n",
    "\n",
    "# Generated image\n",
    "x_hat = Conv2DTranspose(filters=1, kernel_size=(3,3), strides=(1,1), padding='same', activation='sigmoid')(z)\n",
    "\n",
    "decoder = Model(inputs=zin, outputs=x_hat, name='Decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c43c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1568)              26656     \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 14, 14, 32)       9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 28, 28, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 28, 28, 1)        145       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,673\n",
      "Trainable params: 40,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b1500",
   "metadata": {},
   "source": [
    "### Sampling layer\n",
    "\n",
    "Between the encoder and the decoder, we have to put the sampling operation: fiven the mean $\\mu(z|X)$ and the log-variance $log(\\sigma(z|X)^2)$, it generates a sample $z$.\n",
    "\n",
    "This is implemented using a layer. In particular, in keras we can use the `lambda` layer for building a layer starting from a function. (In our case, the `sampling` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "431704e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733013fb",
   "metadata": {},
   "source": [
    "### VAE model\n",
    "\n",
    "Finally, let's define the VAE model.\n",
    "1. We use the encoder as a single layer.\n",
    "2. We define the sampling layer.\n",
    "3. We use the decoder as a single layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89e5d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(28,28,1))\n",
    "\n",
    "z_mean, z_log_var = encoder(x)\n",
    "\n",
    "z = Lambda(function=sampling, output_shape=(latent_dim,), name='Sampling')([z_mean, z_log_var])\n",
    "\n",
    "x_hat = decoder(z)\n",
    "\n",
    "vae = Model(inputs=x, outputs=x_hat, name='VAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e12442e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " Encoder (Functional)           [(None, 16),         55008       ['input_21[0][0]']               \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " Sampling (Lambda)              (None, 16)           0           ['Encoder[0][0]',                \n",
      "                                                                  'Encoder[0][1]']                \n",
      "                                                                                                  \n",
      " Decoder (Functional)           (None, 28, 28, 1)    40673       ['Sampling[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 95,681\n",
      "Trainable params: 95,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a266e",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0affd2a",
   "metadata": {},
   "source": [
    "Sum between two components: reconstruction error and KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4464f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6787ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our loss function\n",
    "rec_loss = 784 * metrics.binary_crossentropy(tf.reshape(x,shape=[-1]), tf.reshape(x_hat,shape=[-1]))\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(rec_loss + kl_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c25447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the loss into our model\n",
    "vae.add_loss(vae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e75299",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f06685e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21356c9b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f49f874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "108a8968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 23s 36ms/step - loss: 164.6727 - val_loss: 117.9775\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 114.7415 - val_loss: 110.3856\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 109.9513 - val_loss: 107.5480\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 107.7055 - val_loss: 105.8013\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 106.2333 - val_loss: 105.1759\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 105.2029 - val_loss: 104.2280\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 104.4876 - val_loss: 103.3176\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 103.8351 - val_loss: 102.9411\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 103.3393 - val_loss: 102.5149\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 102.8562 - val_loss: 102.3660\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 102.5106 - val_loss: 101.7799\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 102.1791 - val_loss: 101.4301\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 101.8668 - val_loss: 101.2044\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 101.6171 - val_loss: 101.3268\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 101.3646 - val_loss: 100.8749\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 101.1566 - val_loss: 100.4998\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 100.9377 - val_loss: 100.2673\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 100.7619 - val_loss: 100.3779\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 100.5866 - val_loss: 100.0719\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 100.5005 - val_loss: 100.0265\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 100.3447 - val_loss: 99.8727\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 100.1973 - val_loss: 99.6059\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 100.0872 - val_loss: 99.5751\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 99.9870 - val_loss: 99.4606\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 99.8618 - val_loss: 99.4900\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 99.7471 - val_loss: 99.3297\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 99.6903 - val_loss: 99.2704\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 99.5484 - val_loss: 99.1220\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 99.5341 - val_loss: 99.1583\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 99.4028 - val_loss: 99.0139\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 99.3655 - val_loss: 99.2310\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 99.2865 - val_loss: 99.0496\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 99.2289 - val_loss: 98.9809\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 99.1690 - val_loss: 98.7991\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 99.1093 - val_loss: 99.0078\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 99.0605 - val_loss: 98.7925\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 99.0026 - val_loss: 98.9604\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 98.9414 - val_loss: 98.5283\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 98.8797 - val_loss: 98.7208\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 98.8461 - val_loss: 98.6104\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 98.7920 - val_loss: 98.5866\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 98.7958 - val_loss: 98.5618\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 98.6805 - val_loss: 98.4751\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 98.6517 - val_loss: 98.7548\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 98.6653 - val_loss: 98.4183\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 98.5944 - val_loss: 98.3775\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 98.5902 - val_loss: 98.3714\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 98.5130 - val_loss: 98.2768\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 98.4963 - val_loss: 98.1465\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 98.4583 - val_loss: 98.2614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1553e5b2e80>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, None, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f1bed",
   "metadata": {},
   "source": [
    "Better loss value with respect to the Dense VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd274069",
   "metadata": {},
   "source": [
    "### Generating MNIST images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0305e1a",
   "metadata": {},
   "source": [
    "Now we want to generate some MNIST images. How to do that?\n",
    "\n",
    "The decoder is our generator. Given a latent encoding $z$, it generates an image $\\hat{X}$ compliant with our dataset: so, a MNIST image.\n",
    "\n",
    "The latent encoding $z$ is sampled from the latent space $N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85530279",
   "metadata": {},
   "source": [
    "We want to generate $n$ MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "326f3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a01176ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sample shape: (10, 16)\n",
      "generated_images shape: (10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Sample of n latent vectors 'z'. Each of them is a vector with 'latent_dim' values.\n",
    "z_sample = np.random.normal(size=(n, latent_dim))\n",
    "print('z_sample shape:', z_sample.shape)\n",
    "\n",
    "# n generated MNISt images\n",
    "generated_images = decoder.predict(z_sample)\n",
    "print('generated_images shape:', generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f34d51e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2*n, 2))\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  plt.imshow(generated_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a9a81",
   "metadata": {},
   "source": [
    "Another generation of $10$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5487d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sample shape: (10, 16)\n",
      "generated_images shape: (10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Sample of n latent vectors 'z'. Each of them is a vector with 'latent_dim' values.\n",
    "z_sample = np.random.normal(size=(n, latent_dim))\n",
    "print('z_sample shape:', z_sample.shape)\n",
    "\n",
    "# n generated MNISt images\n",
    "generated_images = decoder.predict(z_sample)\n",
    "print('generated_images shape:', generated_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6936bf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2*n, 2))\n",
    "for i in range(n):\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  plt.imshow(generated_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19f1c3",
   "metadata": {},
   "source": [
    "Qualitative better than Dense VAE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
