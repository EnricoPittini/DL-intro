{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNET_++.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET"
      ],
      "metadata": {
        "id": "_O59eX29I-YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "J6z_4Rq43c6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIplBB2szfu7"
      },
      "outputs": [],
      "source": [
        "def datagenerator(x1,x2,batchsize):\n",
        "    n1 = x1.shape[0]\n",
        "    n2 = x2.shape[0]\n",
        "    while True:\n",
        "        num1 = np.random.randint(0, n1, batchsize)\n",
        "        num2 = np.random.randint(0, n2, batchsize)\n",
        "\n",
        "        x_data = (x1[num1] + x2[num2]) / 2.0\n",
        "        y_data = np.concatenate((x1[num1], x2[num2]), axis=2)\n",
        "\n",
        "        yield x_data, y_data "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "print(np.shape(mnist_x_train))\n",
        "(fashion_mnist_x_train, fashion_mnist_y_train), (fashion_mnist_x_test, fashion_mnist_y_test) = fashion_mnist.load_data()\n",
        "#normnalize in and pad\n",
        "mnist_x_train = np.pad(mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "print(np.shape(mnist_x_train))\n",
        "mnist_x_test = np.pad(mnist_x_test,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_train = np.pad(fashion_mnist_x_train,((0,0),(2,2),(2,2)))/255.\n",
        "fashion_mnist_x_test = np.pad(fashion_mnist_x_test,((0,0),(2,2),(2,2)))/255."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9dfdA_d2lcE",
        "outputId": "d1741299-e8d0-4152-b935-7d06833bb9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 32, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSLwP7dx3iXB",
        "outputId": "9678a8b8-f1a7-46b8-f66f-34116c235036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVmcjEZx30Qd",
        "outputId": "65fd2bfa-2c53-444c-b289-d7fab5312656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn3257IL3l7J",
        "outputId": "a55085b4-4d37-4ec6-e908-f6298a0f7052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist_x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LmXLzWX3xK6",
        "outputId": "a9848636-5c3a-4bc6-8b66-c88440c2ce58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train, w, h = mnist_x_train.shape[0], mnist_x_train.shape[1], mnist_x_train.shape[2]\n",
        "N_test = mnist_x_test.shape[0]"
      ],
      "metadata": {
        "id": "f0FRmeoh4hDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 64"
      ],
      "metadata": {
        "id": "D11K763l6N9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagenerator(mnist_x_train, fashion_mnist_x_train, batchsize)\n",
        "test_generator = datagenerator(mnist_x_test, fashion_mnist_x_test, batchsize)"
      ],
      "metadata": {
        "id": "Z-NnPXLW6RVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)"
      ],
      "metadata": {
        "id": "nNIO8t0m6Xv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SnnGuQr6hbc",
        "outputId": "a9b58b51-acb4-4851-aaf2-d77e3ace3525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 32, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3BWZO3Z6uMv",
        "outputId": "7b0d6f23-6962-4139-c48c-470959d05ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 32, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch[0].min(), x_batch[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLkLys5S9PtU",
        "outputId": "f49a7b8e-db8a-4320-9c1a-6a46e5b7f661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.7705882352941176)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_batch[0].min(), y_batch[0].max()"
      ],
      "metadata": {
        "id": "FVN_Obg89sEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33009486-6101-4cf5-cb96-8950ab8f6d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (32,32,1)"
      ],
      "metadata": {
        "id": "S6akcp8f2cRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL\n",
        "https://github.com/MrGiovanni/UNetPlusPlus"
      ],
      "metadata": {
        "id": "V9YbgkWGJBFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELS WEIGTHS\n",
        "\n",
        "weights_collection = [\n",
        "\n",
        "    # ResNet18\n",
        "    {\n",
        "        'model': 'resnet18',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000.h5',\n",
        "        'name': 'resnet18_imagenet_1000.h5',\n",
        "        'md5': '64da73012bb70e16c901316c201d9803',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet18',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet18_imagenet_1000.h5',\n",
        "        'md5': '318e3ac0cd98d51e917526c9f62f0b50',\n",
        "    },\n",
        "\n",
        "    # ResNet34\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000.h5',\n",
        "        'name': 'resnet34_imagenet_1000.h5',\n",
        "        'md5': '2ac8277412f65e5d047f255bcbd10383',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet34',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet34_imagenet_1000_no_top.h5',\n",
        "        'md5': '8caaa0ad39d927cb8ba5385bf945d582',\n",
        "    },\n",
        "\n",
        "    # ResNet50\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000.h5',\n",
        "        'name': 'resnet50_imagenet_1000.h5',\n",
        "        'md5': 'd0feba4fc650e68ac8c19166ee1ba87f',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet50_imagenet_1000_no_top.h5',\n",
        "        'md5': 'db3b217156506944570ac220086f09b6',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet11k-places365ch',\n",
        "        'classes': 11586,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_places365_11586.h5',\n",
        "        'name': 'resnet50_places365_11586.h5',\n",
        "        'md5': 'bb8963db145bc9906452b3d9c9917275',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet50',\n",
        "        'dataset': 'imagenet11k-places365ch',\n",
        "        'classes': 11586,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet50_imagenet_11586_no_top.h5',\n",
        "        'name': 'resnet50_imagenet_11586_no_top.h5',\n",
        "        'md5': 'd8bf4e7ea082d9d43e37644da217324a',\n",
        "    },\n",
        "\n",
        "    # ResNet101\n",
        "    {\n",
        "        'model': 'resnet101',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet101_imagenet_1000.h5',\n",
        "        'name': 'resnet101_imagenet_1000.h5',\n",
        "        'md5': '9489ed2d5d0037538134c880167622ad',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet101',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet101_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet101_imagenet_1000_no_top.h5',\n",
        "        'md5': '1016e7663980d5597a4e224d915c342d',\n",
        "    },\n",
        "\n",
        "\n",
        "    # ResNet152\n",
        "    {\n",
        "        'model': 'resnet152',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet152_imagenet_1000.h5',\n",
        "        'name': 'resnet152_imagenet_1000.h5',\n",
        "        'md5': '1efffbcc0708fb0d46a9d096ae14f905',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet152',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet152_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnet152_imagenet_1000_no_top.h5',\n",
        "        'md5': '5867b94098df4640918941115db93734',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet152',\n",
        "        'dataset': 'imagenet11k',\n",
        "        'classes': 11221,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet152_imagenet11k_11221.h5',\n",
        "        'name': 'resnet152_imagenet11k_11221.h5',\n",
        "        'md5': '24791790f6ef32f274430ce4a2ffee5d',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnet152',\n",
        "        'dataset': 'imagenet11k',\n",
        "        'classes': 11221,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet152_imagenet11k_11221_no_top.h5',\n",
        "        'name': 'resnet152_imagenet11k_11221_no_top.h5',\n",
        "        'md5': '25ab66dec217cb774a27d0f3659cafb3',\n",
        "    },\n",
        "\n",
        "\n",
        "    # ResNeXt50\n",
        "    {\n",
        "        'model': 'resnext50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext50_imagenet_1000.h5',\n",
        "        'name': 'resnext50_imagenet_1000.h5',\n",
        "        'md5': '7c5c40381efb044a8dea5287ab2c83db',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnext50',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext50_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnext50_imagenet_1000_no_top.h5',\n",
        "        'md5': '7ade5c8aac9194af79b1724229bdaa50',\n",
        "    },\n",
        "\n",
        "\n",
        "    # ResNeXt101\n",
        "    {\n",
        "        'model': 'resnext101',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': True,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext101_imagenet_1000.h5',\n",
        "        'name': 'resnext101_imagenet_1000.h5',\n",
        "        'md5': '432536e85ee811568a0851c328182735',\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'model': 'resnext101',\n",
        "        'dataset': 'imagenet',\n",
        "        'classes': 1000,\n",
        "        'include_top': False,\n",
        "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext101_imagenet_1000_no_top.h5',\n",
        "        'name': 'resnext101_imagenet_1000_no_top.h5',\n",
        "        'md5': '91fe0126320e49f6ee607a0719828c7e',\n",
        "    },\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Ypftb-4_04DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELS UTILS\n",
        "\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "\n",
        "def find_weights(weights_collection, model_name, dataset, include_top):\n",
        "    w = list(filter(lambda x: x['model'] == model_name, weights_collection))\n",
        "    w = list(filter(lambda x: x['dataset'] == dataset, w))\n",
        "    w = list(filter(lambda x: x['include_top'] == include_top, w))\n",
        "    return w\n",
        "\n",
        "\n",
        "def load_model_weights(weights_collection, model, dataset, classes, include_top):\n",
        "    weights = find_weights(weights_collection, model.name, dataset, include_top)\n",
        "\n",
        "    if weights:\n",
        "        weights = weights[0]\n",
        "\n",
        "        if include_top and weights['classes'] != classes:\n",
        "            raise ValueError('If using `weights` and `include_top`'\n",
        "                             ' as true, `classes` should be {}'.format(weights['classes']))\n",
        "\n",
        "        weights_path = get_file(weights['name'],\n",
        "                                weights['url'],\n",
        "                                cache_subdir='models',\n",
        "                                md5_hash=weights['md5'])\n",
        "\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError('There is no weights for such configuration: ' +\n",
        "                         'model = {}, dataset = {}, '.format(model.name, dataset) +\n",
        "                         'classes = {}, include_top = {}.'.format(classes, include_top))"
      ],
      "metadata": {
        "id": "4hgycImn04F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMS RESNEXT\n",
        "\n",
        "# default parameters for convolution and batchnorm layers of ResNet models\n",
        "# parameters are obtained from MXNet converted model\n",
        "\n",
        "\n",
        "def get_conv_params_RESNEXT(**params):\n",
        "    default_conv_params = {\n",
        "        'kernel_initializer': 'glorot_uniform',\n",
        "        'use_bias': False,\n",
        "        'padding': 'valid',\n",
        "    }\n",
        "    default_conv_params.update(params)\n",
        "    return default_conv_params\n",
        "\n",
        "\n",
        "def get_bn_params_RESNEXT(**params):\n",
        "    default_bn_params = {\n",
        "        'axis': 3,\n",
        "        'momentum': 0.99,\n",
        "        'epsilon': 2e-5,\n",
        "        'center': True,\n",
        "        'scale': True,\n",
        "    }\n",
        "    default_bn_params.update(params)\n",
        "    return default_bn_params"
      ],
      "metadata": {
        "id": "Q8KEyE4I4wq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCKS RESNEXT\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Add\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import ZeroPadding2D\n",
        "\n",
        "\"\"\"from .params import get_conv_params\n",
        "from .params import get_bn_params\"\"\"\n",
        "\n",
        "\n",
        "def handle_block_names_RESNEXT(stage, block):\n",
        "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
        "    conv_name = name_base + 'conv'\n",
        "    bn_name = name_base + 'bn'\n",
        "    relu_name = name_base + 'relu'\n",
        "    sc_name = name_base + 'sc'\n",
        "    return conv_name, bn_name, relu_name, sc_name\n",
        "\n",
        "\n",
        "def GroupConv2D_RESNEXT(filters, kernel_size, conv_params, conv_name, strides=(1,1), cardinality=32):\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        grouped_channels = int(input_tensor.shape[-1]) // cardinality\n",
        "\n",
        "        blocks = []\n",
        "        for c in range(cardinality):\n",
        "            x = Lambda(lambda z: z[:, :, :, c * grouped_channels:(c + 1) * grouped_channels])(input_tensor)\n",
        "            name = conv_name + '_' + str(c)\n",
        "            x = Conv2D(grouped_channels, kernel_size, strides=strides,\n",
        "                       name=name, **conv_params)(x)\n",
        "            blocks.append(x)\n",
        "\n",
        "        x = Concatenate(axis=-1)(blocks)\n",
        "        return x\n",
        "    return layer\n",
        "\n",
        "\n",
        "def conv_block_RESNEXT(filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"The conv block is the block that has conv layer at shortcut.\n",
        "    # Arguments\n",
        "        filters: integer, used for first and second conv layers, third conv layer double this value\n",
        "        strides: tuple of integers, strides for conv (3x3) layer in block\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: integer, current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output layer for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        # extracting params and names for layers\n",
        "        conv_params = get_conv_params_RESNEXT()\n",
        "        bn_params = get_bn_params_RESNEXT()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNEXT(stage, block)\n",
        "\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(input_tensor)\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = GroupConv2D_RESNEXT(filters, (3, 3), conv_params, conv_name + '2', strides=strides)(x)\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "\n",
        "        x = Conv2D(filters * 2, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "\n",
        "        shortcut = Conv2D(filters*2, (1, 1), name=sc_name, strides=strides, **conv_params)(input_tensor)\n",
        "        shortcut = BatchNormalization(name=sc_name+'_bn', **bn_params)(shortcut)\n",
        "        x = Add()([x, shortcut])\n",
        "\n",
        "        x = Activation('relu', name=relu_name)(x)\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def identity_block_RESNEXT(filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        filters: integer, used for first and second conv layers, third conv layer double this value\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: integer, current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output layer for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params_RESNEXT()\n",
        "        bn_params = get_bn_params_RESNEXT()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNEXT(stage, block)\n",
        "\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(input_tensor)\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = GroupConv2D_RESNEXT(filters, (3, 3), conv_params, conv_name + '2')(x)\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "\n",
        "        x = Conv2D(filters * 2, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "\n",
        "        x = Add()([x, input_tensor])\n",
        "\n",
        "        x = Activation('relu', name=relu_name)(x)\n",
        "        return x\n",
        "\n",
        "    return layer"
      ],
      "metadata": {
        "id": "4vsR6Hk14qcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAb6QPjD560J",
        "outputId": "5af2436e-99d3-49aa-dfdb-0a3c002d6ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications) (1.5.2)\n",
            "Installing collected packages: Keras-Applications\n",
            "Successfully installed Keras-Applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDER RESNEXT\n",
        "\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "\n",
        "\n",
        "import keras\n",
        "from distutils.version import StrictVersion\n",
        "\n",
        "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
        "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "else:\n",
        "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "\"\"\"from .params import get_conv_params\n",
        "from .params import get_bn_params\n",
        "\n",
        "from .blocks import conv_block\n",
        "from .blocks import identity_block\"\"\"\n",
        "\n",
        "\n",
        "def build_resnext(\n",
        "     repetitions=(2, 2, 2, 2),\n",
        "     include_top=True,\n",
        "     input_tensor=None,\n",
        "     input_shape=None,\n",
        "     classes=1000,\n",
        "     first_conv_filters=64,\n",
        "     first_block_filters=64):\n",
        "    \n",
        "    \"\"\"\n",
        "    TODO\n",
        "    \"\"\"\n",
        "    \n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=197,\n",
        "                                      data_format='channels_last',\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape, name='data')\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    \n",
        "    # get parameters for model layers\n",
        "    no_scale_bn_params = get_bn_params_RESNEXT(scale=False)\n",
        "    bn_params = get_bn_params_RESNEXT()\n",
        "    conv_params = get_conv_params_RESNEXT()\n",
        "    init_filters = first_block_filters\n",
        "    \n",
        "    # resnext bottom\n",
        "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
        "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
        "    x = Conv2D(first_conv_filters, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
        "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu0')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
        "    \n",
        "    # resnext body\n",
        "    for stage, rep in enumerate(repetitions):\n",
        "        for block in range(rep):\n",
        "            \n",
        "            filters = init_filters * (2**stage)\n",
        "            \n",
        "            # first block of first stage without strides because we have maxpooling before\n",
        "            if stage == 0 and block == 0:\n",
        "                x = conv_block_RESNEXT(filters, stage, block, strides=(1, 1))(x)\n",
        "                \n",
        "            elif block == 0:\n",
        "                x = conv_block_RESNEXT(filters, stage, block, strides=(2, 2))(x)\n",
        "                \n",
        "            else:\n",
        "                x = identity_block_RESNEXT(filters, stage, block)(x)\n",
        "\n",
        "    # resnext top\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
        "        x = Dense(classes, name='fc1')(x)\n",
        "        x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "        \n",
        "    # Create model\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZSshcbMu4jlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNEXT MODEL\n",
        "\n",
        "\"\"\"from .builder import build_resnext\n",
        "from ..utils import load_model_weights\n",
        "from ..weights import weights_collection\"\"\"\n",
        "\n",
        "\n",
        "def ResNeXt50(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnext(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         first_block_filters=128,\n",
        "                         repetitions=(3, 4, 6, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top)\n",
        "    model.name = 'resnext50'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNeXt101(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnext(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         first_block_filters=128,\n",
        "                         repetitions=(3, 4, 23, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top)\n",
        "    model.name = 'resnext101'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FnHVYHIK4dT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET PARAMS\n",
        "\n",
        "# default parameters for convolution and batchnorm layers of ResNet models\n",
        "# parameters are obtained from MXNet converted model\n",
        "\n",
        "\n",
        "def get_conv_params_RESNET(**params):\n",
        "    default_conv_params = {\n",
        "        'kernel_initializer': 'glorot_uniform',\n",
        "        'use_bias': False,\n",
        "        'padding': 'valid',\n",
        "    }\n",
        "    default_conv_params.update(params)\n",
        "    return default_conv_params\n",
        "\n",
        "\n",
        "def get_bn_params_RESNET(**params):\n",
        "    default_bn_params = {\n",
        "        'axis': 3,\n",
        "        'momentum': 0.99,\n",
        "        'epsilon': 2e-5,\n",
        "        'center': True,\n",
        "        'scale': True,\n",
        "    }\n",
        "    default_bn_params.update(params)\n",
        "    return default_bn_params"
      ],
      "metadata": {
        "id": "1akAFULH04IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCKS RESNET\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Add\n",
        "from keras.layers import ZeroPadding2D\n",
        "\n",
        "\"\"\"from .params import get_conv_params\n",
        "from .params import get_bn_params\"\"\"\n",
        "\n",
        "\n",
        "def handle_block_names_RESNET(stage, block):\n",
        "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
        "    conv_name = name_base + 'conv'\n",
        "    bn_name = name_base + 'bn'\n",
        "    relu_name = name_base + 'relu'\n",
        "    sc_name = name_base + 'sc'\n",
        "    return conv_name, bn_name, relu_name, sc_name\n",
        "\n",
        "\n",
        "def basic_identity_block_RESNET(filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params_RESNET()\n",
        "        bn_params = get_bn_params_RESNET()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNET(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = Add()([x, input_tensor])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def basic_conv_block_RESNET(filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params_RESNET()\n",
        "        bn_params = get_bn_params_RESNET()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNET(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        shortcut = x\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        shortcut = Conv2D(filters, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def conv_block_RESNET(filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        input_tensor: input tensor\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params_RESNET()\n",
        "        bn_params = get_bn_params_RESNET()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNET(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        shortcut = x\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '3')(x)\n",
        "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "\n",
        "        shortcut = Conv2D(filters*4, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
        "        x = Add()([x, shortcut])\n",
        "        return x\n",
        "\n",
        "    return layer\n",
        "\n",
        "\n",
        "def identity_block_RESNET(filters, stage, block):\n",
        "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
        "    # Arguments\n",
        "        kernel_size: default 3, the kernel size of\n",
        "            middle conv layer at main path\n",
        "        filters: list of integers, the filters of 3 conv layer at main path\n",
        "        stage: integer, current stage label, used for generating layer names\n",
        "        block: 'a','b'..., current block label, used for generating layer names\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    \"\"\"\n",
        "\n",
        "    def layer(input_tensor):\n",
        "        conv_params = get_conv_params_RESNET()\n",
        "        bn_params = get_bn_params_RESNET()\n",
        "        conv_name, bn_name, relu_name, sc_name = handle_block_names_RESNET(stage, block)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
        "        x = Activation('relu', name=relu_name + '1')(x)\n",
        "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '2')(x)\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
        "\n",
        "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
        "        x = Activation('relu', name=relu_name + '3')(x)\n",
        "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
        "\n",
        "        x = Add()([x, input_tensor])\n",
        "        return x\n",
        "\n",
        "    return layer"
      ],
      "metadata": {
        "id": "5y1SxeKs2ze0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDER RESNET\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "\n",
        "import keras\n",
        "from distutils.version import StrictVersion\n",
        "\n",
        "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
        "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "else:\n",
        "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "\"\"\"from .params import get_conv_params\n",
        "from .params import get_bn_params\n",
        "from .blocks import basic_conv_block\n",
        "from .blocks import basic_identity_block\n",
        "from .blocks import conv_block as usual_conv_block\n",
        "from .blocks import identity_block as usual_identity_block\"\"\"\n",
        "\n",
        "def build_resnet(\n",
        "     repetitions=(2, 2, 2, 2),\n",
        "     include_top=True,\n",
        "     input_tensor=None,\n",
        "     input_shape=None,\n",
        "     classes=1000,\n",
        "     block_type='usual'):\n",
        "    \n",
        "    \"\"\"\n",
        "    TODO\n",
        "    \"\"\"\n",
        "    \n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=197,\n",
        "                                      data_format='channels_last',\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape, name='data')\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    \n",
        "    # get parameters for model layers\n",
        "    no_scale_bn_params = get_bn_params_RESNET(scale=False)\n",
        "    bn_params = get_bn_params_RESNET()\n",
        "    conv_params = get_conv_params_RESNET()\n",
        "    init_filters = 64\n",
        "\n",
        "    if block_type == 'basic':\n",
        "        conv_block = basic_conv_block_RESNET\n",
        "        identity_block = basic_identity_block_RESNET\n",
        "    else:\n",
        "        conv_block = usual_conv_block_RESNET\n",
        "        identity_block = usual_identity_block_RESNET\n",
        "    \n",
        "    # resnet bottom\n",
        "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
        "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
        "    x = Conv2D(init_filters, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
        "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu0')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
        "    \n",
        "    # resnet body\n",
        "    for stage, rep in enumerate(repetitions):\n",
        "        for block in range(rep):\n",
        "            \n",
        "            filters = init_filters * (2**stage)\n",
        "            \n",
        "            # first block of first stage without strides because we have maxpooling before\n",
        "            if block == 0 and stage == 0:\n",
        "                x = conv_block(filters, stage, block, strides=(1, 1))(x)\n",
        "                \n",
        "            elif block == 0:\n",
        "                x = conv_block(filters, stage, block, strides=(2, 2))(x)\n",
        "                \n",
        "            else:\n",
        "                x = identity_block(filters, stage, block)(x)\n",
        "                \n",
        "    x = BatchNormalization(name='bn1', **bn_params)(x)\n",
        "    x = Activation('relu', name='relu1')(x)\n",
        "\n",
        "    # resnet top\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
        "        x = Dense(classes, name='fc1')(x)\n",
        "        x = Activation('softmax', name='softmax')(x)\n",
        "\n",
        "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "        \n",
        "    # Create model.\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "JjOg4z8e04KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET MODELS\n",
        "\n",
        "\"\"\"from .builder import build_resnet\n",
        "from ..utils import load_model_weights\n",
        "from ..weights import weights_collection\"\"\"\n",
        "\n",
        "\n",
        "def ResNet18(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(2, 2, 2, 2),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top,\n",
        "                         block_type='basic')\n",
        "    model.name = 'resnet18'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet34(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(3, 4, 6, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top,\n",
        "                         block_type='basic')\n",
        "    model.name = 'resnet34'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet50(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(3, 4, 6, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top)\n",
        "    model.name = 'resnet50'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet101(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(3, 4, 23, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top)\n",
        "    model.name = 'resnet101'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet152(input_shape, input_tensor=None, weights=None, classes=1000, include_top=True):\n",
        "    model = build_resnet(input_tensor=input_tensor,\n",
        "                         input_shape=input_shape,\n",
        "                         repetitions=(3, 8, 36, 3),\n",
        "                         classes=classes,\n",
        "                         include_top=include_top)\n",
        "    model.name = 'resnet152'\n",
        "\n",
        "    if weights:\n",
        "        load_model_weights(weights_collection, model, weights, classes, include_top)\n",
        "    return model"
      ],
      "metadata": {
        "id": "k8LwGxEZ04M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INCEPTION V3\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Inception V3 model for Keras.\n",
        "Note that the input image format for this model is different than for\n",
        "the VGG16 and ResNet models (299x299 instead of 224x224),\n",
        "and that the input preprocessing function is also different (same as Xception).\n",
        "# Reference\n",
        "- [Rethinking the Inception Architecture for Computer Vision](http://arxiv.org/abs/1512.00567)\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications import imagenet_utils\n",
        "\n",
        "import keras\n",
        "from distutils.version import StrictVersion\n",
        "\n",
        "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
        "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "else:\n",
        "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "def conv2d_bn_INCEPTION(x,\n",
        "              filters,\n",
        "              num_row,\n",
        "              num_col,\n",
        "              padding='same',\n",
        "              strides=(1, 1),\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + '_bn'\n",
        "        conv_name = name + '_conv'\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        bn_axis = 1\n",
        "    else:\n",
        "        bn_axis = 3\n",
        "    x = Conv2D(\n",
        "        filters, (num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=False,\n",
        "        name=conv_name)(x)\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "    x = Activation('relu', name=name)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionV3(include_top=True,\n",
        "                weights='imagenet',\n",
        "                input_tensor=None,\n",
        "                input_shape=None,\n",
        "                pooling=None,\n",
        "                classes=1000):\n",
        "    \"\"\"Instantiates the Inception v3 architecture.\n",
        "    Optionally loads weights pre-trained\n",
        "    on ImageNet. Note that when using TensorFlow,\n",
        "    for best performance you should set\n",
        "    `image_data_format='channels_last'` in your Keras config\n",
        "    at ~/.keras/keras.json.\n",
        "    The model and the weights are compatible with both\n",
        "    TensorFlow and Theano. The data format\n",
        "    convention used by the model is the one\n",
        "    specified in your Keras config file.\n",
        "    Note that the default input image size for this model is 299x299.\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(299, 299, 3)` (with `channels_last` data format)\n",
        "            or `(3, 299, 299)` (with `channels_first` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 139.\n",
        "            E.g. `(150, 150, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(\n",
        "        input_shape,\n",
        "        default_size=299,\n",
        "        min_size=139,\n",
        "        data_format=K.image_data_format(),\n",
        "        require_flatten=False,\n",
        "        weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        channel_axis = 1\n",
        "    else:\n",
        "        channel_axis = 3\n",
        "\n",
        "    x = conv2d_bn_INCEPTION(img_input, 32, 3, 3, strides=(2, 2), padding='same')\n",
        "    x = conv2d_bn_INCEPTION(x, 32, 3, 3, padding='same')\n",
        "    x = conv2d_bn_INCEPTION(x, 64, 3, 3)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = conv2d_bn_INCEPTION(x, 80, 1, 1, padding='same')\n",
        "    x = conv2d_bn_INCEPTION(x, 192, 3, 3, padding='same')\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    # mixed 0, 1, 2: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn_INCEPTION(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn_INCEPTION(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn_INCEPTION(branch_pool, 32, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed0')\n",
        "\n",
        "    # mixed 1: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn_INCEPTION(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn_INCEPTION(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn_INCEPTION(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed1')\n",
        "\n",
        "    # mixed 2: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn_INCEPTION(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn_INCEPTION(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn_INCEPTION(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed2')\n",
        "\n",
        "    # mixed 3: 17 x 17 x 768\n",
        "    branch3x3 = conv2d_bn_INCEPTION(x, 384, 3, 3, strides=(2, 2), padding='same')\n",
        "\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn_INCEPTION(\n",
        "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='same')\n",
        "\n",
        "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
        "\n",
        "    # mixed 4: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn_INCEPTION(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn_INCEPTION(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn_INCEPTION(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn_INCEPTION(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed4')\n",
        "\n",
        "    # mixed 5, 6: 17 x 17 x 768\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn_INCEPTION(x, 160, 1, 1)\n",
        "        branch7x7 = conv2d_bn_INCEPTION(branch7x7, 160, 1, 7)\n",
        "        branch7x7 = conv2d_bn_INCEPTION(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn_INCEPTION(x, 160, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 160, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn_INCEPTION(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(5 + i))\n",
        "\n",
        "    # mixed 7: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "    branch7x7 = conv2d_bn_INCEPTION(branch7x7, 192, 1, 7)\n",
        "    branch7x7 = conv2d_bn_INCEPTION(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn_INCEPTION(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn_INCEPTION(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name='mixed7')\n",
        "\n",
        "    # mixed 8: 8 x 8 x 1280\n",
        "    branch3x3 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn_INCEPTION(branch3x3, 320, 3, 3,\n",
        "                          strides=(2, 2), padding='same')\n",
        "\n",
        "    branch7x7x3 = conv2d_bn_INCEPTION(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn_INCEPTION(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn_INCEPTION(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn_INCEPTION(\n",
        "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='same')\n",
        "\n",
        "    branch_pool = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n",
        "\n",
        "    # mixed 9: 8 x 8 x 2048\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn_INCEPTION(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn_INCEPTION(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn_INCEPTION(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn_INCEPTION(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = layers.concatenate(\n",
        "            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
        "\n",
        "        branch3x3dbl = conv2d_bn_INCEPTION(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn_INCEPTION(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn_INCEPTION(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn_INCEPTION(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = layers.concatenate(\n",
        "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
        "\n",
        "        branch_pool = AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn_INCEPTION(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name='mixed' + str(9 + i))\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='inception_v3')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'imagenet':\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "        if include_top:\n",
        "            weights_path = get_file(\n",
        "                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n",
        "        else:\n",
        "            weights_path = get_file(\n",
        "                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n",
        "        model.load_weights(weights_path)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def preprocess_input_INCEPTION(x):\n",
        "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
        "    # Returns\n",
        "        Preprocessed array.\n",
        "    \"\"\"\n",
        "    return imagenet_utils.preprocess_input(x, mode='tf')"
      ],
      "metadata": {
        "id": "M1JGEH2T04Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INCEPTION RESNET\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Inception-ResNet V2 model for Keras.\n",
        "Model naming and structure follows TF-slim implementation (which has some additional\n",
        "layers and different number of filters from the original arXiv paper):\n",
        "https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py\n",
        "Pre-trained ImageNet weights are also converted from TF-slim, which can be found in:\n",
        "https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models\n",
        "# Reference\n",
        "- [Inception-v4, Inception-ResNet and the Impact of\n",
        "   Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "from keras.applications import imagenet_utils\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "import keras\n",
        "from distutils.version import StrictVersion\n",
        "\n",
        "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
        "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "else:\n",
        "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "\n",
        "BASE_WEIGHT_URL = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.7/'\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
        "    # Arguments\n",
        "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
        "    # Returns\n",
        "        Preprocessed array.\n",
        "    \"\"\"\n",
        "    return imagenet_utils.preprocess_input(x, mode='tf')\n",
        "\n",
        "\n",
        "def conv2d_bn_IRESNET(x,\n",
        "              filters,\n",
        "              kernel_size,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              use_bias=False,\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        kernel_size: kernel size as in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        activation: activation in `Conv2D`.\n",
        "        use_bias: whether to use a bias in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_ac'` for the activation\n",
        "            and `name + '_bn'` for the batch norm layer.\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    x = Conv2D(filters,\n",
        "               kernel_size,\n",
        "               strides=strides,\n",
        "               padding=padding,\n",
        "               use_bias=use_bias,\n",
        "               name=name)(x)\n",
        "    if not use_bias:\n",
        "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
        "        bn_name = None if name is None else name + '_bn'\n",
        "        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "    if activation is not None:\n",
        "        ac_name = None if name is None else name + '_ac'\n",
        "        x = Activation(activation, name=ac_name)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
        "    \"\"\"Adds a Inception-ResNet block.\n",
        "    This function builds 3 types of Inception-ResNet blocks mentioned\n",
        "    in the paper, controlled by the `block_type` argument (which is the\n",
        "    block name used in the official TF-slim implementation):\n",
        "        - Inception-ResNet-A: `block_type='block35'`\n",
        "        - Inception-ResNet-B: `block_type='block17'`\n",
        "        - Inception-ResNet-C: `block_type='block8'`\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        scale: scaling factor to scale the residuals (i.e., the output of\n",
        "            passing `x` through an inception module) before adding them\n",
        "            to the shortcut branch. Let `r` be the output from the residual branch,\n",
        "            the output of this block will be `x + scale * r`.\n",
        "        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n",
        "            the network structure in the residual branch.\n",
        "        block_idx: an `int` used for generating layer names. The Inception-ResNet blocks\n",
        "            are repeated many times in this network. We use `block_idx` to identify\n",
        "            each of the repetitions. For example, the first Inception-ResNet-A block\n",
        "            will have `block_type='block35', block_idx=0`, ane the layer names will have\n",
        "            a common prefix `'block35_0'`.\n",
        "        activation: activation function to use at the end of the block\n",
        "            (see [activations](../activations.md)).\n",
        "            When `activation=None`, no activation is applied\n",
        "            (i.e., \"linear\" activation: `a(x) = x`).\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    # Raises\n",
        "        ValueError: if `block_type` is not one of `'block35'`,\n",
        "            `'block17'` or `'block8'`.\n",
        "    \"\"\"\n",
        "    if block_type == 'block35':\n",
        "        branch_0 = conv2d_bn_IRESNET(x, 32, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(x, 32, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(branch_1, 32, 3)\n",
        "        branch_2 = conv2d_bn_IRESNET(x, 32, 1)\n",
        "        branch_2 = conv2d_bn_IRESNET(branch_2, 48, 3)\n",
        "        branch_2 = conv2d_bn_IRESNET(branch_2, 64, 3)\n",
        "        branches = [branch_0, branch_1, branch_2]\n",
        "    elif block_type == 'block17':\n",
        "        branch_0 = conv2d_bn_IRESNET(x, 192, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(x, 128, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(branch_1, 160, [1, 7])\n",
        "        branch_1 = conv2d_bn_IRESNET(branch_1, 192, [7, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    elif block_type == 'block8':\n",
        "        branch_0 = conv2d_bn_IRESNET(x, 192, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(x, 192, 1)\n",
        "        branch_1 = conv2d_bn_IRESNET(branch_1, 224, [1, 3])\n",
        "        branch_1 = conv2d_bn_IRESNET(branch_1, 256, [3, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    else:\n",
        "        raise ValueError('Unknown Inception-ResNet block type. '\n",
        "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
        "                         'but got: ' + str(block_type))\n",
        "\n",
        "    block_name = block_type + '_' + str(block_idx)\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
        "    mixed = Concatenate(axis=channel_axis, name=block_name + '_mixed')(branches)\n",
        "    up = conv2d_bn_IRESNET(mixed,\n",
        "                   K.int_shape(x)[channel_axis],\n",
        "                   1,\n",
        "                   activation=None,\n",
        "                   use_bias=True,\n",
        "                   name=block_name + '_conv')\n",
        "\n",
        "    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "               output_shape=K.int_shape(x)[1:],\n",
        "               arguments={'scale': scale},\n",
        "               name=block_name)([x, up])\n",
        "\n",
        "    if activation is not None:\n",
        "        x = Activation(activation, name=block_name + '_ac')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionResNetV2(include_top=True,\n",
        "                      weights='imagenet',\n",
        "                      input_tensor=None,\n",
        "                      input_shape=None,\n",
        "                      pooling=None,\n",
        "                      classes=1000):\n",
        "    \"\"\"Instantiates the Inception-ResNet v2 architecture.\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that when using TensorFlow, for best performance you should\n",
        "    set `\"image_data_format\": \"channels_last\"` in your Keras config\n",
        "    at `~/.keras/keras.json`.\n",
        "    The model and the weights are compatible with TensorFlow, Theano and\n",
        "    CNTK backends. The data format convention used by the model is\n",
        "    the one specified in your Keras config file.\n",
        "    Note that the default input image size for this model is 299x299, instead\n",
        "    of 224x224 as in the VGG16 and ResNet models. Also, the input preprocessing\n",
        "    function is different (i.e., do not use `imagenet_utils.preprocess_input()`\n",
        "    with this model. Use `preprocess_input()` defined in this module instead).\n",
        "    # Arguments\n",
        "        include_top: whether to include the fully-connected\n",
        "            layer at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is `False` (otherwise the input shape\n",
        "            has to be `(299, 299, 3)` (with `'channels_last'` data format)\n",
        "            or `(3, 299, 299)` (with `'channels_first'` data format).\n",
        "            It should have exactly 3 inputs channels,\n",
        "            and width and height should be no smaller than 139.\n",
        "            E.g. `(150, 150, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the last convolutional layer.\n",
        "            - `'avg'` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `'max'` means that global max pooling will be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is `True`, and\n",
        "            if no `weights` argument is specified.\n",
        "    # Returns\n",
        "        A Keras `Model` instance.\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape.\n",
        "    \"\"\"\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(\n",
        "        input_shape,\n",
        "        default_size=299,\n",
        "        min_size=139,\n",
        "        data_format=K.image_data_format(),\n",
        "        require_flatten=False,\n",
        "        weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    # Stem block: 35 x 35 x 192\n",
        "    x = conv2d_bn_IRESNET(img_input, 32, 3, strides=2, padding='same')\n",
        "    x = conv2d_bn_IRESNET(x, 32, 3, padding='same')\n",
        "    x = conv2d_bn_IRESNET(x, 64, 3)\n",
        "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    x = conv2d_bn_IRESNET(x, 80, 1, padding='same')\n",
        "    x = conv2d_bn_IRESNET(x, 192, 3, padding='same')\n",
        "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
        "    branch_0 = conv2d_bn_IRESNET(x, 96, 1)\n",
        "    branch_1 = conv2d_bn_IRESNET(x, 48, 1)\n",
        "    branch_1 = conv2d_bn_IRESNET(branch_1, 64, 5)\n",
        "    branch_2 = conv2d_bn_IRESNET(x, 64, 1)\n",
        "    branch_2 = conv2d_bn_IRESNET(branch_2, 96, 3)\n",
        "    branch_2 = conv2d_bn_IRESNET(branch_2, 96, 3)\n",
        "    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n",
        "    branch_pool = conv2d_bn_IRESNET(branch_pool, 64, 1)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
        "\n",
        "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
        "    for block_idx in range(1, 11):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.17,\n",
        "                                   block_type='block35',\n",
        "                                   block_idx=block_idx)\n",
        "\n",
        "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
        "    branch_0 = conv2d_bn_IRESNET(x, 384, 3, strides=2, padding='same')\n",
        "    branch_1 = conv2d_bn_IRESNET(x, 256, 1)\n",
        "    branch_1 = conv2d_bn_IRESNET(branch_1, 256, 3)\n",
        "    branch_1 = conv2d_bn_IRESNET(branch_1, 384, 3, strides=2, padding='same')\n",
        "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    branches = [branch_0, branch_1, branch_pool]\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
        "\n",
        "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
        "    for block_idx in range(1, 21):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.1,\n",
        "                                   block_type='block17',\n",
        "                                   block_idx=block_idx)\n",
        "\n",
        "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
        "    branch_0 = conv2d_bn_IRESNET(x, 256, 1)\n",
        "    branch_0 = conv2d_bn_IRESNET(branch_0, 384, 3, strides=2, padding='same')\n",
        "    branch_1 = conv2d_bn_IRESNET(x, 256, 1)\n",
        "    branch_1 = conv2d_bn_IRESNET(branch_1, 288, 3, strides=2, padding='same')\n",
        "    branch_2 = conv2d_bn_IRESNET(x, 256, 1)\n",
        "    branch_2 = conv2d_bn_IRESNET(branch_2, 288, 3)\n",
        "    branch_2 = conv2d_bn_IRESNET(branch_2, 320, 3, strides=2, padding='same')\n",
        "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
        "\n",
        "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
        "    for block_idx in range(1, 10):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.2,\n",
        "                                   block_type='block8',\n",
        "                                   block_idx=block_idx)\n",
        "    x = inception_resnet_block(x,\n",
        "                               scale=1.,\n",
        "                               activation=None,\n",
        "                               block_type='block8',\n",
        "                               block_idx=10)\n",
        "\n",
        "    # Final convolution block: 8 x 8 x 1536\n",
        "    x = conv2d_bn_IRESNET(x, 1536, 1, name='conv_7b')\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs, x, name='inception_resnet_v2')\n",
        "\n",
        "    # Load weights\n",
        "    if weights == 'imagenet':\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            if K.backend() == 'tensorflow':\n",
        "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                              'are using the Theano '\n",
        "                              'image data format convention '\n",
        "                              '(`image_data_format=\"channels_first\"`). '\n",
        "                              'For best performance, set '\n",
        "                              '`image_data_format=\"channels_last\"` in '\n",
        "                              'your Keras config '\n",
        "                              'at ~/.keras/keras.json.')\n",
        "        if include_top:\n",
        "            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "            weights_path = get_file(fname,\n",
        "                                    BASE_WEIGHT_URL + fname,\n",
        "                                    cache_subdir='models',\n",
        "                                    file_hash='e693bd0210a403b3192acc6073ad2e96')\n",
        "        else:\n",
        "            fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "            weights_path = get_file(fname,\n",
        "                                    BASE_WEIGHT_URL + fname,\n",
        "                                    cache_subdir='models',\n",
        "                                    file_hash='d19885ff4a710c122648d3b5c3b684e4')\n",
        "        model.load_weights(weights_path)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uS_jSz1-04Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BACKBONES\n",
        "\n",
        "\"\"\"from .classification_models.classification_models import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
        "from .classification_models.classification_models import ResNeXt50, ResNeXt101\"\"\"\n",
        "\n",
        "\"\"\"from .inception_resnet_v2 import InceptionResNetV2\n",
        "from .inception_v3 import InceptionV3\"\"\"\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "\n",
        "backbones = {\n",
        "    \"vgg16\": VGG16,\n",
        "    \"vgg19\": VGG19,\n",
        "    \"resnet18\": ResNet18,\n",
        "    \"resnet34\": ResNet34,\n",
        "    \"resnet50\": ResNet50,\n",
        "    \"resnet101\": ResNet101,\n",
        "    \"resnet152\": ResNet152,\n",
        "    \"resnext50\": ResNeXt50,\n",
        "    \"resnext101\": ResNeXt101,\n",
        "    \"inceptionresnetv2\": InceptionResNetV2,\n",
        "    \"inceptionv3\": InceptionV3,\n",
        "    \"densenet121\": DenseNet121,\n",
        "    \"densenet169\": DenseNet169,\n",
        "    \"densenet201\": DenseNet201,\n",
        "\n",
        "}\n",
        "\n",
        "def get_backbone(name, *args, **kwargs):\n",
        "    return backbones[name](*args, **kwargs)"
      ],
      "metadata": {
        "id": "WyGDswAB04UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SEGMENTATION MODELS UTILS\n",
        "\n",
        "\"\"\" Utility functions for segmentation models \"\"\"\n",
        "from functools import wraps\n",
        "import numpy as np\n",
        "\n",
        "def get_layer_number(model, layer_name):\n",
        "    \"\"\"\n",
        "    Help find layer in Keras model by name\n",
        "    Args:\n",
        "        model: Keras `Model`\n",
        "        layer_name: str, name of layer\n",
        "    Returns:\n",
        "        index of layer\n",
        "    Raises:\n",
        "        ValueError: if model does not contains layer with such name\n",
        "    \"\"\"\n",
        "    for i, l in enumerate(model.layers):\n",
        "        if l.name == layer_name:\n",
        "            return i\n",
        "    raise ValueError('No layer with name {} in  model {}.'.format(layer_name, model.name))\n",
        "\n",
        "\n",
        "def extract_outputs(model, layers, include_top=False):\n",
        "    \"\"\"\n",
        "    Help extract intermediate layer outputs from model\n",
        "    Args:\n",
        "        model: Keras `Model`\n",
        "        layer: list of integers/str, list of layers indexes or names to extract output\n",
        "        include_top: bool, include final model layer output\n",
        "    Returns:\n",
        "        list of tensors (outputs)\n",
        "    \"\"\"\n",
        "    layers_indexes = ([get_layer_number(model, l) if isinstance(l, str) else l\n",
        "                      for l in layers])\n",
        "    outputs = [model.layers[i].output for i in layers_indexes]\n",
        "\n",
        "    if include_top:\n",
        "        outputs.insert(0, model.output)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def reverse(l):\n",
        "    \"\"\"Reverse list\"\"\"\n",
        "    return list(reversed(l))\n",
        "\n",
        "\n",
        "# decorator for models aliases, to add doc string\n",
        "def add_docstring(doc_string=None):\n",
        "    def decorator(fn):\n",
        "        if fn.__doc__:\n",
        "            fn.__doc__ += doc_string\n",
        "        else:\n",
        "            fn.__doc__ = doc_string\n",
        "\n",
        "        @wraps(fn)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            return fn(*args, **kwargs)\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "\n",
        "def recompile(model):\n",
        "    model.compile(model.optimizer, model.loss, model.metrics)    \n",
        "\n",
        "    \n",
        "def freeze_model(model):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    return\n",
        "\n",
        "\n",
        "def set_trainable(model):\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    recompile(model)\n",
        "\n",
        "\n",
        "def to_tuple(x):\n",
        "    if isinstance(x, tuple):\n",
        "        if len(x) == 2:\n",
        "            return x\n",
        "    elif np.isscalar(x):\n",
        "        return (x, x)\n",
        "\n",
        "    raise ValueError('Value should be tuple of length 2 or int value, got \"{}\"'.format(x))"
      ],
      "metadata": {
        "id": "pdsLR2VR04Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNET BLOCKS\n",
        "\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "\n",
        "\n",
        "def handle_block_names(stage):\n",
        "    conv_name = 'decoder_stage{}_conv'.format(stage)\n",
        "    bn_name = 'decoder_stage{}_bn'.format(stage)\n",
        "    relu_name = 'decoder_stage{}_relu'.format(stage)\n",
        "    up_name = 'decoder_stage{}_upsample'.format(stage)\n",
        "    return conv_name, bn_name, relu_name, up_name\n",
        "\n",
        "\n",
        "def ConvRelu(filters, kernel_size, use_batchnorm=False, conv_name='conv', bn_name='bn', relu_name='relu'):\n",
        "    def layer(x):\n",
        "        x = Conv2D(filters, kernel_size, padding=\"same\", name=conv_name, use_bias=not(use_batchnorm))(x)\n",
        "        if use_batchnorm:\n",
        "            x = BatchNormalization(name=bn_name)(x)\n",
        "        x = Activation('relu', name=relu_name)(x)\n",
        "        return x\n",
        "    return layer\n",
        "\n",
        "\n",
        "def Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
        "                     use_batchnorm=False, skip=None):\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n",
        "\n",
        "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
        "\n",
        "        if skip is not None:\n",
        "            x = Concatenate()([x, skip])\n",
        "\n",
        "        x = ConvRelu(filters, kernel_size, use_batchnorm=use_batchnorm,\n",
        "                     conv_name=conv_name + '1', bn_name=bn_name + '1', relu_name=relu_name + '1')(x)\n",
        "\n",
        "        x = ConvRelu(filters, kernel_size, use_batchnorm=use_batchnorm,\n",
        "                     conv_name=conv_name + '2', bn_name=bn_name + '2', relu_name=relu_name + '2')(x)\n",
        "\n",
        "        return x\n",
        "    return layer\n",
        "\n",
        "\n",
        "def Transpose2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
        "                      transpose_kernel_size=(4,4), use_batchnorm=False, skip=None):\n",
        "\n",
        "    def layer(input_tensor):\n",
        "\n",
        "        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n",
        "\n",
        "        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate,\n",
        "                            padding='same', name=up_name, use_bias=not(use_batchnorm))(input_tensor)\n",
        "        if use_batchnorm:\n",
        "            x = BatchNormalization(name=bn_name+'1')(x)\n",
        "        x = Activation('relu', name=relu_name+'1')(x)\n",
        "\n",
        "        if skip is not None:\n",
        "            x = Concatenate()([x, skip])\n",
        "\n",
        "        x = ConvRelu(filters, kernel_size, use_batchnorm=use_batchnorm,\n",
        "                     conv_name=conv_name + '2', bn_name=bn_name + '2', relu_name=relu_name + '2')(x)\n",
        "\n",
        "        return x\n",
        "    return layer"
      ],
      "metadata": {
        "id": "yhDZ18dQ1piJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import concatenate"
      ],
      "metadata": {
        "id": "Hzvq2zEZoNCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNET BUILDER\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Activation\n",
        "from keras.models import Model\n",
        "\n",
        "\"\"\"from .blocks import Transpose2D_block\n",
        "from .blocks import Upsample2D_block\n",
        "from ..utils import get_layer_number, to_tuple\"\"\"\n",
        "\n",
        "\n",
        "def build_unet(backbone, classes, skip_connection_layers,\n",
        "               decoder_filters=(256,128,64,32,16),\n",
        "               upsample_rates=(2,2,2,2,2),\n",
        "               n_upsample_blocks=5,\n",
        "               block_type='upsampling',\n",
        "               activation='sigmoid',\n",
        "               use_batchnorm=True):\n",
        "\n",
        "    input = backbone.input\n",
        "    x = backbone.output\n",
        "\n",
        "    if block_type == 'transpose':\n",
        "        up_block = Transpose2D_block\n",
        "    else:\n",
        "        up_block = Upsample2D_block\n",
        "\n",
        "    # convert layer names to indices\n",
        "    skip_connection_idx = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n",
        "                               for l in skip_connection_layers])\n",
        "\n",
        "    for i in range(n_upsample_blocks):\n",
        "\n",
        "        # check if there is a skip connection\n",
        "        skip_connection = None\n",
        "        if i < len(skip_connection_idx):\n",
        "            skip_connection = backbone.layers[skip_connection_idx[i]].output\n",
        "\n",
        "        upsample_rate = to_tuple(upsample_rates[i])\n",
        "\n",
        "        x = up_block(decoder_filters[i], i, upsample_rate=upsample_rate,\n",
        "                     skip=skip_connection, use_batchnorm=use_batchnorm)(x)\n",
        "\n",
        "    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n",
        "    y2 = Activation(activation, name=activation)(x)\n",
        "    \n",
        "    y1 = 2*input - y2\n",
        "\n",
        "    y = concatenate([y1,y2], axis=2)\n",
        "\n",
        "    model = Model(input, y)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ku4_IDAs04Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNET MODEL\n",
        "\n",
        "\"\"\"from .builder import build_unet\n",
        "from ..utils import freeze_model\n",
        "from ..backbones import get_backbone\"\"\"\n",
        "\n",
        "\n",
        "DEFAULT_SKIP_CONNECTIONS = {\n",
        "    'vgg16':            ('block5_conv3', 'block4_conv3', 'block3_conv3', 'block2_conv2', 'block1_conv2'),\n",
        "    'vgg19':            ('block5_conv4', 'block4_conv4', 'block3_conv4', 'block2_conv2', 'block1_conv2'),\n",
        "    'resnet18':         ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'), # check 'bn_data'\n",
        "    'resnet34':         ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'resnet50':         ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'resnet101':        ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'resnet152':        ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'resnext50':        ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'resnext101':       ('stage4_unit1_relu1', 'stage3_unit1_relu1', 'stage2_unit1_relu1', 'relu0'),\n",
        "    'inceptionv3':          (228, 86, 16, 9),\n",
        "    'inceptionresnetv2':    (594, 260, 16, 9),\n",
        "    'densenet121':          (311, 139, 51, 4),\n",
        "    'densenet169':          (367, 139, 51, 4),\n",
        "    'densenet201':          (479, 139, 51, 4),\n",
        "}\n",
        "\n",
        "\n",
        "def Unet(backbone_name='vgg16',\n",
        "         input_shape=(None, None, 3),\n",
        "         input_tensor=None,\n",
        "         encoder_weights='imagenet',\n",
        "         freeze_encoder=False,\n",
        "         skip_connections='default',\n",
        "         decoder_block_type='upsampling',\n",
        "         decoder_filters=(256,128,64,32,16),\n",
        "         decoder_use_batchnorm=True,\n",
        "         n_upsample_blocks=5,\n",
        "         upsample_rates=(2,2,2,2,2),\n",
        "         classes=1,\n",
        "         activation='sigmoid'):\n",
        "    \"\"\"\n",
        "\n",
        "    Args:\n",
        "        backbone_name: (str) look at list of available backbones.\n",
        "        input_shape:  (tuple) dimensions of input data (H, W, C)\n",
        "        input_tensor: keras tensor\n",
        "        encoder_weights: one of `None` (random initialization), \n",
        "            'imagenet' (pre-training on ImageNet), \n",
        "            'dof' (pre-training on DoF)\n",
        "        freeze_encoder: (bool) Set encoder layers weights as non-trainable. Useful for fine-tuning\n",
        "        skip_connections: if 'default' is used take default skip connections,\n",
        "            else provide a list of layer numbers or names starting from top of model\n",
        "        decoder_block_type: (str) one of 'upsampling' and 'transpose' (look at blocks.py)\n",
        "        decoder_filters: (int) number of convolution layer filters in decoder blocks\n",
        "        decoder_use_batchnorm: (bool) if True add batch normalisation layer between `Conv2D` ad `Activation` layers\n",
        "        n_upsample_blocks: (int) a number of upsampling blocks\n",
        "        upsample_rates: (tuple of int) upsampling rates decoder blocks\n",
        "        classes: (int) a number of classes for output\n",
        "        activation: (str) one of keras activations for last model layer\n",
        "\n",
        "    Returns:\n",
        "        keras.models.Model instance\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    backbone = get_backbone(backbone_name,\n",
        "                            input_shape=input_shape,\n",
        "                            input_tensor=input_tensor,\n",
        "                            weights=encoder_weights,\n",
        "                            include_top=False)\n",
        "\n",
        "    if skip_connections == 'default':\n",
        "        skip_connections = DEFAULT_SKIP_CONNECTIONS[backbone_name]\n",
        "\n",
        "    model = build_unet(backbone,\n",
        "                       classes,\n",
        "                       skip_connections,\n",
        "                       decoder_filters=decoder_filters,\n",
        "                       block_type=decoder_block_type,\n",
        "                       activation=activation,\n",
        "                       n_upsample_blocks=n_upsample_blocks,\n",
        "                       upsample_rates=upsample_rates,\n",
        "                       use_batchnorm=decoder_use_batchnorm)\n",
        "\n",
        "    # lock encoder weights for fine-tuning\n",
        "    if freeze_encoder:\n",
        "        freeze_model(backbone)\n",
        "\n",
        "    #model.name = 'u-{}'.format(backbone_name)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dSXoaBxP05IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = Unet(backbone_name='vgg16', #vgg16\n",
        "         input_shape=(32, 32, 1),\n",
        "         input_tensor=None,\n",
        "         encoder_weights=None,\n",
        "         freeze_encoder=False,\n",
        "         skip_connections='default',\n",
        "         decoder_block_type='upsampling',\n",
        "         decoder_filters=(256,128,64,32,16),\n",
        "         #decoder_filters=(128,64,32,16,8),\n",
        "         decoder_use_batchnorm=True,\n",
        "         n_upsample_blocks=5,\n",
        "         upsample_rates=(2,2,2,2,2),\n",
        "         classes=1,\n",
        "         activation='sigmoid')"
      ],
      "metadata": {
        "id": "go-UOAhkAuNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu9uhHbPBSVL",
        "outputId": "3b62efa3-6d68-4ff6-ce4a-4e9d17692085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 32, 32, 64)   640         ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['block1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 1, 1, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage0_upsample (UpSam  (None, 2, 2, 512)   0           ['block5_pool[0][0]']            \n",
            " pling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 2, 2, 1024)   0           ['decoder_stage0_upsample[0][0]',\n",
            "                                                                  'block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage0_conv1 (Conv2D)  (None, 2, 2, 256)    2359296     ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_stage0_bn1 (BatchNorma  (None, 2, 2, 256)   1024        ['decoder_stage0_conv1[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage0_relu1 (Activati  (None, 2, 2, 256)   0           ['decoder_stage0_bn1[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0_conv2 (Conv2D)  (None, 2, 2, 256)    589824      ['decoder_stage0_relu1[0][0]']   \n",
            "                                                                                                  \n",
            " decoder_stage0_bn2 (BatchNorma  (None, 2, 2, 256)   1024        ['decoder_stage0_conv2[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage0_relu2 (Activati  (None, 2, 2, 256)   0           ['decoder_stage0_bn2[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1_upsample (UpSam  (None, 4, 4, 256)   0           ['decoder_stage0_relu2[0][0]']   \n",
            " pling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 4, 4, 768)    0           ['decoder_stage1_upsample[0][0]',\n",
            "                                                                  'block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage1_conv1 (Conv2D)  (None, 4, 4, 128)    884736      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_stage1_bn1 (BatchNorma  (None, 4, 4, 128)   512         ['decoder_stage1_conv1[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage1_relu1 (Activati  (None, 4, 4, 128)   0           ['decoder_stage1_bn1[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1_conv2 (Conv2D)  (None, 4, 4, 128)    147456      ['decoder_stage1_relu1[0][0]']   \n",
            "                                                                                                  \n",
            " decoder_stage1_bn2 (BatchNorma  (None, 4, 4, 128)   512         ['decoder_stage1_conv2[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage1_relu2 (Activati  (None, 4, 4, 128)   0           ['decoder_stage1_bn2[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage2_upsample (UpSam  (None, 8, 8, 128)   0           ['decoder_stage1_relu2[0][0]']   \n",
            " pling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 8, 8, 384)    0           ['decoder_stage2_upsample[0][0]',\n",
            "                                                                  'block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage2_conv1 (Conv2D)  (None, 8, 8, 64)     221184      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_stage2_bn1 (BatchNorma  (None, 8, 8, 64)    256         ['decoder_stage2_conv1[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage2_relu1 (Activati  (None, 8, 8, 64)    0           ['decoder_stage2_bn1[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage2_conv2 (Conv2D)  (None, 8, 8, 64)     36864       ['decoder_stage2_relu1[0][0]']   \n",
            "                                                                                                  \n",
            " decoder_stage2_bn2 (BatchNorma  (None, 8, 8, 64)    256         ['decoder_stage2_conv2[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage2_relu2 (Activati  (None, 8, 8, 64)    0           ['decoder_stage2_bn2[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage3_upsample (UpSam  (None, 16, 16, 64)  0           ['decoder_stage2_relu2[0][0]']   \n",
            " pling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 16, 16, 192)  0           ['decoder_stage3_upsample[0][0]',\n",
            "                                                                  'block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage3_conv1 (Conv2D)  (None, 16, 16, 32)   55296       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_stage3_bn1 (BatchNorma  (None, 16, 16, 32)  128         ['decoder_stage3_conv1[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage3_relu1 (Activati  (None, 16, 16, 32)  0           ['decoder_stage3_bn1[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage3_conv2 (Conv2D)  (None, 16, 16, 32)   9216        ['decoder_stage3_relu1[0][0]']   \n",
            "                                                                                                  \n",
            " decoder_stage3_bn2 (BatchNorma  (None, 16, 16, 32)  128         ['decoder_stage3_conv2[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage3_relu2 (Activati  (None, 16, 16, 32)  0           ['decoder_stage3_bn2[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage4_upsample (UpSam  (None, 32, 32, 32)  0           ['decoder_stage3_relu2[0][0]']   \n",
            " pling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 32, 32, 96)   0           ['decoder_stage4_upsample[0][0]',\n",
            "                                                                  'block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage4_conv1 (Conv2D)  (None, 32, 32, 16)   13824       ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " decoder_stage4_bn1 (BatchNorma  (None, 32, 32, 16)  64          ['decoder_stage4_conv1[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage4_relu1 (Activati  (None, 32, 32, 16)  0           ['decoder_stage4_bn1[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " decoder_stage4_conv2 (Conv2D)  (None, 32, 32, 16)   2304        ['decoder_stage4_relu1[0][0]']   \n",
            "                                                                                                  \n",
            " decoder_stage4_bn2 (BatchNorma  (None, 32, 32, 16)  64          ['decoder_stage4_conv2[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " decoder_stage4_relu2 (Activati  (None, 32, 32, 16)  0           ['decoder_stage4_bn2[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " final_conv (Conv2D)            (None, 32, 32, 1)    145         ['decoder_stage4_relu2[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, 32, 32, 1)   0           ['input_2[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " sigmoid (Activation)           (None, 32, 32, 1)    0           ['final_conv[0][0]']             \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 32, 32, 1)   0           ['tf.math.multiply_1[0][0]',     \n",
            " )                                                                'sigmoid[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 32, 64, 1)    0           ['tf.math.subtract_1[0][0]',     \n",
            "                                                                  'sigmoid[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,037,649\n",
            "Trainable params: 19,035,665\n",
            "Non-trainable params: 1,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "zIa8XRQr6sFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet.compile(optimizer=Adam(), loss='mse')"
      ],
      "metadata": {
        "id": "Le_FzUiH6sFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', min_lr=0.000009, min_delta=0.0001, factor=0.75, patience=3, verbose=1, mode='min')\n",
        "reduce_lr_callback = ReduceLROnPlateau(patience=3, min_delta=0.00001)\n",
        "\n",
        "callback_checkpoint = ModelCheckpoint('UNET++1.{epoch:02d}-{val_loss:.4f}.hdf5', save_weights_only=True) "
      ],
      "metadata": {
        "id": "N7scNdBq6sFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = 10000\n",
        "val_steps = N_test // batchsize"
      ],
      "metadata": {
        "id": "FtrtMI6p6sFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = unet.fit(train_generator, epochs=15, batch_size=batchsize, validation_data=test_generator, callbacks=[callback_checkpoint,reduce_lr_callback],\n",
        "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636e0ac4-b175-4ef7-d5b3-15ce1203ca41",
        "id": "FE9T8SmVpckI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 521s 52ms/step - loss: 0.0020 - val_loss: 9.2359e-04 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "10000/10000 [==============================] - 516s 52ms/step - loss: 8.2196e-04 - val_loss: 7.1547e-04 - lr: 0.0010\n",
            "Epoch 3/15\n",
            " 6905/10000 [===================>..........] - ETA: 3:23 - loss: 6.9664e-04"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet.load_weights('UNET++.02-0.0007.hdf5')"
      ],
      "metadata": {
        "id": "dmBoe0JFmbX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = unet.fit(train_generator, epochs=15, batch_size=batchsize, validation_data=test_generator, callbacks=[callback_checkpoint,reduce_lr_callback],\n",
        "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e9b132-b5ee-4299-be1a-a845bc4c43be",
        "id": "cX3vtQic6sFT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 364s 36ms/step - loss: 6.8541e-04 - val_loss: 6.8095e-04 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 6.2250e-04 - val_loss: 5.7999e-04 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 5.8579e-04 - val_loss: 5.6869e-04 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "10000/10000 [==============================] - 362s 36ms/step - loss: 5.5045e-04 - val_loss: 5.3065e-04 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 5.2770e-04 - val_loss: 5.3127e-04 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 5.1282e-04 - val_loss: 5.2408e-04 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 4.9987e-04 - val_loss: 4.8989e-04 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 4.8813e-04 - val_loss: 5.1394e-04 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 4.7831e-04 - val_loss: 4.7366e-04 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 4.6954e-04 - val_loss: 5.0575e-04 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 4.6097e-04 - val_loss: 4.5655e-04 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 4.5586e-04 - val_loss: 4.5854e-04 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 4.4986e-04 - val_loss: 4.5907e-04 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "10000/10000 [==============================] - 357s 36ms/step - loss: 4.4868e-04 - val_loss: 4.5006e-04 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "10000/10000 [==============================] - 363s 36ms/step - loss: 4.1836e-04 - val_loss: 4.3207e-04 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator1 = datagenerator(mnist_x_test, fashion_mnist_x_test, 20000)\n",
        "mse_list = []\n",
        "for i in range(10):\n",
        "  x_batch, y_batch = next(test_generator1)\n",
        "  mse = unet.evaluate(x_batch, y_batch)\n",
        "  mse_list.append(mse)\n",
        "print(mse_list)\n",
        "print('Min:', min(mse_list))\n",
        "print('Mean:', np.mean(mse_list))\n",
        "print('Std:', np.std(mse_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jzB5JFTsYK",
        "outputId": "e778805a-b09e-4036-877a-07148dbdd28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 7s 10ms/step - loss: 4.1578e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2033e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2042e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1965e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2322e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2012e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2350e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1833e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1840e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.2130e-04\n",
            "[0.00041578258969821036, 0.00042032633791677654, 0.00042042354471050203, 0.00041964618139900267, 0.00042322033550590277, 0.00042012258199974895, 0.00042350240983068943, 0.0004183299606665969, 0.00041840196354314685, 0.0004212978237774223]\n",
            "Min: 0.00041578258969821036\n",
            "Mean: 0.00042010537290479986\n",
            "Std: 2.1855468311672524e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(training_history, n_epochs=None):\n",
        "    if not n_epochs:\n",
        "      n_epochs = len(training_history.history['loss'])\n",
        "\n",
        "    epochs = range(1,n_epochs+1)\n",
        "\n",
        "    plt.plot(epochs, training_history.history['loss'], label='train_loss')\n",
        "    plt.plot(epochs, training_history.history['val_loss'], label='val_loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.title('Loss')"
      ],
      "metadata": {
        "id": "BT9jd0gXTAfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5cddb654-6ca5-45c9-d6a3-d4616ff0af46",
        "id": "d5byqhATTAfq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(test_generator)\n",
        "x = x_batch[0]\n",
        "y = y_batch[0]\n",
        "y_pred = unet.predict(x.reshape((1,32,32)))\n",
        "plt.imshow(x,cmap='gray', interpolation='nearest')\n",
        "plt.show()\n",
        "plt.imshow(y, cmap='gray', interpolation='nearest')\n",
        "plt.show()\n",
        "plt.imshow(y_pred[0].reshape((32,64)), cmap='gray', interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "A6ZaLJm5T5av",
        "outputId": "3c2687d3-66a9-4a09-819d-40d353e54391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More training"
      ],
      "metadata": {
        "id": "E9dJ2I62RcEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = unet.fit(train_generator, epochs=5, batch_size=batchsize, validation_data=test_generator, callbacks=[callback_checkpoint],\n",
        "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eECOl--RbWG",
        "outputId": "e7ddf191-8581-4235-9837-673d392ee3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 4.1199e-04 - val_loss: 4.1482e-04\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 358s 36ms/step - loss: 4.0958e-04 - val_loss: 4.1872e-04\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 359s 36ms/step - loss: 4.0823e-04 - val_loss: 4.2852e-04\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 360s 36ms/step - loss: 4.0662e-04 - val_loss: 4.1243e-04\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 360s 36ms/step - loss: 4.0614e-04 - val_loss: 4.1146e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator1 = datagenerator(mnist_x_test, fashion_mnist_x_test, 20000)\n",
        "mse_list = []\n",
        "for i in range(10):\n",
        "  x_batch, y_batch = next(test_generator1)\n",
        "  mse = unet.evaluate(x_batch, y_batch)\n",
        "  mse_list.append(mse)\n",
        "print(mse_list)\n",
        "print('Min:', min(mse_list))\n",
        "print('Mean:', np.mean(mse_list))\n",
        "print('Std:', np.std(mse_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7c2ElnhZrCU",
        "outputId": "95d4c058-e4e4-4fd2-db17-96f9bd31c39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 7s 12ms/step - loss: 4.0839e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1168e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1410e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1372e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1917e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1195e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.0845e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1398e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1946e-04\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 4.1283e-04\n",
            "[0.0004083911480847746, 0.00041167845483869314, 0.000414097448810935, 0.00041372375562787056, 0.0004191736807115376, 0.0004119540099054575, 0.00040845180046744645, 0.00041397541644982994, 0.00041945945122279227, 0.0004128326545469463]\n",
            "Min: 0.0004083911480847746\n",
            "Mean: 0.00041337378206662834\n",
            "Std: 3.548486762025747e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG19"
      ],
      "metadata": {
        "id": "jF1laZjaJfGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg19\n",
        "hist = unet.fit(train_generator, epochs=15, batch_size=batchsize, validation_data=test_generator, callbacks=[callback_checkpoint,reduce_lr_callback],\n",
        "              steps_per_epoch=steps_per_epoch, validation_steps=val_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "8FBIyoBFu1c1",
        "outputId": "3ce8cd6f-6cd3-4834-a27a-0f9861d0e0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 433s 42ms/step - loss: 0.0020 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 2/15\n",
            " 3609/10000 [=========>....................] - ETA: 4:27 - loss: 9.0750e-04"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-82dcb8b824cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = unet.fit(train_generator, epochs=15, batch_size=batchsize, validation_data=test_generator, callbacks=[callback_checkpoint,reduce_lr_callback],\n\u001b[0;32m----> 2\u001b[0;31m               steps_per_epoch=steps_per_epoch, validation_steps=val_steps)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}