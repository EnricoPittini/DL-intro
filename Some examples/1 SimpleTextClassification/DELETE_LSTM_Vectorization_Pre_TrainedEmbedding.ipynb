{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DELETE LSTM Vectorization Pre-TrainedEmbedding",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "2RP-0aZ9iPxC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_data.csv')\n",
        "x_train = train['tweet']\n",
        "y_train = train['class']"
      ],
      "metadata": {
        "id": "o24H7hQpjtXG"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Class $0$ -> hate speech\n",
        "- Class $1$ -> offensive language\n",
        "- Class $2$ -> neither"
      ],
      "metadata": {
        "id": "3S-tu4b3mHVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.loc[:20, ['tweet', 'class']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "NHQ65EH7khVJ",
        "outputId": "1cc0fd35-ecf6-4ed9-da22-2ce514391df6"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                tweet  class\n",
              "0            Can't get no money from me you silly hoe      1\n",
              "1   That was almost 10 years ago. I gave ALL them ...      1\n",
              "2   RT @RakwonOGOD: Bitches tweeting \"last night &...      1\n",
              "3          That hoe out there, Fat Trel said it best.      1\n",
              "4   Can Charlie Crist pull one over on Rick Scott?...      2\n",
              "5   RT @Realistt__: &#128525; &#8220;@Squirtology:...      1\n",
              "6     My problem is caring about bitches &amp; noggas      1\n",
              "7   All da white folk off twitter yet? Da colored ...      2\n",
              "8   &#128514;&#128514;&#128514; played that nigga ...      1\n",
              "9   RT @FlowDaddy24: @_RinkO0 @d_brad80 @0biwankob...      1\n",
              "10  Good they trash RT @jerseyzbest74: Niggas ate ...      1\n",
              "11  #ReasonsWeCantBeTogether if u was talkin to my...      0\n",
              "12                      Paige better text a bitch lol      1\n",
              "13  RT @_theDarius: &#8220;@JetsAndASwisher: @_the...      1\n",
              "14  &#128119;&#128119; you needa stop sucking dick...      1\n",
              "15  Ain't nothing that good head or pussy that cur...      1\n",
              "16  RT @Hinojosa214: Bitch fucking fuck Brandeis. ...      1\n",
              "17  I was smoking a blunt outside and these nasty ...      1\n",
              "18  @b0ssladyre just ate a wees brownie and is see...      2\n",
              "19  @illest_will @djdynamiq @edrobersonsf @sarahli...      1\n",
              "20  RT @DonnieWahlberg: On set of #BlueBloods. Hop...      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50361f88-92b4-4d26-b5be-a4d68e25f370\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can't get no money from me you silly hoe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>That was almost 10 years ago. I gave ALL them ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @RakwonOGOD: Bitches tweeting \"last night &amp;...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That hoe out there, Fat Trel said it best.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can Charlie Crist pull one over on Rick Scott?...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RT @Realistt__: &amp;#128525; &amp;#8220;@Squirtology:...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>My problem is caring about bitches &amp;amp; noggas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>All da white folk off twitter yet? Da colored ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&amp;#128514;&amp;#128514;&amp;#128514; played that nigga ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RT @FlowDaddy24: @_RinkO0 @d_brad80 @0biwankob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Good they trash RT @jerseyzbest74: Niggas ate ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>#ReasonsWeCantBeTogether if u was talkin to my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Paige better text a bitch lol</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RT @_theDarius: &amp;#8220;@JetsAndASwisher: @_the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&amp;#128119;&amp;#128119; you needa stop sucking dick...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Ain't nothing that good head or pussy that cur...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RT @Hinojosa214: Bitch fucking fuck Brandeis. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I was smoking a blunt outside and these nasty ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>@b0ssladyre just ate a wees brownie and is see...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>@illest_will @djdynamiq @edrobersonsf @sarahli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>RT @DonnieWahlberg: On set of #BlueBloods. Hop...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50361f88-92b4-4d26-b5be-a4d68e25f370')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50361f88-92b4-4d26-b5be-a4d68e25f370 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50361f88-92b4-4d26-b5be-a4d68e25f370');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test_data.csv')\n",
        "x_test = test['tweet']\n",
        "y_test = test['class']"
      ],
      "metadata": {
        "id": "z1R_M2QUmUyn"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = pd.read_csv('val_data.csv')\n",
        "x_val = val['tweet']\n",
        "y_val = val['class']"
      ],
      "metadata": {
        "id": "k_SuH387mVME"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPROCESSING"
      ],
      "metadata": {
        "id": "q5oyGSMsmndG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SXH50E1nma9U",
        "outputId": "de3aa343-a6d3-4384-e554-e6cd9ae92b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT @KingUlyssesIV: These bitches aint shit &amp; pussy is my greatest vice\\nI love smokin weed, i hate advice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gdeXFkJUmbAF",
        "outputId": "1dd30ec5-281f-4216-ad9b-74c83cdbbaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@creepgoddess @iPostDickPrints hell no! Where is the pussy print page?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-duILJBombCU",
        "outputId": "37dc9305-7a8c-4e71-dfe3-0033d18ea71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ion like the ho cause she talk to mf much with ha real butt ugly ass dumb young ass ho &#128553;&#128074;&#128522;&#128299;&#128591;&#128079;&#128530;&#9996;&#65039;'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(s):\n",
        "  return ''.join([(c if c.isalnum() else (' ' if c!='\\'' else '')) for c in re.sub('((&|@).*?(;| ))', ' ', s.replace('\\n', ' ').replace('\\t', ' ').replace('RT', ' '))]).lower()\n",
        "\n",
        "x_train_p = x_train.map(f)\n",
        "x_train_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzWq1rTyonRv",
        "outputId": "c70afa19-af19-4262-ec14-a18cf3a6e91a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                  cant get no money from me you silly hoe\n",
              "1        that was almost 10 years ago  i gave all them ...\n",
              "2           bitches tweeting  last night     like they ...\n",
              "3               that hoe out there  fat trel said it best \n",
              "4        can charlie crist pull one over on rick scott ...\n",
              "                               ...                        \n",
              "17343    going hard bitch swear im on my job throw a qu...\n",
              "17344        parent in phoenix says administrators made...\n",
              "17345       aw yall some hoes hating on that girl that ...\n",
              "17346    watch out  ned   crc  worldcup2014  puravida h...\n",
              "17347    jk  im going to be a pussy about it  i dont wa...\n",
              "Name: tweet, Length: 17348, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed7-b7u0xk_o",
        "outputId": "b7b017df-ef5e-47ad-9862-50bfc0348095"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 Can't get no money from me you silly hoe\n",
              "1        That was almost 10 years ago. I gave ALL them ...\n",
              "2        RT @RakwonOGOD: Bitches tweeting \"last night &...\n",
              "3               That hoe out there, Fat Trel said it best.\n",
              "4        Can Charlie Crist pull one over on Rick Scott?...\n",
              "                               ...                        \n",
              "17343    Going hard bitch swear I'm on my job throw a q...\n",
              "17344    RT @AmPowerBlog: @velvethammer Parent in Phoen...\n",
              "17345    RT @nostalgic_mike: Aw y'all some hoes hating ...\n",
              "17346    Watch out #ned! #crc #worldcup2014 #puravida h...\n",
              "17347    Jk. I'm going to be a pussy about it. I don't ...\n",
              "Name: tweet, Length: 17348, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "text = x_test[4]\n",
        "\n",
        "re.sub('@.*? ', '', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B7c3ZzQOqXdu",
        "outputId": "35027545-2f37-40da-a67a-aa710b0702f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RT These bitches aint shit &amp; pussy is my greatest vice\\nI love smokin weed, i hate advice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.replace(['\\n','\\t','RT'], ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4BPDd5mwuQXw",
        "outputId": "7469fe47-5228-4883-e372-07419854836f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a54a8b4569b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: replace() argument 1 must be str, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join([c for c in re.sub('((&|@).*?(;| ))', ' ', text.replace('\\n', ' ').replace('\\t', ' ').replace('RT', ' ')) if c.isalnum() or c==' '])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OlGyIZHhtKJ_",
        "outputId": "9a5e501a-749f-458b-ba84-7c9e2f401f9e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   These bitches aint shit   pussy is my greatest vice I love smokin weed i hate advice'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(s):\n",
        "  return ''.join([(c if c.isalnum() else (' ' if c!='\\'' else '')) for c in re.sub('((&|@).*?(;| ))', ' ', s.replace('\\n', ' ').replace('\\t', ' ').replace('RT', ' '))]).lower()\n",
        "\n",
        "x_test_p = x_test.map(f)\n",
        "x_test_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrpGN2b2yHEv",
        "outputId": "231c277c-aa0b-4d35-fdbe-7134adbe4df7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 i hit raw while im listening to papoose\n",
              "1                   yes mimi bitch yo dumb ass got played\n",
              "2             these people at jury selection are retarded\n",
              "3       lol shawty at sheets gave me her number haha i...\n",
              "4          these bitches aint shit   pussy is my great...\n",
              "                              ...                        \n",
              "3712                               this bitches voice    \n",
              "3713     i was like  this bitch better chill   oh hey ...\n",
              "3714    got ya crackas  spics  chinks  and carpet ride...\n",
              "3715     i assume so  the tranny went out this morning...\n",
              "3716                                                  fag\n",
              "Name: tweet, Length: 3717, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AshTV-k0yP2H",
        "outputId": "ea277917-6aae-41c3-ed94-7bc08538b2ba"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 I hit raw while im listening to papoose\n",
              "1       RT @PRETTYGIRLNEICE: Yes Mimi bitch yo dumb as...\n",
              "2             These people at jury selection are retarded\n",
              "3       Lol shawty at sheets gave me her number haha I...\n",
              "4       RT @KingUlyssesIV: These bitches aint shit &am...\n",
              "                              ...                        \n",
              "3712       This bitches voice &#128567;&#128567;&#128567;\n",
              "3713    @airam12_ I was like \"This bitch better chill-...\n",
              "3714    Got ya crackas, spics, chinks, and carpet ride...\n",
              "3715    @serenity_23 I assume so, the tranny went out ...\n",
              "3716                    @1Josh_Warwick3 @ashleyypat17 fag\n",
              "Name: tweet, Length: 3717, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(s):\n",
        "  return ''.join([(c if c.isalnum() else (' ' if c!='\\'' else '')) for c in re.sub('((&|@).*?(;| ))', ' ', s.replace('\\n', ' ').replace('\\t', ' ').replace('RT', ' '))]).lower()\n",
        "\n",
        "x_val_p = x_val.map(f)\n",
        "x_val_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ0Qzd0nyVlD",
        "outputId": "8b7d1c6c-71ca-45c5-d158-87968d590ced"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                boy dats cold   tyga dwn bad for cuff...\n",
              "1                        the shit you hear about me mi...\n",
              "2                                    bitch plz whatever  \n",
              "3                   cant you see these hoes wont change  \n",
              "4              if youre toes aint done you pussy stinks  \n",
              "                              ...                        \n",
              "3713                         you are a hoe  hoe    a hoe \n",
              "3714                                you fake niggah lolol\n",
              "3715                   you got niggas  and i got bitches \n",
              "3716    you gotta understand that these bitches are ch...\n",
              "3717    youre such a retard i hope you get type 2 diab...\n",
              "Name: tweet, Length: 3718, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9sHivzEyZoT",
        "outputId": "b9451fc7-5e75-4b48-de46-4ea81d36d2cd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "1       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "2                                  \" bitch plz whatever \"\n",
              "3                 \" cant you see these hoes wont change \"\n",
              "4          \" if you're toes ain't done you pussy stinks \"\n",
              "                              ...                        \n",
              "3713                     you are a hoe, hoe, &amp; a hoe.\n",
              "3714                                you fake niggah lolol\n",
              "3715                   you got niggas, and i got bitches.\n",
              "3716    you gotta understand that these bitches are ch...\n",
              "3717    you're such a retard i hope you get type 2 dia...\n",
              "Name: tweet, Length: 3718, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VECTORIZATION"
      ],
      "metadata": {
        "id": "CYhpu3l61BAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_p = pd.concat([x_train_p, x_test_p, x_val_p], axis=0)\n",
        "x_p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8thu-2sH6NHf",
        "outputId": "92f02839-f5c3-409e-af93-585ba25dfdce"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 cant get no money from me you silly hoe\n",
              "1       that was almost 10 years ago  i gave all them ...\n",
              "2          bitches tweeting  last night     like they ...\n",
              "3              that hoe out there  fat trel said it best \n",
              "4       can charlie crist pull one over on rick scott ...\n",
              "                              ...                        \n",
              "3713                         you are a hoe  hoe    a hoe \n",
              "3714                                you fake niggah lolol\n",
              "3715                   you got niggas  and i got bitches \n",
              "3716    you gotta understand that these bitches are ch...\n",
              "3717    youre such a retard i hope you get type 2 diab...\n",
              "Name: tweet, Length: 24783, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "ul-OPuFh1AME"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(standardize='lower_and_strip_punctuation', split='whitespace')"
      ],
      "metadata": {
        "id": "vyeQvHbM1b_I"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(x_p)"
      ],
      "metadata": {
        "id": "qCKsUiP11g9y"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_p.shape)\n",
        "print(x_p[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3uhGwVZ1wMz",
        "outputId": "b8b7dc69-66dc-43fb-fe5d-9b7f124cd594"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24783,)\n",
            "0              cant get no money from me you silly hoe\n",
            "1    that was almost 10 years ago  i gave all them ...\n",
            "2       bitches tweeting  last night     like they ...\n",
            "3           that hoe out there  fat trel said it best \n",
            "4    can charlie crist pull one over on rick scott ...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer(x_p).shape)\n",
        "print(vectorizer(x_p)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaJkuG3N1sgy",
        "outputId": "a0a1a113-f06c-4835-977d-8093aaaf5cbd"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24783, 34)\n",
            "tf.Tensor(\n",
            "[[   77    38    42   162    85    18     6  1388    28     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [   10    52   643   387   431   652     4   514    33    70    12   389\n",
            "     74    41   224  2558     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [   12   862   228   254    17    41   195   236   947  1140    22    21\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [   10    28    58   144   198  7076   121    27   232     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [   67   160   845   437    71   125    20   871  1199   206    62   195\n",
            "    437    71   125    20 19357  3282  2785  7095  5129     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]], shape=(5, 34), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 34"
      ],
      "metadata": {
        "id": "bH6xgxk777xb"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "voc[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD-9cRhb4oWz",
        "outputId": "1a3cd8aa-abe8-41a4-9835-e6b4c4d24c79"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'a', 'bitch', 'i']"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = len(voc)\n",
        "n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnf9WE_76ht3",
        "outputId": "bdfd93d1-47af-43d1-8e78-502935678720"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24033"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the dictionary for the mapping word -> index\n",
        "word2index = dict(zip(voc, range(len(voc))))\n",
        "\n",
        "# Build the dictionary for the mapping index -> word\n",
        "index2word = dict(zip(range(len(voc)), voc))"
      ],
      "metadata": {
        "id": "lTrNN4k_6ure"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform the dataset using the vectorizer"
      ],
      "metadata": {
        "id": "iprO7v2d66Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_integers = vectorizer(x_p)"
      ],
      "metadata": {
        "id": "1Q9NIItC9iAc"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tWptpb39n6O",
        "outputId": "6985e226-24bd-444c-d43d-9c468ffbee22"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17348,)\n",
            "(3717,)\n",
            "(3718,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_integers = x_integers[:17348]\n",
        "x_test_integers = x_integers[17348:17348+3717]\n",
        "x_val_integers = x_integers[17348+3717:]"
      ],
      "metadata": {
        "id": "MI3H2-rC9mVK"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_integers.shape)\n",
        "print(x_test_integers.shape)\n",
        "print(x_val_integers.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VTZTIF7-FNg",
        "outputId": "eecef3b2-b0e1-41d5-d406-e8c3b5b4169f"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17348, 34)\n",
            "(3717, 34)\n",
            "(3718, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EMBEDDING"
      ],
      "metadata": {
        "id": "dRmrKEhG7WhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100"
      ],
      "metadata": {
        "id": "TRJFOdY-7Ydw"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnPY6Yi77ajQ",
        "outputId": "ef601f28-102d-4b79-8a33-47c655acaf80"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-02 12:40:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-07-02 12:40:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-07-02 12:40:59--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 38s  \n",
            "\n",
            "2022-07-02 12:43:38 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = 'glove.6B.100d.txt'"
      ],
      "metadata": {
        "id": "QoIE1mGO7dLR"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "word2embedding = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, embedding = line.split(maxsplit=1)\n",
        "        embedding = np.fromstring(embedding, \"f\", sep=\" \")\n",
        "        word2embedding[word] = embedding\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(word2embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5bDuNon7e68",
        "outputId": "bf2e7e2c-21f9-4b98-ba1f-c98e924cc92e"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We count the number of words in our (vectorized) dataset which are not found in the imported embedding\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "index2embedding = {}\n",
        "for word, i in word2index.items():\n",
        "    embedding_vector = word2embedding.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in word2embedding will be all-zeros.\n",
        "        word2embedding[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjKoxvFO7jSX",
        "outputId": "56d72aa0-021e-4587-f235-d9a97eeb5d09"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 16089 words (7944 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((n_words, embedding_dim))\n",
        "for i, embedding_vector in index2embedding.items():\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "aTHuNjvf7lj6"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ],
      "metadata": {
        "id": "HYJ8LO6P703A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as ks\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "O-Y5MG9572KM"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input x: sequence of N word, where each word is an index/integer\n",
        "xin = Input(shape=(N,))\n",
        "\n",
        "# Embedding: we put as embedding layer our pre-trained embedding.\n",
        "# It transforms a word represented as an index to an embedding vector, with 'embedding_dim' values\n",
        "embedding_layer = Embedding(\n",
        "    n_words,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=ks.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,  # WE SET IT AS NON-TRAINABLE\n",
        ")\n",
        "x = embedding_layer(xin)\n",
        "\n",
        "h_outputs = LSTM(units=128,  return_sequences=True)(x)\n",
        "h_outputs = Dropout(0.2)(h_outputs)\n",
        "\n",
        "# LSTM: it takes in input a sequence of N words, where each word is a vector of 'embedding_dim' values.\n",
        "# We keep only the last output h_N, which is a vector with 128 values\n",
        "last_h = LSTM(units=128)(h_outputs)\n",
        "last_h = Dropout(0.2)(last_h)\n",
        "\n",
        "# Dense layer: it takes in input h_n, and it produces y_hat, which is the categorical distribution over all the possible words, represented as integers\n",
        "y_hat = Dense(units=3)(last_h) #activation='softmax')(last_h)\n",
        "\n",
        "model = Model(inputs=xin, outputs=y_hat)"
      ],
      "metadata": {
        "id": "egOLcctl73xc"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruS8PiaL8dSn",
        "outputId": "4e7c1c1d-792c-4fc8-cdf5-aa055ccd5308"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 34)]              0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 34, 100)           2403300   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 34, 128)           117248    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 34, 128)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,652,519\n",
            "Trainable params: 249,219\n",
            "Non-trainable params: 2,403,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "1dPyCVyL8yeH"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer=Adam())"
      ],
      "metadata": {
        "id": "v_xD97j08zGh"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " model.fit(x_train_integers, y_train, batch_size=128, epochs=15, validation_data=[x_val_integers,y_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQrY5adK83TY",
        "outputId": "33e35a07-775e-4400-8a0a-00a02d294014"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "136/136 [==============================] - 45s 240ms/step - loss: 0.6891 - val_loss: 0.6640\n",
            "Epoch 2/15\n",
            "136/136 [==============================] - 33s 246ms/step - loss: 0.6681 - val_loss: 0.6461\n",
            "Epoch 3/15\n",
            "136/136 [==============================] - 32s 233ms/step - loss: 0.6675 - val_loss: 0.6454\n",
            "Epoch 4/15\n",
            "136/136 [==============================] - 33s 243ms/step - loss: 0.6670 - val_loss: 0.6489\n",
            "Epoch 5/15\n",
            "136/136 [==============================] - 32s 234ms/step - loss: 0.6668 - val_loss: 0.6483\n",
            "Epoch 6/15\n",
            "136/136 [==============================] - 32s 235ms/step - loss: 0.6665 - val_loss: 0.6466\n",
            "Epoch 7/15\n",
            "136/136 [==============================] - 32s 234ms/step - loss: 0.6663 - val_loss: 0.6454\n",
            "Epoch 8/15\n",
            "136/136 [==============================] - 32s 235ms/step - loss: 0.6659 - val_loss: 0.6458\n",
            "Epoch 9/15\n",
            "136/136 [==============================] - 32s 235ms/step - loss: 0.6667 - val_loss: 0.6453\n",
            "Epoch 10/15\n",
            "136/136 [==============================] - 32s 234ms/step - loss: 0.6662 - val_loss: 0.6453\n",
            "Epoch 11/15\n",
            "136/136 [==============================] - 32s 233ms/step - loss: 0.6659 - val_loss: 0.6458\n",
            "Epoch 12/15\n",
            "136/136 [==============================] - 32s 233ms/step - loss: 0.6665 - val_loss: 0.6475\n",
            "Epoch 13/15\n",
            "136/136 [==============================] - 32s 233ms/step - loss: 0.6665 - val_loss: 0.6459\n",
            "Epoch 14/15\n",
            "136/136 [==============================] - 33s 240ms/step - loss: 0.6669 - val_loss: 0.6465\n",
            "Epoch 15/15\n",
            "136/136 [==============================] - 31s 231ms/step - loss: 0.6658 - val_loss: 0.6481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7d2272e310>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report \n",
        "\n",
        "y_test_pred = model.predict(x_test_integers)\n",
        "print(y_test_pred.shape)\n",
        "y_test_pred = np.argmax(y_test_pred, axis=-1)\n",
        "print(y_test_pred.shape)\n",
        "\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqxhDtUUOhtQ",
        "outputId": "3fb24a2b-90f5-46c9-c0e5-ef677a04284c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3717, 3)\n",
            "(3717,)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       230\n",
            "           1       0.77      1.00      0.87      2867\n",
            "           2       0.00      0.00      0.00       620\n",
            "\n",
            "    accuracy                           0.77      3717\n",
            "   macro avg       0.26      0.33      0.29      3717\n",
            "weighted avg       0.59      0.77      0.67      3717\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}