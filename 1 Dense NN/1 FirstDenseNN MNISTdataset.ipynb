{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to https://d2l.ai to an (almost) complete review about Deep Learning.\n",
    "\n",
    "We use the [TensorFlow](https://www.tensorflow.org/) framework. In particular, the [Keras](https://keras.io/) dialect (sub-package of TensorFlow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief recap of Dense NN\n",
    "\n",
    "A Dense Neural Network model is defined as a sequence of *dense layers*. \n",
    "\n",
    "Each dense layer is a fully-connected layer which consists in a vector $I \\in R^{1xn}$ of $n$ inputs (i.e. *input neurons*) and a vector $O \\in R^{1xm}$ of $m$ outputs (i.e. *output neurons*).\n",
    "\n",
    "Each output neuron takes input from all input neurons, with a weigth corresponding to each input neuron: vector $W \\in R^{1xn}$ of $n$ weigths. In addition, each output neuron has also a bias $b$ (scalar). The value of the output neuron is computed as $o = I*W+b$, where $I*W$ is the dot product.\n",
    "\n",
    "We have $m$ output neurons, with independent weigths. So, on the whole, we have a matrix $W \\in R^{nxm}$ of weigths. In addition, each output neuron has its own bias: vector $B$ of $m$ biases. Therefore, on the whole the dense layer computes the following operation: $O = I*W+B$, where $I*B$ is the rows-by-columns product.\n",
    "\n",
    "The matrix $W$ plus the vector $B$ are the parameters of the layer. They are the parameters that must be learnt. \n",
    "\n",
    "Finally, in addition to all that, an activation function $\\sigma$ can be applied: $O = \\sigma(I*W+B)$.\n",
    "\n",
    "Without the activation function, a dense layer simply computes a linear operation. The aim of the activation function is mainly to add non-linearity into out layer, in order to make it more powerful and expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8wSwJnsjx5P"
   },
   "source": [
    "# FirstDenseNN MNISTdataset\n",
    "\n",
    "A first example of a simple Dense Neural Network, applied to a well known dataset: the MNIST dataset.\n",
    "\n",
    "The classic MNIST dataset is a dataset about images representing handwritten digits. \n",
    "\n",
    "Basically, there are $N$ images. Each image represents a certain digit. Each digit represents a certain number among $0, 1, ..., 9$.\n",
    "\n",
    "Each image is labeled with the digit represented by that image. This is the class of the image. $10$ different classes: $0, 1, ..., 9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES\n",
    "\n",
    "As always, the first thing we need to do is importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3wMZ2Ge6jw1E"
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import keras dataset Mnist\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDiNppLVkvqd"
   },
   "source": [
    "Let us load the mnist dataset. It is already splitted into train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL8GyC0Nk14o",
    "outputId": "2fb5509c-8d5f-4a87-e9b8-3cf691280518"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 samples in the training set\n",
      "There are 10000 samples in the test set\n"
     ]
    }
   ],
   "source": [
    "print('There are {} samples in the training set'.format(x_train.shape[0]))\n",
    "print('There are {} samples in the test set'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's better inspect the input data `x`. \n",
    "\n",
    "Each instance is an greyscale image, with $28*28$ pixels. \n",
    "\n",
    "For example, let's see the shape of the first instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each pixel has a value in the range $[0,255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of the values in x_train: [0,255]\n",
      "Range of the values in x_test: [0,255]\n"
     ]
    }
   ],
   "source": [
    "print('Range of the values in x_train: [{},{}]'.format(x_train.min(),x_train.max()))\n",
    "print('Range of the values in x_test: [{},{}]'.format(x_test.min(),x_test.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the image representation of the first instance of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c81359fdc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, each instance in `x` is a matrix. This means that the input data `x` (both the `x_train` and the `x_test`) is a tensor (i.e. it has 3 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dimensions: (60000, 28, 28)\n",
      "x_test dimensions: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('x_train dimensions:', x_train.shape)\n",
    "print('x_test dimensions:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target vector `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target vector `y` contains the label/class of each image. In other words, it contains the digit represented by each image.\n",
    "\n",
    "In total, there are $10$ different classes, represented as numbers: $0, 1, ..., 9$. They are the $10$ different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the label of the first image in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some pre-processing operations must be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Normalization of the input data `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in `x` (both `x_train` and `x_test`) are in the range $[0,255]$. We want to normalize these values into the range $[0,1]$. Remapping the values into the range $[0,1]$.\n",
    "\n",
    "Why do we do that? Because the computations becomes faster, easier, and it improves the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing this transformation, we simply use the **MinMaxScaling technique**. Basically, we take each value `x_{ij}` of `x`, we subtract the min of `x` and we divide by the difference between the max value of `x` and the min value of `x`. In this way we get the new value $x'_{ij}$.\n",
    "\n",
    "$x'_{ij} = \\frac{x_{ij} - x_{min}}{x_{max}-x_{min}}$\n",
    "\n",
    "Doing this transformation, all the values in `x` are now in the range $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this transformation both in the training set `x_train` and in the test set `x_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.min()) / ( x_train.max() - x_train.min())\n",
    "\n",
    "x_test = (x_test - x_test.min()) / ( x_test.max() - x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of the values in x_train: [0.0,1.0]\n",
      "Range of the values in x_test: [0.0,1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Range of the values in x_train: [{},{}]'.format(x_train.min(),x_train.max()))\n",
    "print('Range of the values in x_test: [{},{}]'.format(x_test.min(),x_test.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.**\n",
    "\n",
    "Since the min value of both `x_train` and `x_test` is $0$ (and the maximum is $255$), the MinMaxScaling operation could have been simply achieved in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Flattening of the input data `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instances in the input data `x` are bidimensional structures: they are images. They are $28*28$ matrices.\n",
    "\n",
    "Since we are using dense layers, we need to flat the images into one-dimensional vectors with $28*28=784$ elements. (Dense layers work with a flat input)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do that in two ways.\n",
    "1. We modify the input data `x` (both training and test) in such a way that each instance now is the flat representation of an image. Each instance now is a vector with $28*28=784$ values. So, we modify our input data `x`.\n",
    "2. We don't modify our input data `x`, but we keep it as it is: the instances are images. However, we add in the beginning of the NN a special layer whose purpose is to flat the image received in input (FlatLayer). Layer which takes a $28*28$ image and flats it into a vector with length $784$.\n",
    "\n",
    "In this notebook we use the first way. In the next notebooks we will use the second way. *The second is in general better, because we don't need to pre-process our input data `x`: our input data `x` is kept as it is*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reshaping the input data `x` we use the NumPy `reshape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a8uA2Kp7mG9s"
   },
   "outputs": [],
   "source": [
    "# Flattening each image in the training set\n",
    "x_train = np.reshape(x_train, (60000,28*28)) \n",
    "\n",
    "# Flattening each image in the test set\n",
    "x_test = np.reshape(x_test, (10000,28*28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Transforming `y` into the categorical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjrzmhgh3TZv"
   },
   "source": [
    "The output of the network will be a probability distribution over the different labels. Basically, given an image, the output of the Neural Network is a vector $[p_0, p_1, ..., p_9]$, where $p_i$ is the probability that this image has label $i$. In other words, it is the probability that this image represents the digit $i$. The sum of all these probabilities is $1$. This vector is called **(predicted) categorical distribution** of that image. To sum up, the output of the NN, given an image, is the predicted categorical distribution of that image.\n",
    "\n",
    "\n",
    "For this reason, we have to change the dataset. We transform the target vector $y$ (both training and test). Each element now is not a single label, but it is a vector $[p_0, p_1, ..., p_9]$. If an image represents the digit $i$, then its corresponding vector in $y$ is $[0, 0, ..., 1, ..., 0]$: the only element different from $0$ is the element with index $i$. This vector is the true categorical distribution of that image: it has probaility $1$ for the label $i$, and $0$ for all the others.\n",
    "\n",
    "The training objective will consist in minimizing the distance between the true categorical distributions and the predicted ones. The distance between two categorical distribution is the **categorical crossentropy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing this transformation, we use the Keras utility function `to_categorical`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhzWUm0UnODb",
    "outputId": "e0cf94cf-aabf-4d35-f84e-b481d72c10ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image in the training set, value contained in 'y': 5\n",
      "First image in the training set, value contained in 'y': [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Tranforming the vector y, both training and test.\n",
    "\n",
    "print('First image in the training set, value contained in \\'y\\':', y_train[0])\n",
    "\n",
    "# Transforming y_train into y_train_cat\n",
    "y_train_cat = keras.utils.to_categorical(y_train)\n",
    "print('First image in the training set, value contained in \\'y\\':', y_train_cat[0])\n",
    "\n",
    "# Transforming y_test into y_test_cat\n",
    "y_test_cat = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ya_bpK_ubIq"
   },
   "source": [
    "Let's build the first NN. For now, we use a dense NN. Dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two kinds of keras layers: `Input`, for defining the input layer of the NN; `Dense`, for defining the dense layers of the NN.\n",
    "\n",
    "We also have to import `Model`, which is the keras class used for defining the NN. Basically, our NN will be an instance of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WZF2FlLI3lGT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense  # Import Layers from Keras\n",
    "from tensorflow.keras.models import Model  # Class for defining the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model by concatenating the layers that we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfeZF3bUrFZf"
   },
   "source": [
    "Our first Netwok just has the input layer and the output layer. The output layer is a dense layer.\n",
    "\n",
    "The input layer has $28*28=784$ nodes, representing the pixels of the given image (flat image, no bidimensional structure).\n",
    "\n",
    "The output layer has $10$ nodes, corresponding to the $10$ outputs of the neural network. Basicaly, each output is a real number in $[0,1]$, representing the probability that the given image has that label (categorical distribution).\n",
    "\n",
    "The activation function of the output layer is the softmax. The softmax activation function is important in the output layer, because it ensures us that: each output of the NN is between $0$ and $1$ (i.e. it is a probability); the sum of all the outputs of the NN is $1$. Basically, softmax ensures us that the output of the NN is a probability distribution, over the different classes (i.e. categorical distribution). The softmax is a generalization of the sigmoid, since the sigmoid is applied when the NN has a single output and it simply ensures that this output is between $0$ and $1$. Softmax: is used when the NN has a single output; sigmoid: is used when the NN has more outputs. (This at least for classification problems).\n",
    "\n",
    "So, both the number of neurons and the activation function of the output dense layer are mandatory. The user does not have much to choose.\n",
    "\n",
    "*Since there is only one output layer, which is a dense layer with softmax activation function, this basic neural network basically implements logistic regression.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hBJtMj2pqJiR"
   },
   "outputs": [],
   "source": [
    "# Input layer. Each input instance x_i is a flat image: vector with 28*28=784 values.\n",
    "xin = Input(shape=(784))  \n",
    "\n",
    "# Output layer. It is a dense layer, with 10 neurons. The activation function is 'softmax'.\n",
    "res = Dense(units=10, activation='softmax')(xin)  \n",
    "\n",
    "# We define out model: instance of the class Model\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the summary of the NN.\n",
    "\n",
    "The summary shows the layers of the network. For each layer, it shows the kind of the layer, the shape of the output (i.e. number of nodes) and the number of parameters (i.e. number of weigths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXD5JT2ZrTJc",
    "outputId": "36886e01-b9bb-4729-a1ad-257e43f09726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input layer. Dimensions: ($784$). The number of parameters is $0$.\n",
    "\n",
    "2. Output layer. It is a dense layer. Dimensions of the output: ($10$) (i.e. $10$ neurons).. The number of parameters of the output layer is $7850$. This because each neuron is fully connected to all the $784$ nodes of the previous layer: so, each neuron has $784$ inputs. In addition, each node of the output layer has also the bias. So, each neuron of the output layer has $785$ parameters. Since there are $10$ neurons in the output layer, on the whole there are $10*785=7850$ parameters.\n",
    "\n",
    "On the whole, there are $7850$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "Let's see some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Python object returned by the application of a layer.**\n",
    "\n",
    "The object returned by the application of a layer represents not the layer, but the output of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = Dense(...)(x_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_out` represents the output of the application of the defined Dense layer on the input `x_in`. So, both `x_in` and\n",
    "`x_out` are vectors (in general tensors).\n",
    "\n",
    "So, `x_out` does not represent the Dense layer. The object representing the Dense layer is `Dense(...)(x_in)`. Indeed, the name of the layer (i.e. `Dense`) is a class constructor.\n",
    "\n",
    "Typically, we keep only one variable `x`, and we overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(...)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Batch dimension**\n",
    "\n",
    "The NNs in keras work with an additional dimensions: the batch dimension.\n",
    "\n",
    "Even if our data don't have this dimension (as it is typical), the NNs implicitely add this dimension to the data we give to them. This dimension is added as first dimension: `(B, ...)`, where `B` is the batch dimension.\n",
    "\n",
    "The batch dimension represents the number of instances. Number of instances we are processing. Number of instances in a batch. It is the batch size.\n",
    "\n",
    "When we ask for the summary of our NN, for each layer we see the simensions of the output of that layer: the first shown dimension is the batch dimension: `(B, ...)`.\n",
    "\n",
    "Typically, when defining our NN, we don't define the batch dimension. We leave it unspecified as `None`. This means that the NN can work with any batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXD5JT2ZrTJc",
    "outputId": "36886e01-b9bb-4729-a1ad-257e43f09726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Leaving unspecified a dimension**\n",
    "\n",
    "When defining a NN, we can leave unspecified any dimension: we simply put that dimensions as `None`. Undefined dimension.\n",
    "\n",
    "This means that the NN is able to work woth any possible value of that dimension. It can accept any possible value of that dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Specify the dimensions**\n",
    "\n",
    "The dimensions of the data in our NN are basically specified only in the Input layer. Then, in all the other layers, the dimensions are inferred from the input on which the layer has been applied.\n",
    "\n",
    "So, the Input layer is the place where the dimensions are specified. If we want, we can leave some dimensions unspecified (i.e. `None`): these dimensions will be unspecified in all the other layers (for a \"cascade\" effect)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Activation function**\n",
    "\n",
    "The activation function can be specified also outside the layer. So, we don't specify any activation function in the layer (no activation function), and we use an additional layer which simply applies the activation function.\n",
    "\n",
    "Example: layer `Softmax`, which simply applies the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(...)(x)  # No activation function\n",
    "x = Softmax()(x)  # Softmax activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the NN, we need to compile it. Compiling a NN means defining the loss function and the optimizer. `compile` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function**\n",
    "\n",
    "The **loss function** is the function that we want to minimize with the training procedure. Basically, it is the function which computes the distance between true value and the corresponding predicted value, for each input instance. \n",
    "\n",
    "In our case, the true value is the actual categorical distribution, while the predicted value is the predicted categorical distribution.\n",
    "\n",
    "For this reason, as loss function, with use the **sparse categorical crossentropy**.\n",
    "\n",
    "*The loss function is an hyperparameter of the NN.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**\n",
    "\n",
    "The **optimizer** is the component which is in charge of governing the details of the training algorithm (i.e. backpropagation algorithm).\n",
    "\n",
    "The most used optimizer in the literature is **Adam**, which is a powerful variant to the classic Stochastic Gradient Descent. Adam implements an ADAptive learning rate with Momentum. \n",
    "\n",
    "Other optimizier can be choose, for example:\n",
    "* SGD -> Stochastic Gradient Descent\n",
    "* RMSprop\n",
    "* Adadelta\n",
    "* Adagrad\n",
    "\n",
    "For a deep explanation on optimizers, refer to https://arxiv.org/abs/1606.04838 .\n",
    "\n",
    "For an explanation of the different kind of optimizers, refer to the official documentation https://keras.io/api/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam  # We import the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying the Adam optimizer, we can specify the learning rate. The default value is $0.001$.\n",
    "\n",
    "*The optimizer and the learning rate are hyperparameters of the NN.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "\n",
    "Loss function and optimizer are the two mandatory arguments of the `compile` method.\n",
    "\n",
    "Optionally, we can specify additional metrics, mostly meant for monitoring the training process. Basically, these metrics are not used for the training process (only the loss function is used). But simply these are metrics that we want to keep track during the training process, simply for curiosity.\n",
    "\n",
    "*During training, these metrics are computed both on the training set and on the validation set, if one is specified.*\n",
    "\n",
    "Now we specify only one additional metric: the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKrXXctDyHzV",
    "outputId": "c1c08b5a-3a57-48cc-a4b4-071c04a281ba"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative way of specifying the optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT EXECUTED\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E58bT-Imvsw2"
   },
   "source": [
    "Finally, we fit the model over the training set. `fit` method.\n",
    "\n",
    "`fit` just requires two arguments: training input data, i.e. `x_train`; and target vector of the training data, i.e. `y_train` (the ground truth of the training data).\n",
    "\n",
    "N.B.: we have to remember to pass `y_train_cat` instead of `y_train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can specify:\n",
    "- the batch size, which is the number of instances in each mini-batch (default is $32$);\n",
    "- the number of epochs, which is the number of full passes over all the training set;\n",
    "- the validation set. \n",
    "\n",
    "*The batch size and the number of epochs are hyperparameters of the NN.*\n",
    "\n",
    "Passing a validation set allows the training procedure to measure loss, and optional additional metrics, both on the training set and on the validation set, at the end of each epoch.\n",
    "\n",
    "In our case, we pass our test set `x_test,y_test` as validation set. N.B.: we have to remember to pass `y_test_cat` instead of `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2woDXbbr6ak",
    "outputId": "493cdebc-26fc-454f-d664-f1f1a60c1043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.5214 - accuracy: 0.7423 - val_loss: 1.0206 - val_accuracy: 0.8359\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8422 - accuracy: 0.8417 - val_loss: 0.6809 - val_accuracy: 0.8647\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6228 - accuracy: 0.8655 - val_loss: 0.5403 - val_accuracy: 0.8804\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5204 - accuracy: 0.8779 - val_loss: 0.4682 - val_accuracy: 0.8913\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4630 - accuracy: 0.8854 - val_loss: 0.4245 - val_accuracy: 0.8959\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4272 - accuracy: 0.8907 - val_loss: 0.3966 - val_accuracy: 0.9006\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4024 - accuracy: 0.8948 - val_loss: 0.3765 - val_accuracy: 0.9043\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3844 - accuracy: 0.8980 - val_loss: 0.3631 - val_accuracy: 0.9047\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3707 - accuracy: 0.8996 - val_loss: 0.3497 - val_accuracy: 0.9075\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3597 - accuracy: 0.9022 - val_loss: 0.3417 - val_accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8104cad00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$10$ epochs. Since the batch_size is $32$, each epoch has $60000/32 = 1875$ steps. ($60000$ is the number of samples in the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of each epoch, several information are shown:\n",
    "- the time; \n",
    "- `loss`, which is the loss on the training data;\n",
    "- `accuracy`, which is the accuracy on the training data;\n",
    "- `val_loss`, which is the loss on the validation data (i.e. test data in this case);\n",
    "- `val_accuracy`, which is the accuracy on the validation data (i.e. test data in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results.\n",
    "- Loss on the training set is $0.2511$, while the accuracy is $0.9308$.\n",
    "- Loss on the test set is $0.2686$, while the accuracy is $0.9251$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight about the `fit` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method is incremental. This means that we can apply multiple times the `fit` method on the same model.\n",
    "\n",
    "Another application of the `fit` method on the same model simply updates the weigths, starting from the weigths which we got from the first `fit`. Incremental update of the weigths.\n",
    "\n",
    "This can be very useful. Also because to the second application of `fit` we can specify different arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOTHER NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to use a more complex network.\n",
    "\n",
    "We use an additional hidden layer in between the input and output layers. As hidden layer, we use a dense layer with $128$ nodes. As activation function we use relu.\n",
    "\n",
    "*In the hidden layer it is not mandatory to use the softmax activation function, since we don't need to have a probability distribution as output.*\n",
    "\n",
    "The number of nodes and the activation function of the hidden layer are an hyperparameter of the network. As the number of hidden layers, and many other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "k0mBuorMulG5"
   },
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(units=128, activation='relu')(xin)  # Hidden layer\n",
    "res = Dense(units=10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SpMyvw7buzhT",
    "outputId": "bb66d7c4-39fa-4a9b-891d-ea7f1662bd41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the summary we can see that we have three layers.\n",
    "1. Input layer. $784$ nodes. No parameters.\n",
    "2. Hidden layer. It is a dense layer. $128$ nodes. $785*128=100480$ parameters. (Each node has 784 inputs and 1 bias, and we have $128$ neurons).\n",
    "3. Output layer. It is a dense layer. $10$ nodes. $129*10$ parameters. (Each node has $128$ inputs and $1$ bias, and we have $10$ neurons).\n",
    "\n",
    "On the whole, $101770$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPILE THE NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rYg0odW2u6cn"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN THE NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDnzgIZVvGOm",
    "outputId": "cb25ba03-19bb-4197-de31-790e50c39cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.1658 - accuracy: 0.7240 - val_loss: 0.5823 - val_accuracy: 0.8579\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4816 - accuracy: 0.8750 - val_loss: 0.3988 - val_accuracy: 0.8952\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3800 - accuracy: 0.8959 - val_loss: 0.3416 - val_accuracy: 0.9051\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3405 - accuracy: 0.9043 - val_loss: 0.3151 - val_accuracy: 0.9102\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3182 - accuracy: 0.9098 - val_loss: 0.3036 - val_accuracy: 0.9151\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3033 - accuracy: 0.9135 - val_loss: 0.2874 - val_accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2915 - accuracy: 0.9163 - val_loss: 0.2788 - val_accuracy: 0.9197\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2814 - accuracy: 0.9193 - val_loss: 0.2715 - val_accuracy: 0.9231\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2723 - accuracy: 0.9222 - val_loss: 0.2669 - val_accuracy: 0.9240\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2639 - accuracy: 0.9243 - val_loss: 0.2561 - val_accuracy: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c811a6ab50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcUKxCzKwzG9"
   },
   "source": [
    "An amazing improvement. WOW!\n",
    "\n",
    "Indeed, now:\n",
    "- the loss on the training set is $0.0152$ (before was $0.2511$) and the accuracy is $0.9953$ (before was $0.9308$);\n",
    "- the loss on the test set is $0.0828$ (before was $0.2686$) and the accuracy is $0.9764$ (before was $0.9251$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLYING THE NN AND EVALUATING IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained a NN, we can apply it to other instances, for predicting their class. This application is performed using the `predict` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application on a single instance**\n",
    "\n",
    "Let's see the application on a signle instance. As example, we take the first instance of the test set (we could have taken also the first instance of the training set, but the test set is of course mor interesting).\n",
    "\n",
    "So, we give in input to the NN the first instance in `x_test`. And the NN returns us the predicted categorical distribution for that instance (i.e. the probabilities of that instance of belonging to the different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c812ae5af0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "instance = x_test[0]\n",
    "\n",
    "plt.imshow(np.reshape(instance, (28,28)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The true class of that image is clearly $7$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8983837e-05, 7.4795485e-09, 1.1581890e-04, 3.9711050e-03,\n",
       "        5.2573228e-07, 7.0129638e-05, 3.9099519e-09, 9.9496245e-01,\n",
       "        1.1723895e-05, 7.6934497e-04]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_cat_distr = model.predict(np.expand_dims(instance, 0))\n",
    "predicted_cat_distr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the predicted class is the one corresponding to the highest probability in the categorical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = np.argmax(predicted_cat_distr)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct!!! The predicted class is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application on more instances at the same time  TODO**\n",
    "\n",
    "The NN can also be applied to more instances at the same time.\n",
    "\n",
    "Let's take the first $20$ instances of the valdiation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = x_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_cat_distr = model.predict(np.expand_dims(instances, 0))\n",
    "# predicted_cat_distr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained a NN, we can evaluate it to other instances, for getting an evaluation score. This is perfomed using the `evaluate` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate` method takes in input a dataset `x',y'`: it is typically different from the training set and from the validation set (it is typically the test set). And it computes the value of the loss function and of the optional additional metrics (e.g. accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's apply it this method on the test set. (Even if we have already used this set as validation set). \n",
    "\n",
    "*We have always to remember to use `y_test_cat`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2561188340187073, 0.9271000027656555]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTORY OF THE TRAINING AND PLOTTING THE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method returns and object which contains the history of the training process. It contains the loss function and the additional optional metrics computed both on the training and on the validation set. They are computed with respect to each epoch (i.e. at the end of each epch).\n",
    "\n",
    "In our case, the history of the training contains:\n",
    "- `loss` (loss computed on the training set)\n",
    "- `accuracy` (accuracy computed on the training set)\n",
    "- `val_loss` (loss computed on the validation set)\n",
    "- `val_accuracy` (accuracy computed on the validation set)\n",
    "\n",
    "with respect to the each epoch (i.e. they are computed at the end of each epoch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(units=128, activation='relu')(xin)  # Hidden layer\n",
    "res = Dense(units=10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.1662 - accuracy: 0.7107 - val_loss: 0.5902 - val_accuracy: 0.8518\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4862 - accuracy: 0.8741 - val_loss: 0.4033 - val_accuracy: 0.8938\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3820 - accuracy: 0.8954 - val_loss: 0.3450 - val_accuracy: 0.9038\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3411 - accuracy: 0.9043 - val_loss: 0.3164 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3174 - accuracy: 0.9095 - val_loss: 0.2971 - val_accuracy: 0.9145\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2999 - accuracy: 0.9139 - val_loss: 0.2843 - val_accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2860 - accuracy: 0.9176 - val_loss: 0.2730 - val_accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2743 - accuracy: 0.9210 - val_loss: 0.2626 - val_accuracy: 0.9241\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2634 - accuracy: 0.9238 - val_loss: 0.2552 - val_accuracy: 0.9260\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2531 - accuracy: 0.9263 - val_loss: 0.2448 - val_accuracy: 0.9302\n"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), \n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the fit method is an object of class `History`. It represents the history of the results obtained during training. These results are contained in the `history` attribute, which is a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.2586393654346466,\n",
       "  0.11360926926136017,\n",
       "  0.0769348219037056,\n",
       "  0.05652725696563721,\n",
       "  0.04306340217590332,\n",
       "  0.03412600979208946,\n",
       "  0.02629777044057846,\n",
       "  0.021958477795124054,\n",
       "  0.017009329050779343,\n",
       "  0.015356196090579033],\n",
       " 'accuracy': [0.9260166883468628,\n",
       "  0.9664833545684814,\n",
       "  0.9771000146865845,\n",
       "  0.9825999736785889,\n",
       "  0.9868000149726868,\n",
       "  0.9895166754722595,\n",
       "  0.9917500019073486,\n",
       "  0.9930833578109741,\n",
       "  0.994616687297821,\n",
       "  0.9950666427612305],\n",
       " 'val_loss': [0.1389441341161728,\n",
       "  0.09745443612337112,\n",
       "  0.08447018265724182,\n",
       "  0.07686164230108261,\n",
       "  0.0808294340968132,\n",
       "  0.07276461273431778,\n",
       "  0.07401105761528015,\n",
       "  0.0862865000963211,\n",
       "  0.08917666971683502,\n",
       "  0.07627350091934204],\n",
       " 'val_accuracy': [0.9591000080108643,\n",
       "  0.9713000059127808,\n",
       "  0.9732999801635742,\n",
       "  0.9764000177383423,\n",
       "  0.9764000177383423,\n",
       "  0.9785000085830688,\n",
       "  0.9785000085830688,\n",
       "  0.9746999740600586,\n",
       "  0.9753000140190125,\n",
       "  0.9803000092506409]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of `loss`, `accuracy`, `val_loss`, `val_accuracy` with respect to the each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results contained into the history object can be easily plotted.\n",
    "\n",
    "We make one plot for the loss function, comparing `loss` and `val_loss` with respect to the number of epochs.\n",
    "\n",
    "We make also one plot for the accuracy, comparing `accuracy` and `val_accuracy` with respect to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_epochs = 10\n",
    "epochs = range(1,n_epochs+1)\n",
    "\n",
    "plt.plot(epochs, training_history.history['loss'], label='train_loss')\n",
    "plt.plot(epochs, training_history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, training_history.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(epochs, training_history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function for doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(training_history, n_epochs):\n",
    "    epochs = range(1,n_epochs+1)\n",
    "\n",
    "    plt.plot(epochs, training_history.history['loss'], label='train_loss')\n",
    "    plt.plot(epochs, training_history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, training_history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(epochs, training_history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(training_history, n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyisis of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made the plots of loss and accuracy with respect of the number of epochs. The number of epochs is very important, because it is a property which impacts to the complexity of the model. Basically, the bigger if the number of epochs, the bigger is the complexity of the model.\n",
    "\n",
    "This means that the plots of loss/accuracy (both for training and validation) with respect to the number of epochs, are very important for visualizing the situation of the model with respect to overfitting/underfitting. They are very usefult for visualizing if we are in a situation of underfitting/overfitting.\n",
    "\n",
    "Escpecially overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our specific example, we can see that the validation score (either loss or accuracy) is worse in the rigth tail (biggest number of epochs, i.e. biggest complexity) with respect to using a smaller number of epochs. Basically, the goodness of the validation score is worse in the right tail. In addition, the validation score is also very oscillating. \n",
    "\n",
    "This means that there is a little bit of **overfitting**!!! The model is too complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In defining the NN, there a lot of hyperparameters that the user can play with. Let's recap some of them.\n",
    "- Number of hidden dense layers.\n",
    "- Number of neurons and activation function in each hidden dense layer.\n",
    "- Loss function\n",
    "- Optimizer and learning rate\n",
    "- Batch size and number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that the user play with these hyperparameters, trying to find the best combination, using a test-and-error approach. *This can important also for reducing overfitting.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we try to play with some of these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of hidden dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add three additional hidden dense layers. Four hidden dense layers in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(128, activation='relu')(xin)  # First hidden layer. 128 nodes. Relu activation function.\n",
    "x = Dense(128, activation='relu')(x)  # Second hidden layer. 128 nodes.  Relu activation function.\n",
    "x = Dense(128, activation='relu')(x)  # Third hidden layer. 128 nodes.  Relu activation function.\n",
    "x = Dense(128, activation='relu')(x)  # Fourth hidden layer. 128 nodes.  Relu activation function.\n",
    "res = Dense(10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,306\n",
      "Trainable params: 151,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the summary we can see that we have three layers.\n",
    "1. Input layer. $784$ nodes. No parameters.\n",
    "2. First Hidden layer. It is a dense layer. $128$ nodes. $785*128=100480$ parameters. (Each node has 784 inputs and 1 bias, and we have $128$ neurons).\n",
    "3. Second Hidden layer. It is a dense layer. $128$ nodes. $129*128=16512$ parameters. (Each node has 128 inputs and 1 bias, and we have $128$ neurons).\n",
    "4. Third Hidden layer. It is a dense layer. $128$ nodes. $129*128=16512$ parameters. (Each node has 128 inputs and 1 bias, and we have $128$ neurons).\n",
    "5. Fourth Hidden layer. It is a dense layer. $128$ nodes. $129*128=16512$ parameters. (Each node has 128 inputs and 1 bias, and we have $128$ neurons).\n",
    "3. Output layer. It is a dense layer. $10$ nodes. $129*10$ parameters. (Each node has $128$ inputs and $1$ bias, and we have $10$ neurons).\n",
    "\n",
    "On the whole, $151306$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same compiling and fitting as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.2406 - accuracy: 0.9261 - val_loss: 0.1253 - val_accuracy: 0.9639\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1070 - accuracy: 0.9670 - val_loss: 0.0994 - val_accuracy: 0.9704\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0792 - accuracy: 0.9759 - val_loss: 0.1107 - val_accuracy: 0.9681\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0646 - accuracy: 0.9801 - val_loss: 0.0865 - val_accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 0.0953 - val_accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0952 - val_accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0800 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0818 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.0873 - val_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0829 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c140d5f6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss in the training set: $0.0289$. Worse than before.\n",
    "\n",
    "Loss in the test set: $0.0829$. Worse than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions of the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the NN with only one hidden dense layer. We replace the `relu` activation function with another activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(128, activation='softmax')(xin)  # Hidden layer. SOFTMAX activation function.\n",
    "res = Dense(10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2203 - accuracy: 0.8098 - val_loss: 0.6601 - val_accuracy: 0.8496\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5186 - accuracy: 0.8627 - val_loss: 0.4351 - val_accuracy: 0.8637\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3938 - accuracy: 0.8819 - val_loss: 0.3777 - val_accuracy: 0.8925\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3392 - accuracy: 0.9096 - val_loss: 0.3325 - val_accuracy: 0.9092\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2980 - accuracy: 0.9237 - val_loss: 0.3090 - val_accuracy: 0.9194\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2732 - accuracy: 0.9296 - val_loss: 0.2901 - val_accuracy: 0.9254\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2559 - accuracy: 0.9340 - val_loss: 0.2849 - val_accuracy: 0.9245\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2426 - accuracy: 0.9366 - val_loss: 0.2720 - val_accuracy: 0.9280\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2301 - accuracy: 0.9389 - val_loss: 0.2623 - val_accuracy: 0.9323\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2198 - accuracy: 0.9416 - val_loss: 0.2543 - val_accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c14335cdc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much worse than using 'relu'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**selu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(128, activation='selu')(xin)  # Hidden layer. SELU activation function.\n",
    "res = Dense(10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3108 - accuracy: 0.9097 - val_loss: 0.1938 - val_accuracy: 0.9421\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1652 - accuracy: 0.9518 - val_loss: 0.1447 - val_accuracy: 0.9556\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1121 - accuracy: 0.9663 - val_loss: 0.1074 - val_accuracy: 0.9671\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0832 - accuracy: 0.9749 - val_loss: 0.1004 - val_accuracy: 0.9710\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.0915 - val_accuracy: 0.9729\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.0818 - val_accuracy: 0.9742\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0840 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.0894 - val_accuracy: 0.9748\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0851 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0837 - val_accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1436b8040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit worse than using 'relu'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**elu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(128, activation='elu')(xin)  # Hidden layer. ELU activation function.\n",
    "res = Dense(10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3003 - accuracy: 0.9132 - val_loss: 0.1703 - val_accuracy: 0.9526\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1422 - accuracy: 0.9582 - val_loss: 0.1159 - val_accuracy: 0.9649\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9717 - val_loss: 0.1039 - val_accuracy: 0.9702\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 0.0785 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0533 - accuracy: 0.9834 - val_loss: 0.0818 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.0792 - val_accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0781 - val_accuracy: 0.9765\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0730 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0797 - val_accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.0810 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c14348ca90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_data=(x_test,y_test_cat), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss on the training set is worse than using 'relu', while the loss on the test set is better.\n",
    "\n",
    "The accuracies are better using 'relu'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARSE CATEGORICAL CROSSENTROPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse categorical crossentropy is another loss function, which is an alternative to the classic categorical crossentropy.\n",
    "\n",
    "They are applied in the same situation, which is the situation in which the output of the NN is a probability distribution over the different classes (i.e. categorical distribution over the different classes).\n",
    "\n",
    "They also give very similar results in terms of goodness of the results and of the training.\n",
    "\n",
    "The (main) only difference is that sparse categorical crossentropy saves the user from pre-processing the target vector `y`. Indeed, we know that with the classic categorical crossentropy, the user has to pre-process the target vector `y`, in such a way that it does not contain anymore simple labels, but it contains the true categorical distributions of the inctances. In sparse categorical crossentropy this is not needed anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More in depth explanation**\n",
    "\n",
    "Let $k$ be the number of different classes.\n",
    "\n",
    "Since now, we have seen the categorial_crossentropy. The output of the NN, given an instance, is a vector of probabilities $[p_1, ..., p_k]$ (i.e. categorical distribution), where $p_i$ is the probability that the instance has the class $i$. According to that, also the target vector must $y$ must be transformed. Each element is not a single integer representing the class, but it is a vector representing the categorical distribution: vector $[0, ..., 1, ..., 0]$, where the single element which is equal to $1$ is the element with index the class of that instance.\n",
    "\n",
    "With the sparse_categorical_crossentropy the output of the NN is still a vector with $k$ elements. So the output layer has still $k$ neurons. The difference is that we leave the target vector $y$ as it is: we don't need to transform it. Basically, each element of $y$ is a single integer, which is the class of the corresponding instance. In the target vector $y$ we don't use the categorical distribution, but the actual labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sparse categorical crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the NN with a single NN and `relu` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = Input(shape=(784))  # Input layer\n",
    "x = Dense(128, activation='relu')(xin)  # Hidden layer\n",
    "res = Dense(10, activation='softmax')(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify `sparse_categorical_crossentropy` as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We use `y_train` and `y_test` as they are. No categorical distributions, no `y_train_cat` and `y_test_cat`. But actual integer labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2589 - accuracy: 0.9271 - val_loss: 0.1265 - val_accuracy: 0.9634\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1127 - accuracy: 0.9663 - val_loss: 0.1019 - val_accuracy: 0.9686\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0896 - val_accuracy: 0.9714\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0974 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0447 - accuracy: 0.9860 - val_loss: 0.0834 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.0777 - val_accuracy: 0.9755\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0789 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0771 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0836 - val_accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0820 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c150f9e940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test,y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Slightly) better results than using categorical_crossentropy.\n",
    "\n",
    "But the major advantage is that we didn't pre-process the target vector `y`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an important insight, which involves the specific keras implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SparseCategoricalCrossentropy` has an optional parameter, called `from_logits`. By default, it is `False`.\n",
    "\n",
    "In theory, the two following approaches are equivalent.\n",
    "1. Using an output layer with the softmax activation function and compiling the NN using the `SparseCategoricalCrossentropy` with `from_logits=False`.\n",
    "2. Using an output layer without the softmax activation function (no activation function) and compiling the NN using the `SparseCategoricalCrossentropy` with `from_logits=True`.\n",
    "\n",
    "The first approach seems the better one, because it makes more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is recommended to use the second approach. Because, in keras, the second approach brings more numerical stability in the computation of the gradients. [Here](https://stackoverflow.com/questions/61233425/what-should-i-use-as-target-vector-when-i-use-binarycrossentropyfrom-logits-tru/61237426#61237426) you can find some reasons why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it woulde have been better to proceed in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "xin = Input(shape=(784))  \n",
    "x = Dense(128, activation='relu')(xin)  \n",
    "res = Dense(10)(x)  # NO ACTIVATION FUNCTION  \n",
    "\n",
    "model = Model(inputs=xin, outputs=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "mnistDense.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
